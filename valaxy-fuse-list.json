[{"title":"缓存+分布式锁在Java项目中的应用","tags":["Redis","Spring Cache","Spring Session","Redisson"],"categories":["Java","微系统与第三方框架"],"author":"imklaus","excerpt":"\r\n\r\n参考视频：[雷神谷粒商城项目](https://www.bilibili.com/video/BV1np4y1C7Yf/)\r\n\r\n","link":"/posts/Cache_Project","content":"\r\n\r\n参考视频：[雷神谷粒商城项目](https://www.bilibili.com/video/BV1np4y1C7Yf/)\r\n\r\n<!-- more -->\r\n\r\n\r\n## Ⅰ.仿京东购物车系统\r\n\r\n- 购物车Redis数据结构选型：\r\n  - 双层 Map：`Map<String,Map<String,String>>`\r\n    - 第一层 Map，Key 是用户 id\r\n    - 第二层 Map，Key 是购物车中商品 id，值是购物项数据\r\n- 购物车两个核心功能：新增商品到购物车、查询购物车\r\n  - 新增商品：判断是否登录\r\n    - 是：则添加商品到后台 Redis 中，把 user 的唯一标识符作为 key。\r\n    - 否：则添加商品到后台 Redis 中，使用随机生成的 user-key 作为 key。\r\n- 查询购物车列表：判断是否登录\r\n  - 否：直接根据 user-key 查询 Redis 中数据并展示\r\n  - 是：已登录，则需要先根据 user-key 查询 Redis 是否有数据。\r\n  - 有：需要提交到后台添加到 Redis ，合并数据，而后查询。\r\n  - 否：直接去后台查询 Redis ，而后返回\r\n\r\n### 1、购物车需求\r\n\r\n#### 1）、需求描述：\r\n\r\n- 用户可以在登录状态下将商品添加到购物车【用户购物车/在线购物车】\r\n  - 放入数据库\r\n  - mongodb\r\n  - 放入 redis（采用）\r\n    - 登录以后，会将临时购物车的数据全部合并过来，并清空临时购物车；\r\n- 用户可以在未登录状态下将商品添加到购物车【游客购物车/离线购物车/临时购物车】\r\n  - 放入 localstorage（客户端存储，后台不存）\r\n  - cookie\r\n  - WebSQL\r\n  - 放入 redis（采用）\r\n    - 浏览器即使关闭，下次进入，临时购物车数据都在\r\n- 用户可以使用购物车一起结算下单\r\n- 给购物车添加商品\r\n- 用户可以查询自己的购物车\r\n- 用户可以在购物车中修改购买商品的数量。\r\n- 用户可以在购物车中删除商品。\r\n- 选中不选中商品\r\n- 在购物车中展示商品优惠信息\r\n- 提示购物车商品价格变化\r\n\r\n#### 2）、数据结构\r\n\r\n![image-20230410200320343](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410200320343.png)\r\n\r\n> - `Map<String k1,Map<String k2,CartItemInfo>>` \t|\t\t在redis中\r\n> - k1：标识每一个用户的购物车\t\t\t\t\t\t\t\t\t|\t\tkey:用户标识\r\n> - k2：购物项的商品id  \t\t\t\t\t\t\t\t\t\t\t\t   |\t    value:Hash（k：商品id，v：购物项详情）\r\n\r\n![image-20230424202014610](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230424202014610.png)\r\n\r\n因此每一个购物项信息，都是一个对象，基本字段包括：\r\n\r\n```json\r\n{\r\n\tskuId: 2131241,\r\n\tcheck: true,\r\n\ttitle: \"Apple iphone.....\",\r\n\tdefaultImage: \"...\",\r\n\tprice: 4999,\r\n\tcount: 1,\r\n\ttotalPrice: 4999,\r\n\tskuSaleVO: {...}\r\n}\r\n```\r\n\r\n另外，购物车中不止一条数据，因此最终会是对象的数组。即：\r\n\r\n```json\r\n[\r\n\t{...},{...},{...}\r\n]\r\n```\r\n\r\n> Redis 有 5 种不同数据结构，这里选择哪一种比较合适呢？`Map<String, List<String>>`\r\n> - 首先不同用户应该有独立的购物车，因此购物车应该以用户的作为 key 来存储，Value 是\r\n> 用户的所有购物车信息。这样看来基本的`k-v`结构就可以了。\r\n> - 但是，我们对购物车中的商品进行增、删、改操作，基本都需要根据商品 id 进行判断，\r\n> 为了方便后期处理，我们的购物车也应该是`k-v`结构，key 是商品 id，value 才是这个商品的\r\n> 购物车信息。\r\n> 综上所述，我们的购物车结构是一个双层 Map：Map<String,Map<String,String>>\r\n> - 第一层 Map，Key 是用户 id\r\n> - 第二层 Map，Key 是购物车中商品 id，值是购物项数据\r\n>\r\n\r\n#### 3）、流程\r\n\r\n参照京东\r\n\r\n![image-20230425192047077](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230425192047077.png)\r\n\r\nuser-key 是随机生成的 id，不管有没有登录都会有这个 cookie 信息。\r\n\r\n两个功能：新增商品到购物车、查询购物车。\r\n\r\n-  新增商品：判断是否登录\r\n\r\n   - 是：则添加商品到后台 Redis 中，把 user 的唯一标识符作为 key。\r\n\r\n\r\n  - 否：则添加商品到后台 redis 中，使用随机生成的 user-key 作为 key。\r\n\r\n\r\n-  查询购物车列表：判断是否登录\r\n   - 否：直接根据 user-key 查询 redis 中数据并展示\r\n   - 是：已登录，则需要先根据 user-key 查询 redis 是否有数据。\r\n   - 有：需要提交到后台添加到 redis，合并数据，而后查询。\r\n   - 否：直接去后台查询 redis，而后返回。\r\n\r\n#### 4）、引入依赖\r\n\r\n```xml\r\n<!-- 引入redis -->\r\n<dependency>\r\n  <groupId>org.springframework.boot</groupId>\r\n  <artifactId>spring-boot-starter-data-redis</artifactId>\r\n</dependency>\r\n```\r\n\r\n### 2、添加购物车\r\n\r\n- 用户信息数据传输To\r\n  - tempUser = false表示默认是登录用户，即将用户唯一id作为缓存key\r\n  - tempUser = true表示是游客身份，系统将生成随机码user-key作为缓存key\r\n\r\n```java\r\n@ToString\r\n@Data\r\npublic class UserInfoTo {\r\n\r\n    private Long userId;\r\n    private String userKey;//一定封装\r\n\r\n    private boolean tempUser = false;\r\n}\r\n```\r\n\r\n- 购物车拦截器\r\n\r\n```java\r\n/**\r\n * 拦截器\r\n * 在执行目标方法之前，判断用户的登录状态，并封装传递给controller目标请求\r\n * @author Klaus\r\n * @date 2022/9/19\r\n */\r\npublic class CartInterceptor implements HandlerInterceptor {\r\n\r\n    public static ThreadLocal<UserInfoTo> threadLocal = new ThreadLocal<>();\r\n\r\n    /**\r\n     * 目标方法执行之前\r\n     * @param request\r\n     * @param response\r\n     * @param handler\r\n     * @return\r\n     * @throws Exception\r\n     */\r\n    @Override\r\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response,\r\n                             Object handler) throws Exception {\r\n        UserInfoTo userInfoTo = new UserInfoTo();\r\n        HttpSession session = request.getSession();\r\n        MemberRespVo member = (MemberRespVo) session.getAttribute(AuthServerConstant.LOGIN_USER);\r\n        if (member != null){\r\n            //用户登录\r\n            userInfoTo.setUserId(member.getId());\r\n        }\r\n        Cookie[] cookies = request.getCookies();\r\n        if (cookies != null && cookies.length >0){\r\n            for (Cookie cookie : cookies) {\r\n                //user-key\r\n                String name = cookie.getName();\r\n                if (name.equals(CartConstant.TEMP_USER_COOKIE_NAME)){\r\n                    //user-key:  afrwgrgrg3r\r\n                    userInfoTo.setUserKey(cookie.getValue());\r\n                    userInfoTo.setTempUser(true);\r\n                }\r\n            }\r\n        }\r\n\r\n        //如果没有临时用户一定分配一个临时用户\r\n        if (StringUtils.isEmpty(userInfoTo.getUserKey())){\r\n            String uuid = UUID.randomUUID().toString();\r\n            userInfoTo.setUserKey(uuid);\r\n        }\r\n        //目标方法执行之前\r\n        threadLocal.set(userInfoTo);\r\n        return true;\r\n    }\r\n\r\n    /**\r\n     * 业务执行之后，分配临时用户，让浏览器保存\r\n     * @param request\r\n     * @param response\r\n     * @param handler\r\n     * @param modelAndView\r\n     * @throws Exception\r\n     */\r\n    @Override\r\n    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {\r\n        UserInfoTo userInfoTo = threadLocal.get();\r\n        //如果没有临时用户一定保存一个临时用户，默认不是\r\n        if (!userInfoTo.isTempUser()){\r\n            //是临时用户\r\n            //将user-key放入cookie\r\n            Cookie cookie = new Cookie(CartConstant.TEMP_USER_COOKIE_NAME, userInfoTo.getUserKey());\r\n            //作用域\r\n            cookie.setDomain(\"gulimall.com\");\r\n            //持续延迟临时用户的过期时间\r\n            cookie.setMaxAge(CartConstant.TEMP_USER_COOKIE_TIMEOUT);\r\n            //响应头里加入cookie\r\n            response.addCookie(cookie);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n- DEBUG拦截器\r\n\r\n  - 首次访问首页（未登录状态），执行目标方法之前（添加商品到购物车），在页面没有异步请求没超时前完成以下步骤（超时直接404，操作失败）\r\n\r\n  ![image-20230425004106238](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230425004106238.png)\r\n\r\n  - 在规定时间（30s左右）内完成以上操作，将user-key存入Cookie成功，返回preHandle方法\r\n\r\n  ![image-20230425005929883](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230425005929883.png)\r\n\r\n- 添加购物车接口`org.klaus.zgg01mall.cart.controller.CartController#addToCart`\r\n\r\n```java\r\n/**\r\n     * 添加商品到购物车\r\n     *         redirectAttributes.addFlashAttribute():将数据放在session里面可以在页面取出，但是只能取一次\r\n     *         redirectAttributes.addAttribute(\"skuId\", skuId);将数据放在url后面\r\n     * @return\r\n     */\r\n    @GetMapping(\"/addToCart\")\r\n    public String addToCart(@RequestParam(\"skuId\") Long skuId,\r\n                            @RequestParam(\"num\") Integer num,\r\n                            RedirectAttributes redirectAttributes) throws ExecutionException, InterruptedException {\r\n\r\n        cartService.addToCart(skuId, num);\r\n//        model.addAttribute(\"skuId\", skuId); //Required Long parameter 'skuId' is not present\r\n        redirectAttributes.addAttribute(\"skuId\", skuId);\r\n        //添加商品到购物车，重定向到成功页面->刷新页面不会再增加购物车数量http://cart.gulimall.com/addToCart?skuId=35&num=1\r\n        return \"redirect:http://cart.gulimall.com/addToCartSuccess.html\";\r\n    }\r\n```\r\n\r\n- `org.klaus.zgg01mall.cart.vo.Cart`\r\n\r\n\r\n```java\r\n/**\r\n * 整个购物车的内容\r\n *  需要计算的属性，必须重写他的get方法，保证每次获取属性都会进行计算\r\n * @author Klaus\r\n * @date 2022/9/19\r\n */\r\npublic class Cart {\r\n\r\n    private List<CartItem> items;\r\n\r\n    private Integer countNum;//商品数量\r\n\r\n    private Integer countType;//商品类型数量\r\n\r\n    private BigDecimal totalAmount;//商品总价\r\n\r\n    private BigDecimal reduce = new BigDecimal(\"0.00\");//减免价格\r\n\r\n    public List<CartItem> getItems() {\r\n        return items;\r\n    }\r\n\r\n    public void setItems(List<CartItem> items) {\r\n        this.items = items;\r\n    }\r\n\r\n    /**\r\n     * 统计每一行*数量 再相加\r\n     * @return\r\n     */\r\n    public Integer getCountNum() {\r\n        int count = 0;\r\n        if (items != null && items.size() > 0) {\r\n            for (CartItem item : items) {\r\n                count += item.getCount();\r\n            }\r\n        }\r\n        return count;\r\n    }\r\n\r\n\r\n    /**\r\n     * 统计每一行相加\r\n     * @return\r\n     */\r\n    public Integer getCountType() {\r\n        int count = 0;\r\n        if (items != null && items.size() > 0) {\r\n            for (CartItem item : items) {\r\n                count += 1;\r\n            }\r\n        }\r\n        return count;\r\n    }\r\n\r\n\r\n\r\n    public BigDecimal getTotalAmount() {\r\n        BigDecimal amount = new BigDecimal(\"0\");\r\n        //1、计算购物项总价\r\n        if (items != null && items.size() > 0) {\r\n            for (CartItem item : items) {\r\n                if (item.getCheck()){\r\n                    //购物项被选中才进行计算\r\n                    BigDecimal totalPrice = item.getTotalPrice();\r\n                    amount = amount.add(totalPrice);\r\n                }\r\n            }\r\n        }\r\n\r\n        //2、减去优惠总价\r\n        BigDecimal subtract = amount.subtract(getReduce());\r\n        return subtract;\r\n    }\r\n\r\n\r\n\r\n    public BigDecimal getReduce() {\r\n        return reduce;\r\n    }\r\n\r\n    public void setReduce(BigDecimal reduce) {\r\n        this.reduce = reduce;\r\n    }\r\n}\r\n```\r\n - `org.klaus.zgg01mall.cart.vo.CartItem`\r\n\r\n```java\r\n    /**\r\n     * 购物项\r\n     * 例如：\r\n     * {\r\n     * skuId: 2131241,\r\n     * check: true,\r\n     * title: \"Apple iphone.....\",\r\n     * defaultImage: \"...\",\r\n     * price: 4999,\r\n     * count: 1,\r\n     * totalPrice: 4999,\r\n     * skuSaleVO: {...}\r\n     * }\r\n     * @author Klaus\r\n     * @date 2022/9/19\r\n     */\r\n    \r\n    public class CartItem {\r\n    \r\n        private Long skuId;\r\n        private Boolean check = true;\r\n        private String title;\r\n        private String image;\r\n        private List<String> skuAttrs;\r\n        private BigDecimal price;\r\n        private Integer count;\r\n        private BigDecimal totalPrice;\r\n    \r\n    \t....\r\n    \r\n        /**\r\n         * 计算当前项总价\r\n         * @return\r\n         */\r\n        public BigDecimal getTotalPrice() {\r\n            return this.price.multiply(new BigDecimal(\"\" + this.count));\r\n        }\r\n    \r\n        public void setTotalPrice(BigDecimal totalPrice) {\r\n            this.totalPrice = totalPrice;\r\n        }\r\n    }\r\n```\r\n- 添加购物车方法实现`org.klaus.zgg01mall.cart.service.impl.CartServiceImpl#addToCart`\r\n  - 对购物车进行Redis的hash绑定操作`Map<String, List<String>>`\r\n\r\n|   key=String   |    value=`List<String>`    |\r\n| :------------: | :------------------------: |\r\n| userId/userKey | cart=`Map<skuId,cartItem>` |\r\n| userId/userKey | cart=`Map<skuId,cartItem>` |\r\n| userId/userKey | cart=`Map<skuId,cartItem>` |\r\n\r\n\r\n\r\n ```java\r\n  /**\r\n   * 第一层 Map， Key 是用户 id\r\n   * 第二层 Map， Key 是购物车中商品 id， 值是购物项数据\r\n   * 将商品添加到购物车\r\n   *\r\n   * @param skuId\r\n   * @param num\r\n   * @return\r\n   */\r\n  @Override\r\n  public CartItem addToCart(Long skuId, Integer num) throws ExecutionException, InterruptedException {\r\n      //操作购物车\r\n      BoundHashOperations<String, Object, Object> cartOps = getCartOps();\r\n  \r\n  \r\n      String res = (String) cartOps.get(skuId.toString());\r\n      if (StringUtils.isEmpty(res)) {\r\n          //购物车没有这个商品执行以下代码\r\n          //2、添加新商品到购物车\r\n          CartItem cartItem = new CartItem();\r\n          CompletableFuture<Void> getSkuInfoTask = CompletableFuture.runAsync(() -> {\r\n              //1、远程查询当前要添加的商品的信息\r\n              R r = productFeignService.getSkuInfo(skuId);\r\n              SkuInfoVo data = r.getData(\"skuInfo\", new TypeReference<SkuInfoVo>() {\r\n              });\r\n  \r\n              cartItem.setCheck(true);\r\n              cartItem.setCount(num);\r\n              cartItem.setImage(data.getSkuDefaultImg());\r\n              cartItem.setTitle(data.getSkuTitle());\r\n              cartItem.setSkuId(skuId);\r\n              cartItem.setPrice(data.getPrice());\r\n          }, executor);\r\n  \r\n          //3、远程查询sku的组合信息\r\n          CompletableFuture<Void> getSkuSaleAttrValues = CompletableFuture.runAsync(() -> {\r\n              List<String> values = productFeignService.getSkuSaleAttrValues(skuId);\r\n              cartItem.setSkuAttrs(values);\r\n          }, executor);\r\n  \r\n          //异步全部完成才加入缓存\r\n          CompletableFuture.allOf(getSkuInfoTask, getSkuSaleAttrValues).get();\r\n          String s = JSON.toJSONString(cartItem);\r\n          //加入缓存，skuId cartItem\r\n          cartOps.put(skuId.toString(), s);\r\n          return cartItem;\r\n      } else {\r\n          //购物车有此商品，进行数量修改\r\n          CartItem cartItem = JSON.parseObject(res, CartItem.class);\r\n          //当前操作仅修改了逆转回来的数据，还需要更新redis\r\n          cartItem.setCount(cartItem.getCount() + num);\r\n          //再将修改后的数据转为json并存入redis\r\n          cartOps.put(skuId.toString(), JSON.toJSONString(cartItem));\r\n          return cartItem;\r\n      }\r\n  \r\n  \r\n  }\r\n ```\r\n - hash绑定方法，通过StringRedisTemplate将cartKey=gulimall:cart:userId/userKey与hash进行绑定操作\r\n```java\r\n/**\r\n   * 获取到我们要操作的购物车\r\n   *\r\n   * @return\r\n   */\r\n  private BoundHashOperations<String, Object, Object> getCartOps() {\r\n      UserInfoTo userInfoTo = CartInterceptor.threadLocal.get();\r\n      //1、判断用户是否登录了\r\n      String cartKey = \"\";\r\n      if (userInfoTo.getUserId() != null) {\r\n          //用户登录了\r\n          cartKey = CART_PREFIX + userInfoTo.getUserId();\r\n      } else {\r\n          //用户没登录\r\n          cartKey = CART_PREFIX + userInfoTo.getUserKey();\r\n      }\r\n  \r\n      //将购物车加入缓存绑定操作（hash）\r\n      BoundHashOperations<String, Object, Object> operations = redisTemplate.boundHashOps(cartKey);\r\n      return operations;\r\n  }\r\n```\r\n> 添加购物车时由String res = (String) cartOps.get(skuId.toString());判断指定商品是否加入了购物车，没有就进行添加购物车操作，异步全部完成封装购物项的信息后才加入缓存，将购物项转为Json形式存入hash中->String s = JSON.toJSONString(cartItem);cartOps.put(skuId.toString(), s);      购物车有此商品则进行添加操作，将缓存中的Json数据转为购物项对象进行添加操作，添加完再转回Json并存入hash中\r\n\r\n\r\n\r\n### 3、购物车列表\r\n\r\n- 购物车列表接口`org.klaus.zgg01mall.cart.controller.CartController#cartListPage`\r\n\r\n```java\r\n/**\r\n     * 浏览器有一个cookie：user-key：标识用户身份，一个月后过期\r\n     * 如果第一次使用jd的购物车功能，都会给一个临时的用户身份\r\n     * 浏览器以后保存，每次访问都会带上这个cookie；\r\n     *\r\n     * 登录：session有\r\n     * 没登录，按照cookie里面带来user-key来做\r\n     * 第一次，如果没有临时用户，会帮忙创建一个临时用户。\r\n     * @return\r\n     */\r\n    @GetMapping(\"/cart.html\")\r\n    public String cartListPage(Model model) throws ExecutionException, InterruptedException {\r\n\r\n        //1、快速得到用户信息：id，user-key\r\n//        UserInfoTo userInfoTo = CartInterceptor.threadLocal.get();\r\n//        System.out.println(userInfoTo);\r\n\r\n        Cart cart = cartService.getCart();\r\n        model.addAttribute(\"cart\", cart);\r\n        return \"cartList\";\r\n    }\r\n```\r\n- 获取整个购物车方法实现`org.klaus.zgg01mall.cart.service.impl.CartServiceImpl#getCart`\r\n\r\n```java\r\n/**\r\n * 获取整个购物车\r\n *\r\n * @return\r\n */\r\n@Override\r\npublic Cart getCart() throws ExecutionException, InterruptedException {\r\n    Cart cart = new Cart();\r\n    UserInfoTo userInfoTo = CartInterceptor.threadLocal.get();\r\n    if (userInfoTo.getUserId() != null) {\r\n        //1、登录\r\n        String cartKey = CART_PREFIX + userInfoTo.getUserId();\r\n        //1.1、如果临时购物车的数据还没有合并【合并购物车】\r\n        //临时购物车的所有购物项\r\n        String tempCartKey = CART_PREFIX + userInfoTo.getUserKey();\r\n        List<CartItem> tempCartItems = getCartItems(tempCartKey);\r\n        if (tempCartItems != null) {\r\n            //临时购物车有数据，需要合并\r\n            for (CartItem item : tempCartItems) {\r\n                addToCart(item.getSkuId(), item.getCount());\r\n            }\r\n            //合并完后清除临时购物车的数据\r\n            clearCart(tempCartKey);\r\n        }\r\n        //3、获取登录后的购物车数据【包含合并过来的临时购物车的数据，和登录后的购物车数据】\r\n        List<CartItem> cartItems = getCartItems(cartKey);\r\n        cart.setItems(cartItems);\r\n\r\n    } else {\r\n        //2、没登录\r\n        String cartKey = CART_PREFIX + userInfoTo.getUserKey();\r\n        //获取临时购物车的所有购物项\r\n        List<CartItem> cartItems = getCartItems(cartKey);\r\n        cart.setItems(cartItems);\r\n\r\n    }\r\n    return cart;\r\n}\r\n```\r\n- 获取所有购物项方法`org.klaus.zgg01mall.cart.service.impl.CartServiceImpl#getCartItems`\r\n  - 获取购物项再次进行hash绑定操作，因为之前已经绑定过一次，如果添加过购物车，缓存中是有数据的，直接遍历缓存中的Json数据并转为购物项对象返回出去，若没有则返回null\r\n\r\n```java\r\nprivate List<CartItem> getCartItems(String cartKey) {\r\n    BoundHashOperations<String, Object, Object> hashOps = redisTemplate.boundHashOps(cartKey);\r\n    List<Object> values = hashOps.values();\r\n    if (values != null && values.size() > 0) {\r\n        List<CartItem> collect = values.stream().map((obj) -> {\r\n            String str = (String) obj;\r\n            CartItem cartItem = JSON.parseObject(str, CartItem.class);\r\n            return cartItem;\r\n        }).collect(Collectors.toList());\r\n        return collect;\r\n    }\r\n    return null;\r\n}\r\n```\r\n\r\n### 4、添加购物车成功页\r\n\r\n- 添加购物车成功页接口`org.klaus.zgg01mall.cart.controller.CartController#addToCartSuccessPage`\r\n\r\n```java\r\n/**\r\n * 跳转到成功页，增加购物车用到2个页面，防止在添加购物车之后再刷新页面时自动增加\r\n * @param skuId\r\n * @param model\r\n * @return\r\n */\r\n@GetMapping(\"/addToCartSuccess.html\")\r\npublic String addToCartSuccessPage(@RequestParam(\"skuId\")Long skuId, Model model){\r\n    //重定向到成功页面，再次查询购物车数据即可\r\n    CartItem item = cartService.getCartItem(skuId);\r\n    model.addAttribute(\"item\", item);\r\n    return \"success\";\r\n}\r\n```\r\n\r\n- 获取购物项方法实现`org.klaus.zgg01mall.cart.service.impl.CartServiceImpl#getCartItem`\r\n  - 获取hash操作并拿到指定skuId的购物项Json，然后转为对象返回出去\r\n\r\n```java\r\n/**\r\n * 获取购物车中某个购物项\r\n *\r\n * @param skuId\r\n * @return\r\n */\r\n@Override\r\npublic CartItem getCartItem(Long skuId) {\r\n    BoundHashOperations<String, Object, Object> cartOps = getCartOps();\r\n    String str = (String) cartOps.get(skuId.toString());\r\n    //将缓存中的数据转为vo对象\r\n    CartItem cartItem = JSON.parseObject(str, CartItem.class);\r\n    return cartItem;\r\n}\r\n```\r\n\r\n### 5、删除购物项\r\n\r\n- 删除购物项接口\r\n\r\n```java\r\n@GetMapping(\"/deleteItem\")\r\npublic String deleteItem(@RequestParam(\"skuId\") Long skuId){\r\n    cartService.deleteItem(skuId);\r\n    return \"redirect:http://cart.gulimall.com/cart.html\";\r\n}\r\n```\r\n\r\n- 删除购物项方法实现\r\n  - 通过hash操作删除指定skuId的购物项\r\n\r\n```java\r\n/**\r\n * 删除购物项\r\n *\r\n * @param skuId\r\n */\r\n@Override\r\npublic void deleteItem(Long skuId) {\r\n    BoundHashOperations<String, Object, Object> cartOps = getCartOps();\r\n    //删除指定键\r\n    cartOps.delete(skuId.toString());\r\n}\r\n```\r\n\r\n### 6、改变购物项数量\r\n\r\n- 改变购物项数量接口\r\n\r\n```java\r\n@GetMapping(\"/countItem\")\r\npublic String countItem(@RequestParam(\"skuId\") Long skuId,\r\n                        @RequestParam(\"num\") Integer num){\r\n    cartService.changeItemCount(skuId, num);\r\n    return \"redirect:http://cart.gulimall.com/cart.html\";\r\n}\r\n```\r\n\r\n- 改变购物项数量方法实现\r\n  - 改变数量后通过hash操作将对象转为Json并存入hash\r\n\r\n```java\r\n/**\r\n * 修改购物项数量\r\n *\r\n * @param skuId\r\n * @param num\r\n */\r\n@Override\r\npublic void changeItemCount(Long skuId, Integer num) {\r\n    CartItem cartItem = getCartItem(skuId);\r\n    cartItem.setCount(num);\r\n\r\n    BoundHashOperations<String, Object, Object> cartOps = getCartOps();\r\n    cartOps.put(skuId.toString(), JSON.toJSONString(cartItem));\r\n}\r\n```\r\n\r\n### 7、选中购物项\r\n\r\n- 选中购物项接口\r\n\r\n```java\r\n@GetMapping(\"/checkItem\")\r\npublic String checkItem(@RequestParam(\"skuId\") Long skuId,\r\n                        @RequestParam(\"check\") Integer check){\r\n\r\n    cartService.checkItem(skuId, check);\r\n    return \"redirect:http://cart.gulimall.com/cart.html\";\r\n}\r\n```\r\n\r\n- 选中购物项方法实现\r\n  - 改变购物项的选中状态后通过hash操作将对象转为Json并存入hash\r\n\r\n```java\r\n/**\r\n * 勾选购物项\r\n *\r\n * @param skuId\r\n * @param check\r\n */\r\n@Override\r\npublic void checkItem(Long skuId, Integer check) {\r\n\r\n    BoundHashOperations<String, Object, Object> cartOps = getCartOps();\r\n    CartItem cartItem = getCartItem(skuId);\r\n    cartItem.setCheck(check == 1 ? true : false);\r\n\r\n    //将vo对象转为json序列化的文本\r\n    String s = JSON.toJSONString(cartItem);\r\n    cartOps.put(skuId.toString(), s);\r\n}\r\n```\r\n\r\n### 8、获取当前登录用户的购物项列表\r\n\r\n- 获取当前登录用户的购物项列表接口（**此接口是给订单服务远程调用的**）\r\n\r\n```java\r\n/**\r\n * 不是页面跳转需加@ResponseBody\r\n * @return\r\n */\r\n@GetMapping(\"/currentUserCartItems\")\r\n@ResponseBody\r\npublic List<CartItem> currentUserCartItems(){\r\n\r\n\r\n    return cartService.getUserCartItems();\r\n}\r\n```\r\n\r\n- 获取当前登录用户的购物项列表方法实现\r\n\r\n```java\r\n/**\r\n     * 获取当前用户的所有购物项\r\n     *\r\n     * @return\r\n     */\r\n    @Override\r\n    public List<CartItem> getUserCartItems() {\r\n        UserInfoTo userInfoTo = CartInterceptor.threadLocal.get();\r\n        if (userInfoTo.getUserId() == null){\r\n            //没登录\r\n            return null;\r\n        }else {\r\n            //登录了\r\n            String cartKey = CART_PREFIX + userInfoTo.getUserId();\r\n            List<CartItem> cartItems = getCartItems(cartKey);\r\n            //只要选中了的购物项\r\n            List<CartItem> collect = cartItems.stream().filter(item ->\r\n                item.getCheck()//默认是true\r\n            ).map(item->{\r\n//                R price = productFeignService.getPrice(item.getSkuId());\r\n                BigDecimal price = productFeignService.getPrice(item.getSkuId());\r\n                //todo 更新为最新的价格\r\n//                String data = (String) price.get(\"data\");\r\n//                item.setPrice(new BigDecimal(data));\r\n                item.setPrice(price);\r\n                return item;\r\n            }).collect(Collectors.toList());\r\n            return collect;\r\n        }\r\n    }\r\n```\r\n\r\n## Ⅱ.解决分布式下session共享问题\r\n\r\n### 1、session原理\r\n\r\n![image-20230410195022298](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195022298.png)\r\n\r\n### 2、分布式下session共享问题\r\n\r\n![image-20230410195051946](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195051946.png)\r\n\r\n\r\n\r\n### 3、解决 - session复制\r\n\r\n![image-20230410195126743](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195126743.png)\r\n\r\n\r\n\r\n- 优点\r\n  - web-server（Tomcat）原生支持，只需要修改配置文件\r\n- 缺点\r\n  - session同步需要数据传输，占用大量网络带宽，降低了服务器群的业务处理能力\r\n  - 任意一台web-server保存的数据都是所有web-server的session总和，受到内存限制无法水平扩展更多的web-server\r\n  - 大型分布式集群情况下，由于所有web-server都全量保存数据，所以此方案不可取。\r\n\r\n\r\n\r\n### 4、解决 - 客户端存储\r\n\r\n![image-20230410195314820](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195314820.png)\r\n\r\n\r\n\r\n- 优点\r\n  - 服务器不需存储session，用户保存自己的session信息到cookie中。节省服务端资源\r\n\r\n- 缺点\r\n  - 都是缺点，这只是一种思路。\r\n  - 具体如下：\r\n    - 每次http请求，携带用户在cookie中的完整信息，浪费网络带宽\r\n    - session数据放在cookie中，cookie有长度限制4K，不能保存大量信息\r\n    - session数据放在cookie中，存在泄漏、篡改、窃取等安全隐患\r\n- 这种方式不会使用。\r\n\r\n\r\n\r\n### 5、解决 - hash一致性\r\n\r\n![image-20230410195638892](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195638892.png)\r\n\r\n\r\n\r\n- 优点：\r\n  - 只需要改nginx配置，不需要修改应用代码\r\n  - 负载均衡，只要hash属性的值分布是均匀的，多台web-server的负载是均衡的\r\n  - 可以支持web-server水平扩展（session同步法是不行的，受内存限制）\r\n- 缺点\r\n  - session还是存在web-server中的，所以web-server重启可能导致部分session丢失，影响业务，如部分用户需要重新登录\r\n  - 如果web-server水平扩展，rehash后session重新分布，也会有一部分用户路由不到正确的session\r\n- 但是以上缺点问题也不是很大，因为session本来都是有有效期的。所以这两种反向代理的方式可以使用\r\n\r\n\r\n\r\n### 6、解决 - 统一存储\r\n\r\n![image-20230410195856602](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195856602.png)\r\n\r\n\r\n\r\n- 优点：\r\n  - 没有安全隐患\r\n  - 可以水平扩展，数据库/缓存水平切分即可\r\n  - web-server重启或者扩容都不会有session丢失\r\n- 不足\r\n  - 增加了一次网络调用，并且需要修改应用代码；如将所有的getSession方法替换为从Redis查数据的方式。redis获取数据比内存慢很多\r\n  - 上面缺点可以用SpringSession完美解决\r\n\r\n\r\n\r\n\r\n\r\n### 7、解决 - 不同服务，子域session共享\r\n\r\n> jsessionid这个cookie默认是当前系统域名的。当我们分拆服务，不同域名部署的时候，我们可以使用\r\n> 如下解决方案；\r\n\r\n![image-20230410200123345](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410200123345.png)\r\n\r\n\r\n\r\n\r\n\r\n### 8、SpringSession核心原理\r\n\r\n![image-20230410200156413](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410200156413.png)\r\n\r\n### 9、应用\r\n\r\n```java\r\n/**\r\n * 核心原理\r\n * 1、@EnableRedisHttpSession导入RedisHttpSessionConfiguration配置\r\n *      1）、给容器中添加了一个组件\r\n *          传入SessionRepository==》【RedisOperationsSessionRepository】===》redis操作session，session的增删改查封装类\r\n *      2）、SessionRepositoryFilter==》Filter(web)：session存储过滤器；每个请求过来都必须经过Filter\r\n *         I）、创建的时候，就自动从容器中获取了SessionRepository\r\n *         II）、原始的HttpServletRequest request, HttpServletResponse response都被分别包装成了SessionRepositoryRequestWrapper，SessionRepositoryResponseWrapper\r\n *         III）、以后获取session-》request.getSession();（原始的）\r\n *         //SessionRepositoryRequestWrapper重写getSession方法\r\n *         IV）、wrapperRequest.getSession();==> SessionRepository中获取的到\r\n *  装饰者模式；\r\n *\r\n *  自动延期；redis中的数据也是有过期时间的\r\n */\r\n@EnableRedisHttpSession //整合redis作为session存储\r\n```\r\n\r\n- 导入相关依赖\r\n\r\n```xml\r\n<dependency>\r\n  <groupId>org.springframework.boot</groupId>\r\n  <artifactId>spring-boot-starter-data-redis</artifactId>\r\n</dependency>\r\n\r\n<!--整合Springsession完成session共享问题-->\r\n<dependency>\r\n  <groupId>org.springframework.session</groupId>\r\n  <artifactId>spring-session-data-redis</artifactId>\r\n</dependency>\r\n```\r\n\r\n- SpringBootApplication类加上注解@EnableRedisHttpSession开启SpringSession\r\n- 配置文件添加相关配置\r\n\r\n```properties\r\nspring.redis.host=192.168.10.103\r\nspring.redis.port=6379\r\nspring.session.store-type=REDIS\r\n```\r\n\r\n- 添加配置类配置子域session共享\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/17\r\n */\r\n@Configuration\r\npublic class GulimallSessionConfig {\r\n\r\n    @Bean\r\n    public CookieSerializer cookieSerializer(){\r\n        DefaultCookieSerializer cookieSerializer = new DefaultCookieSerializer();\r\n\r\n        cookieSerializer.setDomainName(\"gulimall.com\");\r\n        cookieSerializer.setCookieName(\"KLAUSSESSION\");\r\n        return cookieSerializer;\r\n    }\r\n\r\n    @Bean\r\n    public RedisSerializer<Object> springSessionDefaultRedisSerializer() {\r\n        return new GenericJackson2JsonRedisSerializer();\r\n    }\r\n}\r\n```\r\n\r\n> 使用session共享的目的是让需要用到登录session的页面都能共享到同一个session\r\n\r\n## Ⅲ.商品系统缓存所有分类\r\n\r\n### 一、缓存\r\n\r\n#### 本地缓存\r\n\r\n![image-20230410191857648](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191857648.png)\r\n\r\n```java\r\n//本地缓存可以使用map\r\nprivate Map<String, Object> cache;\r\n```\r\n\r\n#### 1、缓存使用\r\n\r\n- 为了系统性能的提升，我们一般都会将部分数据放入缓存中，加速访问。而 db 承担数据落盘工作。\r\n\r\n  **哪些数据适合放入缓存？**\r\n\r\n  - 即时性、数据一致性要求不高的\r\n  - 访问量大且更新频率不高的数据（读多，写少）\r\n\r\n- 举例：电商类应用，商品分类，商品列表等适合缓存并加一个失效时间(根据数据更新频率来定)，后台如果发布一个商品，买家需要 5 分钟才能看到新的商品一般还是可以接受的。\r\n\r\n![image-20230425213252713](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230425213252713.png)\r\n\r\n```javascript\r\ndata = cache.load(id);//从缓存加载数据\r\nIf(data == null){\r\ndata = db.load(id);//从数据库加载数据\r\ncache.put(id,data);//保存到 cache 中\r\n}\r\nreturn data;\r\n```\r\n\r\n> 注意：在开发中，凡是放入缓存中的数据我们都应该指定过期时间，使其可以在系统即使没有主动更新数据也能自动触发数据加载进缓存的流程。避免业务崩溃导致的数据永久不一致问题。\r\n\r\n#### 2、整合 redis 作为缓存\r\n\r\n- 1、引入 redis-starter\r\n\r\n```xml\r\n<dependency>\r\n<groupId>org.springframework.boot</groupId>\r\n<artifactId>spring-boot-starter-data-redis</artifactId>\r\n</dependency>\r\n```\r\n\r\n- 2、配置 redis\r\n\r\n```properties\r\nspring.redis.host=192.168.10.103\r\nspring.redis.port=6379\r\n```\r\n\r\n- 3、使用 RedisTemplate 操作 redis\r\n\r\n```java\r\n@Autowired\r\nStringRedisTemplate stringRedisTemplate;\r\n@Test\r\npublic void testStringRedisTemplate(){\r\nValueOperations<String, String> ops = stringRedisTemplate.opsForValue();\r\nops.set(\"hello\",\"world_\"+ UUID.randomUUID().toString());\r\nString hello = ops.get(\"hello\");\r\nSystem.out.println(hello);\r\n}\r\n```\r\n\r\n- 4、切换使用 jedis\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.boot</groupId>\r\n    <artifactId>spring-boot-starter-data-redis</artifactId>\r\n    <exclusions>\r\n        <exclusion>\r\n            <groupId>io.lettuce</groupId>\r\n            <artifactId>lettuce-core</artifactId>\r\n        </exclusion>\r\n    </exclusions>\r\n</dependency>\r\n\r\n<dependency>\r\n    <groupId>redis.clients</groupId>\r\n    <artifactId>jedis</artifactId>\r\n</dependency>\r\n```\r\n\r\n> - 产生堆外内存溢出：OutOfDirectMemoryError\r\n>   1. SpringBoot2.0以后默认使用lettuce作为操作redis的客户端，它使用netty进行网络通信\r\n>   2. lettuce的bug导致netty堆外内存溢出  -Xmx 100m；netty如果没有指定堆外内存，默认使用-Xmx 100m\r\n>      - 可以通过-Di0.netty.maxDirectMemory进行设置\r\n>\r\n> - 解决方案：不能只使用-Di0.netty.maxDirectMemory去调大堆外内存\r\n>   1. 升级lettuce客户端\r\n>   2. 切换使用老版的jedis\r\n> - lettuce,jedis操作redis的底层客户端，Spring再次封装redisTemplate\r\n\r\n### 二、缓存失效问题\r\n\r\n#### 分布式缓存-本地模式在分布式下的问题\r\n\r\n![image-20230410191940056](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191940056.png)\r\n\r\n先来解决大并发读情况下的缓存失效问题；\r\n\r\n##### 1、高并发下缓存失效问题-缓存穿透\r\n\r\n![image-20230410192133778](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410192133778.png)\r\n\r\n- 缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查询的 null 写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。\r\n- 风险：\r\n  - 在流量大时，可能 DB 就挂掉了，要是有人利用不存在的 key 频繁攻击我们的应用，数据库瞬时压力增大，最终导致崩溃，这就是漏洞。\r\n\r\n- 解决：\r\n  - 缓存空结果、并且设置短的过期时间。\r\n\r\n##### 2、高并发下缓存失效问题-缓存雪崩\r\n\r\n- 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到 DB，DB 瞬时压力过重雪崩。\r\n\r\n- 解决：\r\n  - 原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\r\n\r\n##### 3、高并发下缓存失效问题-缓存击穿\r\n\r\n![image-20230410192628947](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410192628947.png)\r\n\r\n- 对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“**热点**”的数据。\r\n- 这个时候，需要考虑一个问题：如果这个 key 在大量请求同时进来前正好失效，那么所有对这个 key 的数据查询都落到 db，我们称为缓存击穿。\r\n- 解决：\r\n  - 加锁\r\n    - 大量并发只让一个去查，其他人等待，查到以后释放锁，其他人获取到锁，先查缓存，就会有数据，不用去db\r\n\r\n### 三、**缓存数据一致性**\r\n\r\n\r\n\r\n#### 1、缓存数据一致性 - 双写模式\r\n\r\n![image-20230410193831064](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193831064.png)\r\n\r\n#### **如何保证数据库和缓存双写一致性？**\r\n\r\n- 数据库和缓存（比如：redis）双写数据一致性问题，是一个跟开发语言无关的公共问题。尤其在高并发的场景下，这个问题变得更加严重。\r\n\r\n\r\n\r\n- 我很负责的告诉你，该问题无论在面试，还是工作中遇到的概率非常大，所以非常有必要跟大家一起探讨一下。\r\n\r\n\r\n\r\n- 今天这篇文章我会从浅入深，跟大家一起聊聊，数据库和缓存双写数据一致性问题常见的解决方案，这些方案中可能存在的坑，以及最优方案是什么。\r\n\r\n\r\n\r\n##### 1.常见方案 \r\n\r\n\r\n\r\n- 通常情况下，我们使用缓存的主要目的是为了提升查询的性能。\r\n-  大多数情况下，我们是这样使用缓存的：\r\n\r\n![image-20230429210507615](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429210507615.png)\r\n\r\n1. 用户请求过来之后，先查缓存有没有数据，如果有则直接返回。\r\n2. 如果缓存没数据，再继续查数据库。\r\n3. 如果数据库有数据，则将查询出来的数据，放入缓存中，然后返回该数据。\r\n4. 如果数据库也没数据，则直接返回空。\r\n\r\n\r\n\r\n- 这是缓存非常常见的用法。一眼看上去，好像没有啥问题。\r\n- 但你忽略了一个非常重要的细节：如果数据库中的某条数据，放入缓存之后，又立马被更新了，那么该如何更新缓存呢？\r\n- 不更新缓存行不行？\r\n  - 答：当然不行，如果不更新缓存，在很长的一段时间内（决定于缓存的过期时间），用户请求从缓存中获取到的都可能是旧值，而非数据库的最新值。这不是有数据不一致的问题？\r\n- 那么，我们该如何更新缓存呢？\r\n  - 目前有以下4种方案：\r\n    1. 先写缓存，再写数据库\r\n    2. 先写数据库，再写缓存\r\n    3. 先删缓存，再写数据库\r\n    4. 先写数据库，再删缓存\r\n\r\n\r\n\r\n接下来，我们详细说说这4种方案。\r\n\r\n\r\n\r\n##### 2.先写缓存，再写数据库 \r\n\r\n\r\n\r\n- 对于更新缓存的方案，很多人第一个想到的可能是在写操作中直接更新缓存（写缓存），更直接明了。\r\n\r\n- 那么，问题来了：在写操作中，到底是先写缓存，还是先写数据库呢？\r\n\r\n  - 我们在这里先聊聊先写缓存，再写数据库的情况，因为它的问题最严重。\r\n\r\n    ![image-20230429211803146](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429211803146.png)\r\n\r\n  - 某一个用户的每一次写操作，如果刚写完缓存，突然网络出现了异常，导致写数据库失败了。\r\n\r\n    ![image-20230429212103693](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429212103693.png)\r\n\r\n\r\n\r\n> - 其结果是缓存更新成了最新数据，但数据库没有，这样缓存中的数据不就变成脏数据了？如果此时该用户的查询请求，正好读取到该数据，就会出现问题，因为该数据在数据库中根本不存在，这个问题非常严重。\r\n> - 我们都知道，缓存的主要目的是把数据库的数据临时保存在内存，便于后续的查询，提升查询速度。\r\n> - 但如果某条数据，在数据库中都不存在，你缓存这种“`假数据`”又有啥意义呢？\r\n> - 因此，先写缓存，再写数据库的方案是不可取的，在实际工作中用得不多。\r\n\r\n\r\n\r\n##### 3.先写数据库，再写缓存\r\n\r\n- 既然上面的方案行不通，接下来，聊聊先写数据库，再写缓存的方案，该方案在低并发编程中有人在用（我猜的）。\r\n\r\n![image-20230429212403247](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429212403247.png)\r\n\r\n- 用户的写操作，先写数据库，再写缓存，可以避免之前“假数据”的问题。但它却带来了新的问题。\r\n\r\n- 什么问题呢？\r\n\r\n  - 写缓存失败了\r\n  - 高并发下的问题\r\n\r\n  - 浪费系统资源\r\n\r\n\r\n\r\n###### 3.1 写缓存失败了\r\n\r\n- 如果把写数据库和写缓存操作，放在同一个事务当中，当写缓存失败了，我们可以把写入数据库的数据进行回滚。\r\n\r\n![image-20230429213036514](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429213036514.png)\r\n\r\n\r\n\r\n> - 如果是并发量比较小，对接口性能要求不太高的系统，可以这么玩。\r\n> - 但如果在高并发的业务场景中，写数据库和写缓存，都属于远程操作。为了防止出现大事务，造成的死锁问题，通常建议写数据库和写缓存不要放在同一个事务中。\r\n> - 也就是说在该方案中，如果写数据库成功了，但写缓存失败了，数据库中已写入的数据不会回滚。\r\n> - 这就会出现：数据库是`新数据`，而缓存是`旧数据`，两边`数据不一致`的情况。\r\n\r\n\r\n\r\n###### 3.2 高并发下的问题\r\n\r\n- 假设在高并发的场景中，针对同一个用户的同一条数据，有两个写数据请求：a和b，它们同时请求到业务系统。\r\n\r\n- 其中请求a获取的是旧数据，而请求b获取的是新数据，如下图所示：\r\n\r\n![image-20230429214141109](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429214141109.png)\r\n\r\n1. 请求a先过来，刚写完了数据库。但由于网络原因，卡顿了一下，还没来得及写缓存。\r\n2. 这时候请求b过来了，先写了数据库。\r\n3. 接下来，请求b顺利写了缓存。\r\n4. 此时，请求a卡顿结束，也写了缓存。\r\n\r\n> - 很显然，在这个过程当中，请求b在缓存中的`新数据`，被请求a的`旧数据`覆盖了。\r\n> - 也就是说：在高并发场景中，如果多个线程同时执行先写数据库，再写缓存的操作，可能会出现数据库是新值，而缓存中是旧值，两边数据不一致的情况。\r\n\r\n\r\n\r\n###### 3.3 浪费系统资源\r\n\r\n- 该方案还有一个比较大的问题就是：每个写操作，写完数据库，会马上写缓存，比较浪费系统资源。\r\n\r\n- 为什么这么说呢？\r\n\r\n  - 你可以试想一下，如果写的缓存，并不是简单的数据内容，而是要经过非常复杂的计算得出的最终结果。这样每写一次缓存，都需要经过一次非常复杂的计算，不是非常浪费系统资源吗？\r\n\r\n  - 尤其是cpu和内存资源。\r\n\r\n> - 还有些业务场景比较特殊：写多读少。\r\n>\r\n> - 如果在这类业务场景中，每个用的写操作，都需要写一次缓存，有点得不偿失。\r\n>\r\n> - 由此可见，在高并发的场景中，先写数据库，再写缓存，这套方案问题挺多的，也不太建议使用。\r\n> - 如果你已经用了，赶紧看看踩坑了没？\r\n\r\n\r\n\r\n##### 4.先删缓存，再写数据库\r\n\r\n- 通过上面的内容我们得知，如果直接更新缓存的问题很多。\r\n- 那么，为何我们不能换一种思路：不去直接更新缓存，而改为删除缓存呢？\r\n\r\n- 删除缓存方案，同样有两种：\r\n  1. 先删缓存，再写数据库\r\n  2. 先写数据库，再删缓存\r\n\r\n- 我们一起先看看：先删缓存，再写数据库的情况。\r\n\r\n![image-20230429214804997](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429214804997.png)\r\n\r\n> 说白了，在用户的写操作中，先执行删除缓存操作，再去写数据库。这套方案，可以是可以，但也会有一样问题。\r\n\r\n\r\n\r\n###### 4.1 高并发下的问题\r\n\r\n- 假设在高并发的场景中，同一个用户的同一条数据，有一个读数据请求c，还有另一个写数据请求d（一个更新操作），同时请求到业务系统。如下图所示：\r\n\r\n![image-20230429215027947](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429215027947.png)\r\n\r\n1. 请求d先过来，把缓存删除了。但由于网络原因，卡顿了一下，还没来得及写数据库。\r\n2. 这时请求c过来了，先查缓存发现没数据，再查数据库，有数据，但是旧值。\r\n3. 请求c将数据库中的旧值，更新到缓存中。\r\n4. 此时，请求d卡顿结束，把新值写入数据库。\r\n\r\n- 在这个过程当中，请求d的新值并没有被请求c写入缓存，同样会导致缓存和数据库的数据不一致的情况。\r\n- 那么，这种场景的数据不一致问题，能否解决呢？\r\n  - 缓存双删\r\n\r\n\r\n\r\n###### 4.2 缓存双删\r\n\r\n- 在上面的业务场景中，一个读数据请求，一个写数据请求。当写数据请求把缓存删了之后，读数据请求，可能把当时从数据库查询出来的旧值，写入缓存当中。\r\n\r\n- 有人说还不好办，请求d在写完数据库之后，把缓存重新删一次不就行了？\r\n\r\n![image-20230429215248760](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429215248760.png)\r\n\r\n- 这就是我们所说的缓存双删，即在写数据库之前删除一次，写完数据库后，再删除一次。\r\n- 该方案有个非常关键的地方是：第二次删除缓存，并非立马就删，而是要在一定的时间间隔之后。\r\n- 我们再重新回顾一下，高并发下一个读数据请求，一个写数据请求导致数据不一致的产生过程：\r\n  1. 请求d先过来，把缓存删除了。但由于网络原因，卡顿了一下，还没来得及写数据库。\r\n  2. 这时请求c过来了，先查缓存发现没数据，再查数据库，有数据，但是旧值。\r\n  3. 请求c将数据库中的旧值，更新到缓存中。\r\n  4. 此时，请求d卡顿结束，把新值写入数据库。\r\n  5. 一段时间之后，比如：500ms，请求d将缓存删除。\r\n\r\n- 这样来看确实可以解决缓存不一致问题。\r\n- 那么，为什么一定要间隔一段时间之后，才能删除缓存呢？\r\n- 请求d卡顿结束，把新值写入数据库后，请求c将数据库中的旧值，更新到缓存中。\r\n- 此时，如果请求d删除太快，在请求c将数据库中的旧值更新到缓存之前，就已经把缓存删除了，这次删除就没任何意义。必须要在请求c更新缓存之后，再删除缓存，才能把旧值及时删除了。\r\n- 所以需要在请求d中加一个时间间隔，确保请求c，或者类似于请求c的其他请求，如果在缓存中设置了旧值，最终都能够被请求d删除掉。\r\n- 接下来，还有一个问题：如果第二次删除缓存时，删除失败了该怎么办？\r\n- 这里先留点悬念，后面会详细说。\r\n\r\n\r\n\r\n##### 5.先写数据库，再删缓存\r\n\r\n- 从前面得知，先删缓存，再写数据库，在并发的情况下，也可能会出现缓存和数据库的数据不一致的情况。\r\n- 那么，我们只能寄希望于最后的方案了。\r\n- 接下来，我们重点看看先写数据库，再删缓存的方案。\r\n\r\n![image-20230429220057198](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429220057198.png)\r\n\r\n- 在高并发的场景中，有一个读数据请求，有一个写数据请求，更新过程如下：\r\n\r\n1. 请求e先写数据库，由于网络原因卡顿了一下，没有来得及删除缓存。\r\n2. 请求f查询缓存，发现缓存中有数据，直接返回该数据。\r\n3. 请求e删除缓存。\r\n\r\n- 在这个过程中，只有请求f读了一次旧数据，后来旧数据被请求e及时删除了，看起来问题不大。\r\n- 但如果是读数据请求先过来呢？\r\n\r\n1. 请求f查询缓存，发现缓存中有数据，直接返回该数据。\r\n2. 请求e先写数据库。\r\n3. 请求e删除缓存。\r\n\r\n- 这种情况看起来也没问题呀？\r\n  - 答：对的。\r\n- 但就怕出现下面这种情况，即缓存自己失效了。如下图所示：\r\n\r\n![image-20230429220431661](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429220431661.png)\r\n\r\n1. 缓存过期时间到了，自动失效。\r\n2. 请求f查询缓存，发缓存中没有数据，查询数据库的旧值，但由于网络原因卡顿了，没有来得及更新缓存。\r\n3. 请求e先写数据库，接着删除了缓存。\r\n4. 请求f更新旧值到缓存中。\r\n\r\n- 这时，缓存和数据库的数据同样出现不一致的情况了。\r\n- 但这种情况还是比较少的，需要同时满足以下条件才可以：\r\n  1. 缓存刚好自动失效。\r\n  2. 请求f从数据库查出旧值，更新缓存的耗时，比请求e写数据库，并且删除缓存的还长。\r\n\r\n- 我们都知道查询数据库的速度，一般比写数据库要快，更何况写完数据库，还要删除缓存。所以绝大多数情况下，写数据请求比读数据情况耗时更长。\r\n- 由此可见，系统同时满足上述两个条件的概率非常小。\r\n\r\n> 推荐大家使用先写数据库，再删缓存的方案，虽说不能100%避免数据不一致问题，但出现该问题的概率，相对于其他方案来说是最小的。\r\n\r\n- 但在该方案中，如果删除缓存失败了该怎么办呢？\r\n\r\n\r\n\r\n##### 6.删缓存失败怎么办？\r\n\r\n- 其实先写数据库，再删缓存的方案，跟缓存双删的方案一样，有一个共同的风险点，即：如果缓存删除失败了，也会导致缓存和数据库的数据不一致。\r\n- 那么，删除缓存失败怎么办呢？\r\n  - 答：需要加`重试机制`。\r\n- 在接口中如果更新了数据库成功了，但更新缓存失败了，可以立刻重试3次。如果其中有任何一次成功，则直接返回成功。如果3次都失败了，则写入数据库，准备后续再处理。\r\n- 当然，如果你在接口中直接`同步重试`，该接口并发量比较高的时候，可能有点影响接口性能。\r\n- 这时，就需要改成`异步重试`了。\r\n- 异步重试方式有很多种，比如：\r\n  1. 每次都单独起一个线程，该线程专门做重试的工作。但如果在高并发的场景下，可能会创建太多的线程，导致系统OOM问题，不太建议使用。\r\n  2. 将重试的任务交给线程池处理，但如果服务器重启，部分数据可能会丢失。\r\n  3. 将重试数据写表，然后使用elastic-job等定时任务进行重试。\r\n  4. 将重试的请求写入mq等消息中间件中，在mq的consumer中处理。\r\n  5. 订阅mysql的binlog，在订阅者中，如果发现了更新数据请求，则删除相应的缓存。\r\n\r\n\r\n\r\n##### 7.定时任务\r\n\r\n- 使用定时任务重试的具体方案如下：\r\n\r\n1. 当用户操作写完数据库，但删除缓存失败了，需要将用户数据写入重试表中。如下图所示：\r\n\r\n![image-20230429221037315](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429221037315.png)\r\n\r\n2. 在定时任务中，异步读取重试表中的用户数据。重试表需要记录一个重试次数字段，初始值为0。然后重试5次，不断删除缓存，每重试一次该字段值+1。如果其中有任意一次成功了，则返回成功。如果重试了5次，还是失败，则我们需要在重试表中记录一个失败的状态，等待后续进一步处理。\r\n\r\n![image-20230429221203146](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429221203146.png)\r\n\r\n\r\n\r\n3. 在高并发场景中，定时任务推荐使用`elastic-job`。相对于xxl-job等定时任务，它可以分片处理，提升处理速度。同时每片的间隔可以设置成：1,2,3,5,7秒等。\r\n\r\n- 如果大家对定时任务比较感兴趣的话，可以看看我的另一篇文章《[学会这10种定时任务，我有点飘了](https://mp.weixin.qq.com/s?__biz=MzkwNjMwMTgzMQ==&mid=2247490314&idx=1&sn=29ddf0c1e99675b86cdfc082556a69a9&chksm=c0ebc3e2f79c4af43cf8582d41b0bc3ede57986cc6c115b103b586a2c7bddb4475555e919b20&token=751314179&lang=zh_CN&scene=21#wechat_redirect)》，里面列出了目前最主流的定时任务。\r\n- 使用定时任务重试的话，有个缺点就是实时性没那么高，对于实时性要求特别高的业务场景，该方案不太适用。但是对于一般场景，还是可以用一用的。\r\n- 但它有一个很大的优点，即数据是落库的，不会丢数据。\r\n\r\n\r\n\r\n##### 8.mq\r\n\r\n- 在高并发的业务场景中，mq（消息队列）是必不可少的技术之一。它不仅可以异步解耦，还能削峰填谷。对保证系统的稳定性是非常有意义的。\r\n- 对mq有兴趣的朋友可以看看我的另一篇文章《[mq的那些破事儿](https://mp.weixin.qq.com/s/j5Jedf7OSPkyNs11610v8Q)》。\r\n- mq的生产者，生产了消息之后，通过指定的topic发送到mq服务器。然后mq的消费者，订阅该topic的消息，读取消息数据之后，做业务逻辑处理。\r\n- 使用mq重试的具体方案如下：\r\n\r\n![image-20230429221455529](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429221455529.png)\r\n\r\n1. 当用户操作写完数据库，但删除缓存失败了，产生一条mq消息，发送给mq服务器。\r\n2. mq消费者读取mq消息，重试5次删除缓存。如果其中有任意一次成功了，则返回成功。如果重试了5次，还是失败，则写入死信队列中。\r\n3. 推荐mq使用rocketmq，重试机制和死信队列默认是支持的。使用起来非常方便，而且还支持顺序消息，延迟消息和事务消息等多种业务场景。\r\n\r\n> - 当然在该方案中，删除缓存可以完全走异步。即用户的写操作，在写完数据库之后，不用立刻删除一次缓存。而直接发送mq消息，到mq服务器，然后有mq消费者全权负责删除缓存的任务。\r\n> - 因为mq的实时性还是比较高的，因此改良后的方案也是一种不错的选择。\r\n\r\n\r\n\r\n##### 9.binlog\r\n\r\n- 前面我们聊过的，无论是定时任务，还是mq（消息队列），做重试机制，对业务都有一定的侵入性。\r\n- 在使用定时任务的方案中，需要在业务代码中增加额外逻辑，如果删除缓存失败，需要将数据写入重试表。\r\n- 而使用mq的方案中，如果删除缓存失败了，需要在业务代码中发送mq消息到mq服务器。\r\n- 其实，还有一种更优雅的实现，即监听binlog，比如使用：canal等中间件。\r\n- 具体方案如下：\r\n\r\n![image-20230429221610975](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429221610975.png)\r\n\r\n1. 在业务接口中写数据库之后，就不管了，直接返回成功。\r\n2. mysql服务器会自动把变更的数据写入binlog中。\r\n3. binlog订阅者获取变更的数据，然后删除缓存。\r\n\r\n- 这套方案中业务接口确实简化了一些流程，只用关心数据库操作即可，而在binlog订阅者中做缓存删除工作。\r\n- 但如果只是按照图中的方案进行删除缓存，只删除了一次，也可能会失败。\r\n- 如何解决这个问题呢？\r\n  - 答：这就需要加上前面聊过的`重试机制`了。如果删除缓存失败，写入重试表，使用定时任务重试。或者写入mq，让mq自动重试。\r\n- 在这里推荐使用mq`自动重试机制`。\r\n\r\n![image-20230429221806980](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429221806980.png)\r\n\r\n> 在binlog订阅者中如果删除缓存失败，则发送一条mq消息到mq服务器，在mq消费者中自动重试5次。如果有任意一次成功，则直接返回成功。如果重试5次后还是失败，则该消息自动被放入死信队列，后面可能需要人工介入。\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n#### 2、缓存数据一致性 - 失效模式\r\n\r\n![image-20230410193909090](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193909090.png)\r\n\r\n\r\n\r\n#### 3、缓存数据一致性 - 解决方案\r\n\r\n-  无论是双写模式还是失效模式，都会导致缓存的不一致问题。即多个实例同时更新会出事。怎么办？\r\n   - 1、如果是用户纬度数据（订单数据、用户数据），这种并发几率非常小，不用考虑这个问题，缓存数据加上过期时间，每隔一段时间触发读的主动更新即可\r\n   - 2、如果是菜单，商品介绍等基础数据，也可以去使用canal订阅binlog的方式。\r\n   - 3、缓存数据+过期时间也足够解决大部分业务对于缓存的要求。\r\n   - 4、通过加锁保证并发读写，写写的时候按顺序排好队。读读无所谓。所以适合使用读写锁。（业务不关心脏数据，允许临时脏数据可忽略）；\r\n-  总结：\r\n   - 我们能放入缓存的数据本就不应该是实时性、一致性要求超高的。所以缓存数据的时候加上过期时间，保证每天拿到当前最新数据即可。\r\n   - 我们不应该过度设计，增加系统的复杂性\r\n   - 遇到实时性、一致性要求高的数据，就应该查数据库，即使慢点。\r\n\r\n\r\n\r\n#### 4、缓存数据一致性 - 解决-Canal\r\n\r\n![image-20230410194458435](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410194458435.png)\r\n\r\n\r\n\r\n### 四、分布式锁\r\n\r\n#### 1、分布式锁与本地锁\r\n\r\n![image-20230425221131744](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230425221131744.png)\r\n\r\n- `org.klaus.zgg01mall.product.service.impl.CategoryServiceImpl#getDataFromDb`\r\n  - 抽取业务方法方便加锁\r\n\r\n```java\r\n/**\r\n * 抽取业务方法\r\n *\r\n * @return\r\n */\r\nprivate Map<String, List<Catalog2Vo>> getDataFromDb() {\r\n    //获取缓存\r\n    String catalogJson = stringRedisTemplate.opsForValue().get(\"catalogJson\");\r\n    if (!StringUtils.isEmpty(catalogJson)) {\r\n        //缓存不为空直接返回\r\n        Map<String, List<Catalog2Vo>> result = JSON.parseObject(catalogJson, new TypeReference<Map<String, List<Catalog2Vo>>>() {\r\n        });\r\n        return result;\r\n    }\r\n    System.out.println(\"查询了数据库。。。\");\r\n\r\n    /**\r\n     * 缓存为空，进行查询业务\r\n     * 1、将数据库的多次查询变为一次，即方法抽取\r\n     */\r\n    //查询所有\r\n    List<CategoryEntity> selectList = baseMapper.selectList(null);\r\n\r\n    //1、查出所有1级分类                                   父分类集合，一级分类父分类id为0\r\n    List<CategoryEntity> level1Categorys = getParent_cid(selectList, 0L);\r\n\r\n    //2、封装数据\r\n    Map<String, List<Catalog2Vo>> map = level1Categorys.stream().collect(Collectors.toMap(\r\n            //\"pCId\":\"c2{}\"\r\n            k -> k.getCatId().toString(),\r\n            v -> {\r\n                //2.1、每一个的一级分类，查到这个一级分类的[二级分类]\r\n                //得到二级分类实体集合 抽取查询方法-> baseMapper.selectList(new QueryWrapper<CategoryEntity>().eq(\"parent_cid\", v.getCatId()));\r\n                //todo                                                 父分类集合， 当前分类id（v为当前遍历的一级分类）\r\n                List<CategoryEntity> catalog2Entities = getParent_cid(selectList, v.getCatId());\r\n                //2.2、封装上面的结果\r\n                List<Catalog2Vo> catalog2Vos = null;\r\n                //父分类不为空，即二级分类实体集合不为空\r\n                if (catalog2Entities != null) {\r\n                    //遍历拿到每个二级分类集合\r\n                    catalog2Vos = catalog2Entities.stream().map(l2 -> {\r\n                        //封装二级分类vo数据\r\n                        Catalog2Vo catalog2Vo = new Catalog2Vo(v.getCatId().toString(), null, l2.getCatId().toString(), l2.getName());\r\n                        //2.2.1、找当前二级分类的三级分类封装成vo baseMapper.selectList(new QueryWrapper<CategoryEntity>(). eq(\"parent_cid\", l2.getCatId()));\r\n                        //                                       （三级分类父分类）父分类集合， 当前分类id（l2为当前遍历的二级分类）\r\n                        List<CategoryEntity> catalog3Entities = getParent_cid(selectList, l2.getCatId());\r\n                        List<Catalog2Vo.Catalog3Vo> catalog3Vos = null;\r\n                        if (catalog3Entities != null) {\r\n                            catalog3Vos = catalog3Entities.stream().map(l3 -> {\r\n                                //2.2.2、封装成指定格式\r\n                                Catalog2Vo.Catalog3Vo catalog3Vo = new Catalog2Vo.Catalog3Vo(l2.getCatId().toString(), l3.getCatId().toString(), l3.getName());\r\n                                return catalog3Vo;\r\n                            }).collect(Collectors.toList());\r\n                            catalog2Vo.setCatalog3List(catalog3Vos);\r\n                        }\r\n\r\n\r\n                        return catalog2Vo;\r\n                    }).collect(Collectors.toList());\r\n                }\r\n                return catalog2Vos;\r\n            }));\r\n    //todo 3、查到的数据再放入缓存，将对象转为json放入缓存中\r\n    String s = JSON.toJSONString(map);\r\n    //将数据放入缓存\r\n    stringRedisTemplate.opsForValue().set(\"catalogJson\", s, 1, TimeUnit.DAYS);\r\n    //将数据库查到的结果直接返回，即将数据库查到的结果放一份到缓存中并返回\r\n    return map;\r\n}\r\n\r\n/**\r\n     * 抽取获取父分类id的查询方法，优化三级分类数据获取，使得在压力测试中吞吐量有明显的提高；\r\n     * 查询数据库是影响吞吐量高低的重要因素之一，因此尽量减少数据库的查询\r\n     *\r\n     * @param selectList\r\n     * @param parent_cid\r\n     * @return\r\n     */\r\n    private List<CategoryEntity> getParent_cid(List<CategoryEntity> selectList, Long parent_cid) {\r\n        //return baseMapper.selectList(new QueryWrapper<CategoryEntity>().eq(\"parent_cid\", v.getCatId()));\r\n        //直接进行过滤得到当前遍历的父分类id为传入的父分类id\r\n        List<CategoryEntity> collect = selectList.stream().filter(item -> item.getParentCid().equals(parent_cid)).collect(Collectors.toList());\r\n        return collect;\r\n    }\r\n```\r\n\r\n- 使用本地锁\r\n\r\n```java\r\n/**\r\n     * 使用redis缓存的同时使用本地锁（同步锁）来执行业务\r\n     *\r\n     * @return\r\n     */\r\n    public Map<String, List<Catalog2Vo>> getCatalogJsonFromDbWithLocalLock() {\r\n\r\n        //如果缓存中有就用缓存的\r\n//        Map<String, List<Catalog2Vo>> catalogJson = (Map<String, List<Catalog2Vo>>) cache.get(\"catalogJson\");\r\n//        if (catalogJson.get(\"catalogJson\") == null){\r\n//            //调用业务xxx\r\n//            //返回数据又放入缓存\r\n//            cache.put(\"catalogJson\", parent_cid);\r\n//        }\r\n//        return catalogJson;\r\n        //只要是同一把锁，就能锁住需要的这个锁的所有线程\r\n        //1、synchronized (this):SpringBoot所有的组件在容器中都是单例的\r\n        //todo 本地锁synchronized，JUC(Lock)，在分布式情况下，想要锁住所有，必须使用分布式锁\r\n\r\n        //单实例的加锁，即本地锁只能锁住当前进程\r\n        synchronized (this) {\r\n            //得到锁以后，我们应该再去缓存中确定一次，如果没有才需要继续查询\r\n            return getDataFromDb();\r\n        }\r\n\r\n    }\r\n```\r\n\r\n##### 锁-时序问题\r\n\r\n![image-20230410193041285](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193041285.png)\r\n\r\n#### 2、分布式锁演进\r\n\r\n##### 分布式锁演进-基本原理\r\n\r\n![image-20230410193221079](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193221079.png)\r\n\r\n> 我们可以同时去一个地方“占坑”，如果占到，就执行逻辑。否则就必须等待，直到释放锁。\r\n> “占坑”可以去redis，可以去数据库，可以去任何大家都能访问的地方。\r\n> 等待可以自旋的方式。\r\n\r\n##### 分布式锁演进-阶段一\r\n\r\n![image-20230410193430589](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193430589.png)\r\n\r\n```java\r\nBoolean lock = redisTemplate.opsForValue().setIfAbsent(\"lock\", \"0\");\r\n        if (lock) {\r\n            // 加锁成功..执行业务\r\n            Map<String,List<Catelog2Vo>> dataFromDb = getDataFromDB();\r\n            redisTemplate.delete(\"lock\"); // 删除锁\r\n            return dataFromDb;\r\n        } else {\r\n            // 加锁失败，重试 synchronized()\r\n            // 休眠100ms重试\r\n            return getCatelogJsonFromDbWithRedisLock();\r\n        }\r\n```\r\n\r\n\r\n\r\n##### 分布式锁演进-阶段二\r\n\r\n![image-20230410193552631](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193552631.png)\r\n\r\n```java\r\nBoolean lock = redisTemplate.opsForValue().setIfAbsent()\r\n        if (lock) {\r\n            // 加锁成功..执行业务\r\n            // 设置过期时间\r\n            redisTemplate.expire(\"lock\",30,TimeUnit.SECONDS);\r\n            Map<String,List<Catelog2Vo>> dataFromDb = getDataFromDB();\r\n            redisTemplate.delete(\"lock\"); // 删除锁\r\n            return dataFromDb;\r\n        } else {\r\n            // 加锁失败，重试 synchronized()\r\n            // 休眠100ms重试\r\n            return getCatelogJsonFromDbWithRedisLock();\r\n        }\r\n```\r\n\r\n\r\n\r\n##### 分布式锁演进-阶段三\r\n\r\n![image-20230410193625611](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193625611.png)\r\n\r\n```java\r\n// 设置值同时设置过期时间\r\nBoolean lock = redisTemplate.opsForValue().setIfAbsent(\"lock\",\"111\",300,TimeUnit.SECONDS);\r\nif (lock) {\r\n    // 加锁成功..执行业务\r\n    // 设置过期时间,必须和加锁是同步的，原子的\r\n    redisTemplate.expire(\"lock\",30,TimeUnit.SECONDS);\r\n    Map<String,List<Catelog2Vo>> dataFromDb = getDataFromDB();\r\n    redisTemplate.delete(\"lock\"); // 删除锁\r\n    return dataFromDb;\r\n} else {\r\n    // 加锁失败，重试 synchronized()\r\n    // 休眠100ms重试\r\n    return getCatelogJsonFromDbWithRedisLock();\r\n}\r\n```\r\n\r\n\r\n\r\n##### 分布式锁演进-阶段四\r\n\r\n![image-20230410193648301](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193648301.png)\r\n\r\n```java\r\nString uuid = UUID.randomUUID().toString();\r\n        // 设置值同时设置过期时间\r\n        Boolean lock = redisTemplate.opsForValue().setIfAbsent(\"lock\",uuid,300,TimeUnit.SECONDS);\r\n        if (lock) {\r\n            // 加锁成功..执行业务\r\n            // 设置过期时间,必须和加锁是同步的，原子的\r\n//            redisTemplate.expire(\"lock\",30,TimeUnit.SECONDS);\r\n            Map<String,List<Catelog2Vo>> dataFromDb = getDataFromDB();\r\n//            String lockValue = redisTemplate.opsForValue().get(\"lock\");\r\n//            if (lockValue.equals(uuid)) {\r\n//                // 删除我自己的锁\r\n//                redisTemplate.delete(\"lock\"); // 删除锁\r\n//            }\r\n// 通过使用lua脚本进行原子性删除\r\n            String script = \"if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end\";\r\n                //删除锁\r\n                Long lock1 = redisTemplate.execute(new DefaultRedisScript<Long>(script, Long.class), Arrays.asList(\"lock\"), uuid);\r\n\r\n            return dataFromDb;\r\n        } else {\r\n            // 加锁失败，重试 synchronized()\r\n            // 休眠100ms重试\r\n            return getCatelogJsonFromDbWithRedisLock();\r\n        }\r\n```\r\n\r\n\r\n\r\n##### 分布式锁演进-阶段五-最终形态\r\n\r\n![image-20230410193719776](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193719776.png)\r\n\r\n- `org.klaus.zgg01mall.product.service.impl.CategoryServiceImpl#getCatalogJsonFromDbWithRedisLock`\r\n\r\n```java\r\n /**\r\n     * 使用redis分布式锁来执行业务（luo脚本解锁）\r\n     *\r\n     * @return\r\n     */\r\n    //@Override\r\n    public Map<String, List<Catalog2Vo>> getCatalogJsonFromDbWithRedisLock() {\r\n\r\n        //抢占锁前，每人都获取唯一id设置成lock的value值\r\n        String uuid = UUID.randomUUID().toString();\r\n        //1、占分布式锁，去redis占坑(原子操作)  SET  lock(k)  1111(v)     NX                        EX(时间不能太短)\r\n        Boolean lock = stringRedisTemplate.opsForValue().setIfAbsent(\"lock\", uuid, 300, TimeUnit.SECONDS);\r\n        if (lock) {\r\n            System.out.println(\"获取分布式锁成功.......\");\r\n            //2、设置过期时间，防止出现死锁情况(若突然断电而无法执行设置过期时间)\r\n            //因此设置过期时间，必须和加锁是同步的，原子的\r\n            //stringRedisTemplate.expire(\"lock\", 30, TimeUnit.SECONDS);\r\n\r\n            Map<String, List<Catalog2Vo>> dataFromDb;\r\n            try {\r\n                //加锁成功.... 执行业务\r\n                dataFromDb = getDataFromDb();\r\n            } finally {\r\n                //无论业务崩溃或异常等情况都执行删除锁，只要保证原子加锁和原子解锁没有问题即可\r\n                //因此可以使用luo脚本解锁来实现原子操作\r\n                //                              指定的lock(key) == 指定的uuid(value)                                        删除返回1，失败返回0\r\n                String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\";\r\n                //执行脚本，删除锁\r\n                Long lock1 = stringRedisTemplate.execute(\r\n                        //删除key->成功返回1，失败返回0，返回值为Integer\r\n                        new DefaultRedisScript<Long>(script, Long.class),\r\n                        //所有的key集合->得到lock集合\r\n                        Arrays.asList(\"lock\"), uuid);\r\n            }\r\n            //获取值对比+对比成功删除=原子操作，否则，即使比对成功也可能删的是别人的锁\r\n//            String lockValue = stringRedisTemplate.opsForValue().get(\"lock\");\r\n//            //根据占锁的唯一Id值判断是不是同一把锁\r\n//            // 极端情况，10s过期时间，执行业务用了9.5s，但获取锁要发送请求到远程的redis来返回数据，所需时间为0.3s，判断需要1s，\r\n//            // 即比对成功时锁已过期，删的是redis刚更新的抢占锁\r\n//            if (uuid.equals(lockValue)){\r\n//                //是同一把锁就把这把锁删掉\r\n//                //业务执行完毕后解锁-> 删除锁(key)\r\n//                stringRedisTemplate.delete(\"lock\");\r\n//            }\r\n\r\n            return dataFromDb;\r\n        } else {\r\n            System.out.println(\"获取分布式锁失败.......等待重试\");\r\n            //加锁失败....重试。。synchronized ()\r\n            //休眠200ms重试\r\n            try {\r\n                Thread.sleep(200);\r\n            } catch (InterruptedException e) {\r\n\r\n            }\r\n            //自旋的方式-> 重新获取锁\r\n            return getCatalogJsonFromDbWithRedisLock();\r\n        }\r\n\r\n\r\n    }\r\n```\r\n\r\n- 给页面返回所有分类的Json数据（加Redis锁）`org.klaus.zgg01mall.product.service.impl.CategoryServiceImpl#getCatalogJson2`\r\n\r\n```java\r\n/**\r\n     * 抽取缓存操作方法（使用了RedisLock）\r\n     * 没加缓存注解前的缓存操作业务代码（获取分类的json数据）\r\n     * @return\r\n     */\r\n    //@Override\r\n    public Map<String, List<Catalog2Vo>> getCatalogJson2() {\r\n\r\n        //给缓存中放json字符串，拿出的json字符串，还要逆转为能用的对象类型【序列化与反序列化】\r\n\r\n        /**\r\n         * 1、空结果缓存，解决缓存穿透\r\n         * 2、设置过期时间（加随机值）：解决缓存雪崩\r\n         * 3、加锁：解决缓存击穿\r\n         */\r\n\r\n        //1、加入缓存逻辑，缓存中存放的数据是json字符串\r\n        //json跨语言，跨平台兼容\r\n        String catalogJson = stringRedisTemplate.opsForValue().get(\"catalogJson\");\r\n        if (StringUtils.isEmpty(catalogJson)) {\r\n            //2、缓存中没有，查询数据库\r\n            //保证数据库查询完成以后，将数据放在redis中，这是一个原子操作\r\n            System.out.println(\"缓存不命中。。。。将要查询数据库。。。\");\r\n            Map<String, List<Catalog2Vo>> catalogJsonFromDb = getCatalogJsonFromDbWithRedisLock();\r\n//            //3、查到的数据再放入缓存，将对象转为json放入缓存中\r\n//            String s = JSON.toJSONString(catalogJsonFromDb);\r\n//            //将数据放入缓存\r\n//            stringRedisTemplate.opsForValue().set(\"catalogJson\", s, 1, TimeUnit.DAYS);\r\n            //将数据库查到的结果直接返回，即将数据库查到的结果放一份到缓存中并返回\r\n            return catalogJsonFromDb;\r\n        }\r\n        System.out.println(\"缓存命中。。。。直接返回。。。\");\r\n        //将数据转为指定类型\r\n        Map<String, List<Catalog2Vo>> result = JSON.parseObject(catalogJson, new TypeReference<Map<String, List<Catalog2Vo>>>() {\r\n        });\r\n        return result;\r\n    }\r\n```\r\n\r\n#### 3、Redisson 完成分布式锁\r\n\r\n**1、简介**\r\n\r\nRedisson 是架设在 Redis 基础上的一个 Java 驻内存数据网格（In-Memory Data Grid）。充分\r\n的利用了 Redis 键值数据库提供的一系列优势，基于 Java 实用工具包中常用接口，为使用者\r\n提供了一系列具有分布式特性的常用工具类。使得原本作为协调单机多线程并发程序的工\r\n具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式\r\n系统的难度。同时结合各富特色的分布式服务，更进一步简化了分布式环境中程序相互之间\r\n的协作。\r\n官方文档：https://github.com/redisson/redisson/wiki/%E7%9B%AE%E5%BD%95\r\n\r\n**2、引入依赖**\r\n\r\n```xml\r\n<!--以后使用redisson作为所有分布式锁，分布式对象等功能框架 -->\r\n<dependency>\r\n    <groupId>org.redisson</groupId>\r\n    <artifactId>redisson</artifactId>\r\n    <version>3.12.0</version>\r\n</dependency>\r\n```\r\n\r\n**3、配置类**\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/7\r\n */\r\n@Configuration\r\npublic class MyRedissonConfig {\r\n\r\n    /**\r\n     * 所有对Redisson的使用都是通过RedissonClient对象\r\n     * @return\r\n     * @throws IOException\r\n     */\r\n    @Bean(destroyMethod=\"shutdown\")\r\n    public RedissonClient redisson() throws IOException {\r\n        //1、创建配置\r\n        //Redis url should start with redis:// or rediss://\r\n        Config config = new Config();\r\n        //可以用\"rediss://\"来启用 SSL 连接\r\n        config.useSingleServer().setAddress(\"redis://192.168.10.103:6379\");\r\n\r\n        //2、根据config创建出Redisson实例\r\n        RedissonClient redissonClient = Redisson.create(config);\r\n        return redissonClient;\r\n    }\r\n}\r\n```\r\n\r\n**4、使用分布式锁**\r\n\r\n```java\r\nRLock lock = redisson.getLock(\"anyLock\");// 最常见的使用方法\r\nlock.lock();\r\n// 加锁以后 10 秒钟自动解锁// 无需调用 unlock 方法手动解锁\r\nlock.lock(10, TimeUnit.SECONDS);\r\n// 尝试加锁，最多等待 100 秒，上锁以后 10 秒自动解锁 \r\nboolean res = lock.tryLock(100,10, TimeUnit.SECONDS);\r\nif (res) {\r\ntry {\r\n\t...\r\n} finally {\r\n\tlock.unlock();\r\n\t}\r\n}\r\n```\r\n\r\n- `org.klaus.zgg01mall.product.service.impl.CategoryServiceImpl#getCatalogJsonFromDbWithRedissonLock`\r\n\r\n```java\r\n/**\r\n * 缓存里面的数据如何和数据库保持一致（使用了RedissonLock）\r\n * 缓存数据一致性\r\n * 1）、双写模式\r\n * 2）、失效模式\r\n *\r\n * @return\r\n */\r\n//@Override\r\npublic Map<String, List<Catalog2Vo>> getCatalogJsonFromDbWithRedissonLock() {\r\n\r\n    //抢占锁前，每人都获取唯一id设置成lock的value值\r\n    //1、占分布式锁，去redis占坑(原子操作)\r\n    //注意：传的锁名字一样，锁就一样，锁的粒度，越细越快\r\n    //锁的粒度：具体缓存的是某个数据，11号-商品；product-11-lock  product-12-lock product-lock\r\n    RLock lock = redisson.getLock(\"catalogJson-lock\");\r\n    lock.lock();\r\n\r\n    Map<String, List<Catalog2Vo>> dataFromDb;\r\n    try {\r\n        dataFromDb = getDataFromDb();\r\n    } finally {\r\n        lock.unlock();\r\n    }\r\n    return dataFromDb;\r\n\r\n\r\n}\r\n```\r\n\r\n- 替换Redis锁业务方法为Redisson锁并返回给页面Json数据\r\n\r\n`Map<String, List<Catalog2Vo>> catalogJsonFromDb = getCatalogJsonFromDbWithRedissonLock();`\r\n\r\n**5、使用其他**\r\n\r\n**补充**\r\n\r\n- 1、获取一把锁，只要锁的名字一样，就是同一把锁\r\n  - RLock lock = redisson.getLock(\"my-lock\");\r\n- 2、加锁 阻塞式等待，(默认加的锁都是30s时间)即如果加不到锁，就会在这一直等直到加到锁为止才继续执行下去\r\n  - lock.lock();\r\n  - 1)、锁的自动续期，如果业务超长，运行期间自动给锁续上新的30s，即不用担心业务时间长而锁自动过期被删掉\r\n  - 2)、加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认在30s以后自动删除\r\n- 10秒自动解锁，自动解锁时间一定要大于业务的执行时间\r\n  - 问题：lock.lock(10, TimeUnit.SECONDS);在锁时间到了以后，不会自动续期\r\n- 1、如果我们传递了锁的超时时间，就发送给redis执行脚本，进行占锁，默认超时时间就是我们指定的时间\r\n- 2、如果我们未指定锁的超时时间，就使用30*1000【LockWatchingTimeout看门狗的默认时间】；\r\n- 只要占锁成功，就会启动一个定时任务【重新给锁设置过期时间，新的过期时间就是看门狗的默认时间】，每隔10s都会自动再次续期，续成30s\r\n- internalLockLeaseTime【看门狗时间】/  3,10s\r\n\r\n- 最佳实战\r\n- lock.lock(30, TimeUnit.SECONDS);省掉了整个续期操作，手动解锁\r\n\r\n```java\r\n@ResponseBody\r\n@GetMapping(\"/hello\")\r\npublic String hello() {\r\n\r\n    //1、获取一把锁，只要锁的名字一样，就是同一把锁\r\n    RLock lock = redisson.getLock(\"my-lock\");\r\n    //2、加锁 阻塞式等待，(默认加的锁都是30s时间)即如果加不到锁，就会在这一直等直到加到锁为止才继续执行下去\r\n    //lock.lock();\r\n    //1)、锁的自动续期，如果业务超长，运行期间自动给锁续上新的30s，即不用担心业务时间长而锁自动过期被删掉\r\n    //2)、加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认在30s以后自动删除\r\n    //10秒自动解锁，自动解锁时间一定要大于业务的执行时间\r\n    lock.lock(30, TimeUnit.SECONDS);\r\n    //todo 问题：lock.lock(10, TimeUnit.SECONDS);在锁时间到了以后，不会自动续期\r\n    //1、如果我们传递了锁的超时时间，就发送给redis执行脚本，进行占锁，默认超时时间就是我们指定的时间\r\n    //2、如果我们未指定锁的超时时间，就使用30*1000【LockWatchingTimeout看门狗的默认时间】；\r\n    //     只要占锁成功，就会启动一个定时任务【重新给锁设置过期时间，新的过期时间就是看门狗的默认时间】，每隔10s都会自动再次续期，续成30s\r\n    //     internalLockLeaseTime【看门狗时间】/  3,10s\r\n\r\n    //最佳实战\r\n    //1）、lock.lock(30, TimeUnit.SECONDS);省掉了整个续期操作，手动解锁\r\n    try {\r\n        System.out.println(\"加锁成功，执行业务。。。\" + Thread.currentThread().getId());\r\n        Thread.sleep(30000);\r\n    } catch (Exception e) {\r\n\r\n    } finally {\r\n        //3、解锁  假设解锁代码没有运行，redisson会不会出现死锁\r\n        System.out.println(\"释放锁。。。\" + Thread.currentThread().getId());\r\n        lock.unlock();\r\n    }\r\n\r\n    return \"hello\";\r\n}\r\n```\r\n\r\n**1、读+写锁**\r\n\r\n```java\r\n /**\r\n     * 保证一定读到最新数据，修改期间，写锁是一个排它锁（互斥锁、独享锁），读锁是一个共享锁\r\n     * 写锁没释放读就必须等待\r\n     * 读 + 读： 相当于无锁，并发读，只会在redis中记录好，所有当前的读锁，它们都会同时加锁成功\r\n     * 写 + 读： 等待写锁释放\r\n     * 写 + 写： 阻塞状态\r\n     * 读 + 写： 有读锁，写也需要等待\r\n     * 只要有写的存在，都必须等待\r\n     * @return\r\n     */\r\n    @ResponseBody\r\n    @GetMapping(\"/write\")\r\n    public String writeValue() {\r\n        RReadWriteLock lock = redisson.getReadWriteLock(\"rw-lock\");\r\n        String s = \"\";\r\n        RLock rLock = lock.writeLock();\r\n        try {\r\n            //1、改数据加写锁，读数据加读锁\r\n            rLock.lock();\r\n            System.out.println(\"写锁加锁成功...\" + Thread.currentThread().getId());\r\n            //v\r\n            s = UUID.randomUUID().toString();\r\n            Thread.sleep(30000);\r\n            //                                  k         v\r\n            redisTemplate.opsForValue().set(\"writeValue\", s);\r\n        } catch (Exception e) {\r\n\r\n        } finally {\r\n            rLock.unlock();\r\n            System.out.println(\"写锁释放\" + Thread.currentThread().getId());\r\n        }\r\n        return s;\r\n    }\r\n\r\n    //分布式里的锁跟JUC的API里的锁完全一样\r\n    @ResponseBody\r\n    @GetMapping(\"/read\")\r\n    public String readValue() {\r\n        RReadWriteLock lock = redisson.getReadWriteLock(\"rw-lock\");\r\n//        ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock();\r\n        String s = \"\";\r\n        RLock rLock = lock.readLock();\r\n        //1、读数据加读锁\r\n        rLock.lock();\r\n        try {\r\n            System.out.println(\"读锁加锁成功.....\" + Thread.currentThread().getId());\r\n            s = redisTemplate.opsForValue().get(\"writeValue\");\r\n            Thread.sleep(30000);\r\n        } catch (Exception e) {\r\n\r\n        } finally {\r\n            rLock.unlock();\r\n            System.out.println(\"读锁释放\" + Thread.currentThread().getId());\r\n        }\r\n        return s;\r\n    }\r\n```\r\n\r\n**2、信号量**\r\n\r\n```java\r\n/**\r\n     * 车库停车\r\n     * 3车位\r\n     * 信号量也可以用作分布式限流\r\n     * @return\r\n     */\r\n    @ResponseBody\r\n    @GetMapping(\"/park\")\r\n    public String park() throws InterruptedException {\r\n        RSemaphore park = redisson.getSemaphore(\"park\");\r\n//        park.acquire();//获取一个信号，获取一个值，占一个车位，阻塞式获取，即一定要获取到一个车位\r\n        boolean b = park.tryAcquire();//尝试获取车位，有就停，没有就算了\r\n        if (b){\r\n            //执行业务\r\n        }else {\r\n            return \"error\";\r\n        }\r\n        return \"ok=>\" + b;\r\n    }\r\n\r\n\r\n    /**\r\n     * 把车开走，腾空车位\r\n     * @return\r\n     */\r\n    @ResponseBody\r\n    @GetMapping(\"/go\")\r\n    public String go(){\r\n        RSemaphore park = redisson.getSemaphore(\"park\");\r\n        park.release();//释放一个信号(车位)\r\n        return \"ok\";\r\n    }\r\n```\r\n\r\n3、CountDownLatch闭锁\r\n\r\n```java\r\n/**\r\n * 放假 锁门\r\n * 1班没人了，2\r\n * 5个班全部都走完，我们可以锁大门\r\n * @return\r\n */\r\n@ResponseBody\r\n@GetMapping(\"/lockDoor\")\r\npublic String lockDoor() throws InterruptedException {\r\n    RCountDownLatch door = redisson.getCountDownLatch(\"door\");\r\n    door.trySetCount(5);\r\n    door.await();//等待闭锁都完成\r\n\r\n    return \"放假了...\";\r\n}\r\n\r\n@ResponseBody\r\n@GetMapping(\"/gogogo/{id}\")\r\npublic String gogogo(@PathVariable(\"id\") Long id){\r\n    RCountDownLatch door = redisson.getCountDownLatch(\"door\");\r\n    door.countDown();//计数减一\r\n\r\n    return id + \"班的人都走了...\";\r\n}\r\n```\r\n\r\n\r\n\r\n### 五、Spring Cache\r\n\r\n#### 1、简介\r\n\r\n- Spring 从 3.1 开始定义了 org.springframework.cache.Cache和 org.springframework.cache.CacheManager 接口来统一不同的缓存技术；并支持使用 JCache（JSR-107）注解简化我们开发；\r\n\r\n- Cache 接口为缓存的组件规范定义，包含缓存的各种操作集合；Cache 接口下 Spring 提供了各种 xxxCache 的实现；如 RedisCache ，EhCacheCache， ConcurrentMapCache 等；\r\n\r\n\r\n- 每次调用需要缓存功能的方法时，Spring 会检查检查指定参数的指定的目标方法是否已经被调用过；如果有就直接从缓存中获取方法调用后的结果，如果没有就调用方法并缓存结果后返回给用户。下次调用直接从缓存中获取。\r\n\r\n- 使用 Spring 缓存抽象时我们需要关注以下两点；\r\n\r\n  - 1、确定方法需要被缓存以及他们的缓存策略\r\n\r\n  - 2、从缓存中读取之前缓存存储的数据\r\n\r\n#### 2、基础概念\r\n\r\n![image-20230425221542910](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230425221542910.png)\r\n\r\n#### 3、注解\r\n\r\n![image-20230425221610523](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230425221610523.png)\r\n\r\n![image-20230425221629685](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230425221629685.png)\r\n\r\n#### 4、表达式语法\r\n\r\n![image-20230425221651923](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230425221651923.png)\r\n\r\n#### 5、缓存穿透问题解决（允许 null 值缓存）\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.boot</groupId>\r\n    <artifactId>spring-boot-starter-data-redis</artifactId>\r\n<dependency>\r\n    <groupId>org.springframework.boot</groupId>\r\n    <artifactId>spring-boot-starter-cache</artifactId>\r\n</dependency>\r\n```\r\n\r\n#### 6、使用\r\n\r\n- 添加配置类将配置文件中的所有配置都生效\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/7\r\n */\r\n@EnableConfigurationProperties(CacheProperties.class)\r\n@EnableCaching\r\n@Configuration\r\npublic class MyCacheConfig {\r\n\r\n//    @Autowired\r\n//    CacheProperties cacheProperties;\r\n\r\n    /**\r\n     * 配置文件中的东西没有用上\r\n     *\r\n     * 1、原来和配置文件绑定的配置类是这样子的\r\n     *      @ConfigurationProperties( prefix = \"spring.cache\")\r\n     *      public class CacheProperties {\r\n     * 2、要让它生效\r\n     *      @EnableConfigurationProperties(CacheProperties.class)\r\n     * @return\r\n     */\r\n    @Bean\r\n    RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties) {\r\n\r\n        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig();\r\n        //config = config.entryTtl();\r\n        //覆盖默认配置\r\n        //将数据的key序列化为字符串\r\n        config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));\r\n        //将数据的值序列化为json格式 new GenericFastJsonRedisSerializer()兼容各种泛型\r\n        config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));\r\n\r\n        CacheProperties.Redis redisProperties = cacheProperties.getRedis();\r\n        //将配置文件中的所有配置都生效\r\n        if (redisProperties.getTimeToLive() != null) {\r\n            config = config.entryTtl(redisProperties.getTimeToLive());\r\n        }\r\n\r\n        if (redisProperties.getKeyPrefix() != null) {\r\n            config = config.prefixKeysWith(redisProperties.getKeyPrefix());\r\n        }\r\n\r\n        if (!redisProperties.isCacheNullValues()) {\r\n            config = config.disableCachingNullValues();\r\n        }\r\n\r\n        if (!redisProperties.isUseKeyPrefix()) {\r\n            config = config.disableKeyPrefix();\r\n        }\r\n\r\n        return config;\r\n    }\r\n}\r\n```\r\n\r\n- 配置文件添加相关配置\r\n\r\n```properties\r\nspring.cache.type=redis\r\n#设置缓存的数据存活时间，即ttl时间（毫秒为单位）\r\nspring.cache.redis.time-to-live=3600000\r\n#todo 设置前缀名配置后，缓存的分区不见了\r\n#如果指定了前缀就用我们指定的前缀CACHE_getLevel1Categorys，没有就默认使用缓存的名字作为前缀\r\n#spring.cache.redis.key-prefix=CACHE_\r\n#不使用前缀就使用自己指定的key值作为缓存名字key = \"#root.method.name\"，getLevel1Categorys\r\nspring.cache.redis.use-key-prefix=true\r\n#是否缓存空值，防止缓存穿透\r\nspring.cache.redis.cache-null-values=true\r\n```\r\n\r\n- 获取所有分类Json数据接口`org.klaus.zgg01mall.product.web.IndexController#getCatalogJson`\r\n\r\n```java\r\n//index/catalog.json\r\n@ResponseBody\r\n@GetMapping(\"/index/catalog.json\")\r\npublic Map<String, List<Catalog2Vo>> getCatalogJson() {\r\n    Map<String, List<Catalog2Vo>> catalogJson = categoryService.getCatalogJson();\r\n    return catalogJson;\r\n}\r\n```\r\n\r\n- 获取所有分类Json数据方法实现`org.klaus.zgg01mall.product.service.impl.CategoryServiceImpl#getCatalogJson`\r\n\r\n```java\r\n/**\r\n * 加入缓存注解，再次简化缓存操作业务代码\r\n * @return\r\n */\r\n@Cacheable(value = \"category\", key = \"#root.methodName\")\r\n@Override\r\npublic Map<String, List<Catalog2Vo>> getCatalogJson() {\r\n    System.out.println(\"查询了数据库。。。\");\r\n\r\n    /**\r\n     * 缓存为空，进行查询业务\r\n     * 1、将数据库的多次查询变为一次，即方法抽取\r\n     */\r\n    //查询所有\r\n    List<CategoryEntity> selectList = baseMapper.selectList(null);\r\n\r\n    //1、查出所有1级分类                                   一级分类集合，一级分类父分类id为0\r\n    List<CategoryEntity> level1Categorys = getParent_cid(selectList, 0L);\r\n\r\n    //2、封装数据\r\n    Map<String, List<Catalog2Vo>> map = level1Categorys.stream().collect(Collectors.toMap(\r\n            //\"pCId\":\"c2{}\"\r\n            k -> k.getCatId().toString(),\r\n            v -> {\r\n                //2.1、每一个的一级分类，查到这个一级分类的[二级分类]\r\n                //得到二级分类实体集合 抽取查询方法-> baseMapper.selectList(new QueryWrapper<CategoryEntity>().eq(\"parent_cid\", v.getCatId()));\r\n                //todo                                                 父分类集合， 当前分类id（v为当前遍历的一级分类）\r\n                List<CategoryEntity> catalog2Entities = getParent_cid(selectList, v.getCatId());\r\n                //2.2、封装上面的结果\r\n                List<Catalog2Vo> catalog2Vos = null;\r\n                //父分类不为空，即二级分类实体集合不为空\r\n                if (catalog2Entities != null) {\r\n                    //遍历拿到每个二级分类集合\r\n                    catalog2Vos = catalog2Entities.stream().map(l2 -> {\r\n                        //封装二级分类vo数据\r\n                        Catalog2Vo catalog2Vo = new Catalog2Vo(v.getCatId().toString(), null, l2.getCatId().toString(), l2.getName());\r\n                        //2.2.1、找当前二级分类的三级分类封装成vo baseMapper.selectList(new QueryWrapper<CategoryEntity>(). eq(\"parent_cid\", l2.getCatId()));\r\n                        //                                       （三级分类父分类）父分类集合， 当前分类id（l2为当前遍历的二级分类）\r\n                        List<CategoryEntity> catalog3Entities = getParent_cid(selectList, l2.getCatId());\r\n                        List<Catalog2Vo.Catalog3Vo> catalog3Vos = null;\r\n                        if (catalog3Entities != null) {\r\n                            catalog3Vos = catalog3Entities.stream().map(l3 -> {\r\n                                //2.2.2、封装成指定格式\r\n                                Catalog2Vo.Catalog3Vo catalog3Vo = new Catalog2Vo.Catalog3Vo(l2.getCatId().toString(), l3.getCatId().toString(), l3.getName());\r\n                                return catalog3Vo;\r\n                            }).collect(Collectors.toList());\r\n                            catalog2Vo.setCatalog3List(catalog3Vos);\r\n                        }\r\n\r\n\r\n                        return catalog2Vo;\r\n                    }).collect(Collectors.toList());\r\n                }\r\n                return catalog2Vos;\r\n            }));\r\n    return map;\r\n}\r\n```\r\n\r\n- 首页获取一级分类响应视图渲染接口`org.klaus.zgg01mall.product.web.IndexController#indexPage`\r\n\r\n```java\r\n@GetMapping({\"/\", \"index.html\"})\r\n    public String indexPage(Model model) {\r\n//        System.out.println(\"\" + Thread.currentThread().getId());\r\n        //todo 1、查出所有的1级分类\r\n        List<CategoryEntity> categoryEntityList = categoryService.getLevel1Categorys();\r\n\r\n        //视图解析器进行拼接\r\n        //classpath:/templates/ + 返回值 +  .html\r\n        model.addAttribute(\"categorys\", categoryEntityList);\r\n        return \"index\";\r\n    }\r\n```\r\n\r\n- 首页获取一级分类方法实现`org.klaus.zgg01mall.product.service.impl.CategoryServiceImpl#getLevel1Categorys`\r\n\r\n```java\r\n@Cacheable(value = {\"category\"}, key = \"#root.method.name\", sync = true)\r\n@Override\r\npublic List<CategoryEntity> getLevel1Categorys() {\r\n    System.out.println(\"getLevel1Categorys.....\");\r\n    long l = System.currentTimeMillis();\r\n    //查出一级分类，即父分类为0\r\n    List<CategoryEntity> categoryEntities = baseMapper.selectList(new QueryWrapper<CategoryEntity>().\r\n            eq(\"parent_cid\", 0));\r\n    //System.out.println(\"消耗时间：\" + (System.currentTimeMillis() - l));\r\n    return categoryEntities;\r\n}\r\n```\r\n\r\n-  级联更新所有关联的数据方法实现`org.klaus.zgg01mall.product.service.impl.CategoryServiceImpl#updateCascade`\r\n\r\n> @CacheEvict:失效模式\r\n> 1、同时进行多种缓存操作@Caching\r\n> 2、指定删除某个分区下的所有数据@CacheEvict(value = \"category\", allEntries = true)\r\n> 3、存储同一类型的数据，都可以指定成同一个分区，分区名默认就是缓存的前缀\r\n\r\n```java\r\n//    @Caching(evict = {\r\n//            @CacheEvict(value = \"category\", key = \"'getLevel1Categorys'\"),\r\n//            @CacheEvict(value = \"category\", key = \"'getCatalogJson'\")\r\n//    })\r\n    //category::key 失效模式\r\n    @CacheEvict(value = \"category\", allEntries = true)\r\n//    @CachePut//双写模式\r\n    @Transactional\r\n    @Override\r\n    public void updateCascade(CategoryEntity category) {\r\n        //先更新自己\r\n        this.updateById(category);\r\n        categoryBrandRelationService.updateCategory(category.getCatId(), category.getName());\r\n\r\n        //同时修改缓存中的数据\r\n        //redis.del(\"catalogJSON\");等待下次主动查询进行更新\r\n    }\r\n```\r\n\r\n#### 7、总结\r\n\r\n**@Cacheable** \r\n\r\n- 1、每一个需要缓存的数据我们都来指定要放到哪个名字的缓存【缓存的分区（按照业务类型分）】\r\n\r\n- 2、 @Cacheable({\"category\"})\r\n\r\n- 代表当前方法的结果需要缓存，\r\n\r\n- 如果缓存中有，方法就不用调用；若缓存中没有，会调用方法，最后将方法的结果放入缓存\r\n\r\n- 3、默认行为\r\n\r\n    * 1）、如果缓存中有，方法就不用调用\r\n\r\n    * 2）、key默认自动生成：`缓存的名字 ::SimpleKey [](自主生成的key值)`\r\n\r\n    * 3）、缓存的value值，默认使用jdk序列化机制，将序列化后的数据存到redis\r\n\r\n    * 4）、默认ttl时间：-1\r\n\r\n    * 自定义：缓存分区：value = {\"category\"} :: 缓存名字：key = \"'level1Categorys'\"/\"#root.method.name\"\r\n        * 1）、指定生成的缓存使用的key：  key属性指定，接受一个SpEl\r\n        * SpEl详情：https://docs.spring.io/spring-framework/docs/current/reference/html/integration.html#cache-spel-cont\r\n        * 2）、指定缓存的数据的存活时间：  配置文件中修改ttl\r\n        * 3）、将数据保存为json格式\r\n\r\n- 4、Spring-Cache的不足：\r\n  - 1）、读模式:\r\n    - 缓存穿透：查询一个null数据，解决：缓存空数据：cache-null-values=true\r\n    - 缓存击穿：大量并发进来同时查询一个正好过期的数据，解决L加锁：？通过调试源码是默认为无加锁的;sync = true（加锁，解决击穿）\r\n    - 缓存雪崩：大量的key同时过期，解决：加随机时间，加上过期时间：spring.cache.redis.time-to-live=3600000\r\n  - 2）、写模式: (缓存与数据库一致)\r\n    - i）、读写加锁（适用于读多写少的系统，但读多了一直加锁等待也不合适）\r\n    - ii）、引入Canal，感知到MySql的更新去更新数据库\r\n    - iii）、读多写多，直接去数据库查询就行\r\n- 总结：\r\n  - 常规数据（读多写少，即时性，一致性要求不高的数据）：完全可以使用Spring-Cache；写模式（只要缓存的数据有过期时间就足够了）\r\n- 特殊数据：特殊设计\r\n- 原理：\r\n  - CacheManager(RedisCacheManager)->Cache(RedisCache)->Cache负责缓存的读写\r\n\r\n**整合SpringCache简化缓存开发**\r\n\r\n- 1)、引入依赖\r\n  - spring-boot-starter-cache、spring-boot-starter-data-redis\r\n- 2）、写配置\r\n  - i)、自动配置了哪些\r\n    - CacheAutoConfiguration会导入RedisCacheConfiguration\r\n    - 自动配好了缓存管理器RedisCacheManager\r\n  - ii)、配置使用redis作为缓存\r\n    - spring.cache.type=redis\r\n- 3）、测试使用缓存\r\n  - @Cacheable: Triggers cache population. ：触发将数据保存到缓存的操作\r\n  - @CacheEvict: Triggers cache eviction. ： 触发将数据从缓存中删除的操作\r\n  - @CachePut: Updates the cache without interfering with the method execution.：不影响方法执行更新缓存\r\n  - @Caching: Regroups multiple cache operations to be applied on a method.：组合以上多个操作\r\n  - @CacheConfig: Shares some common cache-related settings at class-level.：在类级别共享缓存的相同配置\r\n  - i)、开启缓存功能 @EnableCaching\r\n  - ii)、只需要使用注解就能完成缓存操作\r\n- 4)、原理：\r\n  - CacheAutoConfiguration —> RedisCacheConfiguration ->自动配置了RedisCacheManager -> 初始化所有的缓存->每个缓存决定使用什么配置->如果redisCacheConfiguration有就用已有的，没有就用默认->想改缓存的配置，只需要给容器中放一个RedisCacheConfiguration即可->就会应用到当前RedisCacheManager管理的所有缓存分区中"},{"title":"并发编程整理版-基础/同步","tags":["Thread","ReentrantLock","Synchronized"],"categories":["Java","并发编程"],"author":"imklaus","excerpt":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Concurrent_Programming-Basic+Synchronous","content":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n## 进程与线程\r\n\r\n### 概述\r\n\r\n进程：程序是静止的，进程实体的运行过程就是进程，是系统进行**资源分配的基本单位**\r\n\r\n进程的特征：并发性、异步性、动态性、独立性、结构性\r\n\r\n**线程**：线程是属于进程的，是一个基本的 CPU 执行单元，是程序执行流的最小单元。线程是进程中的一个实体，是系统**独立调度的基本单位**，线程本身不拥有系统资源，只拥有一点在运行中必不可少的资源，与同属一个进程的其他线程共享进程所拥有的全部资源\r\n\r\n关系：一个进程可以包含多个线程，这就是多线程，比如看视频是进程，图画、声音、广告等就是多个线程\r\n\r\n线程的作用：使多道程序更好的并发执行，提高资源利用率和系统吞吐量，增强操作系统的并发性能\r\n\r\n并发并行：\r\n\r\n* 并行：在同一时刻，有多个指令在多个 CPU 上同时执行\r\n* 并发：在同一时刻，有多个指令在单个 CPU 上交替执行\r\n\r\n同步异步：\r\n\r\n* 需要等待结果返回，才能继续运行就是同步\r\n* 不需要等待结果返回，就能继续运行就是异步\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 对比\r\n\r\n#### 线程进程对比\r\n\r\n* 进程基本上相互独立的，而线程存在于进程内，是进程的一个子集\r\n\r\n* 进程拥有共享的资源，如内存空间等，供其**内部的线程共享**\r\n\r\n  - 比如在Java中，当我们启动 main 函数其实就启动了一个JVM进程，而 main 函数在的线程就是这个进程中的一个线程，也称主线程。\r\n\r\n  ![程序进程线程关系](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/javathread-3.png)\r\n\r\n  > 一个进程中有多个线程，多个线程共用进程的堆和方法区资源，但是每个线程有自己的程序计数器和栈。\r\n\r\n* 进程间通信较为复杂\r\n\r\n  同一台计算机的进程通信称为 IPC（Inter-process communication）\r\n\r\n  * 信号量：信号量是一个计数器，用于多进程对共享数据的访问，解决同步相关的问题并避免竞争条件\r\n  * 共享存储：多个进程可以访问同一块内存空间，需要使用信号量用来同步对共享存储的访问\r\n  * 管道通信：管道是用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件 pipe 文件，该文件同一时间只允许一个进程访问，所以只支持**半双工通信**\r\n    * 匿名管道（Pipes）：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信\r\n    * 命名管道（Names Pipes）：以磁盘文件的方式存在，可以实现本机任意两个进程通信，遵循 FIFO\r\n  * 消息队列：内核中存储消息的链表，由消息队列标识符标识，能在不同进程之间提供**全双工通信**，对比管道：\r\n    * 匿名管道存在于内存中的文件；命名管道存在于实际的磁盘介质或者文件系统；消息队列存放在内核中，只有在内核重启（操作系统重启）或者显示地删除一个消息队列时，该消息队列才被真正删除\r\n    * 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收\r\n\r\n  不同计算机之间的**进程通信**，需要通过网络，并遵守共同的协议，例如 HTTP\r\n\r\n  * 套接字：与其它通信机制不同的是，可用于不同机器间的互相通信\r\n\r\n* 线程通信相对简单，因为线程之间共享进程内的内存，一个例子是多个线程可以访问同一个共享变量\r\n\r\n  **Java 中的通信机制**：volatile、等待/通知机制、join 方式、InheritableThreadLocal、MappedByteBuffer\r\n\r\n* 线程更轻量，线程上下文切换成本一般上要比进程上下文切换低\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n#### 进程和线程的切换\r\n\r\n**上下文切换**\r\n\r\n内核为每一个进程维持一个上下文。**上下文就是内核重新启动一个被抢占的进程所需的状态**。包括以下内容：\r\n\r\n- 通用目的寄存器\r\n- 浮点寄存器\r\n- 程序计数器\r\n- 用户栈\r\n- 状态寄存器\r\n- 内核栈\r\n- 各种内核数据结构：比如描绘地址空间的**页表**，包含有关当前进程信息的**进程表**，以及包含进程已打开文件的信息的**文件表**\r\n\r\n**进程切换和线程切换的主要区别**\r\n\r\n最主要的一个区别在于**进程切换涉及虚拟地址空间的切换而线程不会**。因为每个进程都有自己的虚拟地址空间，而**线程是共享所在进程的虚拟地址空间的**，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换，页表查找是一个很慢的过程，因此通常使用cache来缓存常用的地址映射，这样可以加速页表查找，这个cache就是快表TLB（translation Lookaside Buffer，用来加速页表查找）。由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么**当进程切换后页表也要进行切换，页表切换后TLB就失效了**，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程线程无需切换地址空间，因此我们通常说线程切换要比较进程切换快，而且还可能出现**缺页中断**，这就需要操作系统将需要的内容调入内存中，若内存已满则还需要将不用的内容调出内存，这也需要花费时间\r\n\r\n**为什么TLB能加快访问速度**\r\n\r\n快表可以避免每次都对页号进行地址的有效性判断。快表中保存了对应的物理块号，可以直接计算出物理地址，无需再进行有效性检查\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n### 并发与并行\r\n\r\n单核 cpu 下，线程实际还是 串行执行 的。操作系统中有一个组件叫做任务调度器，将 cpu 的时间片（windows\r\n下时间片最小约为 15 毫秒）分给不同的程序使用，只是由于 cpu 在线程间（时间片很短）的切换非常快，人类感\r\n觉是 同时运行的 。\r\n总结为一句话就是： 微观串行，宏观并行 ，一般会将这种 线程轮流使用 CPU 的做法称为并发（concurrent） \r\n\r\n![image-20230711144528655](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230711144528655.png)\r\n\r\n![image-20230711144538488](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230711144538488.png)\r\n\r\n多核 cpu下，每个 核（core） 都可以调度运行线程，这时候线程可以是并行的。\r\n\r\n![image-20230711144558304](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230711144558304.png)\r\n\r\n并发是一个CPU在不同的时间去不同线程中执行指令。\r\n\r\n并行是多个CPU同时处理不同的线程。\r\n\r\n引用 Rob Pike 的一段描述：\r\n\r\n- 并发（concurrent）是同一时间**应对**（dealing with）多件事情的能力\r\n- 并行（parallel）是同一时间**动手做**（doing）多件事情的能力\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n## Java 线程\r\n\r\n### 创建线程\r\n\r\n#### Thread\r\n\r\nThread 创建线程方式：创建线程类，匿名内部类方式\r\n\r\n* **start() 方法底层其实是给 CPU 注册当前线程，并且触发 run() 方法执行**\r\n* 线程的启动必须调用 start() 方法，如果线程直接调用 run() 方法，相当于变成了普通类的执行，此时主线程将只有执行该线程\r\n* 建议线程先创建子线程，主线程的任务放在之后，否则主线程（main）永远是先执行完\r\n\r\nThread 构造器：\r\n\r\n* `public Thread()`\r\n* `public Thread(String name)`\r\n\r\n```java\r\npublic class ThreadDemo {\r\n    public static void main(String[] args) {\r\n        Thread t = new MyThread();\r\n        t.start();\r\n       \tfor(int i = 0 ; i < 100 ; i++ ){\r\n            System.out.println(\"main线程\" + i)\r\n        }\r\n        // main线程输出放在上面 就变成有先后顺序了，因为是 main 线程驱动的子线程运行\r\n    }\r\n}\r\nclass MyThread extends Thread {\r\n    @Override\r\n    public void run() {\r\n        for(int i = 0 ; i < 100 ; i++ ) {\r\n            System.out.println(\"子线程输出：\"+i)\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n继承 Thread 类的优缺点：\r\n\r\n* 优点：编码简单\r\n* 缺点：线程类已经继承了 Thread 类无法继承其他类了，功能不能通过继承拓展（单继承的局限性）\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### Runnable\r\n\r\nRunnable 创建线程方式：创建线程类，匿名内部类方式\r\n\r\nThread 的构造器：\r\n\r\n* `public Thread(Runnable target)`\r\n* `public Thread(Runnable target, String name)`\r\n\r\n```java\r\npublic class ThreadDemo {\r\n    public static void main(String[] args) {\r\n        Runnable target = new MyRunnable();\r\n        Thread t1 = new Thread(target,\"1号线程\");\r\n\t\tt1.start();\r\n        Thread t2 = new Thread(target);//Thread-0\r\n    }\r\n}\r\n\r\npublic class MyRunnable implements Runnable{\r\n    @Override\r\n    public void run() {\r\n        for(int i = 0 ; i < 10 ; i++ ){\r\n            System.out.println(Thread.currentThread().getName() + \"->\" + i);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n**Thread 类本身也是实现了 Runnable 接口**，Thread 类中持有 Runnable 的属性，执行线程 run 方法底层是调用 `Runnable#run`：\r\n\r\n```java\r\npublic class Thread implements Runnable {\r\n    private Runnable target;\r\n    \r\n    public void run() {\r\n        if (target != null) {\r\n          \t// 底层调用的是 Runnable 的 run 方法\r\n            target.run();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nRunnable 方式的优缺点：\r\n\r\n* 缺点：代码复杂一点。\r\n\r\n* 优点：\r\n\r\n  1. 线程任务类只是实现了 Runnable 接口，可以继续继承其他类，避免了单继承的局限性\r\n\r\n  2. 同一个线程任务对象可以被包装成多个线程对象\r\n\r\n  3. 适合多个线程去共享同一个资源\r\n\r\n  4. 实现解耦操作，线程任务代码可以被多个线程共享，线程任务代码和线程独立\r\n\r\n  5. 线程池可以放入实现 Runnable 或 Callable 线程任务对象\r\n\r\n​     \r\n\r\n****\r\n\r\n\r\n\r\n#### Callable\r\n\r\n实现 Callable 接口：\r\n\r\n1. 定义一个线程任务类实现 Callable 接口，申明线程执行的结果类型\r\n2. 重写线程任务类的 call 方法，这个方法可以直接返回执行的结果\r\n3. 创建一个 Callable 的线程任务对象\r\n4. 把 Callable 的线程任务对象**包装成一个未来任务对象**\r\n5. 把未来任务对象包装成线程对象\r\n6. 调用线程的 start() 方法启动线程\r\n\r\n`public FutureTask(Callable<V> callable)`：未来任务对象，在线程执行完后得到线程的执行结果\r\n\r\n* FutureTask 就是 Runnable 对象，因为 **Thread 类只能执行 Runnable 实例的任务对象**，所以把 Callable 包装成未来任务对象\r\n* 线程池部分详解了 FutureTask 的源码\r\n\r\n`public V get()`：同步等待 task 执行完毕的结果，如果在线程中获取另一个线程执行结果，会阻塞等待，用于线程同步\r\n\r\n* get() 线程会阻塞等待任务执行完成\r\n* run() 执行完后会把结果设置到 FutureTask  的一个成员变量，get() 线程可以获取到该变量的值\r\n\r\n优缺点：\r\n\r\n* 优点：同 Runnable，并且能得到线程执行的结果\r\n* 缺点：编码复杂\r\n\r\n```java\r\npublic class ThreadDemo {\r\n    public static void main(String[] args) {\r\n        Callable call = new MyCallable();\r\n        FutureTask<String> task = new FutureTask<>(call);\r\n        Thread t = new Thread(task);\r\n        t.start();\r\n        try {\r\n            String s = task.get(); // 获取call方法返回的结果（正常/异常结果）\r\n            System.out.println(s);\r\n        }  catch (Exception e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n\r\npublic class MyCallable implements Callable<String> {\r\n    @Override//重写线程任务类方法\r\n    public String call() throws Exception {\r\n        return Thread.currentThread().getName() + \"->\" + \"Hello World\";\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 线程方法\r\n\r\n#### API\r\n\r\nThread 类 API：\r\n\r\n| 方法                                        | 说明                                                         |\r\n| ------------------------------------------- | ------------------------------------------------------------ |\r\n| public void start()                         | 启动一个新线程，Java虚拟机调用此线程的 run 方法              |\r\n| public void run()                           | 线程启动后调用该方法                                         |\r\n| public void setName(String name)            | 给当前线程取名字                                             |\r\n| public void getName()                       | 获取当前线程的名字<br />线程存在默认名称：子线程是 Thread-索引，主线程是 main |\r\n| public static Thread currentThread()        | 获取当前线程对象，代码在哪个线程中执行                       |\r\n| public static void sleep(long time)         | 让当前线程休眠多少毫秒再继续执行<br />**Thread.sleep(0)** : 让操作系统立刻重新进行一次 CPU 竞争 |\r\n| public static native void yield()           | 提示线程调度器让出当前线程对 CPU 的使用                      |\r\n| public final int getPriority()              | 返回此线程的优先级                                           |\r\n| public final void setPriority(int priority) | 更改此线程的优先级，常用 1 5 10                              |\r\n| public void interrupt()                     | 中断这个线程，异常处理机制                                   |\r\n| public static boolean interrupted()         | 判断当前线程是否被打断，清除打断标记                         |\r\n| public boolean isInterrupted()              | 判断当前线程是否被打断，不清除打断标记                       |\r\n| public final void join()                    | 等待这个线程结束                                             |\r\n| public final void join(long millis)         | 等待这个线程死亡 millis 毫秒，0 意味着永远等待               |\r\n| public final native boolean isAlive()       | 线程是否存活（还没有运行完毕）                               |\r\n| public final void setDaemon(boolean on)     | 将此线程标记为守护线程或用户线程                             |\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### run start\r\n\r\nrun：称为线程体，包含了要执行的这个线程的内容，方法运行结束，此线程随即终止。直接调用 run 是在主线程中执行了 run，没有启动新的线程，需要顺序执行\r\n\r\nstart：使用 start 是启动新的线程，此线程处于就绪（可运行）状态，通过新的线程间接执行 run 中的代码\r\n\r\n说明：**线程控制资源类**\r\n\r\nrun() 方法中的异常不能抛出，只能 try/catch\r\n\r\n* 因为父类中没有抛出任何异常，子类不能比父类抛出更多的异常\r\n* **异常不能跨线程传播回 main() 中**，因此必须在本地进行处理\r\n\r\n> **为什么调用start()方法时会执行run()方法，那怎么不直接调用run()方法？**\r\n>\r\n> JVM执行start方法，会先创建一条线程，由创建出来的新线程去执行thread的run方法，这才起到多线程的效果。\r\n>\r\n> ![start方法](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/javathread-5.png)\r\n>\r\n> **为什么我们不能直接调用run()方法**？也很清楚， 如果直接调用Thread的run()方法，那么run方法还是运行在主线程中，相当于顺序执行，就起不到多线程的效果。\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### sleep yield\r\n\r\nsleep：\r\n\r\n* 调用 sleep 会让当前线程从 `Running` 进入 `Timed Waiting` 状态（阻塞）\r\n* sleep() 方法的过程中，**线程不会释放对象锁**\r\n* 其它线程可以使用 interrupt 方法打断正在睡眠的线程，这时 sleep 方法会抛出 InterruptedException\r\n* 睡眠结束后的线程未必会立刻得到执行，需要抢占 CPU\r\n* 建议用 TimeUnit 的 sleep 代替 Thread 的 sleep 来获得更好的可读性\r\n\r\nyield：\r\n\r\n* 调用 yield 会让提示线程调度器让出当前线程对 CPU 的使用\r\n* 具体的实现依赖于操作系统的任务调度器\r\n* **会放弃 CPU 资源，锁资源不会释放**\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### join\r\n\r\npublic final void join()：等待这个线程结束\r\n\r\n原理：调用者轮询检查线程 alive 状态，t1.join() 等价于：\r\n\r\n```java\r\npublic final synchronized void join(long millis) throws InterruptedException {\r\n    // 调用者线程进入 thread 的 waitSet 等待, 直到当前线程运行结束\r\n    while (isAlive()) {\r\n        wait(0);\r\n    }\r\n}\r\n```\r\n\r\n* join 方法是被 synchronized 修饰的，本质上是一个对象锁，其内部的 wait 方法调用也是释放锁的，但是**释放的是当前的线程对象锁，而不是外面的锁**\r\n\r\n* 当调用某个线程（t1）的 join 方法后，该线程（t1）抢占到 CPU 资源，就不再释放，直到线程执行完毕\r\n\r\n线程同步：\r\n\r\n* join 实现线程同步，因为会阻塞等待另一个线程的结束，才能继续向下运行\r\n  * 需要外部共享变量，不符合面向对象封装的思想\r\n  * 必须等待线程结束，不能配合线程池使用\r\n* Future 实现（同步）：get() 方法阻塞等待执行结果\r\n  * main 线程接收结果\r\n  * get 方法是让调用线程同步等待\r\n\r\n```java\r\npublic class Test {\r\n    static int r = 0;\r\n    public static void main(String[] args) throws InterruptedException {\r\n        test1();\r\n    }\r\n    private static void test1() throws InterruptedException {\r\n        Thread t1 = new Thread(() -> {\r\n            try {\r\n                Thread.sleep(1000);\r\n            } catch (InterruptedException e) {\r\n                e.printStackTrace();\r\n            }\r\n            r = 10;\r\n        });\r\n        t1.start();\r\n        t1.join();//不等待线程执行结束，输出的10\r\n        System.out.println(r);\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### interrupt\r\n\r\n##### 打断线程\r\n\r\n`public void interrupt()`：打断这个线程，异常处理机制\r\n\r\n`public static boolean interrupted()`：判断当前线程是否被打断，打断返回 true，**清除打断标记**，连续调用两次一定返回 false\r\n\r\n`public boolean isInterrupted()`：判断当前线程是否被打断，不清除打断标记\r\n\r\n打断的线程会发生上下文切换，操作系统会保存线程信息，抢占到 CPU 后会从中断的地方接着运行（打断不是停止）\r\n\r\n* sleep、wait、join 方法都会让线程进入阻塞状态，打断线程**会清空打断状态**（false）\r\n\r\n  ```java\r\n  public static void main(String[] args) throws InterruptedException {\r\n      Thread t1 = new Thread(()->{\r\n          try {\r\n              Thread.sleep(1000);\r\n          } catch (InterruptedException e) {\r\n              e.printStackTrace();\r\n          }\r\n      }, \"t1\");\r\n      t1.start();\r\n      Thread.sleep(500);\r\n      t1.interrupt();\r\n      System.out.println(\" 打断状态: {}\" + t1.isInterrupted());// 打断状态: {}false\r\n  }\r\n  ```\r\n\r\n* 打断正常运行的线程：不会清空打断状态（true）\r\n\r\n  ```java\r\n  public static void main(String[] args) throws Exception {\r\n      Thread t2 = new Thread(()->{\r\n          while(true) {\r\n              Thread current = Thread.currentThread();\r\n              boolean interrupted = current.isInterrupted();\r\n              if(interrupted) {\r\n                  System.out.println(\" 打断状态: {}\" + interrupted);//打断状态: {}true\r\n                  break;\r\n              }\r\n          }\r\n      }, \"t2\");\r\n      t2.start();\r\n      Thread.sleep(500);\r\n      t2.interrupt();\r\n  }\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 打断 park\r\n\r\npark 作用类似 sleep，打断 park 线程，不会清空打断状态（true）\r\n\r\n```java\r\npublic static void main(String[] args) throws Exception {\r\n    Thread t1 = new Thread(() -> {\r\n        System.out.println(\"park...\");\r\n        LockSupport.park();\r\n        System.out.println(\"unpark...\");\r\n        System.out.println(\"打断状态：\" + Thread.currentThread().isInterrupted());//打断状态：true\r\n    }, \"t1\");\r\n    t1.start();\r\n    Thread.sleep(2000);\r\n    t1.interrupt();\r\n}\r\n```\r\n\r\n如果打断标记已经是 true, 则 park 会失效\r\n\r\n```java\r\nLockSupport.park();\r\nSystem.out.println(\"unpark...\");\r\nLockSupport.park();//失效，不会阻塞\r\nSystem.out.println(\"unpark...\");//和上一个unpark同时执行\r\n```\r\n\r\n可以修改获取打断状态方法，使用 `Thread.interrupted()`，清除打断标记\r\n\r\nLockSupport 类在 同步 → park-un 详解\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 终止模式\r\n\r\n终止模式之两阶段终止模式：Two Phase Termination\r\n\r\n目标：在一个线程 T1 中如何优雅终止线程 T2？优雅指的是给 T2 一个后置处理器\r\n\r\n错误思想：\r\n\r\n* 使用线程对象的 `stop()` 方法停止线程：stop 方法会真正杀死线程，如果这时线程锁住了共享资源，当它被杀死后就再也没有机会释放锁，其它线程将永远无法获取锁\r\n* 使用 `System.exit(int)` 方法停止线程：目的仅是停止一个线程，但这种做法会让整个程序都停止\r\n\r\n两阶段终止模式图示：\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230715001002432.png\" alt=\"image-20230715001002432\" style=\"zoom:67%;\" />\r\n\r\n打断线程可能在任何时间，所以需要考虑在任何时刻被打断的处理方法：\r\n\r\n```java\r\npublic class Test {\r\n    public static void main(String[] args) throws InterruptedException {\r\n        TwoPhaseTermination tpt = new TwoPhaseTermination();\r\n        tpt.start();\r\n        Thread.sleep(3500);\r\n        tpt.stop();\r\n    }\r\n}\r\nclass TwoPhaseTermination {\r\n    private Thread monitor;\r\n    // 启动监控线程\r\n    public void start() {\r\n        monitor = new Thread(new Runnable() {\r\n            @Override\r\n            public void run() {\r\n                while (true) {\r\n                    Thread thread = Thread.currentThread();\r\n                    if (thread.isInterrupted()) {\r\n                        System.out.println(\"后置处理\");\r\n                        break;\r\n                    }\r\n                    try {\r\n                        Thread.sleep(1000);\t\t\t\t\t// 睡眠\r\n                        System.out.println(\"执行监控记录\");\t// 在此被打断不会异常\r\n                    } catch (InterruptedException e) {\t\t// 在睡眠期间被打断，进入异常处理的逻辑\r\n                        e.printStackTrace();\r\n                        // 重新设置打断标记，打断 sleep 会清除打断状态\r\n                        thread.interrupt();\r\n                    }\r\n                }\r\n            }\r\n        });\r\n        monitor.start();\r\n    }\r\n    // 停止监控线程\r\n    public void stop() {\r\n        monitor.interrupt();\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### daemon\r\n\r\n`public final void setDaemon(boolean on)`：如果是 true ，将此线程标记为守护线程 \r\n\r\n线程**启动前**调用此方法：\r\n\r\n```java\r\nThread t = new Thread() {\r\n    @Override\r\n    public void run() {\r\n        System.out.println(\"running\");\r\n    }\r\n};\r\n// 设置该线程为守护线程\r\nt.setDaemon(true);\r\nt.start();\r\n```\r\n\r\n用户线程：平常创建的普通线程\r\n\r\n守护线程：服务于用户线程，只要其它非守护线程运行结束了，即使守护线程代码没有执行完，也会强制结束。守护进程是**脱离于终端并且在后台运行的进程**，脱离终端是为了避免在执行的过程中的信息在终端上显示\r\n\r\n说明：当运行的线程都是守护线程，Java 虚拟机将退出，因为普通线程执行完后，JVM 是守护线程，不会继续运行下去\r\n\r\n常见的守护线程：\r\n\r\n* 垃圾回收器线程就是一种守护线程\r\n* Tomcat 中的 Acceptor 和 Poller 线程都是守护线程，所以 Tomcat 接收到 shutdown 命令后，不会等待它们处理完当前请求\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 不推荐\r\n\r\n不推荐使用的方法，这些方法已过时，容易破坏同步代码块，造成线程死锁：\r\n\r\n* `public final void stop()`：停止线程运行\r\n\r\n  废弃原因：方法粗暴，除非可能执行 finally 代码块以及释放 synchronized 外，线程将直接被终止，如果线程持有 JUC 的互斥锁可能导致锁来不及释放，造成其他线程永远等待的局面\r\n\r\n* `public final void suspend()`：**挂起（暂停）线程运行**\r\n\r\n  废弃原因：如果目标线程在暂停时对系统资源持有锁，则在目标线程恢复之前没有线程可以访问该资源，如果**恢复目标线程的线程**在调用 resume 之前会尝试访问此共享资源，则会导致死锁\r\n\r\n* `public final void resume()`：恢复线程运行\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 线程原理\r\n\r\n#### 运行机制\r\n\r\nJava Virtual Machine Stacks（Java 虚拟机栈）：每个线程启动后，虚拟机就会为其分配一块栈内存\r\n\r\n* 每个栈由多个栈帧（Frame）组成，对应着每次方法调用时所占用的内存\r\n* 每个线程只能有一个活动栈帧，对应着当前正在执行的那个方法\r\n\r\n线程上下文切换（Thread Context Switch）：一些原因导致 CPU 不再执行当前线程，转而执行另一个线程\r\n\r\n* 线程的 CPU 时间片用完\r\n* 垃圾回收\r\n* 有更高优先级的线程需要运行\r\n* 线程自己调用了 sleep、yield、wait、join、park 等方法\r\n\r\n程序计数器（Program Counter Register）：记住下一条 JVM 指令的执行地址，是线程私有的\r\n\r\n当 Context Switch 发生时，需要由操作系统保存当前线程的状态（PCB 中），并恢复另一个线程的状态，包括程序计数器、虚拟机栈中每个栈帧的信息，如局部变量、操作数栈、返回地址等\r\n\r\nJVM 规范并没有限定线程模型，以 HotSpot 为例：\r\n\r\n* Java 的线程是内核级线程（1:1 线程模型），每个 Java 线程都映射到一个操作系统原生线程，需要消耗一定的内核资源（堆栈）\r\n* **线程的调度是在内核态运行的，而线程中的代码是在用户态运行**，所以线程切换（状态改变）会导致用户与内核态转换进行系统调用，这是非常消耗性能\r\n\r\nJava 中 main 方法启动的是一个进程也是一个主线程，main 方法里面的其他线程均为子线程，main 线程是这些线程的父线程\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 线程调度\r\n\r\n线程调度指系统为线程分配处理器使用权的过程，方式有两种：协同式线程调度、抢占式线程调度（Java 选择）\r\n\r\n协同式线程调度：线程的执行时间由线程本身控制\r\n\r\n* 优点：线程做完任务才通知系统切换到其他线程，相当于所有线程串行执行，不会出现线程同步问题\r\n* 缺点：线程执行时间不可控，如果代码编写出现问题，可能导致程序一直阻塞，引起系统的奔溃\r\n\r\n抢占式线程调度：线程的执行时间由系统分配\r\n\r\n* 优点：线程执行时间可控，不会因为一个线程的问题而导致整体系统不可用\r\n* 缺点：无法主动为某个线程多分配时间\r\n\r\nJava 提供了线程优先级的机制，优先级会提示（hint）调度器优先调度该线程，但这仅仅是一个提示，调度器可以忽略它。在线程的就绪状态时，如果 CPU 比较忙，那么优先级高的线程会获得更多的时间片，但 CPU 闲时，优先级几乎没作用\r\n\r\n说明：并不能通过优先级来判断线程执行的先后顺序\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 未来优化\r\n\r\n内核级线程调度的成本较大，所以引入了更轻量级的协程。用户线程的调度由用户自己实现（多对一的线程模型，多**个用户线程映射到一个内核级线程**），被设计为协同式调度，所以叫协程\r\n\r\n* 有栈协程：协程会完整的做调用栈的保护、恢复工作，所以叫有栈协程\r\n* 无栈协程：本质上是一种有限状态机，状态保存在闭包里，比有栈协程更轻量，但是功能有限\r\n\r\n有栈协程中有一种特例叫纤程，在新并发模型中，一段纤程的代码被分为两部分，执行过程和调度器：\r\n\r\n* 执行过程：用于维护执行现场，保护、恢复上下文状态\r\n* 调度器：负责编排所有要执行的代码顺序\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 线程状态\r\n\r\n#### (1)五种状态\r\n\r\n这是从 **操作系统** 层面来描述的\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608144606.png)\r\n\r\n- 【初始状态】仅是在语言层面创建了线程对象，还未与操作系统线程关联（例如线程调用了start方法）\r\n- 【可运行状态】（就绪状态）指该线程已经被创建（与操作系统线程关联），可以由 CPU 调度执行\r\n- 【运行状态】指获取了 CPU 时间片运行中的状态\r\n  - 当 CPU 时间片用完，会从【运行状态】转换至【可运行状态】，会导致线程的上下文切换\r\n- 【阻塞状态】\r\n  - 如果调用了阻塞 API，如 BIO 读写文件，这时该线程实际不会用到 CPU，会导致线程上下文切换，进入 【阻塞状态】\r\n  - 等 BIO 操作完毕，会由操作系统唤醒阻塞的线程，转换至【可运行状态】\r\n  - 与【可运行状态】的区别是，对【阻塞状态】的线程来说只要它们一直不唤醒，调度器就一直不会考虑调度它们\r\n- 【终止状态】表示线程已经执行完毕，生命周期已经结束，不会再转换为其它状态\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n#### (2)六种状态\r\n\r\n进程的状态参考操作系统：创建态、就绪态、运行态、阻塞态、终止态\r\n\r\n这是从 **Java API** 层面来描述的\r\n\r\n线程由生到死的完整过程（生命周期）：当线程被创建并启动以后，既不是一启动就进入了执行状态，也不是一直处于执行状态，在 API 中 `java.lang.Thread.State` 这个枚举中给出了六种线程状态：\r\n\r\n| 线程状态                   | 导致状态发生条件                                             |\r\n| -------------------------- | ------------------------------------------------------------ |\r\n| NEW（新建）                | 线程刚被创建，但是并未启动，还没调用 start 方法，只有线程对象，没有线程特征 |\r\n| Runnable（可运行）         | 线程可以在 Java 虚拟机中运行的状态，可能正在运行自己代码，也可能没有，这取决于操作系统处理器，调用了 `t.start()` 方法：就绪（经典叫法） |\r\n| Blocked（阻塞）            | 当一个线程试图获取一个对象锁，而该对象锁被其他的线程持有，则该线程进入 Blocked 状态；当该线程持有锁时，该线程将变成 Runnable 状态 |\r\n| Waiting（无限等待）        | 一个线程在等待另一个线程执行一个（唤醒）动作时，该线程进入 Waiting 状态，进入这个状态后不能自动唤醒，必须等待另一个线程调用 notify 或者 notifyAll 方法才能唤醒 |\r\n| Timed Waiting （限期等待） | 有几个方法有超时参数，调用将进入 Timed Waiting 状态，这一状态将一直保持到超时期满或者接收到唤醒通知。带有超时参数的常用方法有 `Thread.sleep` 、`Object.wait` |\r\n| Teminated（结束）          | run 方法正常退出而死亡，或者因为没有捕获的异常终止了 run 方法而死亡 |\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608144621.png)\r\n\r\n* NEW → RUNNABLE：当调用 `t.start()` 方法时，由 NEW → RUNNABLE\r\n\r\n* RUNNABLE ←→ WAITING：\r\n\r\n  * 调用 `obj.wait()` 方法时，t 线程从 RUNNABLE → WAITING\r\n\r\n    调用 `obj.notify()`、`obj.notifyAll()`、`t.interrupt()`：\r\n\r\n    * 竞争锁成功，t 线程从 WAITING → RUNNABLE\r\n    * 竞争锁失败，t 线程从 WAITING → BLOCKED\r\n\r\n  * 当前线程调用 `t.join()` 方法，当前线程从 RUNNABLE → WAITING\r\n\r\n    * 注意是当前线程在 t 线程对象的监视器上等待\r\n\r\n    * t 线程**运行结束**，或调用了**当前线程**的 interrupt() 时，当前线程从 WAITING → RUNNABLE\r\n\r\n  * 当前线程调用 `LockSupport.park()` 方法会让当前线程从 RUNNABLE → WAITING\r\n\r\n  * 调用 `LockSupport.unpark(目标线程)` 或调用了线程 的 `interrupt()` ，会让目标线程从 WAITING → RUNNABLE\r\n\r\n* RUNNABLE ←→ TIMED_WAITING：\r\n\r\n  * t 线程用 synchronized(obj) 获取了对象锁后\r\n    * 调用 `obj.wait(long n)` 方法、当前线程调用 `t.join(long n)` 方法、当前线程调用 `Thread.sleep(long n)`\r\n\r\n    * t 线程等待时间超过了 n 毫秒，或调用 `obj.notify()` ， `obj.notifyAll()` ， `t.interrupt()` 时\r\n      * 竞争锁成功，t 线程从 TIMED_WAITING → RUNNABLE\r\n      * 竞争锁失败，t 线程从 TIMED_WAITING → BLOCKED\r\n\r\n  * 当前线程调用 `t.join(long n)` 方法时，当前线程从 RUNNABLE → TIMED_WAITING\r\n\r\n    - 注意是当前线程在t 线程对象的监视器上等待\r\n\r\n  * 当前线程等待时间超过了 n 毫秒，或t 线程运行结束，或调用了当前线程的 `interrupt()` 时，当前线程从 TIMED_WAITING → RUNNABLE\r\n\r\n  * 当前线程调用 `Thread.sleep(long n)` ，当前线程从 RUNNABLE → TIMED_WAITING\r\n\r\n  * 当前线程等待时间超过了 n 毫秒，当前线程从 TIMED_WAITING → RUNNABLE\r\n\r\n  * 当前线程调用 `LockSupport.parkNanos(long nanos)` 或 `LockSupport.parkUntil(long millis)` 时，当前线 程从 RUNNABLE → TIMED_WAITING\r\n\r\n  * 调用 LockSupport.unpark(目标线程) 或调用了线程 的 `interrupt()` ，或是等待超时，会让目标线程从 TIMED_WAITING → RUNNABLE\r\n\r\n* RUNNABLE ←→ BLOCKED：\r\n\r\n  * t 线程用 `synchronized(obj)` 获取了对象锁时如果**竞争失败**，从 RUNNABLE → BLOCKED\r\n  * 持 obj 锁线程的同步代码块执行完毕，会唤醒该对象上所有 BLOCKED 的线程重新竞争，如果其中 t 线程竞争 成功，从 BLOCKED → RUNNABLE ，其它**失败**的线程仍然 BLOCKED\r\n\r\n* RUNNABLE → TERMINATED：当前线**程所有代码运行完毕**，进入 TERMINATED\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 查看线程\r\n\r\nWindows：\r\n\r\n* 任务管理器可以查看进程和线程数，也可以用来杀死进程\r\n* `tasklist` 查看进程\r\n* `taskkill` 杀死进程\r\n\r\nLinux：\r\n\r\n* `ps -ef` 查看所有进程\r\n* `ps -fT -p <PID>` 查看某个进程（PID）的所有线程\r\n* `kill` 杀死进程\r\n* `top` 按大写 H 切换是否显示线程\r\n* `top -H -p <PID>` 查看某个进程（PID）的所有线程\r\n\r\nJava：\r\n\r\n* `jps` 命令查看所有 Java 进程\r\n* `jstack <PID>` 查看某个 Java 进程（PID）的所有线程状态\r\n* `jconsole` 来查看某个 Java 进程中线程的运行情况（图形界面）\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n## 同步\r\n\r\n### 临界区\r\n\r\n临界资源：一次仅允许一个进程使用的资源成为临界资源\r\n\r\n临界区：访问临界资源的代码块\r\n\r\n竞态条件：多个线程在临界区内执行，由于代码的执行序列不同而导致结果无法预测，称之为发生了竞态条件\r\n\r\n一个程序运行多个线程是没有问题，多个线程读共享资源也没有问题，在多个线程对共享资源读写操作时发生指令交错，就会出现问题\r\n\r\n为了避免临界区的竞态条件发生（解决线程安全问题）：\r\n\r\n* 阻塞式的解决方案：synchronized，lock\r\n* 非阻塞式的解决方案：原子变量\r\n\r\n管程（monitor）：由局部于自己的若干公共变量和所有访问这些公共变量的过程所组成的软件模块，保证同一时刻只有一个进程在管程内活动，即管程内定义的操作在同一时刻只被一个进程调用（由编译器实现）\r\n\r\n**synchronized**：**对象锁**，**保证了临界区内代码的原子性**，采用互斥的方式让同一时刻至多只有一个线程能持有对象锁，其它线程获取这个对象锁时会阻塞，保证拥有锁的线程可以安全的执行临界区内的代码，不用担心线程上下文切换\r\n\r\n互斥和同步都可以采用 synchronized 关键字来完成，区别：\r\n\r\n* 互斥是保证临界区的竞态条件发生，同一时刻只能有一个线程执行临界区代码\r\n* 同步是由于线程执行的先后顺序不同，需要一个线程等待其它线程运行到某个点\r\n\r\n性能：\r\n\r\n* 线程安全，性能差\r\n* 线程不安全性能好，假如开发中不会存在多线程安全问题，建议使用线程不安全的设计类\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### syn-ed\r\n\r\n#### 使用锁\r\n\r\n##### 同步块\r\n\r\n锁对象：理论上可以是**任意的唯一对象**\r\n\r\nsynchronized 是可重入、不公平的重量级锁\r\n\r\n原则上：\r\n\r\n* 锁对象建议使用共享资源\r\n* 在实例方法中使用 this 作为锁对象，锁住的 this 正好是共享资源\r\n* 在静态方法中使用类名 .class 字节码作为锁对象，因为静态成员属于类，被所有实例对象共享，所以需要锁住类\r\n\r\n同步代码块格式：\r\n\r\n```java\r\nsynchronized(锁对象){\r\n\t// 访问共享资源的核心代码\r\n}\r\n```\r\n\r\n实例：\r\n\r\n```java\r\npublic class demo {\r\n    static int counter = 0;\r\n    //static修饰，则元素是属于类本身的，不属于对象  ，与类一起加载一次，只有一个\r\n    static final Object room = new Object();\r\n    public static void main(String[] args) throws InterruptedException {\r\n        Thread t1 = new Thread(() -> {\r\n            for (int i = 0; i < 5000; i++) {\r\n                synchronized (room) {\r\n                    counter++;\r\n                }\r\n            }\r\n        }, \"t1\");\r\n        Thread t2 = new Thread(() -> {\r\n            for (int i = 0; i < 5000; i++) {\r\n                synchronized (room) {\r\n                    counter--;\r\n                }\r\n            }\r\n        }, \"t2\");\r\n        t1.start();\r\n        t2.start();\r\n        t1.join();\r\n        t2.join();\r\n        System.out.println(counter);\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 同步方法\r\n\r\n把出现线程安全问题的核心方法锁起来，每次只能一个线程进入访问\r\n\r\nsynchronized 修饰的方法的不具备继承性，所以子类是线程不安全的，如果子类的方法也被 synchronized 修饰，两个锁对象其实是一把锁，而且是**子类对象作为锁**\r\n\r\n用法：直接给方法加上一个修饰符 synchronized\r\n\r\n```java\r\n//同步方法\r\n修饰符 synchronized 返回值类型 方法名(方法参数) { \r\n\t方法体；\r\n}\r\n//同步静态方法\r\n修饰符 static synchronized 返回值类型 方法名(方法参数) { \r\n\t方法体；\r\n}\r\n```\r\n\r\n同步方法底层也是有锁对象的：\r\n\r\n* 如果方法是实例方法：同步方法默认用 this 作为的锁对象\r\n\r\n  ```java\r\n  public synchronized void test() {} //等价于\r\n  public void test() {\r\n      synchronized(this) {}\r\n  }\r\n  ```\r\n\r\n* 如果方法是静态方法：同步方法默认用类名 .class 作为的锁对象\r\n\r\n  ```java\r\n  class Test{\r\n  \tpublic synchronized static void test() {}\r\n  }\r\n  //等价于\r\n  class Test{\r\n      public static void test() {\r\n          synchronized(Test.class) {}\r\n  \t}\r\n  }\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 线程八锁\r\n\r\n线程八锁就是考察 synchronized 锁住的是哪个对象，直接百度搜索相关的实例\r\n\r\n说明：主要关注锁住的对象是不是同一个\r\n\r\n* 锁住类对象，所有类的实例的方法都是安全的，类的所有实例都相当于同一把锁\r\n* 锁住 this 对象，只有在当前实例对象的线程内是安全的，如果有多个实例就不安全\r\n\r\n线程不安全：因为锁住的不是同一个对象，线程 1 调用 a 方法锁住的类对象，线程 2 调用 b 方法锁住的 n2 对象，不是同一个对象\r\n\r\n```java\r\nclass Number{\r\n    public static synchronized void a(){\r\n\t\tThread.sleep(1000);\r\n        System.out.println(\"1\");\r\n    }\r\n    public synchronized void b() {\r\n        System.out.println(\"2\");\r\n    }\r\n}\r\npublic static void main(String[] args) {\r\n    Number n1 = new Number();\r\n    Number n2 = new Number();\r\n    new Thread(()->{ n1.a(); }).start();\r\n    new Thread(()->{ n2.b(); }).start();\r\n}\r\n```\r\n\r\n线程安全：因为 n1 调用 a() 方法，锁住的是类对象，n2 调用 b() 方法，锁住的也是类对象，所以线程安全\r\n\r\n```java\r\nclass Number{\r\n    public static synchronized void a(){\r\n\t\tThread.sleep(1000);\r\n        System.out.println(\"1\");\r\n    }\r\n    public static synchronized void b() {\r\n        System.out.println(\"2\");\r\n    }\r\n}\r\npublic static void main(String[] args) {\r\n    Number n1 = new Number();\r\n    Number n2 = new Number();\r\n    new Thread(()->{ n1.a(); }).start();\r\n    new Thread(()->{ n2.b(); }).start();\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 锁原理\r\n\r\n##### Monitor\r\n\r\nMonitor 被翻译为监视器或管程\r\n\r\n每个 Java 对象都可以关联一个 Monitor 对象，Monitor 也是 class，其**实例存储在堆中**，如果使用 synchronized 给对象上锁（重量级）之后，该对象头的 Mark Word 中就被设置指向 Monitor 对象的指针，这就是重量级锁\r\n\r\n* Mark Word 结构：最后两位是**锁标志位**\r\n\r\n  ![image-20230712141854417](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712141854417.png)\r\n\r\n* 64 位虚拟机 Mark Word：\r\n\r\n  ![image-20230712141907430](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712141907430.png)\r\n\r\n工作流程：\r\n\r\n* 开始时 Monitor 中 Owner 为 null\r\n* 当 Thread-2 执行 synchronized(obj) 就会将 Monitor 的所有者 Owner 置为 Thread-2，Monitor 中只能有一个 Owner，**obj 对象的 Mark Word 指向 Monitor**，把**对象原有的 MarkWord 存入线程栈中的锁记录**中（轻量级锁部分详解）\r\n  ![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608144917.png)\r\n* 在 Thread-2 上锁的过程，Thread-3、Thread-4、Thread-5 也执行 synchronized(obj)，就会进入 EntryList BLOCKED（双向链表）\r\n* Thread-2 执行完同步代码块的内容，根据 obj 对象头中 Monitor 地址寻找，设置 Owner 为空，把线程栈的锁记录中的对象头的值设置回 MarkWord\r\n* 唤醒 EntryList 中等待的线程来竞争锁，竞争是**非公平的**，如果这时有新的线程想要获取锁，可能直接就抢占到了，阻塞队列的线程就会继续阻塞\r\n* WaitSet 中的 Thread-0，是以前获得过锁，但条件不满足进入 WAITING 状态的线程（wait-notify 机制）\r\n\r\n![image-20230712155102089](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712155102089.png)\r\n\r\n注意：\r\n\r\n* synchronized 必须是进入同一个对象的 Monitor 才有上述的效果\r\n* 不加 synchronized 的对象不会关联监视器，不遵从以上规则\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 字节码\r\n\r\n代码：\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    Object lock = new Object();\r\n    synchronized (lock) {\r\n        System.out.println(\"ok\");\r\n    }\r\n}\r\n```\r\n\r\n```java\r\n0: \tnew\t\t\t\t#2\t\t// new Object\r\n3: \tdup\r\n4: \tinvokespecial \t#1 \t\t// invokespecial <init>:()V，非虚方法\r\n7: \tastore_1 \t\t\t\t// lock引用 -> lock\r\n8: \taload_1\t\t\t\t\t// lock （synchronized开始）\r\n9: \tdup\t\t\t\t\t\t// 一份用来初始化，一份用来引用\r\n10: astore_2 \t\t\t\t// lock引用 -> slot 2\r\n11: monitorenter \t\t\t// 【将 lock对象 MarkWord 置为 Monitor 指针】\r\n12: getstatic \t\t#3\t\t// System.out\r\n15: ldc \t\t\t#4\t\t// \"ok\"\r\n17: invokevirtual \t#5 \t\t// invokevirtual println:(Ljava/lang/String;)V\r\n20: aload_2 \t\t\t\t// slot 2(lock引用)\r\n21: monitorexit \t\t\t// 【将 lock对象 MarkWord 重置, 唤醒 EntryList】\r\n22: goto 30\r\n25: astore_3 \t\t\t\t// any -> slot 3\r\n26: aload_2 \t\t\t\t// slot 2(lock引用)\r\n27: monitorexit \t\t\t// 【将 lock对象 MarkWord 重置, 唤醒 EntryList】\r\n28: aload_3\r\n29: athrow\r\n30: return\r\nException table:\r\n    from to target type\r\n      12 22 25 \t\tany\r\n      25 28 25 \t\tany\r\nLineNumberTable: ...\r\nLocalVariableTable:\r\n    Start Length Slot Name Signature\r\n    \t0 \t31 \t\t0 args [Ljava/lang/String;\r\n    \t8 \t23 \t\t1 lock Ljava/lang/Object;\r\n```\r\n\r\n说明：\r\n\r\n* 通过异常 **try-catch 机制**，确保一定会被解锁\r\n* 方法级别的 synchronized 不会在字节码指令中有所体现\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 锁升级\r\n\r\n##### 升级过程\r\n\r\n**synchronized 是可重入、不公平的重量级锁**，所以可以对其进行优化\r\n\r\n```java\r\n无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁\t// 随着竞争的增加，只能锁升级，不能降级\r\n```\r\n\r\n![image-20230824170452189](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824170452189.png)\r\n\r\n大体上省简的升级过程：\r\n\r\n![锁升级简略过程](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/javathread-36.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 偏向锁\r\n\r\n偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程之后重新获取该锁不再需要同步操作：\r\n\r\n* 当锁对象第一次被线程获得的时候进入偏向状态，标记为 101，同时**使用 CAS 操作将线程 ID 记录到 Mark Word**。如果 CAS 操作成功，这个线程以后进入这个锁相关的同步块，查看这个线程 ID 是自己的就表示没有竞争，就不需要再进行任何同步操作\r\n\r\n* 当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定或轻量级锁状态\r\n\r\n![image-20230712154420092](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712154420092.png)\r\n\r\n![image-20230712154150202](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712154150202.png)\r\n\r\n只有第一次设置对象头时才进行CAS操作（类似于刻名字）\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145109.png)\r\n\r\n\r\n\r\n一个对象创建时：\r\n\r\n* 如果开启了偏向锁（默认开启），那么对象创建后，MarkWord 值为 0x05 即最后 3 位为 101，thread、epoch、age 都为 0\r\n* 偏向锁是默认是延迟的，不会在程序启动时立即生效，如果想避免延迟，可以加 VM 参数                                                                        `-XX:BiasedLockingStartupDelay=0` 来禁用延迟。JDK 8 延迟 4s 开启偏向锁原因：在刚开始执行代码时，会有好多线程来抢锁，如果开偏向锁效率反而降低\r\n* 当一个对象已经计算过 hashCode，就再也无法进入偏向状态了\r\n* 添加 VM 参数 `-XX:-UseBiasedLocking` 禁用偏向锁\r\n\r\n**偏向状态**\r\n\r\n- Normal：一般状态，没有加任何锁，前面62位保存的是对象的信息，**最后2位为状态（01），倒数第三位表示是否使用偏向锁（未使用：0）**\r\n- Biased：偏向状态，使用偏向锁，前面54位保存的当前线程的ID，**最后2位为状态（01），倒数第三位表示是否使用偏向锁（使用：1）**\r\n- Lightweight：使用轻量级锁，前62位保存的是锁记录的指针，**最后两位为状态（00）**\r\n- Heavyweight：使用重量级锁，前62位保存的是Monitor的地址指针，**后两位为状态(10)**\r\n\r\n![image-20230712141907430](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712141907430.png)\r\n\r\n\r\n\r\n**撤销偏向**\r\n\r\n以下几种情况会使对象的偏向锁失效\r\n\r\n- 调用对象的hashCode方法\r\n\r\n  - 调用了对象的 hashCode，但偏向锁的对象 MarkWord 中存储的是线程 id，如果调用 hashCode 会导致偏向锁被撤销，因为对象头里 Mark Word 存储线程Id用了54位，剩余空间不够存储hash值(31位)了\r\n\r\n    - 轻量级锁会在锁记录中记录 hashCode\r\n\r\n    - 重量级锁会在 Monitor 中记录 hashCode\r\n\r\n- 多个线程使用该对象（当有其它线程使用偏向锁对象时，会将偏向锁升级为轻量级锁）\r\n- **调用了wait/notify方法**（wait/notify只有重量级锁才有，只有monitor才有waitset，调用wait/notify方法会导致轻量级锁或偏向锁膨胀而使用**重量级锁**）\r\n\r\n\r\n\r\n**批量重偏向**\r\n\r\n- 如果对象虽然被多个线程访问，但是线程间不存在竞争，这时偏向T1的对象仍有机会重新偏向T2，重偏向会重置Thread ID\r\n- 当撤销超过20次后（超过阈值），JVM会觉得是不是偏向错了，这时会在给对象加锁时，重新偏向至加锁线程。\r\n\r\n\r\n\r\n**批量撤销**\r\n\r\n* 批量撤销：当撤销偏向锁阈值超过 40 次后，JVM 会觉得自己确实偏向错了，根本就不该偏向，于是整个类的所有对象都会变为不可偏向的，新建的对象也是不可偏向的\r\n\r\n```java\r\nstatic Thread t1,t2,t3;\r\nprivate static void test4() throws InterruptedException {\r\n    Vector<Dog> list = new Vector<>();\r\n    int loopNumber = 39;\r\n    t1 = new Thread(() -> {\r\n        for (int i = 0; i < loopNumber; i++) {\r\n            Dog d = new Dog();\r\n            list.add(d);\r\n            synchronized (d) {\r\n                log.debug(i + \"\\t\" + ClassLayout.parseInstance(d).toPrintableSimple(true));\r\n            }\r\n        }\r\n        LockSupport.unpark(t2);\r\n    }, \"t1\");\r\n    t1.start();\r\n    t2 = new Thread(() -> {\r\n        LockSupport.park();\r\n        log.debug(\"===============> \");\r\n        for (int i = 0; i < loopNumber; i++) {\r\n            Dog d = list.get(i);\r\n            log.debug(i + \"\\t\" + ClassLayout.parseInstance(d).toPrintableSimple(true));\r\n            synchronized (d) {\r\n            \tlog.debug(i + \"\\t\" + ClassLayout.parseInstance(d).toPrintableSimple(true));\r\n            }\r\n            log.debug(i + \"\\t\" + ClassLayout.parseInstance(d).toPrintableSimple(true));\r\n        }\r\n        LockSupport.unpark(t3);\r\n    }, \"t2\");\r\n    t2.start();\r\n    t3 = new Thread(() -> {\r\n        LockSupport.park();\r\n        log.debug(\"===============> \");\r\n        for (int i = 0; i < loopNumber; i++) {\r\n            Dog d = list.get(i);\r\n            log.debug(i + \"\\t\" + ClassLayout.parseInstance(d).toPrintableSimple(true));\r\n            synchronized (d) {\r\n            \tlog.debug(i + \"\\t\" + ClassLayout.parseInstance(d).toPrintableSimple(true));\r\n            }\r\n            log.debug(i + \"\\t\" + ClassLayout.parseInstance(d).toPrintableSimple(true));\r\n        }\r\n    }, \"t3\");\r\n    t3.start();\r\n    t3.join();\r\n    log.debug(ClassLayout.parseInstance(new Dog()).toPrintableSimple(true));\r\n}\r\n```\r\n\r\n![image-20230712172438740](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712172438740.png)\r\n\r\n\r\n\r\n> **参考资料**\r\n>\r\n> - https://github.com/farmerjohngit/myblog/issues/12\r\n> - https://www.cnblogs.com/LemonFive/p/11246086.html\r\n> - https://www.cnblogs.com/LemonFive/p/11248248.html\r\n> - [偏向锁论文](https://www.oracle.com/technetwork/java/biasedlocking-oopsla2006-wp-149958.pdf)\r\n>\r\n> 锁是实例级别的，但在批量撤销（偏向锁）上是以类为单位的\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 轻量级锁\r\n\r\n一个对象有多个线程要加锁，但加锁的时间是错开的（没有竞争），可以使用轻量级锁来优化，轻量级锁对使用者是透明的（不可见）\r\n\r\n可重入锁：线程可以进入任何一个它已经拥有的锁所同步着的代码块，可重入锁最大的作用是**避免死锁**\r\n\r\n轻量级锁在没有竞争时（锁重入时），每次重入仍然需要执行 CAS 操作，Java 6 才引入的偏向锁来优化\r\n\r\n锁重入实例：\r\n\r\n```java\r\nstatic final Object obj = new Object();\r\npublic static void method1() {\r\n    synchronized( obj ) {\r\n        // 同步块 A\r\n        method2();\r\n    }\r\n}\r\npublic static void method2() {\r\n    synchronized( obj ) {\r\n    \t// 同步块 B\r\n    }\r\n}\r\n```\r\n\r\n* 创建锁记录（Lock Record）对象，每个线程的**栈帧**都会包含一个锁记录的结构，存储锁定对象的 Mark Word\r\n\r\n  ![image-20230714012545749](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230714012545749.png)\r\n\r\n* 让锁记录中 Object reference 指向锁住的对象，并尝试用 CAS 替换 Object 的 Mark Word，将 Mark Word 的值存入锁记录\r\n\r\n* 如果 CAS 替换成功，对象头中存储了锁记录地址和状态 00（轻量级锁） ，表示由该线程给对象加锁\r\n  ![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608144957.png)\r\n\r\n* 如果 CAS 失败，有两种情况：\r\n\r\n  * 如果是其它线程已经持有了该 Object 的轻量级锁，这时表明有竞争，进入锁膨胀过程\r\n  * 如果是线程自己执行了 synchronized 锁重入，就添加一条 Lock Record 作为重入的计数\r\n\r\n  ![image-20230712155321048](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712155321048.png)\r\n\r\n* 当退出 synchronized 代码块（解锁时）\r\n\r\n  * 如果有取值为 null 的锁记录，表示有重入，这时重置锁记录，表示重入计数减 1\r\n  * 如果锁记录的值不为 null，这时使用 CAS **将 Mark Word 的值恢复给对象头**\r\n    * 成功，则解锁成功\r\n    * 失败，说明轻量级锁进行了锁膨胀或已经升级为重量级锁，进入重量级锁解锁流程\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 锁膨胀\r\n\r\n在尝试加轻量级锁的过程中，CAS 操作无法成功，可能是其它线程为此对象加上了轻量级锁（有竞争），这时需要进行锁膨胀，将轻量级锁变为**重量级锁**\r\n\r\n* 当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁\r\n\r\n  ![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145004.png)\r\n\r\n* Thread-1 加轻量级锁失败，进入锁膨胀流程：Thread-1 为 Object 对象申请 Monitor 锁，**通过 Object 对象头获取到持锁线程**，将 Monitor 的 Owner 置为 Thread-0，将 Object 的对象头指向重量级锁地址，然后自己进入 Monitor 的 EntryList BLOCKED\r\n\r\n  ![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145148.png)\r\n\r\n* 当 Thread-0 退出同步块解锁时，使用 CAS 将 Mark Word 的值恢复给对象头失败，这时进入重量级解锁流程，即按照 Monitor 地址找到 Monitor 对象，设置 Owner 为 null，唤醒 EntryList 中 BLOCKED 线程\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 锁优化\r\n\r\n##### 自旋锁\r\n\r\n重量级锁竞争时，尝试获取锁的线程不会立即阻塞，可以使用**自旋**（默认 10 次）来进行优化，采用循环的方式去尝试获取锁\r\n\r\n注意：\r\n\r\n* 自旋占用 CPU 时间，单核 CPU 自旋就是浪费时间，因为同一时刻只能运行一个线程，多核 CPU 自旋才能发挥优势\r\n* 自旋失败的线程会进入阻塞状态\r\n\r\n优点：不会进入阻塞状态，**减少线程上下文切换的消耗**\r\n\r\n缺点：当自旋的线程越来越多时，会不断的消耗 CPU 资源\r\n\r\n自旋锁情况：\r\n\r\n* 自旋成功的情况：\r\n      ![image-20230714013154482](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230714013154482.png)\r\n\r\n* 自旋失败的情况：\r\n\r\n  ![image-20230714013233028](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230714013233028.png)\r\n\r\n自旋锁说明：\r\n\r\n* 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，比较智能\r\n* Java 7 之后不能控制是否开启自旋功能，由 JVM 控制\r\n\r\n```java\r\n//手写自旋锁\r\npublic class SpinLock {\r\n    // 泛型装的是Thread，原子引用线程\r\n    AtomicReference<Thread> atomicReference = new AtomicReference<>();\r\n\r\n    public void lock() {\r\n        Thread thread = Thread.currentThread();\r\n        System.out.println(thread.getName() + \" come in\");\r\n\r\n        //开始自旋，期望值为null，更新值是当前线程\r\n        while (!atomicReference.compareAndSet(null, thread)) {\r\n            Thread.sleep(1000);\r\n            System.out.println(thread.getName() + \" 正在自旋\");\r\n        }\r\n        System.out.println(thread.getName() + \" 自旋成功\");\r\n    }\r\n\r\n    public void unlock() {\r\n        Thread thread = Thread.currentThread();\r\n\r\n        //线程使用完锁把引用变为null\r\n\t\tatomicReference.compareAndSet(thread, null);\r\n        System.out.println(thread.getName() + \" invoke unlock\");\r\n    }\r\n\r\n    public static void main(String[] args) throws InterruptedException {\r\n        SpinLock lock = new SpinLock();\r\n        new Thread(() -> {\r\n            //占有锁\r\n            lock.lock();\r\n            Thread.sleep(10000); \r\n\r\n            //释放锁\r\n            lock.unlock();\r\n        },\"t1\").start();\r\n\r\n        // 让main线程暂停1秒，使得t1线程，先执行\r\n        Thread.sleep(1000);\r\n\r\n        new Thread(() -> {\r\n            lock.lock();\r\n            lock.unlock();\r\n        },\"t2\").start();\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 锁消除\r\n\r\n锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除，这是 JVM **即时编译器的优化**\r\n\r\n锁消除主要是通过**逃逸分析**来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除（同步消除：JVM 逃逸分析）\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 锁粗化\r\n\r\n对相同对象多次加锁，导致线程发生多次重入，频繁的加锁操作就会导致性能损耗，可以使用锁粗化方式优化\r\n\r\n如果虚拟机探测到一串的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部\r\n\r\n* 一些看起来没有加锁的代码，其实隐式的加了很多锁：\r\n\r\n  ```java\r\n  public static String concatString(String s1, String s2, String s3) {\r\n      return s1 + s2 + s3;\r\n  }\r\n  ```\r\n\r\n* String 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，转化为 StringBuffer 对象的连续 append() 操作，每个 append() 方法中都有一个同步块\r\n\r\n  ```java\r\n  public static String concatString(String s1, String s2, String s3) {\r\n      StringBuffer sb = new StringBuffer();\r\n      sb.append(s1);\r\n      sb.append(s2);\r\n      sb.append(s3);\r\n      return sb.toString();\r\n  }\r\n  ```\r\n\r\n扩展到第一个 append() 操作之前直至最后一个 append() 操作之后，只需要加锁一次就可以\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 多把锁\r\n\r\n多把不相干的锁：一间大屋子有两个功能睡觉、学习，互不相干。现在一人要学习，一人要睡觉，如果只用一间屋子（一个对象锁）的话，那么并发度很低\r\n\r\n将锁的粒度细分：\r\n\r\n* 好处，是可以增强并发度\r\n* 坏处，如果一个线程需要同时获得多把锁，就容易发生死锁 \r\n\r\n解决方法：准备多个对象锁\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    BigRoom bigRoom = new BigRoom();\r\n    new Thread(() -> { bigRoom.study(); }).start();\r\n    new Thread(() -> { bigRoom.sleep(); }).start();\r\n}\r\nclass BigRoom {\r\n    private final Object studyRoom = new Object();\r\n    private final Object sleepRoom = new Object();\r\n\r\n    public void sleep() throws InterruptedException {\r\n        synchronized (sleepRoom) {\r\n            System.out.println(\"sleeping 2 小时\");\r\n            Thread.sleep(2000);\r\n        }\r\n    }\r\n\r\n    public void study() throws InterruptedException {\r\n        synchronized (studyRoom) {\r\n            System.out.println(\"study 1 小时\");\r\n            Thread.sleep(1000);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 活跃性\r\n\r\n##### 死锁\r\n\r\n###### 形成\r\n\r\n死锁：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放，由于线程被无限期地阻塞，因此程序不可能正常终止\r\n\r\nJava 死锁产生的四个必要条件：\r\n\r\n1. 互斥条件，即当资源被一个线程使用（占有）时，别的线程不能使用\r\n2. 不可剥夺条件，资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占有者主动释放\r\n3. 请求和保持条件，即当资源请求者在请求其他的资源的同时保持对原有资源的占有\r\n4. 循环等待条件，即存在一个等待循环队列：p1 要 p2 的资源，p2 要 p1 的资源，形成了一个等待环路\r\n\r\n四个条件都成立的时候，便形成死锁。死锁情况下打破上述任何一个条件，便可让死锁消失\r\n\r\n```java\r\npublic class Dead {\r\n    public static Object resources1 = new Object();\r\n    public static Object resources2 = new Object();\r\n    public static void main(String[] args) {\r\n        new Thread(() -> {\r\n            // 线程1：占用资源1 ，请求资源2\r\n            synchronized(resources1){\r\n                System.out.println(\"线程1已经占用了资源1，开始请求资源2\");\r\n                Thread.sleep(2000);//休息两秒，防止线程1直接运行完成。\r\n                //2秒内线程2肯定可以锁住资源2\r\n                synchronized (resources2){\r\n                    System.out.println(\"线程1已经占用了资源2\");\r\n                }\r\n            }\r\n        }).start();\r\n        new Thread(() -> {\r\n            // 线程2：占用资源2 ，请求资源1\r\n            synchronized(resources2){\r\n                System.out.println(\"线程2已经占用了资源2，开始请求资源1\");\r\n                Thread.sleep(2000);\r\n                synchronized (resources1){\r\n                    System.out.println(\"线程2已经占用了资源1\");\r\n                }\r\n            }\r\n        }).start();\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n###### 定位\r\n\r\n定位死锁的方法：\r\n\r\n* 使用 jps 定位进程 id，再用 `jstack id` 定位死锁，找到死锁的线程去查看源码，解决优化\r\n\r\n  ```sh\r\n  \"Thread-1\" #12 prio=5 os_prio=0 tid=0x000000001eb69000 nid=0xd40 waiting formonitor entry [0x000000001f54f000]\r\n  \tjava.lang.Thread.State: BLOCKED (on object monitor)\r\n  #省略    \r\n  \"Thread-1\" #12 prio=5 os_prio=0 tid=0x000000001eb69000 nid=0xd40 waiting for monitor entry [0x000000001f54f000]\r\n  \tjava.lang.Thread.State: BLOCKED (on object monitor)\r\n  #省略\r\n  \r\n  Found one Java-level deadlock:\r\n  ===================================================\r\n  \"Thread-1\":\r\n      waiting to lock monitor 0x000000000361d378 (object 0x000000076b5bf1c0, a java.lang.Object),\r\n      which is held by \"Thread-0\"\r\n  \"Thread-0\":\r\n      waiting to lock monitor 0x000000000361e768 (object 0x000000076b5bf1d0, a java.lang.Object),\r\n      which is held by \"Thread-1\"\r\n      \r\n  Java stack information for the threads listed above:\r\n  ===================================================\r\n  \"Thread-1\":\r\n      at thread.TestDeadLock.lambda$main$1(TestDeadLock.java:28)\r\n      - waiting to lock <0x000000076b5bf1c0> (a java.lang.Object)\r\n      - locked <0x000000076b5bf1d0> (a java.lang.Object)\r\n      at thread.TestDeadLock$$Lambda$2/883049899.run(Unknown Source)\r\n      at java.lang.Thread.run(Thread.java:745)\r\n  \"Thread-0\":\r\n      at thread.TestDeadLock.lambda$main$0(TestDeadLock.java:15)\r\n      - waiting to lock <0x000000076b5bf1d0> (a java.lang.Object)\r\n      - locked <0x000000076b5bf1c0> (a java.lang.Object)\r\n      at thread.TestDeadLock$$Lambda$1/495053715\r\n  ```\r\n\r\n* Linux 下可以通过 top 先定位到 CPU 占用高的 Java 进程，再利用 `top -Hp 进程id` 来定位是哪个线程，最后再用 `jstack <pid>`的输出来看各个线程栈\r\n\r\n* 避免死锁：避免死锁要注意加锁顺序\r\n\r\n* 可以使用 jconsole 工具，在 `jdk\\bin` 目录下\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n###### 解决\r\n\r\n在线程使用锁对象时，**顺序加锁**即可避免死锁\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145450.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 活锁\r\n\r\n###### 定义\r\n\r\n活锁指的是任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试—失败—尝试—失败的过程\r\n\r\n两个线程互相改变对方的结束条件，最后谁也无法结束：\r\n\r\n```java\r\nclass TestLiveLock {\r\n    static volatile int count = 10;\r\n    static final Object lock = new Object();\r\n    public static void main(String[] args) {\r\n        new Thread(() -> {\r\n            // 期望减到 0 退出循环\r\n            while (count > 0) {\r\n                Thread.sleep(200);\r\n                count--;\r\n                System.out.println(\"线程一count:\" + count);\r\n            }\r\n        }, \"t1\").start();\r\n        new Thread(() -> {\r\n            // 期望超过 20 退出循环\r\n            while (count < 20) {\r\n                Thread.sleep(200);\r\n                count++;\r\n                System.out.println(\"线程二count:\"+ count);\r\n            }\r\n        }, \"t2\").start();\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n###### 解决\r\n\r\n在线程执行时，中途给予**不同的间隔时间**即可。\r\n\r\n**死锁与活锁的区别**\r\n\r\n- 死锁是因为线程互相持有对象想要的锁，并且都不释放，直到最后**线程阻塞**，**停止运行**的现象。\r\n- 活锁是因为线程间修改了对方的结束条件，而导致代码**一直在运行**，却一直**运行不完**的现象。\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 饥饿\r\n\r\n饥饿：一个线程由于优先级太低，始终得不到 CPU 调度执行，也不能够结束\r\n\r\n在使用顺序加锁时，可能会出现饥饿现象\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### wait-ify\r\n\r\n#### 基本使用\r\n\r\n需要获取对象锁后才可以调用 `锁对象.wait()`，notify 随机唤醒一个线程，notifyAll 唤醒所有线程去竞争 CPU\r\n\r\nObject 类 API：\r\n\r\n```java\r\npublic final void notify():唤醒正在等待对象监视器的单个线程。\r\npublic final void notifyAll():唤醒正在等待对象监视器的所有线程。\r\npublic final void wait():导致当前线程等待，直到另一个线程调用该对象的notify()方法或 notifyAll()方法。\r\npublic final native void wait(long timeout):有时限的等待, 到n毫秒后结束等待，或是被唤醒\r\n```\r\n\r\n说明：**wait 是挂起线程，需要唤醒的都是挂起操作**，阻塞线程可以自己去争抢锁，挂起的线程需要唤醒后去争抢锁\r\n\r\n对比 sleep()：\r\n\r\n* 原理不同：sleep() 方法是属于 Thread 类，是线程用来控制自身流程的，使此线程暂停执行一段时间而把执行机会让给其他线程；wait() 方法属于 Object 类，用于线程间通信\r\n* 对**锁的处理机制**不同：调用 sleep() 方法的过程中，线程不会释放对象锁，当调用 wait() 方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池（不释放锁其他线程怎么抢占到锁执行唤醒操作），但是都会释放 CPU\r\n* 使用区域不同：wait() 方法必须放在**同步控制方法和同步代码块（先获取锁）中使用**，sleep() 方法则可以放在任何地方使用\r\n\r\n底层原理：\r\n\r\n* Owner 线程发现条件不满足，调用 wait 方法，即可进入 WaitSet 变为 WAITING 状态\r\n* BLOCKED 和 WAITING 的线程都处于阻塞状态，不占用 CPU 时间片\r\n* BLOCKED 线程会在 Owner 线程释放锁时唤醒\r\n* WAITING 线程会在 Owner 线程调用 notify 或 notifyAll 时唤醒，唤醒后并不意味者立刻获得锁，**需要进入 EntryList 重新竞争**\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145204.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 代码优化\r\n\r\n虚假唤醒：notify 只能随机唤醒一个 WaitSet 中的线程，这时如果有其它线程也在等待，那么就可能唤醒不了正确的线程\r\n\r\n解决方法：采用 notifyAll\r\n\r\nnotifyAll 仅解决某个线程的唤醒问题，使用 if + wait 判断仅有一次机会，一旦条件不成立，无法重新判断\r\n\r\n解决方法：用 while + wait，当条件不成立，再次 wait\r\n\r\n```java\r\n@Slf4j(topic = \"c.demo\")\r\npublic class demo {\r\n    static final Object room = new Object();\r\n    static boolean hasCigarette = false;    //有没有烟\r\n    static boolean hasTakeout = false;\r\n\r\n    public static void main(String[] args) throws InterruptedException {\r\n        new Thread(() -> {\r\n            synchronized (room) {\r\n                log.debug(\"有烟没？[{}]\", hasCigarette);\r\n                while (!hasCigarette) {//while防止虚假唤醒\r\n                    log.debug(\"没烟，先歇会！\");\r\n                    try {\r\n                        room.wait();\r\n                    } catch (InterruptedException e) {\r\n                        e.printStackTrace();\r\n                    }\r\n                }\r\n                log.debug(\"有烟没？[{}]\", hasCigarette);\r\n                if (hasCigarette) {\r\n                    log.debug(\"可以开始干活了\");\r\n                } else {\r\n                    log.debug(\"没干成活...\");\r\n                }\r\n            }\r\n        }, \"小南\").start();\r\n\r\n        new Thread(() -> {\r\n            synchronized (room) {\r\n                Thread thread = Thread.currentThread();\r\n                log.debug(\"外卖送到没？[{}]\", hasTakeout);\r\n                if (!hasTakeout) {\r\n                    log.debug(\"没外卖，先歇会！\");\r\n                    try {\r\n                        room.wait();\r\n                    } catch (InterruptedException e) {\r\n                        e.printStackTrace();\r\n                    }\r\n                }\r\n                log.debug(\"外卖送到没？[{}]\", hasTakeout);\r\n                if (hasTakeout) {\r\n                    log.debug(\"可以开始干活了\");\r\n                } else {\r\n                    log.debug(\"没干成活...\");\r\n                }\r\n            }\r\n        }, \"小女\").start();\r\n\r\n\r\n        Thread.sleep(1000);\r\n        new Thread(() -> {\r\n        // 这里能不能加 synchronized (room)？\r\n            synchronized (room) {\r\n                hasTakeout = true;\r\n\t\t\t\t//log.debug(\"烟到了噢！\");\r\n                log.debug(\"外卖到了噢！\");\r\n                room.notifyAll();\r\n            }\r\n        }, \"送外卖的\").start();\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### park-un\r\n\r\nLockSupport 是用来创建锁和其他同步类的**线程原语**\r\n\r\nLockSupport 类方法：\r\n\r\n* `LockSupport.park()`：暂停当前线程，挂起原语\r\n* `LockSupport.unpark(暂停的线程对象)`：恢复某个线程的运行\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    Thread t1 = new Thread(() -> {\r\n        System.out.println(\"start...\");\t//1\r\n\t\tThread.sleep(1000);// Thread.sleep(3000)\r\n        // 先 park 再 unpark 和先 unpark 再 park 效果一样，都会直接恢复线程的运行\r\n        System.out.println(\"park...\");\t//2\r\n        LockSupport.park();\r\n        System.out.println(\"resume...\");//4\r\n    },\"t1\");\r\n    t1.start();\r\n   \tThread.sleep(2000);\r\n    System.out.println(\"unpark...\");\t//3\r\n    LockSupport.unpark(t1);\r\n}\r\n```\r\n\r\nLockSupport 出现就是为了增强 wait & notify 的功能：\r\n\r\n* wait，notify 和 notifyAll 必须配合 Object Monitor 一起使用，而 park、unpark 不需要\r\n* park & unpark **以线程为单位**来阻塞和唤醒线程，而 notify 只能随机唤醒一个等待线程，notifyAll 是唤醒所有等待线程\r\n* park & unpark 可以先 unpark，而 wait & notify 不能先 notify。类比生产消费，先消费发现有产品就消费，没有就等待；先生产就直接产生商品，然后线程直接消费\r\n* wait 会释放锁资源进入等待队列，**park 不会释放锁资源**，只负责阻塞当前线程，会释放 CPU\r\n\r\n原理：类似生产者消费者\r\n\r\n* 每个线程都有一个自己的**Park对象**，并且该对象由`_counter, _cond, _mutex`组成\r\n\r\n  - 先调用 park 再调用 unpark 时\r\n\r\n    - 先调用 park\r\n\r\n      - 线程运行时，会将Park对象中的 **`_counter`** **的值设为0**；\r\n      - 调用 park 时，会先查看`_counter`的值是否为0，如果为0，则将线程放入阻塞队列`_cond`中\r\n      - 放入阻塞队列中后，会**再次**将`_counter`设置为0\r\n\r\n    <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145250.png\" alt=\"img\" style=\"zoom:50%;\" />\r\n\r\n    - 然后调用unpark\r\n\r\n      - 调用unpark方法后，会将`_counter`的值设置为1\r\n\r\n      - 去唤醒阻塞队列`_cond`中的线程\r\n\r\n      - 线程继续运行并将`_counter`的值设为0\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145303.png\" alt=\"img\" style=\"zoom:50%;\" />\r\n\r\n  - 先调用unpark，再调用park\r\n    - 调用unpark\r\n      - 会将`_counter`设置为1（运行时0）\r\n    - 调用park方法\r\n      - 查看`_counter`是否为0\r\n      - 因为unpark已经把`_counter`设置为1，所以此时将`_counter`设置为0，但**不放入**阻塞队列`_cond`中\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145313.png\" alt=\"img\" style=\"zoom:50%;\" />\r\n\r\n> 当程序启动后，当前线程先park才会进入阻塞队列，无论是否先调用unpark，在调用unpark后再调用park，当前线程都不会进入阻塞队列，即阻塞失效（park-unpark-park（阻塞失效）、unpark-park-park（阻塞失效））\r\n>\r\n\r\n***\r\n\r\n\r\n\r\n### 安全分析\r\n\r\n成员变量和静态变量：\r\n\r\n* 如果它们没有共享，则线程安全\r\n* 如果它们被共享了，根据它们的状态是否能够改变，分两种情况：\r\n  * 如果只有读操作，则线程安全\r\n  * 如果有读写操作，则这段代码是临界区，需要考虑线程安全问题\r\n\r\n局部变量：\r\n\r\n* 局部变量是线程安全的\r\n* 局部变量引用的对象不一定线程安全（逃逸分析）：\r\n  * 如果该对象没有逃离方法的作用范围，它是线程安全的（每一个方法有一个栈帧）\r\n  * 如果该对象逃离方法的作用范围，需要考虑线程安全问题（暴露引用）\r\n\r\n常见线程安全类：String、Integer、StringBuffer、Random、Vector、Hashtable、java.util.concurrent 包\r\n\r\n* 线程安全指的是，多个线程调用它们同一个实例的某个方法时，是线程安全的\r\n\r\n* **每个方法是原子的，但多个方法的组合不是原子的**，只能保证调用的方法内部安全：\r\n\r\n  ```java\r\n  Hashtable table = new Hashtable();\r\n  // 线程1，线程2\r\n  if(table.get(\"key\") == null) {\r\n  \ttable.put(\"key\", value);\r\n  }\r\n  ```\r\n\r\n无状态类线程安全，就是没有成员变量的类\r\n\r\n不可变类线程安全：String、Integer 等都是不可变类，**内部的状态不可以改变**，所以方法是线程安全\r\n\r\n* replace 等方法底层是新建一个对象，复制过去\r\n\r\n  ```java\r\n  Map<String,Object> map = new HashMap<>();\t// 线程不安全\r\n  String S1 = \"...\";\t\t\t\t\t\t\t// 线程安全\r\n  final String S2 = \"...\";\t\t\t\t\t// 线程安全\r\n  Date D1 = new Date();\t\t\t\t\t\t// 线程不安全\r\n  final Date D2 = new Date();\t\t\t\t\t// 线程不安全，final让D2引用的对象不能变，但对象的内容可以变\r\n  ```\r\n\r\n抽象方法如果有参数，被重写后行为不确定可能造成线程不安全，被称之为外星方法：`public abstract foo(Student s);`\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 同步模式\r\n\r\n#### 保护性暂停\r\n\r\n##### 单任务版\r\n\r\nGuarded Suspension，用在一个线程等待另一个线程的执行结果\r\n\r\n* 有一个结果需要从一个线程传递到另一个线程，让它们关联同一个 GuardedObject\r\n* 如果有结果不断从一个线程到另一个线程那么可以使用消息队列（见生产者/消费者）\r\n* JDK 中，join 的实现、Future 的实现，采用的就是此模式\r\n\r\n![image-20230714223418977](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230714223418977.png)\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    GuardedObjectV2 object = new GuardedObjectV2();\r\n    new Thread(() -> {\r\n        sleep(1);\r\n        object.complete(Arrays.asList(\"a\", \"b\", \"c\"));\r\n    }).start();\r\n    \r\n    Object response = object.get(2500);\r\n    if (response != null) {\r\n        log.debug(\"get response: [{}] lines\", ((List<String>) response).size());\r\n    } else {\r\n        log.debug(\"can't get response\");\r\n    }\r\n}\r\n\r\nclass GuardedObject {\r\n    private Object response;\r\n    private final Object lock = new Object();\r\n\r\n    //获取结果\r\n    //timeout :最大等待时间\r\n    public Object get(long millis) {\r\n        synchronized (lock) {\r\n            // 1) 记录最初时间\r\n            long begin = System.currentTimeMillis();\r\n            // 2) 已经经历的时间\r\n            long timePassed = 0;\r\n            while (response == null) {\r\n                // 4) 假设 millis 是 1000，结果在 400 时唤醒了，那么还有 600 要等\r\n                long waitTime = millis - timePassed;\r\n                log.debug(\"waitTime: {}\", waitTime);\r\n                //经历时间超过最大等待时间退出循环\r\n                if (waitTime <= 0) {\r\n                    log.debug(\"break...\");\r\n                    break;\r\n                }\r\n                try {\r\n                    lock.wait(waitTime);\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n                // 3) 如果提前被唤醒，这时已经经历的时间假设为 400\r\n                timePassed = System.currentTimeMillis() - begin;\r\n                log.debug(\"timePassed: {}, object is null {}\",\r\n                        timePassed, response == null);\r\n            }\r\n            return response;\r\n        }\r\n    }\r\n\r\n    //产生结果\r\n    public void complete(Object response) {\r\n        synchronized (lock) {\r\n            // 条件满足，通知等待线程\r\n            this.response = response;\r\n            log.debug(\"notify...\");\r\n            lock.notifyAll();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n##### 多任务版\r\n\r\n多任务版保护性暂停：\r\n\r\n![image-20230712214912432](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712214912432.png)\r\n\r\n```java\r\n@Slf4j(topic = \"c.Test20\")\r\npublic class Test20 {\r\n    public static void main(String[] args) throws InterruptedException {\r\n        for (int i = 0; i < 3; i++) {\r\n            new People().start();\r\n        }\r\n        Sleeper.sleep(1);\r\n        for (Integer id : Mailboxes.getIds()) {\r\n            new Postman(id, \"内容\" + id).start();\r\n        }\r\n    }\r\n}\r\n\r\n@Slf4j(topic = \"c.People\")\r\nclass People extends Thread{\r\n    @Override\r\n    public void run() {\r\n        // 收信\r\n        GuardedObject guardedObject = Mailboxes.createGuardedObject();\r\n        log.debug(\"开始收信 id:{}\", guardedObject.getId());\r\n        Object mail = guardedObject.get(5000);\r\n        log.debug(\"收到信 id:{}, 内容:{}\", guardedObject.getId(), mail);\r\n    }\r\n}\r\n\r\n@Slf4j(topic = \"c.Postman\")\r\nclass Postman extends Thread {\r\n    private int id;\r\n    private String mail;\r\n\r\n    public Postman(int id, String mail) {\r\n        this.id = id;\r\n        this.mail = mail;\r\n    }\r\n\r\n    @Override\r\n    public void run() {\r\n        GuardedObject guardedObject = Mailboxes.getGuardedObject(id);\r\n        log.debug(\"送信 id:{}, 内容:{}\", id, mail);\r\n        guardedObject.complete(mail);\r\n    }\r\n}\r\n\r\nclass Mailboxes {\r\n    private static Map<Integer, GuardedObject> boxes = new Hashtable<>();\r\n\r\n    private static int id = 1;\r\n    // 产生唯一 id\r\n    private static synchronized int generateId() {\r\n        return id++;\r\n    }\r\n\r\n    public static GuardedObject getGuardedObject(int id) {\r\n        return boxes.remove(id);\r\n    }\r\n\r\n    public static GuardedObject createGuardedObject() {\r\n        GuardedObject go = new GuardedObject(generateId());\r\n        boxes.put(go.getId(), go);\r\n        return go;\r\n    }\r\n\r\n    public static Set<Integer> getIds() {\r\n        return boxes.keySet();\r\n    }\r\n}\r\n\r\n// 增加超时效果\r\n@Slf4j(topic = \"c.GuardedObject\")\r\nclass GuardedObject {\r\n\r\n    // 标识 Guarded Object\r\n    private int id;\r\n\r\n    public GuardedObject(int id) {\r\n        this.id = id;\r\n    }\r\n\r\n    public int getId() {\r\n        return id;\r\n    }\r\n\r\n    // 结果\r\n    private Object response;\r\n\r\n    private final Object lock = new Object();\r\n\r\n    // 获取结果\r\n    public Object get(long millis) {\r\n        synchronized (this) {\r\n            // 1) 记录最初时间\r\n            long last = System.currentTimeMillis();\r\n            // 2) 已经经历的时间\r\n            long timePassed = 0;\r\n            while (response == null) {\r\n                // 4) 假设 millis 是 1000，结果在 400 时唤醒了，那么还有 600 要等\r\n                long waitTime = millis - timePassed;\r\n                log.debug(\"waitTime: {}\", waitTime);\r\n                if (waitTime <= 0) {\r\n                    log.debug(\"break...\");\r\n                    break;\r\n                }\r\n                try {\r\n                    this.wait(waitTime);\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n                // 3) 如果提前被唤醒，这时已经经历的时间假设为 400\r\n                timePassed = System.currentTimeMillis() - last;\r\n                log.debug(\"timePassed: {}, object is null? {}\", timePassed, response == null);\r\n            }\r\n            return response;\r\n        }\r\n    }\r\n\r\n    // 产生结果\r\n    public void complete(Object response) {\r\n        synchronized (this) {\r\n            // 给结果成员变量赋值\r\n            this.response = response;\r\n            log.debug(\"notify...\");\r\n            this.notifyAll();\r\n        }\r\n    }\r\n}\r\n\r\n\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 顺序输出\r\n\r\n**Wait/Notify版本**\r\n\r\n```java\r\nstatic final Object LOCK = new Object();\r\n//判断先执行的内容是否执行完毕\r\nstatic Boolean judge = false;\r\npublic static void main(String[] args) {\r\n\tnew Thread(()->{\r\n\t\tsynchronized (LOCK) {\r\n\t\t\twhile (!judge) {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tLOCK.wait();\r\n\t\t\t\t} catch (InterruptedException e) {\r\n\t\t\t\t\te.printStackTrace();\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tSystem.out.println(\"2\");\r\n\t\t}\r\n\t}).start();\r\n\r\n\tnew Thread(()->{\r\n\t\tsynchronized (LOCK) {\r\n\t\t\tSystem.out.println(\"1\");\r\n\t\t\tjudge = true;\r\n               //执行完毕，唤醒所有等待线程\r\n\t\t\tLOCK.notifyAll();\r\n\t\t}\r\n\t}).start();\r\n}\r\n```\r\n\r\n**Park Unpark 版**\r\n\r\n```java\r\nThread t1 = new Thread(() -> {\r\ntry { Thread.sleep(1000); } catch (InterruptedException e) { }\r\n// 当没有『许可』时，当前线程暂停运行；有『许可』时，用掉这个『许可』，当前线程恢复运行\r\nLockSupport.park();\r\nSystem.out.println(\"1\");\r\n});\r\nThread t2 = new Thread(() -> {\r\nSystem.out.println(\"2\");\r\n// 给线程 t1 发放『许可』（多次连续调用 unpark 只会发放一个『许可』）\r\nLockSupport.unpark(t1);\r\n});\r\nt1.start();\r\nt2.start();\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 交替输出\r\n\r\n**wait/notify版本**\r\n\r\n```java\r\npublic class Test4 {\r\n\tstatic Symbol symbol = new Symbol();\r\n\tpublic static void main(String[] args) {\r\n\t\tnew Thread(()->{\r\n\t\t\tsymbol.run(\"a\", 1, 2);\r\n\t\t}).start();\r\n\r\n\t\tnew Thread(()->{\r\n\t\t\tsymbol.run(\"b\", 2, 3);\r\n\r\n\t\t}).start();\r\n\t\t\r\n\t\tnew Thread(()->{\r\n\t\t\tsymbol.run(\"c\", 3, 1);\r\n\t\t}).start();\r\n\t}\r\n}\r\n\r\nclass Symbol {\r\n\tpublic synchronized void run(String str, int flag, int nextFlag) {\r\n\t\tfor(int i=0; i<loopNumber; i++) {\r\n\t\t\twhile(flag != this.flag) {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tthis.wait();\r\n\t\t\t\t} catch (InterruptedException e) {\r\n\t\t\t\t\te.printStackTrace();\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tSystem.out.println(str);\r\n\t\t\t//设置下一个运行的线程标记\r\n\t\t\tthis.flag = nextFlag;\r\n\t\t\t//唤醒所有线程\r\n\t\t\tthis.notifyAll();\r\n\t\t}\r\n\t}\r\n\r\n\t/**\r\n\t * 线程的执行标记， 1->a 2->b 3->c\r\n\t */\r\n\tprivate int flag = 1;\r\n\tprivate int loopNumber = 5;\r\n\r\n\tpublic int getFlag() {\r\n\t\treturn flag;\r\n\t}\r\n\r\n\tpublic void setFlag(int flag) {\r\n\t\tthis.flag = flag;\r\n\t}\r\n\r\n\tpublic int getLoopNumber() {\r\n\t\treturn loopNumber;\r\n\t}\r\n\r\n\tpublic void setLoopNumber(int loopNumber) {\r\n\t\tthis.loopNumber = loopNumber;\r\n\t}\r\n}\r\n```\r\n\r\n**await/signal版本**\r\n\r\n```java\r\npublic class Test5 {\r\n\tstatic AwaitSignal awaitSignal = new AwaitSignal();\r\n\tstatic Condition conditionA = awaitSignal.newCondition();\r\n\tstatic Condition conditionB = awaitSignal.newCondition();\r\n\tstatic Condition conditionC = awaitSignal.newCondition();\r\n\tpublic static void main(String[] args) {\r\n\t\tnew Thread(()->{\r\n\t\t\tawaitSignal.run(\"a\", conditionA, conditionB);\r\n\t\t}).start();\r\n\r\n\t\tnew Thread(()->{\r\n\t\t\tawaitSignal.run(\"b\", conditionB, conditionC);\r\n\t\t}).start();\r\n\r\n\t\tnew Thread(()->{\r\n\t\t\tawaitSignal.run(\"c\", conditionC, conditionA);\r\n\t\t}).start();\r\n\r\n\r\n\t\ttry {\r\n\t\t\tThread.sleep(1000);\r\n\t\t} catch (InterruptedException e) {\r\n\t\t\te.printStackTrace();\r\n\t\t}\r\n\t\tawaitSignal.lock();\r\n\t\ttry {\r\n            //唤醒一个等待的线程\r\n\t\t\tconditionA.signal();\r\n\t\t}finally {\r\n\t\t\tawaitSignal.unlock();\r\n\t\t}\r\n\t}\r\n}\r\n\r\nclass AwaitSignal extends ReentrantLock{\r\n\tpublic void run(String str, Condition thisCondition, Condition nextCondition) {\r\n\t\tfor(int i=0; i<loopNumber; i++) {\r\n\t\t\tlock();\r\n\t\t\ttry {\r\n                //全部进入等待状态\r\n\t\t\t\tthisCondition.await();\r\n\t\t\t\tSystem.out.print(str);\r\n\t\t\t\tnextCondition.signal();\r\n\t\t\t} catch (InterruptedException e) {\r\n\t\t\t\te.printStackTrace();\r\n\t\t\t} finally {\r\n\t\t\t\tunlock();\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\tprivate int loopNumber=5;\r\n\r\n\tpublic int getLoopNumber() {\r\n\t\treturn loopNumber;\r\n\t}\r\n\r\n\tpublic void setLoopNumber(int loopNumber) {\r\n\t\tthis.loopNumber = loopNumber;\r\n\t}\r\n}\r\n```\r\n\r\n**Park Unpark 版**\r\n\r\n```java\r\n@Slf4j(topic = \"c.Test31\")\r\npublic class Test31 {\r\n\r\n    static Thread t1;\r\n    static Thread t2;\r\n    static Thread t3;\r\n    public static void main(String[] args) {\r\n        ParkUnpark pu = new ParkUnpark(5);\r\n        t1 = new Thread(() -> {\r\n            pu.print(\"a\", t2);\r\n        });\r\n        t2 = new Thread(() -> {\r\n            pu.print(\"b\", t3);\r\n        });\r\n        t3 = new Thread(() -> {\r\n            pu.print(\"c\", t1);\r\n        });\r\n        t1.start();\r\n        t2.start();\r\n        t3.start();\r\n\r\n        LockSupport.unpark(t1);\r\n    }\r\n}\r\n\r\nclass ParkUnpark {\r\n    public void print(String str, Thread next) {\r\n        for (int i = 0; i < loopNumber; i++) {\r\n            LockSupport.park();\r\n            System.out.print(str);\r\n            LockSupport.unpark(next);\r\n        }\r\n    }\r\n\r\n    private int loopNumber;\r\n\r\n    public ParkUnpark(int loopNumber) {\r\n        this.loopNumber = loopNumber;\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 异步模式\r\n\r\n#### 传统版\r\n\r\n异步模式之生产者/消费者：\r\n\r\n```java\r\nclass ShareData {\r\n    private int number = 0;\r\n    private Lock lock = new ReentrantLock();\r\n    private Condition condition = lock.newCondition();\r\n\r\n    public void increment() throws Exception{\r\n        // 同步代码块，加锁\r\n        lock.lock();\r\n        try {\r\n            // 判断  防止虚假唤醒\r\n            while(number != 0) {\r\n                // 等待不能生产\r\n                condition.await();\r\n            }\r\n            // 干活\r\n            number++;\r\n            System.out.println(Thread.currentThread().getName() + \"\\t \" + number);\r\n            // 通知 唤醒\r\n            condition.signalAll();\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }\r\n\r\n    public void decrement() throws Exception{\r\n        // 同步代码块，加锁\r\n        lock.lock();\r\n        try {\r\n            // 判断 防止虚假唤醒\r\n            while(number == 0) {\r\n                // 等待不能消费\r\n                condition.await();\r\n            }\r\n            // 干活\r\n            number--;\r\n            System.out.println(Thread.currentThread().getName() + \"\\t \" + number);\r\n            // 通知 唤醒\r\n            condition.signalAll();\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }\r\n}\r\n\r\npublic class TraditionalProducerConsumer {\r\n\tpublic static void main(String[] args) {\r\n        ShareData shareData = new ShareData();\r\n        // t1线程，生产\r\n        new Thread(() -> {\r\n            for (int i = 0; i < 5; i++) {\r\n            \tshareData.increment();\r\n            }\r\n        }, \"t1\").start();\r\n\r\n        // t2线程，消费\r\n        new Thread(() -> {\r\n            for (int i = 0; i < 5; i++) {\r\n\t\t\t\tshareData.decrement();\r\n            }\r\n        }, \"t2\").start(); \r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n#### 改进版\r\n\r\n异步模式之生产者/消费者：\r\n\r\n* 消费队列可以用来平衡生产和消费的线程资源，不需要产生结果和消费结果的线程一一对应\r\n* 生产者仅负责产生结果数据，不关心数据该如何处理，而消费者专心处理结果数据\r\n* 消息队列是有容量限制的，满时不会再加入数据，空时不会再消耗数据\r\n* JDK 中各种阻塞队列，采用的就是这种模式\r\n\r\n![image-20230712221519679](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230712221519679.png)\r\n\r\n```java\r\npublic class demo {\r\n    public static void main(String[] args) {\r\n        MessageQueue queue = new MessageQueue(2);\r\n        for (int i = 0; i < 3; i++) {\r\n            int id = i;\r\n            new Thread(() -> {\r\n                queue.put(new Message(id,\"值\"+id));\r\n            }, \"生产者\" + i).start();\r\n        }\r\n        \r\n        new Thread(() -> {\r\n            while (true) {\r\n                try {\r\n                    Thread.sleep(1000);\r\n                    Message message = queue.take();\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        },\"消费者\").start();\r\n    }\r\n}\r\n\r\n//消息队列类，Java间线程之间通信\r\nclass MessageQueue {\r\n    private LinkedList<Message> list = new LinkedList<>();//消息的队列集合\r\n    private int capacity;//队列容量\r\n    public MessageQueue(int capacity) {\r\n        this.capacity = capacity;\r\n    }\r\n\r\n    //获取消息\r\n    public Message take() {\r\n        //检查队列是否为空\r\n        synchronized (list) {\r\n            while (list.isEmpty()) {\r\n                try {\r\n                    sout(Thread.currentThread().getName() + \":队列为空，消费者线程等待\");\r\n                    list.wait();\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n            //从队列的头部获取消息返回\r\n            Message message = list.removeFirst();\r\n            sout(Thread.currentThread().getName() + \"：已消费消息--\" + message);\r\n            list.notifyAll();\r\n            return message;\r\n        }\r\n    }\r\n\r\n    //存入消息\r\n    public void put(Message message) {\r\n        synchronized (list) {\r\n            //检查队列是否满\r\n            while (list.size() == capacity) {\r\n                try {\r\n                    sout(Thread.currentThread().getName()+\":队列为已满，生产者线程等待\");\r\n                    list.wait();\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n            //将消息加入队列尾部\r\n            list.addLast(message);\r\n            sout(Thread.currentThread().getName() + \":已生产消息--\" + message);\r\n            list.notifyAll();\r\n        }\r\n    }\r\n}\r\n\r\nfinal class Message {\r\n    private int id;\r\n    private Object value;\r\n\t//get set\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 阻塞队列\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    ExecutorService consumer = Executors.newFixedThreadPool(1);\r\n    ExecutorService producer = Executors.newFixedThreadPool(1);\r\n    BlockingQueue<Integer> queue = new SynchronousQueue<>();\r\n    producer.submit(() -> {\r\n        try {\r\n            System.out.println(\"生产...\");\r\n            Thread.sleep(1000);\r\n            queue.put(10);\r\n        } catch (InterruptedException e) {\r\n            e.printStackTrace();\r\n        }\r\n    });\r\n    consumer.submit(() -> {\r\n        try {\r\n            System.out.println(\"等待消费...\");\r\n            Integer result = queue.take();\r\n            System.out.println(\"结果为:\" + result);\r\n        } catch (InterruptedException e) {\r\n            e.printStackTrace();\r\n        }\r\n    });\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n\r\n\r\n"},{"title":"并发编程整理版-JUC","tags":["ConcurrentHashMap","CopyOnWriteArrayList","SkipListMap","ConcurrentLinkedQueue"],"categories":["Java","并发编程"],"author":"imklaus","excerpt":"\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\n\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\n\n","link":"/posts/Concurrent_Programming-JUC","content":"\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\n\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\n\n<!-- more -->\n\n## 并发包\n\n### ConHashMap\n\n#### 并发集合\n\n##### 集合对比\n\n三种集合：\n\n* HashMap 是线程不安全的，性能好\n* Hashtable 线程安全基于 synchronized，综合性能差，已经被淘汰\n* ConcurrentHashMap 保证了线程安全，综合性能较好，不止线程安全，而且效率高，性能好\n\n集合对比：\n\n1. Hashtable 继承 Dictionary 类，HashMap、ConcurrentHashMap 继承 AbstractMap，均实现 Map 接口\n2. Hashtable 底层是数组 + 链表，JDK8 以后 HashMap 和 ConcurrentHashMap 底层是数组 + 链表 + 红黑树\n3. HashMap 线程非安全，Hashtable 线程安全，Hashtable 的方法都加了 synchronized 关来确保线程同步\n4. ConcurrentHashMap、Hashtable **不允许 null 值**，HashMap 允许 null 值\n5. ConcurrentHashMap、HashMap 的初始容量为 16，Hashtable 初始容量为11，填充因子默认都是 0.75，两种 Map 扩容是当前容量翻倍：capacity * 2，Hashtable 扩容时是容量翻倍 + 1：capacity*2 + 1\n\n![image-20230824175111596](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824175111596.png)\n\n工作步骤：\n\n1. 初始化，使用 cas 来保证并发安全，懒惰初始化 table\n\n2. 树化，当 table.length < 64 时，先尝试扩容，超过 64 时，并且 bin.length > 8 时，会将**链表树化**，树化过程会用 synchronized 锁住链表头\n\n   说明：锁住某个槽位的对象头，是一种很好的**细粒度的加锁**方式，类似 MySQL 中的行锁\n\n3. put，如果该 bin 尚未创建，只需要使用 cas 创建 bin；如果已经有了，锁住链表头进行后续 put 操作，元素添加至 bin 的尾部\n\n4. get，无锁操作仅需要保证可见性，扩容过程中 get 操作拿到的是 ForwardingNode 会让 get 操作在新 table 进行搜索\n\n5. 扩容，扩容时以 bin 为单位进行，需要对 bin 进行 synchronized，但这时其它竞争线程也不是无事可做，它们会帮助把其它 bin 进行扩容\n\n6. size，元素个数保存在 baseCount 中，并发时的个数变动保存在 CounterCell[] 当中，最后统计数量时累加\n\n```java\n//需求：多个线程同时往HashMap容器中存入数据会出现安全问题\npublic class ConcurrentHashMapDemo{\n    public static Map<String,String> map = new ConcurrentHashMap();\n    \n    public static void main(String[] args){\n        new AddMapDataThread().start();\n        new AddMapDataThread().start();\n        \n        Thread.sleep(1000 * 5);//休息5秒，确保两个线程执行完毕\n        System.out.println(\"Map大小：\" + map.size());//20万\n    }\n}\n\npublic class AddMapDataThread extends Thread{\n    @Override\n    public void run() {\n        for(int i = 0 ; i < 1000000 ; i++ ){\n            ConcurrentHashMapDemo.map.put(\"键：\"+i , \"值\"+i);\n        }\n    }\n}\n```\n\n\n\n****\n\n\n\n##### 并发死链\n\nJDK1.7 的 HashMap 采用的头插法（拉链法）进行节点的添加，HashMap 的扩容长度为原来的 2 倍\n\nresize() 中节点（Entry）转移的源代码：\n\n```java\nvoid transfer(Entry[] newTable, boolean rehash) {\n    int newCapacity = newTable.length;//得到新数组的长度   \n    // 遍历整个数组对应下标下的链表，e代表一个节点\n    for (Entry<K,V> e : table) {   \n        // 当e == null时，则该链表遍历完了，继续遍历下一数组下标的链表 \n        while(null != e) { \n            // 先把e节点的下一节点存起来\n            Entry<K,V> next = e.next; \n            if (rehash) {              //得到新的hash值\n                e.hash = null == e.key ? 0 : hash(e.key);  \n            }\n            // 在新数组下得到新的数组下标\n            int i = indexFor(e.hash, newCapacity);  \n             // 将e的next指针指向新数组下标的位置\n            e.next = newTable[i];   \n            // 将该数组下标的节点变为e节点\n            newTable[i] = e; \n            // 遍历链表的下一节点\n            e = next;                                   \n        }\n    }\n}\n```\n\nJDK 8 虽然将扩容算法做了调整，改用了尾插法，但仍不意味着能够在多线程环境下能够安全扩容，还会出现其它问题（如扩容丢数据）\n\n\n\nB站视频解析：https://www.bilibili.com/video/BV1n541177Ea\n\n\n\n***\n\n\n\n#### 成员属性\n\n##### 变量\n\n* 存储数组：\n\n  ```java\n  transient volatile Node<K,V>[] table;\n  ```\n\n* 散列表的长度：\n\n  ```java\n  private static final int MAXIMUM_CAPACITY = 1 << 30;\t// 最大长度\n  private static final int DEFAULT_CAPACITY = 16;\t\t\t// 默认长度\n  ```\n\n* 并发级别，JDK7 遗留下来，1.8 中不代表并发级别：\n\n  ```java\n  private static final int DEFAULT_CONCURRENCY_LEVEL = 16;\n  ```\n\n* 负载因子，JDK1.8 的 ConcurrentHashMap 中是固定值：\n\n  ```java\n  private static final float LOAD_FACTOR = 0.75f;\n  ```\n\n* 阈值：\n\n  ```java\n  static final int TREEIFY_THRESHOLD = 8;\t\t// 链表树化的阈值\n  static final int UNTREEIFY_THRESHOLD = 6;\t// 红黑树转化为链表的阈值\n  static final int MIN_TREEIFY_CAPACITY = 64;\t// 当数组长度达到64且某个桶位中的链表长度超过8，才会真正树化\n  ```\n\n* 扩容相关：\n\n  ```java\n  private static final int MIN_TRANSFER_STRIDE = 16;\t// 线程迁移数据【最小步长】，控制线程迁移任务的最小区间\n  private static int RESIZE_STAMP_BITS = 16;\t\t\t// 用来计算扩容时生成的【标识戳】\n  private static final int MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1;// 65535-1并发扩容最多线程数\n  private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;\t\t// 扩容时使用\n  ```\n\n* 节点哈希值：\n\n  ```java\n  static final int MOVED     = -1; \t\t\t// 表示当前节点是 FWD 节点\n  static final int TREEBIN   = -2; \t\t\t// 表示当前节点已经树化，且当前节点为 TreeBin 对象\n  static final int RESERVED  = -3; \t\t\t// 表示节点时临时节点\n  static final int HASH_BITS = 0x7fffffff; \t// 正常节点的哈希值的可用的位数\n  ```\n\n* 扩容过程：volatile 修饰保证多线程的可见性\n\n  ```java\n  // 扩容过程中，会将扩容中的新 table 赋值给 nextTable 保持引用，扩容结束之后，这里会被设置为 null\n  private transient volatile Node<K,V>[] nextTable;\n  // 记录扩容进度，所有线程都要从 0 - transferIndex 中分配区间任务，简单说就是老表转移到哪了，索引从高到低转移\n  private transient volatile int transferIndex;\n  ```\n\n* 累加统计：\n\n  ```java\n  // LongAdder 中的 baseCount 未发生竞争时或者当前LongAdder处于加锁状态时，增量累到到 baseCount 中\n  private transient volatile long baseCount;\n  // LongAdder 中的 cellsBuzy，0 表示当前 LongAdder 对象无锁状态，1 表示当前 LongAdder 对象加锁状态\n  private transient volatile int cellsBusy;\n  // LongAdder 中的 cells 数组，\n  private transient volatile CounterCell[] counterCells;\n  ```\n\n* 控制变量：\n\n  **sizeCtl** < 0：\n\n  * -1 表示当前 table 正在初始化（有线程在创建 table 数组），当前线程需要自旋等待\n\n  * 其他负数表示当前 map 的 table 数组正在进行扩容，高 16 位表示扩容的标识戳；低 16 位表示 (1 + nThread) 当前参与并发扩容的线程数量 + 1\n\n  sizeCtl = 0，表示创建 table 数组时使用 DEFAULT_CAPACITY 为数组大小\n\n  sizeCtl > 0：\n\n  * 如果 table 未初始化，表示初始化大小\n  * 如果 table 已经初始化，表示下次扩容时的触发条件（阈值，元素个数，不是数组的长度）\n\n  ```java\n  private transient volatile int sizeCtl;\t\t// volatile 保持可见性\n  ```\n\n\n\n***\n\n\n\n##### 内部类\n\n* Node 节点：\n\n  ```java\n  static class Node<K,V> implements Entry<K,V> {\n      // 节点哈希值\n      final int hash;\n      final K key;\n      volatile V val;\n      // 单向链表\n      volatile Node<K,V> next;\n  }\n  ```\n\n* TreeBin 节点：\n\n  ```java\n   static final class TreeBin<K,V> extends Node<K,V> {\n       // 红黑树根节点\n       TreeNode<K,V> root;\n       // 链表的头节点\n       volatile TreeNode<K,V> first;\n       // 等待者线程\n       volatile Thread waiter;\n  \n       volatile int lockState;\n       // 写锁状态 写锁是独占状态，以散列表来看，真正进入到 TreeBin 中的写线程同一时刻只有一个线程\n       static final int WRITER = 1;\n       // 等待者状态（写线程在等待），当 TreeBin 中有读线程目前正在读取数据时，写线程无法修改数据\n       static final int WAITER = 2;\n       // 读锁状态是共享，同一时刻可以有多个线程 同时进入到 TreeBi 对象中获取数据，每一个线程都给 lockState + 4\n       static final int READER = 4;\n   }\n  ```\n\n* TreeNode 节点：\n\n  ```java\n  static final class TreeNode<K,V> extends Node<K,V> {\n      TreeNode<K,V> parent;  // red-black tree links\n      TreeNode<K,V> left;\n      TreeNode<K,V> right;\n      TreeNode<K,V> prev;   //双向链表\n      boolean red;\n  }\n  ```\n\n* ForwardingNode 节点：转移节点\n\n  ```java\n   static final class ForwardingNode<K,V> extends Node<K,V> {\n       // 持有扩容后新的哈希表的引用\n       final Node<K,V>[] nextTable;\n       ForwardingNode(Node<K,V>[] tab) {\n           // ForwardingNode 节点的 hash 值设为 -1\n           super(MOVED, null, null, null);\n           this.nextTable = tab;\n       }\n   }\n  ```\n\n\n\n***\n\n\n\n##### 代码块\n\n* 变量：\n\n  ```java\n  // 表示sizeCtl属性在 ConcurrentHashMap 中内存偏移地址\n  private static final long SIZECTL;\n  // 表示transferIndex属性在 ConcurrentHashMap 中内存偏移地址\n  private static final long TRANSFERINDEX;\n  // 表示baseCount属性在 ConcurrentHashMap 中内存偏移地址\n  private static final long BASECOUNT;\n  // 表示cellsBusy属性在 ConcurrentHashMap 中内存偏移地址\n  private static final long CELLSBUSY;\n  // 表示cellValue属性在 CounterCell 中内存偏移地址\n  private static final long CELLVALUE;\n  // 表示数组第一个元素的偏移地址\n  private static final long ABASE;\n  // 用位移运算替代乘法\n  private static final int ASHIFT;\n  ```\n\n* 赋值方法：\n\n  ```java\n  // 表示数组单元所占用空间大小，scale 表示 Node[] 数组中每一个单元所占用空间大小，int 是 4 字节\n  int scale = U.arrayIndexScale(ak);\n  // 判断一个数是不是 2 的 n 次幂，比如 8：1000 & 0111 = 0000\n  if ((scale & (scale - 1)) != 0)\n      throw new Error(\"data type scale not a power of two\");\n  \n  // numberOfLeadingZeros(n)：返回当前数值转换为二进制后，从高位到低位开始统计，看有多少个0连续在一起\n  // 8 → 1000 numberOfLeadingZeros(8) = 28\n  // 4 → 100 numberOfLeadingZeros(4) = 29   int 值就是占4个字节\n  ASHIFT = 31 - Integer.numberOfLeadingZeros(scale);\n  \n  // ASHIFT = 31 - 29 = 2 ，int 的大小就是 2 的 2 次方，获取次方数\n  // ABASE + （5 << ASHIFT） 用位移运算替代了乘法，获取 arr[5] 的值\n  ```\n\n\n\n\n\n***\n\n\n\n#### 构造方法\n\n* 无参构造， 散列表结构延迟初始化，默认的数组大小是 16：\n\n  ```java\n  public ConcurrentHashMap() {\n  }\n  ```\n\n* 有参构造：\n\n  ```java\n  public ConcurrentHashMap(int initialCapacity) {\n      // 指定容量初始化\n      if (initialCapacity < 0) throw new IllegalArgumentException();\n      int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?\n                 MAXIMUM_CAPACITY :\n                 // 假如传入的参数是 16，16 + 8 + 1 ，最后得到 32\n                 // 传入 12， 12 + 6 + 1 = 19，最后得到 32，尽可能的大，与 HashMap不一样\n                 tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));\n      // sizeCtl > 0，当目前 table 未初始化时，sizeCtl 表示初始化容量\n      this.sizeCtl = cap;\n  }\n  ```\n\n  ```java\n  private static final int tableSizeFor(int c) {\n      int n = c - 1;\n      n |= n >>> 1;\n      n |= n >>> 2;\n      n |= n >>> 4;\n      n |= n >>> 8;\n      n |= n >>> 16;\n      return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;\n  }\n  ```\n\n  HashMap 部分详解了该函数，核心思想就是**把最高位是 1 的位以及右边的位全部置 1**，结果加 1 后就是 2 的 n 次幂\n\n* 多个参数构造方法：\n\n  ```java\n  public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) {\n      if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)\n          throw new IllegalArgumentException();\n      // 初始容量小于并发级别\n      if (initialCapacity < concurrencyLevel)  \n          // 把并发级别赋值给初始容量\n          initialCapacity = concurrencyLevel; \n  \t// loadFactor 默认是 0.75\n      long size = (long)(1.0 + (long)initialCapacity / loadFactor);\n      int cap = (size >= (long)MAXIMUM_CAPACITY) ?\n          MAXIMUM_CAPACITY : tableSizeFor((int)size);\n      // sizeCtl > 0，当目前 table 未初始化时，sizeCtl 表示初始化容量\n      this.sizeCtl = cap;\n  }\n  ```\n  \n* 集合构造方法：\n\n  ```java\n  public ConcurrentHashMap(Map<? extends K, ? extends V> m) {\n      this.sizeCtl = DEFAULT_CAPACITY;\t// 默认16\n      putAll(m);\n  }\n  public void putAll(Map<? extends K, ? extends V> m) {\n      // 尝试触发扩容\n      tryPresize(m.size());\n      for (Entry<? extends K, ? extends V> e : m.entrySet())\n          putVal(e.getKey(), e.getValue(), false);\n  }\n  ```\n\n  ```java\n  private final void tryPresize(int size) {\n      // 扩容为大于 2 倍的最小的 2 的 n 次幂\n      int c = (size >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY :\n      \ttableSizeFor(size + (size >>> 1) + 1);\n      int sc;\n      while ((sc = sizeCtl) >= 0) {\n          Node<K,V>[] tab = table; int n;\n          // 数组还未初始化，【一般是调用集合构造方法才会成立，put 后调用该方法都是不成立的】\n          if (tab == null || (n = tab.length) == 0) {\n              n = (sc > c) ? sc : c;\n              if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {\n                  try {\n                      if (table == tab) {\n                          Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];\n                          table = nt;\n                          sc = n - (n >>> 2);// 扩容阈值：n - 1/4 n\n                      }\n                  } finally {\n                      sizeCtl = sc;\t// 扩容阈值赋值给sizeCtl\n                  }\n              }\n          }\n          // 未达到扩容阈值或者数组长度已经大于最大长度\n          else if (c <= sc || n >= MAXIMUM_CAPACITY)\n              break;\n          // 与 addCount 逻辑相同\n          else if (tab == table) {\n             \n          }\n      }\n  }\n  ```\n  \n  \n\n\n\n***\n\n\n\n#### 成员方法\n\n##### 数据访存\n\n* tabAt()：获取数组某个槽位的**头节点**，类似于数组中的直接寻址 arr[i]\n\n  ```java\n  // i 是数组索引\n  static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {\n      // (i << ASHIFT) + ABASE == ABASE + i * 4 （一个 int 占 4 个字节），这就相当于寻址，替代了乘法\n      return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);\n  }\n  ```\n\n* casTabAt()：指定数组索引位置修改原值为指定的值\n\n  ```java\n  static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i, Node<K,V> c, Node<K,V> v) {\n      return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);\n  }\n  ```\n\n* setTabAt()：指定数组索引位置设置值\n\n  ```java\n  static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {\n      U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);\n  }\n  ```\n\n  \n\n\n\n***\n\n\n\n##### 添加方法\n\n```java\npublic V put(K key, V value) {\n    // 第三个参数 onlyIfAbsent 为 false 表示哈希表中存在相同的 key 时【用当前数据覆盖旧数据】\n    return putVal(key, value, false);\n}\n```\n\n* putVal()\n\n  ```java\n  final V putVal(K key, V value, boolean onlyIfAbsent) {\n      // 【ConcurrentHashMap 不能存放 null 值】\n      if (key == null || value == null) throw new NullPointerException();\n      // 扰动运算，高低位都参与寻址运算\n      int hash = spread(key.hashCode());\n      // 表示当前 k-v 封装成 node 后插入到指定桶位后，在桶位中的所属链表的下标位置\n      int binCount = 0;\n      // tab 引用当前 map 的数组 table，开始自旋\n      for (Node<K,V>[] tab = table;;) {\n          // f 表示桶位的头节点，n 表示哈希表数组的长度\n          // i 表示 key 通过寻址计算后得到的桶位下标，fh 表示桶位头结点的 hash 值\n          Node<K,V> f; int n, i, fh;\n          \n          // 【CASE1】：表示当前 map 中的 table 尚未初始化\n          if (tab == null || (n = tab.length) == 0)\n              //【延迟初始化】\n              tab = initTable();\n          \n          // 【CASE2】：i 表示 key 使用【寻址算法】得到 key 对应数组的下标位置，tabAt 获取指定桶位的头结点f\n          else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {\n              // 对应的数组为 null 说明没有哈希冲突，直接新建节点添加到表中\n              if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value, null)))\n                  break;\n          }\n          // 【CASE3】：逻辑说明数组已经被初始化，并且当前 key 对应的位置不为 null\n          // 条件成立表示当前桶位的头结点为 FWD 结点，表示目前 map 正处于扩容过程中\n          else if ((fh = f.hash) == MOVED)\n              // 当前线程【需要去帮助哈希表完成扩容】\n              tab = helpTransfer(tab, f);\n          \n          // 【CASE4】：哈希表没有在扩容，当前桶位可能是链表也可能是红黑树\n          else {\n              // 当插入 key 存在时，会将旧值赋值给 oldVal 返回\n              V oldVal = null;\n              // 【锁住当前 key 寻址的桶位的头节点】\n              synchronized (f) {\n                  // 这里重新获取一下桶的头节点有没有被修改，因为可能被其他线程修改过，这里是线程安全的获取\n                  if (tabAt(tab, i) == f) {\n                      // 【头节点的哈希值大于 0 说明当前桶位是普通的链表节点】\n                      if (fh >= 0) {\n                          // 当前的插入操作没出现重复的 key，追加到链表的末尾，binCount表示链表长度 -1\n                          // 插入的key与链表中的某个元素的 key 一致，变成替换操作，binCount 表示第几个节点冲突\n                          binCount = 1;\n                          // 迭代循环当前桶位的链表，e 是每次循环处理节点，e 初始是头节点\n                          for (Node<K,V> e = f;; ++binCount) {\n                              // 当前循环节点 key\n                              K ek;\n                              // key 的哈希值与当前节点的哈希一致，并且 key 的值也相同\n                              if (e.hash == hash &&\n                                  ((ek = e.key) == key ||\n                                   (ek != null && key.equals(ek)))) {\n                                  // 把当前节点的 value 赋值给 oldVal\n                                  oldVal = e.val;\n                                  // 允许覆盖\n                                  if (!onlyIfAbsent)\n                                      // 新数据覆盖旧数据\n                                      e.val = value;\n                                  // 跳出循环\n                                  break;\n                              }\n                              Node<K,V> pred = e;\n                              // 如果下一个节点为空，把数据封装成节点插入链表尾部，【binCount 代表长度 - 1】\n                              if ((e = e.next) == null) {\n                                  pred.next = new Node<K,V>(hash, key,\n                                                            value, null);\n                                  break;\n                              }\n                          }\n                      }\n                      // 当前桶位头节点是红黑树\n                      else if (f instanceof TreeBin) {\n                          Node<K,V> p;\n                          binCount = 2;\n                          if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,\n                                                                value)) != null) {\n                              oldVal = p.val;\n                              if (!onlyIfAbsent)\n                                  p.val = value;\n                          }\n                      }\n                  }\n              }\n              \n              // 条件成立说明当前是链表或者红黑树\n              if (binCount != 0) {\n                  // 如果 binCount >= 8 表示处理的桶位一定是链表，说明长度是 9\n                  if (binCount >= TREEIFY_THRESHOLD)\n                      // 树化\n                      treeifyBin(tab, i);\n                  if (oldVal != null)\n                      return oldVal;\n                  break;\n              }\n          }\n      }\n      // 统计当前 table 一共有多少数据，判断是否达到扩容阈值标准，触发扩容\n      // binCount = 0 表示当前桶位为 null，node 可以直接放入，2 表示当前桶位已经是红黑树\n      addCount(1L, binCount);\n      return null;\n  }\n  ```\n  \n* spread()：扰动函数\n\n  将 hashCode 无符号右移 16 位，高 16bit 和低 16bit 做异或，最后与 HASH_BITS 相与变成正数，**与树化节点和转移节点区分**，把高低位都利用起来减少哈希冲突，保证散列的均匀性\n\n  ```java\n  static final int spread(int h) {\n      return (h ^ (h >>> 16)) & HASH_BITS; // 0111 1111 1111 1111 1111 1111 1111 1111\n  }\n  ```\n\n* initTable()：初始化数组，延迟初始化\n\n  ```java\n  private final Node<K,V>[] initTable() {\n      // tab 引用 map.table，sc 引用 sizeCtl\n      Node<K,V>[] tab; int sc;\n      // table 尚未初始化，开始自旋\n      while ((tab = table) == null || tab.length == 0) {\n          // sc < 0 说明 table 正在初始化或者正在扩容，当前线程可以释放 CPU 资源\n          if ((sc = sizeCtl) < 0)\n              Thread.yield();\n          // sizeCtl 设置为 -1，相当于加锁，【设置的是 SIZECTL 位置的数据】，\n          // 因为是 sizeCtl 是基本类型，不是引用类型，所以 sc 保存的是数据的副本\n          else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {\n              try {\n                  // 线程安全的逻辑，再进行一次判断\n                  if ((tab = table) == null || tab.length == 0) {\n                      // sc > 0 创建 table 时使用 sc 为指定大小，否则使用 16 默认值\n                      int n = (sc > 0) ? sc : DEFAULT_CAPACITY;\n                      // 创建哈希表数组\n                      Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];\n                      table = tab = nt;\n                      // 扩容阈值，n >>> 2  => 等于 1/4 n ，n - (1/4)n = 3/4 n => 0.75 * n\n                      sc = n - (n >>> 2);\n                  }\n              } finally {\n                  // 解锁，把下一次扩容的阈值赋值给 sizeCtl\n                  sizeCtl = sc;\n              }\n              break;\n          }\n      }\n      return tab;\n  }\n  ```\n\n* treeifyBin()：树化方法\n\n  ```java\n  private final void treeifyBin(Node<K,V>[] tab, int index) {\n      Node<K,V> b; int n, sc;\n      if (tab != null) {\n          // 条件成立：【说明当前 table 数组长度未达到 64，此时不进行树化操作，进行扩容操作】\n          if ((n = tab.length) < MIN_TREEIFY_CAPACITY)\n              // 当前容量的 2 倍\n              tryPresize(n << 1);\n  \n          // 条件成立：说明当前桶位有数据，且是普通 node 数据。\n          else if ((b = tabAt(tab, index)) != null && b.hash >= 0) {\n              // 【树化加锁】\n              synchronized (b) {\n                  // 条件成立：表示加锁没问题。\n                  if (tabAt(tab, index) == b) {\n                      TreeNode<K,V> hd = null, tl = null;\n                      for (Node<K,V> e = b; e != null; e = e.next) {\n                          TreeNode<K,V> p = new TreeNode<K,V>(e.hash, e.key, e.val,null, null);\n                          if ((p.prev = tl) == null)\n                              hd = p;\n                          else\n                              tl.next = p;\n                          tl = p;\n                      }\n                      setTabAt(tab, index, new TreeBin<K,V>(hd));\n                  }\n              }\n          }\n      }\n  }\n  ```\n  \n* addCount()：添加计数，**代表哈希表中的数据总量**\n\n  ```java\n  private final void addCount(long x, int check) {\n      // 【上面这部分的逻辑就是 LongAdder 的累加逻辑】\n      CounterCell[] as; long b, s;\n      // 判断累加数组 cells 是否初始化，没有就去累加 base 域，累加失败进入条件内逻辑\n      if ((as = counterCells) != null ||\n          !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {\n          CounterCell a; long v; int m;\n          // true 未竞争，false 发生竞争\n          boolean uncontended = true;\n          // 判断 cells 是否被其他线程初始化\n          if (as == null || (m = as.length - 1) < 0 ||\n              // 前面的条件为 fasle 说明 cells 被其他线程初始化，通过 hash 寻址对应的槽位\n              (a = as[ThreadLocalRandom.getProbe() & m]) == null ||\n              // 尝试去对应的槽位累加，累加失败进入 fullAddCount 进行重试或者扩容\n              !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {\n              // 与 Striped64#longAccumulate 方法相同\n              fullAddCount(x, uncontended);\n              return;\n          }\n          // 表示当前桶位是 null，或者一个链表节点\n          if (check <= 1)\t\n              return;\n      \t// 【获取当前散列表元素个数】，这是一个期望值\n          s = sumCount();\n      }\n      \n      // 表示一定 【是一个 put 操作调用的 addCount】\n      if (check >= 0) {\n          Node<K,V>[] tab, nt; int n, sc;\n          \n          // 条件一：true 说明当前 sizeCtl 可能为一个负数表示正在扩容中，或者 sizeCtl 是一个正数，表示扩容阈值\n          //        false 表示哈希表的数据的数量没达到扩容条件\n          // 然后判断当前 table 数组是否初始化了，当前 table 长度是否小于最大值限制，就可以进行扩容\n          while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&\n                 (n = tab.length) < MAXIMUM_CAPACITY) {\n              // 16 -> 32 扩容 标识为：1000 0000 0001 1011，【负数，扩容批次唯一标识戳】\n              int rs = resizeStamp(n);\n              \n              // 表示当前 table，【正在扩容】，sc 高 16 位是扩容标识戳，低 16 位是线程数 + 1\n              if (sc < 0) {\n                  // 条件一：判断扩容标识戳是否一样，fasle 代表一样\n                  // 勘误两个条件：\n                  // 条件二是：sc == (rs << 16 ) + 1，true 代表扩容完成，因为低16位是1代表没有线程扩容了\n                  // 条件三是：sc == (rs << 16) + MAX_RESIZERS，判断是否已经超过最大允许的并发扩容线程数\n                  // 条件四：判断新表的引用是否是 null，代表扩容完成\n                  // 条件五：【扩容是从高位到低位转移】，transferIndex < 0 说明没有区间需要扩容了\n                  if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                      sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||\n                      transferIndex <= 0)\n                      break;\n                  \n                  // 设置当前线程参与到扩容任务中，将 sc 低 16 位值加 1，表示多一个线程参与扩容\n                  // 设置失败其他线程或者 transfer 内部修改了 sizeCtl 值\n                  if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))\n                      //【协助扩容线程】，持有nextTable参数\n                      transfer(tab, nt);\n              }\n              // 逻辑到这说明当前线程是触发扩容的第一个线程，线程数量 + 2\n              // 1000 0000 0001 1011 0000 0000 0000 0000 +2 => 1000 0000 0001 1011 0000 0000 0000 0010\n              else if (U.compareAndSwapInt(this, SIZECTL, sc,(rs << RESIZE_STAMP_SHIFT) + 2))\n                  //【触发扩容条件的线程】，不持有 nextTable，初始线程会新建 nextTable\n                  transfer(tab, null);\n              s = sumCount();\n          }\n      }\n  }\n  ```\n\n* resizeStamp()：扩容标识符，**每次扩容都会产生一个，不是每个线程都产生**，16 扩容到 32 产生一个，32 扩容到 64 产生一个\n\n  ```java\n  /**\n   * 扩容的标识符\n   * 16 -> 32 从16扩容到32\n   * numberOfLeadingZeros(16) => 1 0000 => 32 - 5 = 27 => 0000 0000 0001 1011\n   * (1 << (RESIZE_STAMP_BITS - 1)) => 1000 0000 0000 0000 => 32768\n   * ---------------------------------------------------------------\n   * 0000 0000 0001 1011\n   * 1000 0000 0000 0000\n   * 1000 0000 0001 1011\n   * 永远是负数\n   */\n  static final int resizeStamp(int n) {\n      // 或运算\n      return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1)); // (16 -1 = 15)\n  }\n  ```\n\n\n\n\n\n***\n\n\n\n##### 扩容方法\n\n扩容机制：\n\n* 当链表中元素个数超过 8 个，数组的大小还未超过 64 时，此时进行数组的扩容，如果超过则将链表转化成红黑树\n* put 数据后调用 addCount() 方法，判断当前哈希表的容量超过阈值 sizeCtl，超过进行扩容\n* 增删改线程发现其他线程正在扩容，帮其扩容\n\n常见方法：\n\n* transfer()：数据转移到新表中，完成扩容\n\n  ```java\n  private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {\n      // n 表示扩容之前 table 数组的长度\n      int n = tab.length, stride;\n      // stride 表示分配给线程任务的步长，默认就是 16 \n      if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)\n          stride = MIN_TRANSFER_STRIDE;\n      // 如果当前线程为触发本次扩容的线程，需要做一些扩容准备工作，【协助线程不做这一步】\n      if (nextTab == null) {\n          try {\n              // 创建一个容量是之前【二倍的 table 数组】\n              Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];\n              nextTab = nt;\n          } catch (Throwable ex) {\n              sizeCtl = Integer.MAX_VALUE;\n              return;\n          }\n          // 把新表赋值给对象属性 nextTable，方便其他线程获取新表\n          nextTable = nextTab;\n          // 记录迁移数据整体位置的一个标记，transferIndex 计数从1开始不是 0，所以这里是长度，不是长度-1\n          transferIndex = n;\n      }\n      // 新数组的长度\n      int nextn = nextTab.length;\n      // 当某个桶位数据处理完毕后，将此桶位设置为 fwd 节点，其它写线程或读线程看到后，可以从中获取到新表\n      ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);\n      // 推进标记\n      boolean advance = true;\n      // 完成标记\n      boolean finishing = false;\n      \n      // i 表示分配给当前线程任务，执行到的桶位\n      // bound 表示分配给当前线程任务的下界限制，因为是倒序迁移，16 迁移完 迁移 15，15完成去迁移14\n      for (int i = 0, bound = 0;;) {\n          Node<K,V> f; int fh;\n          \n          // 给当前线程【分配任务区间】\n          while (advance) {\n              // 分配任务的开始下标，分配任务的结束下标\n              int nextIndex, nextBound;\n           \n              // --i 让当前线程处理下一个索引，true说明当前的迁移任务尚未完成，false说明线程已经完成或者还未分配\n              if (--i >= bound || finishing)\n                  advance = false;\n              // 迁移的开始下标，小于0说明没有区间需要迁移了，设置当前线程的 i 变量为 -1 跳出循环\n              else if ((nextIndex = transferIndex) <= 0) {\n                  i = -1;\n                  advance = false;\n              }\n              // 逻辑到这说明还有区间需要分配，然后给当前线程分配任务，\n              else if (U.compareAndSwapInt(this, TRANSFERINDEX, nextIndex,\n                        // 判断区间是否还够一个步长，不够就全部分配\n                        nextBound = (nextIndex > stride ? nextIndex - stride : 0))) {\n                  // 当前线程的结束下标\n                  bound = nextBound;\n                  // 当前线程的开始下标，上一个线程结束的下标的下一个索引就是这个线程开始的下标\n                  i = nextIndex - 1;\n                  // 任务分配结束，跳出循环执行迁移操作\n                  advance = false;\n              }\n          }\n          \n          // 【分配完成，开始数据迁移操作】\n          // 【CASE1】：i < 0 成立表示当前线程未分配到任务，或者任务执行完了\n          if (i < 0 || i >= n || i + n >= nextn) {\n              int sc;\n              // 如果迁移完成\n              if (finishing) {\n                  nextTable = null;\t// help GC\n                  table = nextTab;\t// 新表赋值给当前对象\n                  sizeCtl = (n << 1) - (n >>> 1);// 扩容阈值为 2n - n/2 = 3n/2 = 0.75*(2n)\n                  return;\n              }\n              // 当前线程完成了分配的任务区间，可以退出，先把 sizeCtl 赋值给 sc 保留\n              if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {\n                  // 判断当前线程是不是最后一个线程，不是的话直接 return，\n                  if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)\n                      return;\n                  // 所以最后一个线程退出的时候，sizeCtl 的低 16 位为 1\n                  finishing = advance = true;\n                  // 【这里表示最后一个线程需要重新检查一遍是否有漏掉的区间】\n                  i = n;\n              }\n          }\n          \n          // 【CASE2】：当前桶位未存放数据，只需要将此处设置为 fwd 节点即可。\n          else if ((f = tabAt(tab, i)) == null)\n              advance = casTabAt(tab, i, null, fwd);\n          // 【CASE3】：说明当前桶位已经迁移过了，当前线程不用再处理了，直接处理下一个桶位即可\n          else if ((fh = f.hash) == MOVED)\n              advance = true; \n          // 【CASE4】：当前桶位有数据，而且 node 节点不是 fwd 节点，说明这些数据需要迁移\n          else {\n              // 【锁住头节点】\n              synchronized (f) {\n                  // 二次检查，防止头节点已经被修改了，因为这里才是线程安全的访问\n                  if (tabAt(tab, i) == f) {\n                      // 【迁移数据的逻辑，和 HashMap 相似】\n                          \n                      // ln 表示低位链表引用\n                      // hn 表示高位链表引用\n                      Node<K,V> ln, hn;\n                      // 哈希 > 0 表示当前桶位是链表桶位\n                      if (fh >= 0) {\n                          // 和 HashMap 的处理方式一致，与老数组长度相与，16 是 10000\n                          // 判断对应的 1 的位置上是 0 或 1 分成高低位链表\n                          int runBit = fh & n;\n                          Node<K,V> lastRun = f;\n                          // 遍历链表，寻找【逆序看】最长的对应位相同的链表，看下面的图更好的理解\n                          for (Node<K,V> p = f.next; p != null; p = p.next) {\n                              // 将当前节点的哈希 与 n\n                              int b = p.hash & n;\n                              // 如果当前值与前面节点的值 对应位 不同，则修改 runBit，把 lastRun 指向当前节点\n                              if (b != runBit) {\n                                  runBit = b;\n                                  lastRun = p;\n                              }\n                          }\n                          // 判断筛选出的链表是低位的还是高位的\n                          if (runBit == 0) {\n                              ln = lastRun;\t// ln 指向该链表\n                              hn = null;\t\t// hn 为 null\n                          }\n                          // 说明 lastRun 引用的链表为高位链表，就让 hn 指向高位链表头节点\n                          else {\n                              hn = lastRun;\n                              ln = null;\n                          }\n                          // 从头开始遍历所有的链表节点，迭代到 p == lastRun 节点跳出循环\n                          for (Node<K,V> p = f; p != lastRun; p = p.next) {\n                              int ph = p.hash; K pk = p.key; V pv = p.val;\n                              if ((ph & n) == 0)\n                                  // 【头插法】，从右往左看，首先 ln 指向的是上一个节点，\n                                  // 所以这次新建的节点的 next 指向上一个节点，然后更新 ln 的引用\n                                  ln = new Node<K,V>(ph, pk, pv, ln);\n                              else\n                                  hn = new Node<K,V>(ph, pk, pv, hn);\n                          }\n                          // 高低位链设置到新表中的指定位置\n                          setTabAt(nextTab, i, ln);\n                          setTabAt(nextTab, i + n, hn);\n                          // 老表中的该桶位设置为 fwd 节点\n                          setTabAt(tab, i, fwd);\n                          advance = true;\n                      }\n                      // 条件成立：表示当前桶位是 红黑树结点\n                      else if (f instanceof TreeBin) {\n                          TreeBin<K,V> t = (TreeBin<K,V>)f;\n                          TreeNode<K,V> lo = null, loTail = null;\n                          TreeNode<K,V> hi = null, hiTail = null;\n                          int lc = 0, hc = 0;\n                          // 迭代 TreeBin 中的双向链表，从头结点至尾节点\n                          for (Node<K,V> e = t.first; e != null; e = e.next) {\n                              // 迭代的当前元素的 hash\n                              int h = e.hash;\n                              TreeNode<K,V> p = new TreeNode<K,V>\n                                  (h, e.key, e.val, null, null);\n                              // 条件成立表示当前循环节点属于低位链节点\n                              if ((h & n) == 0) {\n                                  if ((p.prev = loTail) == null)\n                                      lo = p;\n                                  else\n                                      //【尾插法】\n                                      loTail.next = p;\n                                  // loTail 指向尾节点\n                                  loTail = p;\n                                  ++lc;\n                              }\n                              else {\n                                  if ((p.prev = hiTail) == null)\n                                      hi = p;\n                                  else\n                                      hiTail.next = p;\n                                  hiTail = p;\n                                  ++hc;\n                              }\n                          }\n                          // 拆成的高位低位两个链，【判断是否需要需要转化为链表】，反之保持树化\n                          ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :\n                          (hc != 0) ? new TreeBin<K,V>(lo) : t;\n                          hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :\n                          (lc != 0) ? new TreeBin<K,V>(hi) : t;\n                          setTabAt(nextTab, i, ln);\n                          setTabAt(nextTab, i + n, hn);\n                          setTabAt(tab, i, fwd);\n                          advance = true;\n                      }\n                  }\n              }\n          }\n      }\n  }\n  ```\n  \n  链表处理的 LastRun 机制，**可以减少节点的创建**\n  \n  ![image-20230824175210854](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824175210854.png)\n  \n* helpTransfer()：帮助扩容机制\n\n  ```java\n  final Node<K,V>[] helpTransfer(Node<K,V>[] tab, Node<K,V> f) {\n      Node<K,V>[] nextTab; int sc;\n      // 数组不为空，节点是转发节点，获取转发节点指向的新表开始协助主线程扩容\n      if (tab != null && (f instanceof ForwardingNode) &&\n          (nextTab = ((ForwardingNode<K,V>)f).nextTable) != null) {\n          // 扩容标识戳\n          int rs = resizeStamp(tab.length);\n          // 判断数据迁移是否完成，迁移完成会把 新表赋值给 nextTable 属性\n          while (nextTab == nextTable && table == tab && (sc = sizeCtl) < 0) {\n              if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||\n                  sc == rs + MAX_RESIZERS || transferIndex <= 0)\n                  break;\n              // 设置扩容线程数量 + 1\n              if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {\n                  // 协助扩容\n                  transfer(tab, nextTab);\n                  break;\n              }\n          }\n          return nextTab;\n      }\n      return table;\n  }\n  ```\n  \n  \n\n\n\n***\n\n\n\n##### 获取方法\n\nConcurrentHashMap 使用 get()  方法获取指定 key 的数据\n\n* get()：获取指定数据的方法\n\n  ```java\n  public V get(Object key) {\n      Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;\n      // 扰动运算，获取 key 的哈希值\n      int h = spread(key.hashCode());\n      // 判断当前哈希表的数组是否初始化\n      if ((tab = table) != null && (n = tab.length) > 0 &&\n          // 如果 table 已经初始化，进行【哈希寻址】，映射到数组对应索引处，获取该索引处的头节点\n          (e = tabAt(tab, (n - 1) & h)) != null) {\n          // 对比头结点 hash 与查询 key 的 hash 是否一致\n          if ((eh = e.hash) == h) {\n              // 进行值的判断，如果成功就说明当前节点就是要查询的节点，直接返回\n              if ((ek = e.key) == key || (ek != null && key.equals(ek)))\n                  return e.val;\n          }\n          // 当前槽位的【哈希值小于0】说明是红黑树节点或者是正在扩容的 fwd 节点\n          else if (eh < 0)\n              return (p = e.find(h, key)) != null ? p.val : null;\n          // 当前桶位是【链表】，循环遍历查找\n          while ((e = e.next) != null) {\n              if (e.hash == h &&\n                  ((ek = e.key) == key || (ek != null && key.equals(ek))))\n                  return e.val;\n          }\n      }\n      return null;\n  }\n  ```\n  \n* ForwardingNode#find：转移节点的查找方法\n\n  ```java\n  Node<K,V> find(int h, Object k) {\n      // 获取新表的引用\n      outer: for (Node<K,V>[] tab = nextTable;;)  {\n          // e 表示在扩容而创建新表使用寻址算法得到的桶位头结点，n 表示为扩容而创建的新表的长度\n          Node<K,V> e; int n;\n   \n          if (k == null || tab == null || (n = tab.length) == 0 ||\n              // 在新表中重新定位 hash 对应的头结点，表示在 oldTable 中对应的桶位在迁移之前就是 null\n              (e = tabAt(tab, (n - 1) & h)) == null)\n              return null;\n  \n          for (;;) {\n              int eh; K ek;\n              // 【哈希相同值也相同】，表示新表当前命中桶位中的数据，即为查询想要数据\n              if ((eh = e.hash) == h && ((ek = e.key) == k || (ek != null && k.equals(ek))))\n                  return e;\n  \n              // eh < 0 说明当前新表中该索引的头节点是 TreeBin 类型，或者是 FWD 类型\n              if (eh < 0) {\n                  // 在并发很大的情况下新扩容的表还没完成可能【再次扩容】，在此方法处再次拿到 FWD 类型\n                  if (e instanceof ForwardingNode) {\n                      // 继续获取新的 fwd 指向的新数组的地址，递归了\n                      tab = ((ForwardingNode<K,V>)e).nextTable;\n                      continue outer;\n                  }\n                  else\n                      // 说明此桶位为 TreeBin 节点，使用TreeBin.find 查找红黑树中相应节点。\n                      return e.find(h, k);\n              }\n  \n              // 逻辑到这说明当前桶位是链表，将当前元素指向链表的下一个元素，判断当前元素的下一个位置是否为空\n              if ((e = e.next) == null)\n                  // 条件成立说明迭代到链表末尾，【未找到对应的数据，返回 null】\n                  return null;\n          }\n      }\n  }\n  ```\n  \n  \n\n\n\n****\n\n\n\n##### 删除方法\n\n* remove()：删除指定元素\n\n  ```java\n  public V remove(Object key) {\n      return replaceNode(key, null, null);\n  }\n  ```\n\n* replaceNode()：替代指定的元素，会协助扩容，**增删改（写）都会协助扩容，查询（读）操作不会**，因为读操作不涉及加锁\n\n  ```java\n  final V replaceNode(Object key, V value, Object cv) {\n      // 计算 key 扰动运算后的 hash\n      int hash = spread(key.hashCode());\n      // 开始自旋\n      for (Node<K,V>[] tab = table;;) {\n          Node<K,V> f; int n, i, fh;\n          \n          // 【CASE1】：table 还未初始化或者哈希寻址的数组索引处为 null，直接结束自旋，返回 null\n          if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) & hash)) == null)\n              break;\n          // 【CASE2】：条件成立说明当前 table 正在扩容，【当前是个写操作，所以当前线程需要协助 table 完成扩容】\n          else if ((fh = f.hash) == MOVED)\n              tab = helpTransfer(tab, f);\n          // 【CASE3】：当前桶位可能是 链表 也可能是 红黑树 \n          else {\n              // 保留替换之前数据引用\n              V oldVal = null;\n              // 校验标记\n              boolean validated = false;\n              // 【加锁当前桶位头结点】，加锁成功之后会进入代码块\n              synchronized (f) {\n                  // 双重检查\n                  if (tabAt(tab, i) == f) {\n                      // 说明当前节点是链表节点\n                      if (fh >= 0) {\n                          validated = true;\n                          //遍历所有的节点\n                          for (Node<K,V> e = f, pred = null;;) {\n                              K ek;\n                              // hash 和值都相同，定位到了具体的节点\n                              if (e.hash == hash &&\n                                  ((ek = e.key) == key ||\n                                   (ek != null && key.equals(ek)))) {\n                                  // 当前节点的value\n                                  V ev = e.val;\n                                  if (cv == null || cv == ev ||\n                                      (ev != null && cv.equals(ev))) {\n                                      // 将当前节点的值 赋值给 oldVal 后续返回会用到\n                                      oldVal = ev;\n                                      if (value != null)\t\t// 条件成立说明是替换操作\n                                          e.val = value;\t\n                                      else if (pred != null)\t// 非头节点删除操作，断开链表\n                                          pred.next = e.next;\t\n                                      else\n                                          // 说明当前节点即为头结点，将桶位头节点设置为以前头节点的下一个节点\n                                          setTabAt(tab, i, e.next);\n                                  }\n                                  break;\n                              }\n                              pred = e;\n                              if ((e = e.next) == null)\n                                  break;\n                          }\n                      }\n                      // 说明是红黑树节点\n                      else if (f instanceof TreeBin) {\n                          validated = true;\n                          TreeBin<K,V> t = (TreeBin<K,V>)f;\n                          TreeNode<K,V> r, p;\n                          if ((r = t.root) != null &&\n                              (p = r.findTreeNode(hash, key, null)) != null) {\n                              V pv = p.val;\n                              if (cv == null || cv == pv ||\n                                  (pv != null && cv.equals(pv))) {\n                                  oldVal = pv;\n                                  // 条件成立说明替换操作\n                                  if (value != null)\n                                      p.val = value;\n                                  // 删除操作\n                                  else if (t.removeTreeNode(p))\n                                      setTabAt(tab, i, untreeify(t.first));\n                              }\n                          }\n                      }\n                  }\n              }\n              // 其他线程修改过桶位头结点时，当前线程 sync 头结点锁错对象，validated 为 false，会进入下次 for 自旋\n              if (validated) {\n                  if (oldVal != null) {\n                      // 替换的值为 null，【说明当前是一次删除操作，更新当前元素个数计数器】\n                      if (value == null)\n                          addCount(-1L, -1);\n                      return oldVal;\n                  }\n                  break;\n              }\n          }\n      }\n      return null;\n  }\n  ```\n  \n  \n\n参考视频：https://space.bilibili.com/457326371/\n\n\n\n***\n\n\n\n#### JDK7原理\n\nConcurrentHashMap 对锁粒度进行了优化，**分段锁技术**，将整张表分成了多个数组（Segment），每个数组又是一个类似 HashMap 数组的结构。允许多个修改操作并发进行，Segment 是一种可重入锁，继承 ReentrantLock，并发时锁住的是每个 Segment，其他 Segment 还是可以操作的，这样不同 Segment 之间就可以实现并发，大大提高效率。\n\n底层结构： **Segment 数组 + HashEntry 数组 + 链表**（数组 + 链表是 HashMap 的结构）\n\n* 优点：如果多个线程访问不同的 segment，实际是没有冲突的，这与 JDK8 中是类似的\n\n* 缺点：Segments 数组默认大小为16，这个容量初始化指定后就不能改变了，并且不是懒惰初始化\n\n  ![image-20230824175317393](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824175317393.png)\n\n\n\n\n\n\n\n***\n\n\n\n### CopyOnWrite\n\n#### 原理分析\n\nCopyOnWriteArrayList 采用了**写入时拷贝**的思想，增删改操作会将底层数组拷贝一份，在新数组上执行操作，不影响其它线程的**并发读，读写分离**\n\nCopyOnWriteArraySet 底层对 CopyOnWriteArrayList 进行了包装，装饰器模式\n\n```java\npublic CopyOnWriteArraySet() {\n    al = new CopyOnWriteArrayList<E>();\n}\n```\n\n* 存储结构：\n\n  ```java\n  private transient volatile Object[] array;\t// volatile 保证了读写线程之间的可见性\n  ```\n\n* 全局锁：保证线程的执行安全\n\n  ```java\n  final transient ReentrantLock lock = new ReentrantLock();\n  ```\n  \n* 新增数据：需要加锁，**创建新的数组操作**\n\n  ```java\n  public boolean add(E e) {\n      final ReentrantLock lock = this.lock;\n      // 加锁，保证线程安全\n      lock.lock();\n      try {\n          // 获取旧的数组\n          Object[] elements = getArray();\n          int len = elements.length;\n          // 【拷贝新的数组（这里是比较耗时的操作，但不影响其它读线程）】\n          Object[] newElements = Arrays.copyOf(elements, len + 1);\n          // 添加新元素\n          newElements[len] = e;\n          // 替换旧的数组，【这个操作以后，其他线程获取数组就是获取的新数组了】\n          setArray(newElements);\n          return true;\n      } finally {\n          lock.unlock();\n      }\n  }\n  ```\n\n* 读操作：不加锁，**在原数组上操作**\n\n  ```java\n  public E get(int index) {\n      return get(getArray(), index);\n  }\n  private E get(Object[] a, int index) {\n      return (E) a[index];\n  }\n  ```\n\n  适合读多写少的应用场景\n\n* 迭代器：CopyOnWriteArrayList 在返回迭代器时，**创建一个内部数组当前的快照（引用）**，即使其他线程替换了原始数组，迭代器遍历的快照依然引用的是创建快照时的数组，所以这种实现方式也存在一定的数据延迟性，对其他线程并行添加的数据不可见\n\n  ```java\n  public Iterator<E> iterator() {\n      // 获取到数组引用，整个遍历的过程该数组都不会变，一直引用的都是老数组，\n      return new COWIterator<E>(getArray(), 0);\n  }\n  \n  // 迭代器会创建一个底层array的快照，故主类的修改不影响该快照\n  static final class COWIterator<E> implements ListIterator<E> {\n      // 内部数组快照\n      private final Object[] snapshot;\n  \n      private COWIterator(Object[] elements, int initialCursor) {\n          cursor = initialCursor;\n          // 数组的引用在迭代过程不会改变\n          snapshot = elements;\n      }\n      // 【不支持写操作】，因为是在快照上操作，无法同步回去\n      public void remove() {\n          throw new UnsupportedOperationException();\n      } \n  }\n  ```\n  \n  \n\n***\n\n\n\n#### 弱一致性\n\n数据一致性就是读到最新更新的数据：\n\n* 强一致性：当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值\n\n* 弱一致性：系统并不保证进程或者线程的访问都会返回最新的更新过的值，也不会承诺多久之后可以读到\n\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230720205728245.png\" alt=\"image-20230720205728245\" style=\"zoom:50%;\" />\n\n| 时间点 | 操作                         |\n| ------ | ---------------------------- |\n| 1      | Thread-0 getArray()          |\n| 2      | Thread-1 getArray()          |\n| 3      | Thread-1 setArray(arrayCopy) |\n| 4      | Thread-0 array[index]        |\n\nThread-0 读到了脏数据\n\n不一定弱一致性就不好\n\n* 数据库的**事务隔离级别**就是弱一致性的表现\n* 并发高和一致性是矛盾的，需要权衡\n\n\n\n***\n\n\n\n#### 安全失败\n\n在 java.util 包的集合类就都是快速失败的，而 java.util.concurrent 包下的类都是安全失败\n\n* 快速失败：在 A 线程使用**迭代器**对集合进行遍历的过程中，此时 B 线程对集合进行修改（增删改），或者 A 线程在遍历过程中对集合进行修改，都会导致 A 线程抛出 ConcurrentModificationException 异常\n  * AbstractList 类中的成员变量 modCount，用来记录 List 结构发生变化的次数，**结构发生变化**是指添加或者删除至少一个元素的操作，或者是调整内部数组的大小，仅仅设置元素的值不算结构发生变化\n  * 在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了抛出 CME 异常\n  \n* 安全失败：采用安全失败机制的集合容器，在**迭代器**遍历时直接在原集合数组内容上访问，但其他线程的增删改都会新建数组进行修改，就算修改了集合底层的数组容器，迭代器依然引用着以前的数组（**快照思想**），所以不会出现异常\n\n  ConcurrentHashMap 不会出现并发时的迭代异常，因为在迭代过程中 CHM 的迭代器并没有判断结构的变化，迭代器还可以根据迭代的节点状态去寻找并发扩容时的新表进行迭代\n\n  ```java\n  ConcurrentHashMap map = new ConcurrentHashMap();\n  // KeyIterator\n  Iterator iterator = map.keySet().iterator();\n  ```\n\n  ```java\n   Traverser(Node<K,V>[] tab, int size, int index, int limit) {\n       // 引用还是原来集合的 Node 数组，所以其他线程对数据的修改是可见的\n       this.tab = tab;\n       this.baseSize = size;\n       this.baseIndex = this.index = index;\n       this.baseLimit = limit;\n       this.next = null;\n   }\n  ```\n\n  ```java\n  public final boolean hasNext() { return next != null; }\n  public final K next() {\n      Node<K,V> p;\n      if ((p = next) == null)\n          throw new NoSuchElementException();\n      K k = p.key;\n      lastReturned = p;\n      // 在方法中进行下一个节点的获取，会进行槽位头节点的状态判断\n      advance();\n      return k;\n  }\n  ```\n\n  \n\n\n\n***\n\n\n\n### Collections\n\nCollections类是用来操作集合的工具类，提供了集合转换成线程安全的方法：\n\n```java\n public static <T> Collection<T> synchronizedCollection(Collection<T> c) {\n     return new SynchronizedCollection<>(c);\n }\npublic static <K,V> Map<K,V> synchronizedMap(Map<K,V> m) {\n    return new SynchronizedMap<>(m);\n}\n```\n\n源码：底层也是对方法进行加锁\n\n```java\npublic boolean add(E e) {\n    synchronized (mutex) {return c.add(e);}\n}\n```\n\n\n\n***\n\n\n\n### SkipListMap\n\n#### 底层结构\n\n跳表 SkipList 是一个**有序的链表**，默认升序，底层是链表加多级索引的结构。跳表可以对元素进行快速查询，类似于平衡树，是一种利用空间换时间的算法\n\n对于单链表，即使链表是有序的，如果查找数据也只能从头到尾遍历链表，所以采用链表上建索引的方式提高效率，跳表的查询时间复杂度是 **O(logn)**，空间复杂度 O(n)\n\nConcurrentSkipListMap 提供了一种线程安全的并发访问的排序映射表，内部是跳表结构实现，通过 CAS + volatile 保证线程安全\n\n平衡树和跳表的区别：\n\n* 对平衡树的插入和删除往往很可能导致平衡树进行一次全局的调整；而对跳表的插入和删除，**只需要对整个结构的局部进行操作**\n* 在高并发的情况下，保证整个平衡树的线程安全需要一个全局锁；对于跳表则只需要部分锁，拥有更好的性能\n\n![image-20230824175500066](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824175500066.png)\n\nBaseHeader 存储数据，headIndex 存储索引，纵向上**所有索引都指向链表最下面的节点**\n\n\n\n***\n\n\n\n#### 成员变量\n\n* 标识索引头节点位置\n\n  ```java\n  private static final Object BASE_HEADER = new Object();\n  ```\n\n* 跳表的顶层索引\n\n  ```java\n  private transient volatile HeadIndex<K,V> head;\n  ```\n\n* 比较器，为 null 则使用自然排序\n\n  ```java\n  final Comparator<? super K> comparator;\n  ```\n\n* Node 节点\n\n  ```java\n  static final class Node<K, V>{\n      final K key;  \t\t\t\t// key 是 final 的, 说明节点一旦定下来, 除了删除, 一般不会改动 key\n      volatile Object value; \t\t// 对应的 value\n      volatile Node<K, V> next; \t// 下一个节点，单向链表\n  }\n  ```\n\n* 索引节点 Index，只有向下和向右的指针\n\n  ```java\n  static class Index<K, V>{\n      final Node<K, V> node; \t\t// 索引指向的节点，每个都会指向数据节点\n      final Index<K, V> down; \t// 下边level层的Index，分层索引\n      volatile Index<K, V> right; // 右边的Index，单向\n  \n      // 在 index 本身和 succ 之间插入一个新的节点 newSucc\n      final boolean link(Index<K, V> succ, Index<K, V> newSucc){\n          Node<K, V> n = node;\n          newSucc.right = succ;\n          // 把当前节点的右指针从 succ 改为 newSucc\n          return n.value != null && casRight(succ, newSucc);\n      }\n  \n      // 断开当前节点和 succ 节点，将当前的节点 index 设置其的 right 为 succ.right，就是把 succ 删除\n      final boolean unlink(Index<K, V> succ){\n          return node.value != null && casRight(succ, succ.right);\n      }\n  }\n  ```\n\n* 头索引节点 HeadIndex\n\n  ```java\n  static final class HeadIndex<K,V> extends Index<K,V> {\n      final int level;\t// 表示索引层级，所有的 HeadIndex 都指向同一个 Base_header 节点\n      HeadIndex(Node<K,V> node, Index<K,V> down, Index<K,V> right, int level) {\n          super(node, down, right);\n          this.level = level;\n      }\n  }\n  ```\n\n\n\n***\n\n\n\n#### 成员方法\n\n##### 其他方法\n\n* 构造方法：\n\n  ```java\n  public ConcurrentSkipListMap() {\n      this.comparator = null;\t// comparator 为 null，使用 key 的自然序，如字典序\n      initialize();\n  }\n  ```\n\n  ```java\n  private void initialize() {\n      keySet = null;\n      entrySet = null;\n      values = null;\n      descendingMap = null;\n      // 初始化索引头节点，Node 的 key 为 null，value 为 BASE_HEADER 对象，下一个节点为 null\n      // head 的分层索引 down 为 null，链表的后续索引 right 为 null，层级 level 为第 1 层\n      head = new HeadIndex<K,V>(new Node<K,V>(null, BASE_HEADER, null), null, null, 1);\n  }\n  ```\n  \n* cpr：排序\n\n  ```java\n  //　x 是比较者，y 是被比较者，比较者大于被比较者 返回正数，小于返回负数，相等返回 0\n  static final int cpr(Comparator c, Object x, Object y) {\n      return (c != null) ? c.compare(x, y) : ((Comparable)x).compareTo(y);\n  }\n  ```\n\n\n\n***\n\n\n\n##### 添加方法\n\n* findPredecessor()：寻找前置节点\n\n  从最上层的头索引开始向右查找（链表的后续索引），如果后续索引的节点的 key 大于要查找的 key，则头索引移到下层链表，在下层链表查找，以此反复，一直查找到没有下层的分层索引为止，返回该索引的节点。如果后续索引的节点的 key 小于要查找的 key，则在该层链表中向后查找。由于查找的 key 可能永远大于索引节点的 key，所以只能找到目标的前置索引节点。如果遇到空值索引的存在，通过 CAS 来断开索引\n\n  ```java\n  private Node<K,V> findPredecessor(Object key, Comparator<? super K> cmp) {\n      if (key == null)\n          throw new NullPointerException(); // don't postpone errors\n      for (;;) {\n          // 1.初始数据 q 是 head，r 是最顶层 h 的右 Index 节点\n          for (Index<K,V> q = head, r = q.right, d;;) {\n              // 2.右索引节点不为空，则进行向下查找\n              if (r != null) {\n                  Node<K,V> n = r.node;\n                  K k = n.key;\n                  // 3.n.value 为 null 说明节点 n 正在删除的过程中，此时【当前线程帮其删除索引】\n                  if (n.value == null) {\n                      // 在 index 层直接删除 r 索引节点\n                      if (!q.unlink(r))\n                          // 删除失败重新从 head 节点开始查找，break 一个 for 到步骤 1，又从初始值开始\n                          break;\n                      \n                      // 删除节点 r 成功，获取新的 r 节点,\n                      r = q.right;\n                      // 回到步骤 2，还是从这层索引开始向右遍历\n                      continue;\n                  }\n                  // 4.若参数 key > r.node.key，则继续向右遍历, continue 到步骤 2 处获取右节点\n                  //   若参数 key < r.node.key，说明需要进入下层索引，到步骤 5\n                  if (cpr(cmp, key, k) > 0) {\n                      q = r;\n                      r = r.right;\n                      continue;\n                  }\n              }\n              // 5.先让 d 指向 q 的下一层，判断是否是 null，是则说明已经到了数据层，也就是第一层\n              if ((d = q.down) == null) \n                  return q.node;\n              // 6.未到数据层, 进行重新赋值向下扫描\n              q = d;\t\t// q 指向 d\n              r = d.right;// r 指向 q 的后续索引节点，此时(q.key < key < r.key)\n          }\n      }\n  }\n  ```\n\n  ![image-20230824175548648](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824175548648.png)\n\n* put()：添加数据\n\n  ```java\n  public V put(K key, V value) {\n      // 非空判断，value不能为空\n      if (value == null)\n          throw new NullPointerException();\n      return doPut(key, value, false);\n  }\n  ```\n\n  ```java\n  private V doPut(K key, V value, boolean onlyIfAbsent) {\n      Node<K,V> z;\n      // 非空判断，key 不能为空\n      if (key == null)\n          throw new NullPointerException();\n      Comparator<? super K> cmp = comparator;\n      // outer 循环，【把待插入数据插入到数据层的合适的位置，并在扫描过程中处理已删除(value = null)的数据】\n      outer: for (;;) {\n          //0.for (;;)\n          //1.将 key 对应的前继节点找到, b 为前继节点，是数据层的, n 是前继节点的 next, \n  \t\t//  若没发生条件竞争，最终 key 在 b 与 n 之间 (找到的 b 在 base_level 上)\n          for (Node<K,V> b = findPredecessor(key, cmp), n = b.next;;) {\n              // 2.n 不为 null 说明 b 不是链表的最后一个节点\n              if (n != null) {\n                  Object v; int c;\n                  // 3.获取 n 的右节点\n                  Node<K,V> f = n.next;\n                  // 4.条件竞争，并发下其他线程在 b 之后插入节点或直接删除节点 n, break 到步骤 0\n                  if (n != b.next)              \n                      break;\n                  //  若节点 n 已经删除, 则调用 helpDelete 进行【帮助删除节点】\n                  if ((v = n.value) == null) {\n                      n.helpDelete(b, f);\n                      break;\n                  }\n                  // 5.节点 b 被删除中，则 break 到步骤 0,\n  \t\t\t\t//  【调用findPredecessor帮助删除index层的数据, node层的数据会通过helpDelete方法进行删除】\n                  if (b.value == null || v == n) \n                      break;\n                  // 6.若 key > n.key，则进行向后扫描\n                  //   若 key < n.key，则证明 key 应该存储在 b 和 n 之间\n                  if ((c = cpr(cmp, key, n.key)) > 0) {\n                      b = n;\n                      n = f;\n                      continue;\n                  }\n                  // 7.key 的值和 n.key 相等，则可以直接覆盖赋值\n                  if (c == 0) {\n                      // onlyIfAbsent 默认 false，\n                      if (onlyIfAbsent || n.casValue(v, value)) {\n                          @SuppressWarnings(\"unchecked\") V vv = (V)v;\n                          // 返回被覆盖的值\n                          return vv;\n                      }\n                      // cas失败，break 一层循环，返回 0 重试\n                      break;\n                  }\n                  // else c < 0; fall through\n              }\n              // 8.此时的情况 b.key < key < n.key，对应流程图1中的7，创建z节点指向n\n              z = new Node<K,V>(key, value, n);\n              // 9.尝试把 b.next 从 n 设置成 z\n              if (!b.casNext(n, z))\n                  // cas失败，返回到步骤0，重试\n                  break;\n              // 10.break outer 后, 上面的 for 循环不会再执行, 而后执行下面的代码\n              break outer;\n          }\n      }\n  \t// 【以上插入节点已经完成，剩下的任务要根据随机数的值来表示是否向上增加层数与上层索引】\n      \n      // 随机数\n      int rnd = ThreadLocalRandom.nextSecondarySeed();\n      \n      // 如果随机数的二进制与 10000000000000000000000000000001 进行与运算为 0\n      // 即随机数的二进制最高位与最末尾必须为 0，其他位无所谓，就进入该循环\n      // 如果随机数的二进制最高位与最末位不为 0，不增加新节点的层数\n      \n      // 11.判断是否需要添加 level，32 位\n      if ((rnd & 0x80000001) == 0) {\n          // 索引层 level，从 1 开始，就是最底层\n          int level = 1, max;\n          // 12.判断最低位前面有几个 1，有几个leve就加几：0..0 0001 1110，这是4个，则1+4=5\n          //    【最大有30个就是 1 + 30 = 31\n          while (((rnd >>>= 1) & 1) != 0)\n              ++level;\n          // 最终会指向 z 节点，就是添加的节点 \n          Index<K,V> idx = null;\n          // 指向头索引节点\n          HeadIndex<K,V> h = head;\n          \n          // 13.判断level是否比当前最高索引小，图中 max 为 3\n          if (level <= (max = h.level)) {\n              for (int i = 1; i <= level; ++i)\n                  // 根据层数level不断创建新增节点的上层索引，索引的后继索引留空\n                  // 第一次idx为null，也就是下层索引为空，第二次把上次的索引作为下层索引，【类似头插法】\n                  idx = new Index<K,V>(z, idx, null);\n              // 循环以后的索引结构\n              // index-3\t← idx\n              //   ↓\n              // index-2\n              //   ↓\n              // index-1\n              //   ↓\n              //  z-node\n          }\n          // 14.若 level > max，则【只增加一层 index 索引层】，3 + 1 = 4\n          else { \n              level = max + 1;\n              //创建一个 index 数组，长度是 level+1，假设 level 是 4，创建的数组长度为 5\n              Index<K,V>[] idxs = (Index<K,V>[])new Index<?,?>[level+1];\n              // index[0]的数组 slot 并没有使用，只使用 [1,level] 这些数组的 slot\n              for (int i = 1; i <= level; ++i)\n                  idxs[i] = idx = new Index<K,V>(z, idx, null);\n                \t\t// index-4   ← idx\n                      //   ↓\n                    \t// ......\n                      //   ↓\n                      // index-1\n                      //   ↓\n                      //  z-node\n              \n              for (;;) {\n                  h = head;\n                  // 获取头索引的层数，3\n                  int oldLevel = h.level;\n                  // 如果 level <= oldLevel，说明其他线程进行了 index 层增加操作，退出循环\n                  if (level <= oldLevel)\n                      break;\n                  // 定义一个新的头索引节点\n                  HeadIndex<K,V> newh = h;\n                  // 获取头索引的节点，就是 BASE_HEADER\n                  Node<K,V> oldbase = h.node;\n                  // 升级 baseHeader 索引，升高一级，并发下可能升高多级\n                  for (int j = oldLevel + 1; j <= level; ++j)\n                      // 参数1：底层node，参数二：down，为以前的头节点，参数三：right，新建\n                      newh = new HeadIndex<K,V>(oldbase, newh, idxs[j], j);\n                  // 执行完for循环之后，baseHeader 索引长这个样子，这里只升高一级\n                  // index-4             →             index-4\t← idx\n                  //   ↓                                  ↓\n                  // index-3                           index-3     \n                  //   ↓                                  ↓\n                  // index-2                           index-2\n                  //   ↓                                  ↓\n                  // index-1                           index-1\n                  //   ↓                                  ↓\n                  // baseHeader    →    ....      →     z-node\n                  \n                  // cas 成功后，head 字段指向最新的 headIndex，baseHeader 的 index-4\n                  if (casHead(h, newh)) {\n                      // h 指向最新的 index-4 节点\n                      h = newh;\n                      // 让 idx 指向 z-node 的 index-3 节点，\n  \t\t\t\t\t// 因为从 index-3 - index-1 的这些 z-node 索引节点 都没有插入到索引链表\n                      idx = idxs[level = oldLevel];\n                      break;\n                  }\n              }\n          }\n          // 15.【把新加的索引插入索引链表中】，有上述两种情况，一种索引高度不变，另一种是高度加 1\n          // 要插入的是第几层的索引\n          splice: for (int insertionLevel = level;;) {\n              // 获取头索引的层数，情况 1 是 3，情况 2 是 4\n              int j = h.level;\n              // 【遍历 insertionLevel 层的索引，找到合适的插入位置】\n              for (Index<K,V> q = h, r = q.right, t = idx;;) {\n                  // 如果头索引为 null 或者新增节点索引为 null，退出插入索引的总循环\n                  if (q == null || t == null)\n                      // 此处表示有其他线程删除了头索引或者新增节点的索引\n                      break splice;\n                  // 头索引的链表后续索引存在，如果是新层则为新节点索引，如果是老层则为原索引\n                  if (r != null) {\n                      // 获取r的节点\n                      Node<K,V> n = r.node;\n                      // 插入的key和n.key的比较值\n                      int c = cpr(cmp, key, n.key);\n                      // 【删除空值索引】\n                      if (n.value == null) {\n                          if (!q.unlink(r))\n                              break;\n                          r = q.right;\n                          continue;\n                      }\n                      // key > r.node.key，向右扫描\n                      if (c > 0) {\n                          q = r;\n                          r = r.right;\n                          continue;\n                      }\n                  }\n                  // 执行到这里，说明 key < r.node.key，判断是否是第 j 层插入新增节点的前置索引\n                  if (j == insertionLevel) {\n                      // 【将新索引节点 t 插入 q r 之间】\n                      if (!q.link(r, t))\n                          break; \n                      // 如果新增节点的值为 null，表示该节点已经被其他线程删除\n                      if (t.node.value == null) {\n                          // 找到该节点\n                          findNode(key);\n                          break splice;\n                      }\n                      // 插入层逐层自减，当为最底层时退出循环\n                      if (--insertionLevel == 0)\n                          break splice;\n                  }\n  \t\t\t\t// 其他节点随着插入节点的层数下移而下移\n                  if (--j >= insertionLevel && j < level)\n                      t = t.down;\n                  q = q.down;\n                  r = q.right;\n              }\n          }\n      }\n      return null;\n  }\n  ```\n\n* findNode()\n\n  ```java\n  private Node<K,V> findNode(Object key) {\n      // 原理与doGet相同，无非是 findNode 返回节点，doGet 返回 value\n      if ((c = cpr(cmp, key, n.key)) == 0)\n          return n;\n  }\n  ```\n\n\n\n\n***\n\n\n\n##### 获取方法\n\n* get(key)：获取对应的数据\n\n  ```java\n  public V get(Object key) {\n      return doGet(key);\n  }\n  ```\n  \n* doGet()：扫描过程会对已 value = null 的元素进行删除处理\n\n  ```java\n  private V doGet(Object key) {\n      if (key == null)\n          throw new NullPointerException();\n      Comparator<? super K> cmp = comparator;\n      outer: for (;;) {\n          // 1.找到最底层节点的前置节点\n          for (Node<K,V> b = findPredecessor(key, cmp), n = b.next;;) {\n              Object v; int c;\n              // 2.【如果该前置节点的链表后续节点为 null，说明不存在该节点】\n              if (n == null)\n                  break outer;\n              // b → n → f\n              Node<K,V> f = n.next;\n              // 3.如果n不为前置节点的后续节点，表示已经有其他线程删除了该节点\n              if (n != b.next) \n                  break;\n              // 4.如果后续节点的值为null，【需要帮助删除该节点】\n              if ((v = n.value) == null) {\n                  n.helpDelete(b, f);\n                  break;\n              }\n              // 5.如果前置节点已被其他线程删除，重新循环\n              if (b.value == null || v == n)\n                  break;\n               // 6.如果要获取的key与后续节点的key相等，返回节点的value\n              if ((c = cpr(cmp, key, n.key)) == 0) {\n                  @SuppressWarnings(\"unchecked\") V vv = (V)v;\n                  return vv;\n              }\n              // 7.key < n.key，因位 key > b.key，b 和 n 相连，说明不存在该节点或者被其他线程删除了\n              if (c < 0)\n                  break outer;\n              b = n;\n              n = f;\n          }\n      }\n      return null;\n  }\n  ```\n\n  \n\n****\n\n\n\n##### 删除方法\n\n* remove()\n\n  ```java\n  public V remove(Object key) {\n      return doRemove(key, null);\n  }\n  final V doRemove(Object key, Object value) {\n      if (key == null)\n          throw new NullPointerException();\n      Comparator<? super K> cmp = comparator;\n      outer: for (;;) {\n          // 1.找到最底层目标节点的前置节点，b.key < key\n          for (Node<K,V> b = findPredecessor(key, cmp), n = b.next;;) {\n              Object v; int c;\n              // 2.如果该前置节点的链表后续节点为 null，退出循环，说明不存在这个元素\n              if (n == null)\n                  break outer;\n              // b → n → f\n              Node<K,V> f = n.next;\n              if (n != b.next)                    // inconsistent read\n                  break;\n              if ((v = n.value) == null) {        // n is deleted\n                  n.helpDelete(b, f);\n                  break;\n              }\n              if (b.value == null || v == n)      // b is deleted\n                  break;\n              //3.key < n.key，说明被其他线程删除了，或者不存在该节点\n              if ((c = cpr(cmp, key, n.key)) < 0)\n                  break outer;\n              //4.key > n.key，继续向后扫描\n              if (c > 0) {\n                  b = n;\n                  n = f;\n                  continue;\n              }\n              //5.到这里是 key = n.key，value 不为空的情况下判断 value 和 n.value 是否相等\n              if (value != null && !value.equals(v))\n                  break outer;\n              //6.【把 n 节点的 value 置空】\n              if (!n.casValue(v, null))\n                  break;\n              //7.【给 n 添加一个删除标志 mark】，mark.next = f，然后把 b.next 设置为 f，成功后n出队\n              if (!n.appendMarker(f) || !b.casNext(n, f))\n                  // 对 key 对应的 index 进行删除，调用了 findPredecessor 方法\n                  findNode(key);\n              else {\n                  // 进行操作失败后通过 findPredecessor 中进行 index 的删除\n                  findPredecessor(key, cmp);\n                  if (head.right == null)\n                      // 进行headIndex 对应的index 层的删除\n                      tryReduceLevel();\n              }\n              @SuppressWarnings(\"unchecked\") V vv = (V)v;\n              return vv;\n          }\n      }\n      return null;\n  }\n  ```\n\n  经过 findPredecessor() 中的 unlink() 后索引已经被删除\n\n  ![image-20230824175621276](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824175621276.png)\n\n* appendMarker()：添加删除标记节点\n\n  ```java\n  boolean appendMarker(Node<K,V> f) {\n      // 通过 CAS 让 n.next 指向一个 key 为 null，value 为 this，next 为 f 的标记节点\n      return casNext(f, new Node<K,V>(f));\n  }\n  ```\n  \n* helpDelete()：将添加了删除标记的节点清除，参数是该节点的前驱和后继节点\n\n  ```java\n  void helpDelete(Node<K,V> b, Node<K,V> f) {\n      // this 节点的后续节点为 f，且本身为 b 的后续节点，一般都是正确的，除非被别的线程删除\n      if (f == next && this == b.next) {\n          // 如果 n 还还没有被标记\n          if (f == null || f.value != f) \n              casNext(f, new Node<K,V>(f));\n          else\n              // 通过 CAS，将 b 的下一个节点 n 变成 f.next，即成为图中的样式\n              b.casNext(this, f.next);\n      }\n  }\n  ```\n  \n* tryReduceLevel()：删除索引\n\n  ```java\n  private void tryReduceLevel() {\n      HeadIndex<K,V> h = head;\n      HeadIndex<K,V> d;\n      HeadIndex<K,V> e;\n      if (h.level > 3 &&\n          (d = (HeadIndex<K,V>)h.down) != null &&\n          (e = (HeadIndex<K,V>)d.down) != null &&\n          e.right == null &&\n          d.right == null &&\n          h.right == null &&\n          // 设置头索引\n          casHead(h, d) && \n          // 重新检查\n          h.right != null) \n          // 重新检查返回true，说明其他线程增加了索引层级，把索引头节点设置回来\n          casHead(d, h);   \n  }\n  ```\n\n\n\n参考文章：https://my.oschina.net/u/3768341/blog/3135659\n\n参考视频：https://www.bilibili.com/video/BV1Er4y1P7k1\n\n\n\n\n\n***\n\n\n\n### NoBlocking\n\n#### 非阻塞队列\n\n并发编程中，需要用到安全的队列，实现安全队列可以使用 2 种方式：\n\n* 加锁，这种实现方式是阻塞队列\n* 使用循环 CAS 算法实现，这种方式是非阻塞队列\n\nConcurrentLinkedQueue 是一个基于链接节点的无界线程安全队列，采用先进先出的规则对节点进行排序，当添加一个元素时，会添加到队列的尾部，当获取一个元素时，会返回队列头部的元素\n\n补充：ConcurrentLinkedDeque 是双向链表结构的无界并发队列\n\nConcurrentLinkedQueue 使用约定：\n\n1. 不允许 null 入列\n2. 队列中所有未删除的节点的 item 都不能为 null 且都能从 head 节点遍历到\n3. 删除节点是将 item 设置为 null，队列迭代时跳过 item 为 null 节点\n4. head 节点跟 tail 不一定指向头节点或尾节点，可能**存在滞后性**\n\nConcurrentLinkedQueue 由 head 节点和 tail 节点组成，每个节点由节点元素和指向下一个节点的引用组成，组成一张链表结构的队列\n\n```java\nprivate transient volatile Node<E> head;\nprivate transient volatile Node<E> tail;\n\nprivate static class Node<E> {\n    volatile E item;\n    volatile Node<E> next;\n    //.....\n}\n```\n\n\n\n***\n\n\n\n#### 构造方法\n\n* 无参构造方法：\n\n  ```java\n  public ConcurrentLinkedQueue() {\n      // 默认情况下 head 节点存储的元素为空，dummy 节点，tail 节点等于 head 节点\n      head = tail = new Node<E>(null);\n  }\n  ```\n\n* 有参构造方法\n\n  ```java\n  public ConcurrentLinkedQueue(Collection<? extends E> c) {\n      Node<E> h = null, t = null;\n      // 遍历节点\n      for (E e : c) {\n          checkNotNull(e);\n          Node<E> newNode = new Node<E>(e);\n          if (h == null)\n              h = t = newNode;\n          else {\n              // 单向链表\n              t.lazySetNext(newNode);\n              t = newNode;\n          }\n      }\n      if (h == null)\n          h = t = new Node<E>(null);\n      head = h;\n      tail = t;\n  }\n  ```\n\n\n\n***\n\n\n\n#### 入队方法\n\n与传统的链表不同，单线程入队的工作流程：\n\n* 将入队节点设置成当前队列尾节点的下一个节点\n* 更新 tail 节点，如果 tail 节点的 next 节点不为空，则将入队节点设置成 tail 节点；如果 tail 节点的 next 节点为空，则将入队节点设置成 tail 的 next 节点，所以 tail 节点不总是尾节点，**存在滞后性**\n\n```java\npublic boolean offer(E e) {\n    checkNotNull(e);\n    // 创建入队节点\n    final Node<E> newNode = new Node<E>(e);\n\t\n    // 循环 CAS 直到入队成功\n    for (Node<E> t = tail, p = t;;) {\n        // p 用来表示队列的尾节点，初始情况下等于 tail 节点，q 是 p 的 next 节点\n        Node<E> q = p.next;\n        // 条件成立说明 p 是尾节点\n        if (q == null) {\n            // p 是尾节点，设置 p 节点的下一个节点为新节点\n            // 设置成功则 casNext 返回 true，否则返回 false，说明有其他线程更新过尾节点，继续寻找尾节点，继续 CAS\n            if (p.casNext(null, newNode)) {\n                // 首次添加时，p 等于 t，不进行尾节点更新，所以尾节点存在滞后性\n                if (p != t)\n                    // 将 tail 设置成新入队的节点，设置失败表示其他线程更新了 tail 节点\n                    casTail(t, newNode); \n                return true;\n            }\n        }\n        else if (p == q)\n            // 当 tail 不指向最后节点时，如果执行出列操作，可能将 tail 也移除，tail 不在链表中 \n        \t// 此时需要对 tail 节点进行复位，复位到 head 节点\n            p = (t != (t = tail)) ? t : head;\n        else\n            // 推动 tail 尾节点往队尾移动\n            p = (p != t && t != (t = tail)) ? t : q;\n    }\n}\n```\n\n图解入队：\n\n![image-20230824175705470](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824175705470.png)\n\n![image-20230824175745374](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824175745374.png)\n\n![image-20230824175937960](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824175937960.png)\n\n当 tail 节点和尾节点的距离**大于等于 1** 时（每入队两次）更新 tail，可以减少 CAS 更新 tail 节点的次数，提高入队效率\n\n线程安全问题：\n\n* 线程 1 线程 2 同时入队，无论从哪个位置开始并发入队，都可以循环 CAS，直到入队成功，线程安全\n* 线程 1 遍历，线程 2 入队，所以造成 ConcurrentLinkedQueue 的 size 是变化，需要加锁保证安全\n* 线程 1 线程 2 同时出列，线程也是安全的\n\n\n\n***\n\n\n\n#### 出队方法\n\n出队列的就是从队列里返回一个节点元素，并清空该节点对元素的引用，并不是每次出队都更新 head 节点\n\n* 当 head 节点里有元素时，直接弹出 head 节点里的元素，而不会更新 head 节点\n* 当 head 节点里没有元素时，出队操作才会更新 head 节点\n\n**批处理方式**可以减少使用 CAS 更新 head 节点的消耗，从而提高出队效率\n\n```java\npublic E poll() {\n    restartFromHead:\n    for (;;) {\n        // p 节点表示首节点，即需要出队的节点，FIFO\n        for (Node<E> h = head, p = h, q;;) {\n            E item = p.item;\n\t\t\t// 如果 p 节点的元素不为 null，则通过 CAS 来设置 p 节点引用元素为 null，成功返回 item\n            if (item != null && p.casItem(item, null)) {\n                if (p != h)\t\n                   \t// 对 head 进行移动\n                    updateHead(h, ((q = p.next) != null) ? q : p);\n                return item;\n            }\n           \t// 逻辑到这说明头节点的元素为空或头节点发生了变化，头节点被另外一个线程修改了\n            // 那么获取 p 节点的下一个节点，如果 p 节点的下一节点也为 null，则表明队列已经空了\n            else if ((q = p.next) == null) {\n                updateHead(h, p);\n                return null;\n            }\n      \t\t// 第一轮操作失败，下一轮继续，调回到循环前\n            else if (p == q)\n                continue restartFromHead;\n            // 如果下一个元素不为空，则将头节点的下一个节点设置成头节点\n            else\n                p = q;\n        }\n    }\n}\nfinal void updateHead(Node<E> h, Node<E> p) {\n    if (h != p && casHead(h, p))\n        // 将旧结点 h 的 next 域指向为 h，help gc\n        h.lazySetNext(h);\n}\n```\n\n在更新完 head 之后，会将旧的头结点 h 的 next 域指向为 h，图中所示的虚线也就表示这个节点的自引用，被移动的节点（item 为 null 的节点）会被 GC 回收\n\n![image-20230824180023394](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824180023394.png)\n\n![image-20230824180101118](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824180101118.png)\n\n![image-20230824180122859](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824180122859.png)\n\n如果这时，有一个线程来添加元素，通过 tail 获取的 next 节点则仍然是它本身，这就出现了p == q 的情况，出现该种情况之后，则会触发执行 head 的更新，将 p 节点重新指向为 head\n\n\n\n参考文章：https://www.jianshu.com/p/231caf90f30b\n\n\n\n***\n\n\n\n#### 成员方法\n\n* peek()：会改变 head 指向，执行 peek() 方法后 head 会指向第一个具有非空元素的节点\n\n  ```java\n  // 获取链表的首部元素，只读取而不移除\n  public E peek() {\n      restartFromHead:\n      for (;;) {\n          for (Node<E> h = head, p = h, q;;) {\n              E item = p.item;\n              if (item != null || (q = p.next) == null) {\n                  // 更改h的位置为非空元素节点\n                  updateHead(h, p);\n                  return item;\n              }\n              else if (p == q)\n                  continue restartFromHead;\n              else\n                  p = q;\n          }\n      }\n  }\n  ```\n  \n* size()：用来获取当前队列的元素个数，因为整个过程都没有加锁，在并发环境中从调用 size 方法到返回结果期间有可能增删元素，导致统计的元素个数不精确\n\n  ```java\n  public int size() {\n      int count = 0;\n      // first() 获取第一个具有非空元素的节点，若不存在，返回 null\n      // succ(p) 方法获取 p 的后继节点，若 p == p.next，则返回 head\n      // 类似遍历链表\n      for (Node<E> p = first(); p != null; p = succ(p))\n          if (p.item != null)\n              // 最大返回Integer.MAX_VALUE\n              if (++count == Integer.MAX_VALUE)\n                  break;\n      return count;\n  }\n  ```\n  \n* remove()：移除元素\n\n  ```java\n  public boolean remove(Object o) {\n      // 删除的元素不能为null\n      if (o != null) {\n          Node<E> next, pred = null;\n          for (Node<E> p = first(); p != null; pred = p, p = next) {\n              boolean removed = false;\n              E item = p.item;\n              // 节点元素不为null\n              if (item != null) {\n                  // 若不匹配，则获取next节点继续匹配\n                  if (!o.equals(item)) {\n                      next = succ(p);\n                      continue;\n                  }\n                  // 若匹配，则通过 CAS 操作将对应节点元素置为 null\n                  removed = p.casItem(item, null);\n              }\n              // 获取删除节点的后继节点\n              next = succ(p);\n              // 将被删除的节点移除队列\n              if (pred != null && next != null) // unlink\n                  pred.casNext(p, next);\n              if (removed)\n                  return true;\n          }\n      }\n      return false;\n  }\n  ```\n\n\n\n\n\n\n\n***\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"并发编程整理版-无锁","tags":["CAS","Atomic","volatile","LongAdder","Unsafe","final","ThreadLocal"],"categories":["Java","并发编程"],"author":"imklaus","excerpt":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Concurrent_Programming-Lock_Free","content":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n## 无锁\r\n\r\n### CAS\r\n\r\n#### 例子\r\n\r\n```java\r\ninterface Account {\r\n\tInteger getBalance();\r\n\r\n\tvoid withdraw(Integer amount);\r\n\r\n\t/**\r\n\t * 方法内会启动 1000 个线程，每个线程做 -10 元 的操作     \r\n\t * 如果初始余额为 10000 那么正确的结果应当是 0\r\n\t */\r\n\tstatic void demo(Account account) {\r\n\t\tList<Thread> ts = new ArrayList<>();\r\n\t\tlong start = System.nanoTime();\r\n\t\tfor (int i = 0; i < 1000; i++) {\r\n\t\t\tts.add(new Thread(() -> {\r\n\t\t\t\taccount.withdraw(10);\r\n\t\t\t}));\r\n\t\t}\r\n\t\tts.forEach(Thread::start);\r\n\t\tts.forEach(t -> {\r\n\t\t\ttry {\r\n\t\t\t\tt.join();\r\n\t\t\t} catch (InterruptedException e) {\r\n\t\t\t\te.printStackTrace();\r\n\t\t\t}\r\n\t\t});\r\n\t\tlong end = System.nanoTime();\r\n\t\tSystem.out.println(account.getBalance() + \" cost: \" + (end - start) / 1000_000 + \" ms\");\r\n\t}\r\n}\r\n\r\n//线程不安全的做法\r\nclass AccountUnsafe implements Account {\r\n\tprivate Integer balance;\r\n\r\n\tpublic AccountUnsafe(Integer balance) {\r\n\t\tthis.balance = balance;\r\n\t}\r\n\r\n\r\n\t@Override\r\n\tpublic Integer getBalance() {\r\n\t\treturn this.balance;\r\n\t}\r\n\r\n\t@Override\r\n\tpublic synchronized void withdraw(Integer amount) {\r\n\t\tbalance -= amount;\r\n\t}\r\n\r\n\tpublic static void main(String[] args) {\r\n\t\tAccount.demo(new AccountUnsafe(10000));\r\n\t\tAccount.demo(new AccountCas(10000));\r\n\t}\r\n}\r\n\r\n//线程安全的做法\r\nclass AccountCas implements Account {\r\n\t//使用原子整数\r\n\tprivate AtomicInteger balance;\r\n\r\n\tpublic AccountCas(int balance) {\r\n\t\tthis.balance = new AtomicInteger(balance);\r\n\t}\r\n\r\n\t@Override\r\n\tpublic Integer getBalance() {\r\n\t\t//得到原子整数的值\r\n\t\treturn balance.get();\r\n\t}\r\n\r\n\t@Override\r\n\tpublic void withdraw(Integer amount) {\r\n\t\t\t// 需要不断尝试，直到成功为止\r\n            while (true) {\r\n            // 比如拿到了旧值 1000\r\n            int prev = balance.get();\r\n            // 在这个基础上 1000-10 = 990\r\n            int next = prev - amount;\r\n            /*\r\n            compareAndSet 正是做这个检查，在 set 前，先比较 prev 与当前值\r\n            - 不一致了，next 作废，返回 false 表示失败\r\n            比如，别的线程已经做了减法，当前值已经被减成了 990\r\n            那么本线程的这次 990 就作废了，进入 while 下次循环重试\r\n            - 一致，以 next 设置为新值，返回 true 表示成功\r\n            */\r\n\t\t\tif(balance.compareAndSet(prev, next)) {\r\n\t\t\t\tbreak;\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n```\r\n\r\n前面看到的 AtomicInteger 通过无锁解决线程安全问题，内部并没有用锁来保护共享变量的线程安全。那么它是如何实现的呢？其中的**关键是 compareAndSet**（比较并设置值），它的**简称就是 CAS** （也有 Compare And Swap 的说法），它必须是**原子操作**。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145914.png)\r\n\r\n**工作流程**\r\n\r\n- 当一个线程要去修改Account对象中的值时，先获取值pre（调用get方法），然后再将其设置为新的值next（调用cas方法）。在调用cas方法时，会将pre与Account中的余额进行比较。\r\n  - 如果**两者相等**，就说明该值还未被其他线程修改，此时便可以进行修改操作。\r\n  - 如果**两者不相等**，就不设置值，重新获取值pre（调用get方法），然后再将其设置为新的值next（调用cas方法），直到修改成功为止。\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n#### 原理\r\n\r\n无锁编程：Lock Free\r\n\r\nCAS 的全称是 Compare-And-Swap，是 **CPU 并发原语**\r\n\r\n* CAS 并发原语体现在 Java 语言中就是 sun.misc.Unsafe 类的各个方法，调用 UnSafe 类中的 CAS 方法，JVM 会实现出 CAS 汇编指令，这是一种完全依赖于硬件的功能，实现了原子操作\r\n* CAS 是一种系统原语，原语属于操作系统范畴，是由若干条指令组成 ，用于完成某个功能的一个过程，并且原语的执行必须是连续的，执行过程中不允许被中断，所以 CAS 是一条 CPU 的原子指令，不会造成数据不一致的问题，是线程安全的\r\n\r\n底层原理：CAS 的底层是 `lock cmpxchg` 指令（X86 架构），在单核和多核 CPU 下都能够保证比较交换的原子性\r\n\r\n* 程序是在单核处理器上运行，会省略 lock 前缀，单处理器自身会维护处理器内的顺序一致性，不需要 lock 前缀的内存屏障效果\r\n\r\n* 程序是在多核处理器上运行，会为 cmpxchg 指令加上 lock 前缀。当某个核执行到带 lock 的指令时，CPU 会执行**总线锁定或缓存锁定**，将修改的变量写入到主存，这个过程不会被线程的调度机制所打断，保证了多个线程对内存操作的原子性\r\n\r\n作用：比较当前工作内存中的值和主物理内存中的值，如果相同则执行规定操作，否则继续比较直到主内存和工作内存的值一致为止\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n#### 前提\r\n\r\n**CAS 必须借助 volatile** 才能读取到共享变量的新值来实现【比较并交换】的效果\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n#### **效率高**\r\n\r\n- 无锁情况下，即使重试失败，线程始终在高速运行，没有停歇，而 synchronized 会让线程在没有获得锁的时候，发生上下文切换，进入阻塞。\r\n- 打个比喻，线程就好像高速跑道上的赛车，高速运行时，速度超快，一旦发生上下文切换，就好比赛车要减速、熄火，等被唤醒又得重新打火、启动、加速... 恢复到高速运行，代价比较大\r\n- 但无锁情况下，因为线程要保持运行，需要额外 CPU 的支持，CPU 在这里就好比高速跑道，没有额外的跑道，线程想高速运行也无从谈起，虽然不会进入阻塞，但由于没有分到时间片，仍然会进入不可运行状态，还是会导致上下文切换。（超过了CPU核心数也就没有了额外的跑道了，运行也运行不了，只能上下文切换，所以**在线程数小于CPU核心数时用CAS是非常合适的**）\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n#### 优缺点\r\n\r\nCAS 特点:\r\n\r\n* CAS 体现的是**无锁并发、无阻塞并发**，线程不会陷入阻塞，线程不需要频繁切换状态（上下文切换，系统调用）\r\n* CAS 是基于乐观锁的思想\r\n\r\nCAS 缺点：\r\n\r\n- 执行的是循环操作，如果比较不成功一直在循环，最差的情况某个线程一直取到的值和预期值都不一样，就会无限循环导致饥饿，**使用 CAS 线程数不要超过 CPU 的核心数**，采用分段 CAS 和自动迁移机制\r\n- 只能保证一个共享变量的原子操作\r\n  - 对于一个共享变量执行操作时，可以通过循环 CAS 的方式来保证原子操作\r\n  - 对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候**只能用锁来保证原子性**\r\n- 引出来 ABA 问题\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 乐观锁\r\n\r\nCAS 与 synchronized 总结：\r\n\r\n* synchronized 是从悲观的角度出发：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程），因此 synchronized 也称之为悲观锁，ReentrantLock 也是一种悲观锁，性能较差\r\n* CAS 是从乐观的角度出发：总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据。**如果别人修改过，则获取现在最新的值，如果别人没修改过，直接修改共享数据的值**，CAS 这种机制也称之为乐观锁，综合性能较好\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Atomic\r\n\r\n#### 常用API\r\n\r\n常见原子类：AtomicInteger、AtomicBoolean、AtomicLong\r\n\r\n构造方法：\r\n\r\n* `public AtomicInteger()`：初始化一个默认值为 0 的原子型 Integer\r\n* `public AtomicInteger(int initialValue)`：初始化一个指定值的原子型 Integer\r\n\r\n常用API：\r\n\r\n| 方法                                  | 作用                                                         |\r\n| ------------------------------------- | ------------------------------------------------------------ |\r\n| public final int get()                | 获取 AtomicInteger 的值                                      |\r\n| public final int getAndIncrement()    | 以原子方式将当前值加 1，返回的是自增前的值                   |\r\n| public final int incrementAndGet()    | 以原子方式将当前值加 1，返回的是自增后的值                   |\r\n| public final int getAndSet(int value) | 以原子方式设置为 newValue 的值，返回旧值                     |\r\n| public final int addAndGet(int data)  | 以原子方式将输入的数值与实例中的值相加并返回<br />实例：AtomicInteger 里的 value |\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 原理分析\r\n\r\n**AtomicInteger 原理**：自旋锁  + CAS 算法\r\n\r\nCAS 算法：有 3 个操作数（内存值 V， 旧的预期值 A，要修改的值 B）\r\n\r\n* 当旧的预期值 A == 内存值 V   此时可以修改，将 V 改为 B\r\n* 当旧的预期值 A !=  内存值 V   此时不能修改，并重新获取现在的最新值，重新获取的动作就是自旋 \r\n\r\n分析 getAndSet 方法：\r\n\r\n* AtomicInteger：\r\n\r\n  ```java\r\n  public final int getAndSet(int newValue) {\r\n      /**\r\n      * this: \t\t当前对象\r\n      * valueOffset:\t内存偏移量，内存地址\r\n      */\r\n      return unsafe.getAndSetInt(this, valueOffset, newValue);\r\n  }\r\n  ```\r\n\r\n  valueOffset：偏移量表示该变量值相对于当前对象地址的偏移，Unsafe 就是根据内存偏移地址获取数据\r\n\r\n  ```java\r\n  valueOffset = unsafe.objectFieldOffset\r\n                  (AtomicInteger.class.getDeclaredField(\"value\"));\r\n  //调用本地方法   -->\r\n  public native long objectFieldOffset(Field var1);\r\n  ```\r\n\r\n* unsafe 类：\r\n\r\n  ```java\r\n  // val1: AtomicInteger对象本身，var2: 该对象值得引用地址，var4: 需要变动的数\r\n  public final int getAndSetInt(Object var1, long var2, int var4) {\r\n      int var5;\r\n      do {\r\n          // var5: 用 var1 和 var2 找到的内存中的真实值\r\n          var5 = this.getIntVolatile(var1, var2);\r\n      } while(!this.compareAndSwapInt(var1, var2, var5, var4));\r\n  \r\n      return var5;\r\n  }\r\n  ```\r\n\r\n  var5：从主内存中拷贝到工作内存中的值（每次都要从主内存拿到最新的值到本地内存），然后执行 `compareAndSwapInt()` 再和主内存的值进行比较，假设方法返回 false，那么就一直执行 while 方法，直到期望的值和真实值一样，修改数据\r\n\r\n* 变量 value 用 volatile 修饰，保证了多线程之间的内存可见性，避免线程从**工作缓存**中获取失效的变量\r\n\r\n  ```java\r\n  private volatile int value\r\n  ```\r\n\r\n  **CAS 必须借助 volatile 才能读取到共享变量的最新值来实现比较并交换的效果**\r\n  \r\n  > 在计算机系统中，缓存（cache）是一种存储数据的临时存储器，用于加快数据的访问速度。缓存通常位于CPU和主存之间，用于存储最近或频繁访问的数据，以避免频繁访问主存所带来的延迟。\r\n  >\r\n  > 当一个变量被读取或写入时，CPU会首先在缓存中查找该变量的值。如果在缓存中找到了相应的值（即命中缓存），CPU就无需访问主存，从而加快了数据访问速度。但是，当不同的线程同时访问同一个变量时，由于缓存是每个CPU核心独立的，其中的数据可能并不是最新的，这就可能导致线程间的数据不一致性。\r\n  >\r\n  > 所以，volatile关键字可以告诉CPU每次访问该变量都要从内存中读取最新的值，而不是从缓存中读取，从而保证了该变量对所有线程的可见性。\r\n\r\n分析 getAndUpdate 方法：\r\n\r\n* getAndUpdate：\r\n\r\n  ```java\r\n  public final int getAndUpdate(IntUnaryOperator updateFunction) {\r\n      int prev, next;\r\n      do {\r\n          prev = get();\t//当前值，cas的期望值\r\n          next = updateFunction.applyAsInt(prev);//期望值更新到该值\r\n      } while (!compareAndSet(prev, next));//自旋\r\n      return prev;\r\n  }\r\n  ```\r\n\r\n  模仿：\r\n\r\n  ```java\r\n  public static void main(String[] args) {\r\n      AtomicInteger i = new AtomicInteger(5);\r\n      System.out.println(updateAndGet(i, p -> p / 2));\r\n  }\r\n  public static int updateAndGet(AtomicInteger i, IntUnaryOperator operator) {\r\n          while (true) {\r\n              int prev = i.get();\r\n              int next = operator.applyAsInt(prev);\r\n              if (i.compareAndSet(prev, next)) {\r\n                  return next;\r\n              }\r\n          }\r\n      }\r\n  ```\r\n\r\n  函数式接口：可以自定义操作逻辑\r\n\r\n  ```java\r\n  AtomicInteger a = new AtomicInteger();\r\n  a.getAndUpdate(i -> i + 10);\r\n  ```\r\n\r\n* compareAndSet：\r\n\r\n  ```java\r\n  public final boolean compareAndSet(int expect, int update) {\r\n      /**\r\n      * this: \t\t当前对象\r\n      * valueOffset:\t内存偏移量，内存地址\r\n      * expect:\t\t期望的值\r\n      * update: \t\t更新的值\r\n      */\r\n      return unsafe.compareAndSwapInt(this, valueOffset, expect, update);\r\n  }\r\n  ```\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 原子引用\r\n\r\n原子引用：对 Object 进行原子操作，提供一种读和写都是原子性的对象引用变量\r\n\r\n原子引用类：AtomicReference、AtomicStampedReference、AtomicMarkableReference\r\n\r\nAtomicReference 类：\r\n\r\n* 构造方法：\r\n  * `public AtomicReference(V initialValue)`：初始化一个指定值的原子引用\r\n\r\n  * `public AtomicReference()`：初始化一个默认值为 null 的原子引用\r\n\r\n* 常用 API：\r\n  * `public final boolean compareAndSet(V expectedValue, V newValue)`：CAS 操作\r\n  * `public final void set(V newValue)`：将值设置为 newValue \r\n  * `public final V get()`：返回当前值\r\n\r\n```java\r\npublic class AtomicReferenceDemo {\r\n    public static void main(String[] args) {\r\n        Student s1 = new Student(33, \"z3\");\r\n        \r\n        // 创建原子引用包装类\r\n        AtomicReference<Student> atomicReference = new AtomicReference<>();\r\n        // 设置主内存共享变量为s1\r\n        atomicReference.set(s1);\r\n\r\n        // 比较并交换，如果现在主物理内存的值为 z3，那么交换成 l4\r\n        while (true) {\r\n            Student s2 = new Student(44, \"l4\");\r\n            if (atomicReference.compareAndSet(s1, s2)) {\r\n                break;\r\n            }\r\n        }\r\n        System.out.println(atomicReference.get());\r\n    }\r\n}\r\n\r\nclass Student {\r\n    private int id;\r\n    private String name;\r\n    //。。。。\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 原子数组\r\n\r\n原子数组类：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray\r\n\r\nAtomicIntegerArray 类方法：\r\n\r\n```java\r\n/**\r\n*   i\t\tthe index\r\n* expect \tthe expected value\r\n* update \tthe new value\r\n*/\r\npublic final boolean compareAndSet(int i, int expect, int update) {\r\n    return compareAndSetRaw(checkedByteOffset(i), expect, update);\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 原子更新器\r\n\r\n原子更新器类：AtomicReferenceFieldUpdater、AtomicIntegerFieldUpdater、AtomicLongFieldUpdater\r\n\r\n利用字段更新器，可以针对对象的某个域（Field）进行原子操作，只能配合 volatile 修饰的字段使用，否则会出现异常 `IllegalArgumentException: Must be volatile type`\r\n\r\n常用 API：\r\n\r\n* `static <U> AtomicIntegerFieldUpdater<U> newUpdater(Class<U> c, String fieldName)`：静态方法\r\n* `abstract boolean compareAndSet(T obj, int expect, int update)`：CAS\r\n\r\n```java\r\npublic class UpdateDemo {\r\n    private volatile int field;\r\n    \r\n    public static void main(String[] args) {\r\n        AtomicIntegerFieldUpdater fieldUpdater = AtomicIntegerFieldUpdater\r\n            \t\t.newUpdater(UpdateDemo.class, \"field\");\r\n        UpdateDemo updateDemo = new UpdateDemo();\r\n        fieldUpdater.compareAndSet(updateDemo, 0, 10);\r\n        System.out.println(updateDemo.field);//10\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 原子累加器\r\n\r\n原子累加器类：LongAdder、DoubleAdder、LongAccumulator、DoubleAccumulator \r\n\r\nLongAdder 和 LongAccumulator 区别：\r\n\r\n相同点：\r\n\r\n* LongAdder 与 LongAccumulator 类都是使用非阻塞算法 CAS 实现的\r\n* LongAdder 类是 LongAccumulator 类的一个特例，只是 LongAccumulator 提供了更强大的功能，可以自定义累加规则，当accumulatorFunction 为 null 时就等价于 LongAdder\r\n\r\n不同点：\r\n\r\n* 调用 casBase 时，LongAccumulator 使用 function.applyAsLong(b = base, x) 来计算，LongAdder 使用 casBase(b = base, b + x) \r\n* LongAccumulator 类功能更加强大，构造方法参数中\r\n\r\n  * accumulatorFunction 是一个双目运算器接口，可以指定累加规则，比如累加或者相乘，其根据输入的两个参数返回一个计算值，LongAdder 内置累加规则\r\n  * identity 则是 LongAccumulator 累加器的初始值，LongAccumulator 可以为累加器提供非0的初始值，而 LongAdder 只能提供默认的 0\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Adder\r\n\r\n#### 优化机制\r\n\r\nLongAdder 是 Java8 提供的类，跟 AtomicLong 有相同的效果，但对 CAS 机制进行了优化，尝试使用分段 CAS 以及自动分段迁移的方式来大幅度提升多线程高并发执行 CAS 操作的性能\r\n\r\nCAS 底层实现是在一个循环中不断地尝试修改目标值，直到修改成功。如果竞争不激烈修改成功率很高，否则失败率很高，失败后这些重复的原子性操作会耗费性能（导致大量线程**空循环，自旋转**）\r\n\r\n优化核心思想：数据分离，将 AtomicLong 的**单点的更新压力分担到各个节点，空间换时间**，在低并发的时候直接更新，可以保障和 AtomicLong 的性能基本一致，而在高并发的时候通过分散减少竞争，提高了性能\r\n\r\n**分段 CAS 机制**：\r\n\r\n* 在发生竞争时，创建 Cell 数组用于将不同线程的操作离散（通过 hash 等算法映射）到不同的节点上\r\n* 设置多个累加单元（会根据需要扩容，最大为 CPU 核数），Therad-0 累加 Cell[0]，而 Thread-1 累加 Cell[1] 等，最后将结果汇总\r\n* 在累加时操作的不同的 Cell 变量，因此减少了 CAS 重试失败，从而提高性能\r\n\r\n**自动分段迁移机制**：某个 Cell 的 value 执行 CAS 失败，就会自动寻找另一个 Cell 分段内的 value 值进行 CAS 操作\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 伪共享\r\n\r\nCell 为累加单元：数组访问索引是通过 Thread 里的 threadLocalRandomProbe 域取模实现的，这个域是 ThreadLocalRandom 更新的\r\n\r\n```java\r\n// Striped64.Cell\r\n@sun.misc.Contended static final class Cell {\r\n    volatile long value;\r\n    Cell(long x) { value = x; }\r\n    // 用 cas 方式进行累加, prev 表示旧值, next 表示新值\r\n    final boolean cas(long prev, long next) {\r\n    \treturn UNSAFE.compareAndSwapLong(this, valueOffset, prev, next);\r\n    }\r\n    // 省略不重要代码\r\n}\r\n```\r\n\r\nCell 是数组形式，**在内存中是连续存储的**，64 位系统中，一个 Cell 为 24 字节（16 字节的对象头和 8 字节的 value），每一个 cache line 为 64 字节，因此缓存行可以存下 2 个的 Cell 对象，当 Core-0 要修改 Cell[0]、Core-1 要修改 Cell[1]，**无论谁修改成功都会导致当前缓存行失效**，从而导致对方的数据失效，需要重新去主存获取，影响效率\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608150111.png\" alt=\"img\" style=\"zoom: 67%;\" />\r\n\r\n@sun.misc.Contended：防止缓存行伪共享，在使用此注解的对象或字段的前后各增加 128 字节大小的 padding，使用 2 倍于大多数硬件缓存行让 CPU 将对象预读至缓存时**占用不同的缓存行**，这样就不会造成对方缓存行的失效\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608150119.png\" alt=\"img\" style=\"zoom: 67%;\" />\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 源码解析\r\n\r\nStriped64 类成员属性：\r\n\r\n```java\r\n// 表示当前计算机CPU数量\r\nstatic final int NCPU = Runtime.getRuntime().availableProcessors()\r\n// 累加单元数组, 懒惰初始化\r\ntransient volatile Cell[] cells;\r\n// 基础值, 如果没有竞争, 则用 cas 累加这个域，当 cells 扩容时，也会将数据写到 base 中\r\ntransient volatile long base;\r\n// 在 cells 初始化或扩容时只能有一个线程执行, 通过 CAS 更新 cellsBusy 置为 1 来实现一个锁\r\ntransient volatile int cellsBusy;\r\n```\r\n\r\n工作流程：\r\n\r\n* cells 占用内存是相对比较大的，是惰性加载的，在无竞争或者其他线程正在初始化 cells 数组的情况下，直接更新 base 域\r\n\r\n* 在第一次发生竞争时（casBase 失败）会创建一个大小为 2 的 cells 数组，将当前累加的值包装为 Cell 对象，放入映射的槽位上\r\n* 分段累加的过程中，如果当前线程对应的 cells 槽位为空，就会新建 Cell 填充，如果出现竞争，就会重新计算线程对应的槽位，继续自旋尝试修改\r\n* 分段迁移后还出现竞争就会扩容 cells 数组长度为原来的两倍，然后 rehash，**数组长度总是 2 的 n 次幂**，默认最大为 CPU 核数，但是可以超过，如果核数是 6 核，数组最长是 8 \r\n\r\n方法分析：\r\n\r\n* `LongAdder#add`：累加方法\r\n\r\n  ```java\r\n  public void add(long x) {\r\n      // as 为累加单元数组的引用，b 为基础值，v 表示期望值\r\n      // m 表示 cells 数组的长度 - 1，a 表示当前线程命中的 cell 单元格\r\n      Cell[] as; long b, v; int m; Cell a;\r\n      \r\n      // cells 不为空说明 cells 已经被初始化，线程发生了竞争，去更新对应的 cell 槽位\r\n      // 进入 || 后的逻辑去更新 base 域，更新失败表示发生竞争进入条件\r\n      if ((as = cells) != null || !casBase(b = base, b + x)) {\r\n          // uncontended 为 true 表示 cell 没有竞争\r\n          boolean uncontended = true;\r\n          \r\n          // 条件一: true 说明 cells 未初始化，多线程写 base 发生竞争需要进行初始化 cells 数组\r\n          //\t\t  fasle 说明 cells 已经初始化，进行下一个条件寻找自己的 cell 去累加\r\n          // 条件二: getProbe() 获取 hash 值，& m 的逻辑和 HashMap 的逻辑相同，保证散列的均匀性\r\n          // \t\t  true 说明当前线程对应下标的 cell 为空，需要创建 cell\r\n          //        false 说明当前线程对应的 cell 不为空，进行下一个条件【将 x 值累加到对应的 cell 中】\r\n          // 条件三: 有取反符号，false 说明 cas 成功，直接返回，true 说明失败，当前线程对应的 cell 有竞争\r\n          if (as == null || (m = as.length - 1) < 0 ||\r\n              (a = as[getProbe() & m]) == null ||\r\n              !(uncontended = a.cas(v = a.value, v + x)))\r\n              longAccumulate(x, null, uncontended);\r\n          \t// 【uncontended 在对应的 cell 上累加失败的时候才为 false，其余情况均为 true】\r\n      }\r\n  }\r\n  ```\r\n\r\n* `Striped64`\r\n\r\n```java\r\n// Unsafe mechanics\r\nprivate static final sun.misc.Unsafe UNSAFE;\r\nprivate static final long BASE;\r\nprivate static final long CELLSBUSY;\r\nprivate static final long PROBE;\r\nstatic {\r\n    try {\r\n        UNSAFE = sun.misc.Unsafe.getUnsafe();\r\n        Class<?> sk = Striped64.class;\r\n        BASE = UNSAFE.objectFieldOffset\r\n            (sk.getDeclaredField(\"base\"));\r\n        CELLSBUSY = UNSAFE.objectFieldOffset\r\n            (sk.getDeclaredField(\"cellsBusy\"));\r\n        Class<?> tk = Thread.class;\r\n        PROBE = UNSAFE.objectFieldOffset\r\n            (tk.getDeclaredField(\"threadLocalRandomProbe\"));\r\n    } catch (Exception e) {\r\n        throw new Error(e);\r\n    }\r\n}\r\n```\r\n\r\n* `Striped64#casBase`\r\n\r\n```java\r\n/**\r\n * CASes the base field.\r\n */\r\nfinal boolean casBase(long cmp, long val) {\r\n    return UNSAFE.compareAndSwapLong(this, BASE, cmp, val);\r\n}\r\n```\r\n\r\n* `Striped64#longAccumulate`：cell 数组创建\r\n\r\n  ```java\r\n  // \t\t\t\t\t\t\tx  \t\t\tnull \t\t\tfalse | true\r\n  final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) {\r\n      int h;\r\n      // 当前线程还没有对应的 cell, 需要随机生成一个 hash 值用来将当前线程绑定到 cell\r\n      if ((h = getProbe()) == 0) {\r\n          // 初始化 probe，获取 hash 值\r\n          ThreadLocalRandom.current(); \r\n          h = getProbe();\t\r\n          // 默认情况下 当前线程肯定是写入到了 cells[0] 位置，不把它当做一次真正的竞争\r\n          wasUncontended = true;\r\n      }\r\n      // 表示【扩容意向】，false 一定不会扩容，true 可能会扩容\r\n      boolean collide = false; \r\n      //自旋\r\n      for (;;) {\r\n          // as 表示cells引用，a 表示当前线程命中的 cell，n 表示 cells 数组长度，v 表示 期望值\r\n          Cell[] as; Cell a; int n; long v;\r\n          // 【CASE1】: 表示 cells 已经初始化了，当前线程应该将数据写入到对应的 cell 中\r\n          if ((as = cells) != null && (n = as.length) > 0) {\r\n              // CASE1.1: true 表示当前线程对应的索引下标的 Cell 为 null，需要创建 new Cell\r\n              if ((a = as[(n - 1) & h]) == null) {\r\n                  // 判断 cellsBusy 是否被锁\r\n                  if (cellsBusy == 0) {   \r\n                      // 创建 cell, 初始累加值为 x\r\n                      Cell r = new Cell(x);  \r\n                      // 加锁\r\n                      if (cellsBusy == 0 && casCellsBusy()) {\r\n                          // 创建成功标记，进入【创建 cell 逻辑】\r\n                          boolean created = false;\t\r\n                          try {\r\n                              Cell[] rs; int m, j;\r\n                              // 把当前 cells 数组赋值给 rs，并且不为 null\r\n                              if ((rs = cells) != null &&\r\n                                  (m = rs.length) > 0 &&\r\n                                  // 再次判断防止其它线程初始化过该位置，当前线程再次初始化该位置会造成数据丢失\r\n                                  // 因为这里是线程安全的判断，进行的逻辑不会被其他线程影响\r\n                                  rs[j = (m - 1) & h] == null) {\r\n                                  // 把新创建的 cell 填充至当前位置\r\n                                  rs[j] = r;\r\n                                  created = true;\t// 表示创建完成\r\n                              }\r\n                          } finally {\r\n                              cellsBusy = 0;\t\t// 解锁\r\n                          }\r\n                          if (created)\t\t\t// true 表示创建完成，可以推出循环了\r\n                              break;\r\n                          continue;\r\n                      }\r\n                  }\r\n                  collide = false;\r\n              }\r\n              // CASE1.2: 条件成立说明线程对应的 cell 有竞争, 改变线程对应的 cell 来重试 cas\r\n              else if (!wasUncontended)\r\n                  wasUncontended = true;\r\n              // CASE 1.3: 当前线程 rehash 过，如果新命中的 cell 不为空，就尝试累加，false 说明新命中也有竞争\r\n              else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x))))\r\n                  break;\r\n              // CASE 1.4: cells 长度已经超过了最大长度 CPU 内核的数量或者已经扩容\r\n              else if (n >= NCPU || cells != as)\r\n                  collide = false; \t\t// 扩容意向改为false，【表示不能扩容了】\r\n              // CASE 1.5: 更改扩容意向，如果 n >= NCPU，这里就永远不会执行到，case1.4 永远先于 1.5 执行\r\n              else if (!collide)\r\n                  collide = true;\r\n              // CASE 1.6: 【扩容逻辑】，进行加锁\r\n              else if (cellsBusy == 0 && casCellsBusy()) {\r\n                  try {\r\n                      // 线程安全的检查，防止期间被其他线程扩容了\r\n                      if (cells == as) {     \r\n                          // 扩容为以前的 2 倍\r\n                          Cell[] rs = new Cell[n << 1];\r\n                          // 遍历移动值\r\n                          for (int i = 0; i < n; ++i)\r\n                              rs[i] = as[i];\r\n                          // 把扩容后的引用给 cells\r\n                          cells = rs;\r\n                      }\r\n                  } finally {\r\n                      cellsBusy = 0;\t// 解锁\r\n                  }\r\n                  collide = false;\t// 扩容意向改为 false，表示不扩容了\r\n                  continue;\r\n              }\r\n              // 重置当前线程 Hash 值，这就是【分段迁移机制】\r\n              h = advanceProbe(h);\r\n          }\r\n  \r\n          // 【CASE2】: 运行到这说明 cells 还未初始化，as 为null\r\n          // 判断是否没有加锁，没有加锁就用 CAS 加锁\r\n          // 条件二判断是否其它线程在当前线程给 as 赋值之后修改了 cells，这里不是线程安全的判断\r\n          else if (cellsBusy == 0 && cells == as && casCellsBusy()) {\r\n              // 初始化标志，开始 【初始化 cells 数组】\r\n              boolean init = false;\r\n              try { \r\n                 \t// 再次判断 cells == as 防止其它线程已经提前初始化了，当前线程再次初始化导致丢失数据\r\n                  // 因为这里是【线程安全的，重新检查，经典 DCL】\r\n                  if (cells == as) {\r\n                      Cell[] rs = new Cell[2];\t// 初始化数组大小为2\r\n                      rs[h & 1] = new Cell(x);\t// 填充线程对应的cell\r\n                      cells = rs;\r\n                      init = true;\t\t\t\t// 初始化成功，标记置为 true\r\n                  }\r\n              } finally {\r\n                  cellsBusy = 0;\t\t\t\t\t// 解锁\r\n              }\r\n              if (init)\r\n                  break;\t\t\t\t\t\t\t// 初始化成功直接跳出自旋\r\n          }\r\n          // 【CASE3】: 运行到这说明其他线程在初始化 cells，当前线程将值累加到 base，累加成功直接结束自旋\r\n          else if (casBase(v = base, ((fn == null) ? v + x :\r\n                                      fn.applyAsLong(v, x))))\r\n              break; \r\n      }\r\n  }\r\n  ```\r\n\r\n* `LongAdder#sum`：获取最终结果通过 sum 整合，**保证最终一致性，不保证强一致性**\r\n\r\n  ```java\r\n  public long sum() {\r\n      Cell[] as = cells; Cell a;\r\n      long sum = base;\r\n      if (as != null) {\r\n          // 遍历 累加\r\n          for (int i = 0; i < as.length; ++i) {\r\n              if ((a = as[i]) != null)\r\n                  sum += a.value;\r\n          }\r\n      }\r\n      return sum;\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### ABA\r\n\r\nABA 问题：当进行获取主内存值时，该内存值在写入主内存时已经被修改了 N 次，但是最终又改成原来的值\r\n\r\n其他线程先把 A 改成 B 又改回 A，主线程**仅能判断出共享变量的值与最初值 A 是否相同**，不能感知到这种从 A 改为 B 又 改回 A 的情况，这时 CAS 虽然成功，但是过程存在问题\r\n\r\n\r\n\r\n#### **AtomicStampedReference**\r\n\r\n* 构造方法：\r\n  * `public AtomicStampedReference(V initialRef, int initialStamp)`：初始值和初始版本号\r\n\r\n* 常用API：\r\n  * ` public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp)`：**期望引用和期望版本号都一致**才进行 CAS 修改数据\r\n  * `public void set(V newReference, int newStamp)`：设置值和版本号\r\n  * `public V getReference()`：返回引用的值\r\n  * `public int getStamp()`：返回当前版本号\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    AtomicStampedReference<Integer> atomicReference = new AtomicStampedReference<>(100,1);\r\n    int startStamp = atomicReference.getStamp();\r\n    new Thread(() ->{\r\n        int stamp = atomicReference.getStamp();\r\n        atomicReference.compareAndSet(100, 101, stamp, stamp + 1);\r\n        stamp = atomicReference.getStamp();\r\n        atomicReference.compareAndSet(101, 100, stamp, stamp + 1);\r\n    },\"t1\").start();\r\n\r\n    new Thread(() ->{\r\n        try {\r\n            Thread.sleep(1000);\r\n        } catch (InterruptedException e) {\r\n            e.printStackTrace();\r\n        }\r\n        if (!atomicReference.compareAndSet(100, 200, startStamp, startStamp + 1)) {\r\n            System.out.println(atomicReference.getReference());//100\r\n            System.out.println(Thread.currentThread().getName() + \"线程修改失败\");\r\n        }\r\n    },\"t2\").start();\r\n}\r\n```\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n#### AtomicMarkableReference\r\n\r\nAtomicStampedReference 可以给原子引用加上版本号，追踪原子引用整个的变化过程，如： A -> B -> A -> C ，通过AtomicStampedReference，我们可以知道，引用变量中途被更改了几次。\r\n但是有时候，并不关心引用变量更改了几次，只是单纯的关心**是否更改过**，所以就有了 **AtomicMarkableReference**\r\n\r\n![image-20230714183156551](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230714183156551.png)\r\n\r\n```java\r\n@Slf4j(topic = \"c.Test38\")\r\npublic class Test38 {\r\n    public static void main(String[] args) throws InterruptedException {\r\n        GarbageBag bag = new GarbageBag(\"装满了垃圾\");\r\n        // 参数2 mark 可以看作一个标记，表示垃圾袋满了\r\n        AtomicMarkableReference<GarbageBag> ref = new AtomicMarkableReference<>(bag, true);\r\n\r\n        log.debug(\"start...\");\r\n        GarbageBag prev = ref.getReference();\r\n        log.debug(prev.toString());\r\n\r\n        new Thread(() -> {\r\n            log.debug(\"start...\");\r\n            bag.setDesc(\"空垃圾袋\");\r\n            ref.compareAndSet(bag, bag, true, false);\r\n            log.debug(bag.toString());\r\n        },\"保洁阿姨\").start();\r\n\r\n        sleep(1);\r\n        log.debug(\"想换一只新垃圾袋？\");\r\n        boolean success = ref.compareAndSet(prev, new GarbageBag(\"空垃圾袋\"), true, false);\r\n        log.debug(\"换了么？\" + success);\r\n        log.debug(ref.getReference().toString());\r\n    }\r\n}\r\n\r\nclass GarbageBag {\r\n    String desc;\r\n\r\n    public GarbageBag(String desc) {\r\n        this.desc = desc;\r\n    }\r\n\r\n    public void setDesc(String desc) {\r\n        this.desc = desc;\r\n    }\r\n\r\n    @Override\r\n    public String toString() {\r\n        return super.toString() + \" \" + desc;\r\n    }\r\n}\r\n```\r\n\r\n![image-20230714183338108](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230714183338108.png)\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n#### 两者的区别\r\n\r\n- **AtomicStampedReference** 需要我们传入**整型变量**作为版本号，来判定是否被更改过\r\n- **AtomicMarkableReference**需要我们传入**布尔变量**作为标记，来判断是否被更改过\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Unsafe\r\n\r\nUnsafe 是 CAS 的核心类，由于 Java 无法直接访问底层系统，需要通过本地（Native）方法来访问\r\n\r\nUnsafe 类存在 sun.misc 包，其中所有方法都是 native 修饰的，都是直接调用**操作系统底层资源**执行相应的任务，基于该类可以直接操作特定的内存数据，其内部方法操作类似 C 的指针\r\n\r\n模拟实现原子整数：\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    MyAtomicInteger atomicInteger = new MyAtomicInteger(10);\r\n    if (atomicInteger.compareAndSwap(20)) {\r\n        System.out.println(atomicInteger.getValue());\r\n    }\r\n}\r\n\r\nclass MyAtomicInteger {\r\n    private static final Unsafe UNSAFE;\r\n    private static final long VALUE_OFFSET;\r\n    private volatile int value;\r\n\r\n    static {\r\n        try {\r\n            //Unsafe unsafe = Unsafe.getUnsafe()这样会报错，需要反射获取\r\n            Field theUnsafe = Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n            theUnsafe.setAccessible(true);\r\n            UNSAFE = (Unsafe) theUnsafe.get(null);\r\n            // 获取 value 属性的内存地址，value 属性指向该地址，直接设置该地址的值可以修改 value 的值\r\n            VALUE_OFFSET = UNSAFE.objectFieldOffset(\r\n                \t\t   MyAtomicInteger.class.getDeclaredField(\"value\"));\r\n        } catch (NoSuchFieldException | IllegalAccessException e) {\r\n            e.printStackTrace();\r\n            throw new RuntimeException();\r\n        }\r\n    }\r\n\r\n    public MyAtomicInteger(int value) {\r\n        this.value = value;\r\n    }\r\n    public int getValue() {\r\n        return value;\r\n    }\r\n\r\n    public boolean compareAndSwap(int update) {\r\n        while (true) {\r\n            int prev = this.value;\r\n            int next = update;\r\n            //\t\t\t\t\t\t\t当前对象  内存偏移量    期望值 更新值\r\n            if (UNSAFE.compareAndSwapInt(this, VALUE_OFFSET, prev, update)) {\r\n                System.out.println(\"CAS成功\");\r\n                return true;\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### final\r\n\r\n#### 原理\r\n\r\n```java\r\npublic class TestFinal {\r\n\tfinal int a = 20;\r\n}\r\n```\r\n\r\n字节码：\r\n\r\n```java\r\n0: aload_0\r\n1: invokespecial #1 // Method java/lang/Object.\"<init>\":()V\r\n4: aload_0\r\n5: bipush 20\t\t// 将值直接放入栈中\r\n7: putfield #2 \t\t// Field a:I\r\n<-- 写屏障\r\n10: return\r\n```\r\n\r\nfinal 变量的赋值通过 putfield 指令来完成，在这条指令之后也会加入写屏障，保证在其它线程读到它的值时不会出现为 0 的情况\r\n\r\n其他线程访问 final 修饰的变量**会复制一份放入栈中**，效率更高\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 不可变\r\n\r\n不可变：如果一个对象不能够修改其内部状态（属性），那么就是不可变对象\r\n\r\n不可变对象线程安全的，不存在并发修改和可见性问题，是另一种避免竞争的方式\r\n\r\nString 类也是不可变的，该类和类中所有属性都是 final 的\r\n\r\n* 类用 final 修饰保证了该类中的方法不能被覆盖，防止子类无意间破坏不可变性\r\n\r\n* 无写入方法（set）确保外部不能对内部属性进行修改\r\n\r\n* 属性用 final 修饰保证了该属性是只读的，不能修改\r\n\r\n  ```java\r\n  public final class String\r\n      implements java.io.Serializable, Comparable<String>, CharSequence {\r\n      /** The value is used for character storage. */\r\n      private final char value[];\r\n      //....\r\n  }\r\n  ```\r\n\r\n* 更改 String 类数据时，会构造新字符串对象，生成新的 char[] value，通过**创建副本对象来避免共享的方式称之为保护性拷贝**\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### State\r\n\r\n无状态：成员变量保存的数据也可以称为状态信息，无状态就是没有成员变量\r\n\r\nServlet 为了保证其线程安全，一般不为 Servlet 设置成员变量，这种没有任何成员变量的类是线程安全的\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Local\r\n\r\n#### 基本介绍\r\n\r\nThreadLocal 类用来提供线程内部的局部变量，这种变量在多线程环境下访问（通过 get 和 set 方法访问）时能保证各个线程的变量相对独立于其他线程内的变量，分配在堆内的 **TLAB** 中\r\n\r\nThreadLocal 实例通常来说都是 `private static` 类型的，属于一个线程的本地变量，用于关联线程和线程上下文。每个线程都会在 ThreadLocal 中保存一份该线程独有的数据，所以是线程安全的\r\n\r\nThreadLocal 作用：\r\n\r\n* 线程并发：应用在多线程并发的场景下\r\n\r\n* 传递数据：通过 ThreadLocal 实现在同一线程不同函数或组件中传递公共变量，减少传递复杂度\r\n\r\n* 线程隔离：每个线程的变量都是独立的，不会互相影响\r\n\r\n对比 synchronized：\r\n\r\n|        | synchronized                                                 | ThreadLocal                                                  |\r\n| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| 原理   | 同步机制采用**以时间换空间**的方式，只提供了一份变量，让不同的线程排队访问 | ThreadLocal 采用**以空间换时间**的方式，为每个线程都提供了一份变量的副本，从而实现同时访问而互不干扰 |\r\n| 侧重点 | 多个线程之间访问资源的同步                                   | 多线程中让每个线程之间的数据相互隔离                         |\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 基本使用\r\n\r\n##### 常用方法\r\n\r\n| 方法                       | 描述                         |\r\n| -------------------------- | ---------------------------- |\r\n| ThreadLocal<>()            | 创建 ThreadLocal 对象        |\r\n| protected T initialValue() | 返回当前线程局部变量的初始值 |\r\n| public void set( T value)  | 设置当前线程绑定的局部变量   |\r\n| public T get()             | 获取当前线程绑定的局部变量   |\r\n| public void remove()       | 移除当前线程绑定的局部变量   |\r\n\r\n```java\r\npublic class MyDemo {\r\n\r\n    private static ThreadLocal<String> tl = new ThreadLocal<>();\r\n\r\n    private String content;\r\n\r\n    private String getContent() {\r\n        // 获取当前线程绑定的变量\r\n        return tl.get();\r\n    }\r\n\r\n    private void setContent(String content) {\r\n        // 变量content绑定到当前线程\r\n        tl.set(content);\r\n    }\r\n\r\n    public static void main(String[] args) {\r\n        MyDemo demo = new MyDemo();\r\n        for (int i = 0; i < 5; i++) {\r\n            Thread thread = new Thread(new Runnable() {\r\n                @Override\r\n                public void run() {\r\n                    // 设置数据\r\n                    demo.setContent(Thread.currentThread().getName() + \"的数据\");\r\n                    System.out.println(\"-----------------------\");\r\n                    System.out.println(Thread.currentThread().getName() + \"--->\" + demo.getContent());\r\n                }\r\n            });\r\n            thread.setName(\"线程\" + i);\r\n            thread.start();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 应用场景\r\n\r\nThreadLocal 适用于下面两种场景：\r\n\r\n- 每个线程需要有自己单独的实例\r\n- 实例需要在多个方法中共享，但不希望被多线程共享\r\n\r\nThreadLocal 方案有两个突出的优势： \r\n\r\n1. 传递数据：保存每个线程绑定的数据，在需要的地方可以直接获取，避免参数直接传递带来的代码耦合问题\r\n2. 线程隔离：各线程之间的数据相互隔离却又具备并发性，避免同步方式带来的性能损失\r\n\r\nThreadLocal 用于数据连接的事务管理：\r\n\r\n```java\r\npublic class JdbcUtils {\r\n    // ThreadLocal对象，将connection绑定在当前线程中\r\n    private static final ThreadLocal<Connection> tl = new ThreadLocal();\r\n    // c3p0 数据库连接池对象属性\r\n    private static final ComboPooledDataSource ds = new ComboPooledDataSource();\r\n    // 获取连接\r\n    public static Connection getConnection() throws SQLException {\r\n        //取出当前线程绑定的connection对象\r\n        Connection conn = tl.get();\r\n        if (conn == null) {\r\n            //如果没有，则从连接池中取出\r\n            conn = ds.getConnection();\r\n            //再将connection对象绑定到当前线程中，非常重要的操作\r\n            tl.set(conn);\r\n        }\r\n        return conn;\r\n    }\r\n\t// ...\r\n}\r\n```\r\n\r\n用 ThreadLocal 使 SimpleDateFormat 从独享变量变成单个线程变量：\r\n\r\n```java\r\npublic class ThreadLocalDateUtil {\r\n    private static ThreadLocal<DateFormat> threadLocal = new ThreadLocal<DateFormat>() {\r\n        @Override\r\n        protected DateFormat initialValue() {\r\n            return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\r\n        }\r\n    };\r\n\r\n    public static Date parse(String dateStr) throws ParseException {\r\n        return threadLocal.get().parse(dateStr);\r\n    }\r\n\r\n    public static String format(Date date) {\r\n        return threadLocal.get().format(date);\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 实现原理\r\n\r\n##### 底层结构\r\n\r\nJDK8 以前：每个 ThreadLocal 都创建一个 Map，然后用线程作为 Map 的 key，要存储的局部变量作为 Map 的 value，达到各个线程的局部变量隔离的效果。这种结构会造成 Map 结构过大和内存泄露，因为 Thread 停止后无法通过 key 删除对应的数据\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824171552294.png\" alt=\"image-20230824171552294\" style=\"zoom:80%;\" />\r\n\r\nJDK8 以后：每个 Thread 维护一个 ThreadLocalMap，这个 Map 的 key 是 ThreadLocal 实例本身，value 是真正要存储的值\r\n\r\n* **每个 Thread 线程内部都有一个 Map (ThreadLocalMap)**\r\n* Map 里面存储 ThreadLocal 对象（key）和线程的私有变量（value）\r\n* Thread 内部的 Map 是由 ThreadLocal 维护的，由 ThreadLocal 负责向 map 获取和设置线程的变量值\r\n* 对于不同的线程，每次获取副本值时，别的线程并不能获取到当前线程的副本值，形成副本的隔离，互不干扰\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824171625312.png\" alt=\"image-20230824171625312\" style=\"zoom:80%;\" />\r\n\r\nJDK8 前后对比：\r\n\r\n* 每个 Map 存储的 Entry 数量会变少，因为之前的存储数量由 Thread 的数量决定，现在由 ThreadLocal 的数量决定，在实际编程当中，往往 ThreadLocal 的数量要少于 Thread 的数量\r\n* 当 Thread 销毁之后，对应的 ThreadLocalMap 也会随之销毁，能减少内存的使用，**防止内存泄露**\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 成员变量\r\n\r\n* Thread 类的相关属性：**每一个线程持有一个 ThreadLocalMap 对象**，存放由 ThreadLocal 和数据组成的 Entry 键值对\r\n\r\n  ```java\r\n  ThreadLocal.ThreadLocalMap threadLocals = null\r\n  ```\r\n\r\n* 计算 ThreadLocal 对象的哈希值：\r\n\r\n  ```java\r\n  private final int threadLocalHashCode = nextHashCode()\r\n  ```\r\n\r\n  使用 `threadLocalHashCode & (table.length - 1)` 计算当前 entry 需要存放的位置\r\n\r\n* 每创建一个 ThreadLocal 对象就会使用 nextHashCode 分配一个 hash 值给这个对象：\r\n\r\n  ```java\r\n  private static AtomicInteger nextHashCode = new AtomicInteger()\r\n  ```\r\n\r\n* 斐波那契数也叫黄金分割数，hash 的**增量**就是这个数字，带来的好处是 hash 分布非常均匀：\r\n\r\n  ```java\r\n  private static final int HASH_INCREMENT = 0x61c88647\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 成员方法\r\n\r\n方法都是线程安全的，因为 ThreadLocal 属于一个线程的，ThreadLocal 中的方法，逻辑都是获取当前线程维护的 ThreadLocalMap 对象，然后进行数据的增删改查，没有指定初始值的 threadlcoal 对象默认赋值为 null\r\n\r\n* initialValue()：返回该线程局部变量的初始值\r\n\r\n  * 延迟调用的方法，在执行 get 方法时才执行\r\n  * 该方法缺省（默认）实现直接返回一个 null\r\n  * 如果想要一个初始值，可以重写此方法， 该方法是一个 `protected` 的方法，为了让子类覆盖而设计的\r\n\r\n  ```java\r\n  protected T initialValue() {\r\n      return null;\r\n  }\r\n  ```\r\n\r\n* nextHashCode()：计算哈希值，ThreadLocal 的散列方式称之为**斐波那契散列**，每次获取哈希值都会加上 HASH_INCREMENT，这样做可以尽量避免 hash 冲突，让哈希值能均匀的分布在 2 的 n 次方的数组中\r\n\r\n  ```java\r\n  private static int nextHashCode() {\r\n      // 哈希值自增一个 HASH_INCREMENT 数值\r\n      return nextHashCode.getAndAdd(HASH_INCREMENT);\r\n  }\r\n  ```\r\n\r\n* set()：修改当前线程与当前 threadlocal 对象相关联的线程局部变量\r\n\r\n  ```java\r\n  public void set(T value) {\r\n      // 获取当前线程对象\r\n      Thread t = Thread.currentThread();\r\n      // 获取此线程对象中维护的 ThreadLocalMap 对象\r\n      ThreadLocalMap map = getMap(t);\r\n      // 判断 map 是否存在\r\n      if (map != null)\r\n          // 调用 threadLocalMap.set 方法进行重写或者添加\r\n          map.set(this, value);\r\n      else\r\n          // map 为空，调用 createMap 进行 ThreadLocalMap 对象的初始化。参数1是当前线程，参数2是局部变量\r\n          createMap(t, value);\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 获取当前线程 Thread 对应维护的 ThreadLocalMap \r\n  ThreadLocalMap getMap(Thread t) {\r\n      return t.threadLocals;\r\n  }\r\n  // 创建当前线程Thread对应维护的ThreadLocalMap \r\n  void createMap(Thread t, T firstValue) {\r\n      // 【这里的 this 是调用此方法的 threadLocal】，创建一个新的 Map 并设置第一个数据\r\n      t.threadLocals = new ThreadLocalMap(this, firstValue);\r\n  }\r\n  ```\r\n\r\n* get()：获取当前线程与当前 ThreadLocal 对象相关联的线程局部变量\r\n\r\n  ```java\r\n  public T get() {\r\n      Thread t = Thread.currentThread();\r\n      ThreadLocalMap map = getMap(t);\r\n      // 如果此map存在\r\n      if (map != null) {\r\n          // 以当前的 ThreadLocal 为 key，调用 getEntry 获取对应的存储实体 e\r\n          ThreadLocalMap.Entry e = map.getEntry(this);\r\n          // 对 e 进行判空 \r\n          if (e != null) {\r\n              // 获取存储实体 e 对应的 value值\r\n              T result = (T)e.value;\r\n              return result;\r\n          }\r\n      }\r\n      /*有两种情况有执行当前代码\r\n        第一种情况: map 不存在，表示此线程没有维护的 ThreadLocalMap 对象\r\n        第二种情况: map 存在, 但是【没有与当前 ThreadLocal 关联的 entry】，就会设置为默认值 */\r\n      // 初始化当前线程与当前 threadLocal 对象相关联的 value\r\n      return setInitialValue();\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  private T setInitialValue() {\r\n      // 调用initialValue获取初始化的值，此方法可以被子类重写, 如果不重写默认返回 null\r\n      T value = initialValue();\r\n      Thread t = Thread.currentThread();\r\n      ThreadLocalMap map = getMap(t);\r\n      // 判断 map 是否初始化过\r\n      if (map != null)\r\n          // 存在则调用 map.set 设置此实体 entry，value 是默认的值\r\n          map.set(this, value);\r\n      else\r\n          // 调用 createMap 进行 ThreadLocalMap 对象的初始化中\r\n          createMap(t, value);\r\n      // 返回线程与当前 threadLocal 关联的局部变量\r\n      return value;\r\n  }\r\n  ```\r\n\r\n* remove()：移除当前线程与当前 threadLocal 对象相关联的线程局部变量\r\n\r\n  ```java\r\n  public void remove() {\r\n      // 获取当前线程对象中维护的 ThreadLocalMap 对象\r\n      ThreadLocalMap m = getMap(Thread.currentThread());\r\n      if (m != null)\r\n          // map 存在则调用 map.remove，this时当前ThreadLocal，以this为key删除对应的实体\r\n          m.remove(this);\r\n  }\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### LocalMap\r\n\r\n##### 成员属性\r\n\r\nThreadLocalMap 是 ThreadLocal 的内部类，没有实现 Map 接口，用独立的方式实现了 Map 的功能，其内部 Entry 也是独立实现\r\n\r\n```java\r\n// 初始化当前 map 内部散列表数组的初始长度 16\r\nprivate static final int INITIAL_CAPACITY = 16;\r\n\r\n// 存放数据的table，数组长度必须是2的整次幂。\r\nprivate Entry[] table;\r\n\r\n// 数组里面 entrys 的个数，可以用于判断 table 当前使用量是否超过阈值\r\nprivate int size = 0;\r\n\r\n// 进行扩容的阈值，表使用量大于它的时候进行扩容。\r\nprivate int threshold;\r\n```\r\n\r\n存储结构 Entry：\r\n\r\n* Entry 继承 WeakReference，key 是弱引用，目的是将 ThreadLocal 对象的生命周期和线程生命周期解绑\r\n* Entry 限制只能用 ThreadLocal 作为 key，key 为 null (entry.get() == null) 意味着 key 不再被引用，entry 也可以从 table 中清除\r\n\r\n```java\r\nstatic class Entry extends WeakReference<ThreadLocal<?>> {\r\n    Object value;\r\n    Entry(ThreadLocal<?> k, Object v) {\r\n        // this.referent = referent = key;\r\n        super(k);\r\n        value = v;\r\n    }\r\n}\r\n```\r\n\r\n构造方法：延迟初始化的，线程第一次存储 threadLocal - value 时才会创建 threadLocalMap 对象\r\n\r\n```java\r\nThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {\r\n    // 初始化table，创建一个长度为16的Entry数组\r\n    table = new Entry[INITIAL_CAPACITY];\r\n    // 【寻址算法】计算索引\r\n    int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);\r\n    // 创建 entry 对象，存放到指定位置的 slot 中\r\n    table[i] = new Entry(firstKey, firstValue);\r\n    // 数据总量是 1\r\n    size = 1;\r\n    // 将阈值设置为 （当前数组长度 * 2）/ 3。\r\n    setThreshold(INITIAL_CAPACITY);\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 成员方法\r\n\r\n* set()：添加数据，ThreadLocalMap 使用**线性探测法来解决哈希冲突**\r\n\r\n  * 该方法会一直探测下一个地址，直到有空的地址后插入，若插入后 Map 数量超过阈值，数组会扩容为原来的 2 倍\r\n\r\n    假设当前 table 长度为16，计算出来 key 的 hash 值为 14，如果 table[14] 上已经有值，并且其 key 与当前 key 不一致，那么就发生了 hash 冲突，这个时候将 14 加 1 得到 15，取 table[15] 进行判断，如果还是冲突会回到 0，取 table[0]，以此类推，直到可以插入，可以把 Entry[]  table 看成一个**环形数组**\r\n\r\n  * 线性探测法会出现**堆积问题**，可以采取平方探测法解决\r\n\r\n  * 在探测过程中 ThreadLocal 会复用 key 为 null 的脏 Entry 对象，并进行垃圾清理，防止出现内存泄漏\r\n\r\n  ```java\r\n  private void set(ThreadLocal<?> key, Object value) {\r\n      // 获取散列表\r\n      ThreadLocal.ThreadLocalMap.Entry[] tab = table;\r\n      int len = tab.length;\r\n      // 哈希寻址\r\n      int i = key.threadLocalHashCode & (len-1);\r\n      // 使用线性探测法向后查找元素，碰到 entry 为空时停止探测\r\n      for (ThreadLocal.ThreadLocalMap.Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) {\r\n          // 获取当前元素 key\r\n          ThreadLocal<?> k = e.get();\r\n          // ThreadLocal 对应的 key 存在，【直接覆盖之前的值】\r\n          if (k == key) {\r\n              e.value = value;\r\n              return;\r\n          }\r\n          // 【这两个条件谁先成立不一定，所以 replaceStaleEntry 中还需要判断 k == key 的情况】\r\n          \r\n          // key 为 null，但是值不为 null，说明之前的 ThreadLocal 对象已经被回收了，当前是【过期数据】\r\n          if (k == null) {\r\n              // 【碰到一个过期的 slot，当前数据复用该槽位，替换过期数据】\r\n              // 这个方法还进行了垃圾清理动作，防止内存泄漏\r\n              replaceStaleEntry(key, value, i);\r\n              return;\r\n          }\r\n      }\r\n  \t// 逻辑到这说明碰到 slot == null 的位置，则在空元素的位置创建一个新的 Entry\r\n      tab[i] = new Entry(key, value);\r\n      // 数量 + 1\r\n      int sz = ++size;\r\n      \r\n      // 【做一次启发式清理】，如果没有清除任何 entry 并且【当前使用量达到了负载因子所定义，那么进行 rehash\r\n      if (!cleanSomeSlots(i, sz) && sz >= threshold)\r\n          // 扩容\r\n          rehash();\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 获取【环形数组】的下一个索引\r\n  private static int nextIndex(int i, int len) {\r\n      // 索引越界后从 0 开始继续获取\r\n      return ((i + 1 < len) ? i + 1 : 0);\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 在指定位置插入指定的数据\r\n  private void replaceStaleEntry(ThreadLocal<?> key, Object value, int staleSlot) {\r\n      // 获取散列表\r\n      Entry[] tab = table;\r\n      int len = tab.length;\r\n      Entry e;\r\n  \t// 探测式清理的开始下标，默认从当前 staleSlot 开始\r\n      int slotToExpunge = staleSlot;\r\n      // 以当前 staleSlot 开始【向前迭代查找】，找到索引靠前过期数据，找到以后替换 slotToExpunge 值\r\n      // 【保证在一个区间段内，从最前面的过期数据开始清理】\r\n      for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len))\r\n          if (e.get() == null)\r\n              slotToExpunge = i;\r\n  \r\n  \t// 以 staleSlot 【向后去查找】，直到碰到 null 为止，还是线性探测\r\n      for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) {\r\n          // 获取当前节点的 key\r\n          ThreadLocal<?> k = e.get();\r\n  \t\t// 条件成立说明是【替换逻辑】\r\n          if (k == key) {\r\n              e.value = value;\r\n              // 因为本来要在 staleSlot 索引处插入该数据，现在找到了i索引处的key与数据一致\r\n              // 但是 i 位置距离正确的位置更远，因为是向后查找，所以还是要在 staleSlot 位置插入当前 entry\r\n              // 然后将 table[staleSlot] 这个过期数据放到当前循环到的 table[i] 这个位置，\r\n              tab[i] = tab[staleSlot];\r\n              tab[staleSlot] = e;\r\n  \t\t\t\r\n              // 条件成立说明向前查找过期数据并未找到过期的 entry，但 staleSlot 位置已经不是过期数据了，i 位置才是\r\n              if (slotToExpunge == staleSlot)\r\n                  slotToExpunge = i;\r\n              \r\n              // 【清理过期数据，expungeStaleEntry 探测式清理，cleanSomeSlots 启发式清理】\r\n              cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);\r\n              return;\r\n          }\r\n  \t\t// 条件成立说明当前遍历的 entry 是一个过期数据，并且该位置前面也没有过期数据\r\n          if (k == null && slotToExpunge == staleSlot)\r\n              // 探测式清理过期数据的开始下标修改为当前循环的 index，因为 staleSlot 会放入要添加的数据\r\n              slotToExpunge = i;\r\n      }\r\n  \t// 向后查找过程中并未发现 k == key 的 entry，说明当前是一个【取代过期数据逻辑】\r\n      // 删除原有的数据引用，防止内存泄露\r\n      tab[staleSlot].value = null;\r\n      // staleSlot 位置添加数据，【上面的所有逻辑都不会更改 staleSlot 的值】\r\n      tab[staleSlot] = new Entry(key, value);\r\n  \r\n      // 条件成立说明除了 staleSlot 以外，还发现其它的过期 slot，所以要【开启清理数据的逻辑】\r\n      if (slotToExpunge != staleSlot)\r\n          cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);\r\n  }\r\n  ```\r\n\r\n  ![image-20230824171823217](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824171823217.png)\r\n\r\n  ```java\r\n  private static int prevIndex(int i, int len) {\r\n      // 形成一个环绕式的访问，头索引越界后置为尾索引\r\n      return ((i - 1 >= 0) ? i - 1 : len - 1);\r\n  }\r\n  ```\r\n\r\n* getEntry()：ThreadLocal 的 get 方法以当前的 ThreadLocal 为 key，调用 getEntry 获取对应的存储实体 e\r\n\r\n  ```java\r\n  private Entry getEntry(ThreadLocal<?> key) {\r\n      // 哈希寻址\r\n      int i = key.threadLocalHashCode & (table.length - 1);\r\n      // 访问散列表中指定指定位置的 slot \r\n      Entry e = table[i];\r\n      // 条件成立，说明 slot 有值并且 key 就是要寻找的 key，直接返回\r\n      if (e != null && e.get() == key)\r\n          return e;\r\n      else\r\n          // 进行线性探测\r\n          return getEntryAfterMiss(key, i, e);\r\n  }\r\n  // 线性探测寻址\r\n  private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {\r\n      // 获取散列表\r\n      Entry[] tab = table;\r\n      int len = tab.length;\r\n  \r\n      // 开始遍历，碰到 slot == null 的情况，搜索结束\r\n      while (e != null) {\r\n  \t\t// 获取当前 slot 中 entry 对象的 key\r\n          ThreadLocal<?> k = e.get();\r\n          // 条件成立说明找到了，直接返回\r\n          if (k == key)\r\n              return e;\r\n          if (k == null)\r\n               // 过期数据，【探测式过期数据回收】\r\n              expungeStaleEntry(i);\r\n          else\r\n              // 更新 index 继续向后走\r\n              i = nextIndex(i, len);\r\n          // 获取下一个槽位中的 entry\r\n          e = tab[i];\r\n      }\r\n      // 说明当前区段没有找到相应数据\r\n      // 【因为存放数据是线性的向后寻找槽位，都是紧挨着的，不可能越过一个 空槽位 在后面放】，可以减少遍历的次数\r\n      return null;\r\n  }\r\n  ```\r\n\r\n* rehash()：触发一次全量清理，如果数组长度大于等于长度的 `2/3 * 3/4 = 1/2`，则进行 resize\r\n\r\n  ```java\r\n  private void rehash() {\r\n      // 清除当前散列表内的【所有】过期的数据\r\n      expungeStaleEntries();\r\n      \r\n      // threshold = len * 2 / 3，就是 2/3 * (1 - 1/4)\r\n      if (size >= threshold - threshold / 4)\r\n          resize();\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  private void expungeStaleEntries() {\r\n      Entry[] tab = table;\r\n      int len = tab.length;\r\n      // 【遍历所有的槽位，清理过期数据】\r\n      for (int j = 0; j < len; j++) {\r\n          Entry e = tab[j];\r\n          if (e != null && e.get() == null)\r\n              expungeStaleEntry(j);\r\n      }\r\n  }\r\n  ```\r\n\r\n  Entry **数组扩容为原来的 2 倍** ，重新计算 key 的散列值，如果遇到 key 为 null 的情况，会将其 value 也置为 null，帮助 GC\r\n\r\n  ```java\r\n  private void resize() {\r\n      Entry[] oldTab = table;\r\n      int oldLen = oldTab.length;\r\n      // 新数组的长度是老数组的二倍\r\n      int newLen = oldLen * 2;\r\n      Entry[] newTab = new Entry[newLen];\r\n      // 统计新table中的entry数量\r\n      int count = 0;\r\n  \t// 遍历老表，进行【数据迁移】\r\n      for (int j = 0; j < oldLen; ++j) {\r\n          // 访问老表的指定位置的 entry\r\n          Entry e = oldTab[j];\r\n          // 条件成立说明老表中该位置有数据，可能是过期数据也可能不是\r\n          if (e != null) {\r\n              ThreadLocal<?> k = e.get();\r\n              // 过期数据\r\n              if (k == null) {\r\n                  e.value = null; // Help the GC\r\n              } else {\r\n                  // 非过期数据，在新表中进行哈希寻址\r\n                  int h = k.threadLocalHashCode & (newLen - 1);\r\n                  // 【线程探测】\r\n                  while (newTab[h] != null)\r\n                      h = nextIndex(h, newLen);\r\n                  // 将数据存放到新表合适的 slot 中\r\n                  newTab[h] = e;\r\n                  count++;\r\n              }\r\n          }\r\n      }\r\n  \t// 设置下一次触发扩容的指标：threshold = len * 2 / 3;\r\n      setThreshold(newLen);\r\n      size = count;\r\n      // 将扩容后的新表赋值给 threadLocalMap 内部散列表数组引用\r\n      table = newTab;\r\n  }\r\n  ```\r\n\r\n* remove()：删除 Entry\r\n\r\n  ```java\r\n  private void remove(ThreadLocal<?> key) {\r\n      Entry[] tab = table;\r\n      int len = tab.length;\r\n      // 哈希寻址\r\n      int i = key.threadLocalHashCode & (len-1);\r\n      for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) {\r\n          // 找到了对应的 key\r\n          if (e.get() == key) {\r\n              // 设置 key 为 null\r\n              e.clear();\r\n              // 探测式清理\r\n              expungeStaleEntry(i);\r\n              return;\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 清理方法\r\n\r\n* 探测式清理：沿着开始位置向后探测清理过期数据，沿途中碰到未过期数据则将此数据 rehash 在 table 数组中的定位，重定位后的元素理论上更接近 `i = entry.key & (table.length - 1)`，让**数据的排列更紧凑**，会优化整个散列表查询性能\r\n\r\n  ```java\r\n  // table[staleSlot] 是一个过期数据，以这个位置开始继续向后查找过期数据\r\n  private int expungeStaleEntry(int staleSlot) {\r\n      // 获取散列表和数组长度\r\n      Entry[] tab = table;\r\n      int len = tab.length;\r\n  \r\n      // help gc，先把当前过期的 entry 置空，在取消对 entry 的引用\r\n      tab[staleSlot].value = null;\r\n      tab[staleSlot] = null;\r\n      // 数量-1\r\n      size--;\r\n  \r\n      Entry e;\r\n      int i;\r\n      // 从 staleSlot 开始向后遍历，直到碰到 slot == null 结束，【区间内清理过期数据】\r\n      for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) {\r\n          ThreadLocal<?> k = e.get();\r\n          // 当前 entry 是过期数据\r\n          if (k == null) {\r\n              // help gc\r\n              e.value = null;\r\n              tab[i] = null;\r\n              size--;\r\n          } else {\r\n              // 当前 entry 不是过期数据的逻辑，【rehash】\r\n              // 重新计算当前 entry 对应的 index\r\n              int h = k.threadLocalHashCode & (len - 1);\r\n              // 条件成立说明当前 entry 存储时发生过 hash 冲突，向后偏移过了\r\n              if (h != i) {\r\n                  // 当前位置置空\r\n                  tab[i] = null;\r\n                  // 以正确位置 h 开始，向后查找第一个可以存放 entry 的位置\r\n                  while (tab[h] != null)\r\n                      h = nextIndex(h, len);\r\n                  // 将当前元素放入到【距离正确位置更近的位置，有可能就是正确位置】\r\n                  tab[h] = e;\r\n              }\r\n          }\r\n      }\r\n      // 返回 slot = null 的槽位索引，图例是 7，这个索引代表【索引前面的区间已经清理完成垃圾了】\r\n      return i;\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824171939245.png\" alt=\"image-20230824171939245\" style=\"zoom:80%;\" />\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824172017188.png\" alt=\"image-20230824172017188\" style=\"zoom:80%;\" />\r\n\r\n* 启发式清理：向后循环扫描过期数据，发现过期数据调用探测式清理方法，如果连续几次的循环都没有发现过期数据，就停止扫描\r\n\r\n  ```java\r\n  //  i 表示启发式清理工作开始位置，一般是空 slot，n 一般传递的是 table.length \r\n  private boolean cleanSomeSlots(int i, int n) {\r\n      // 表示启发式清理工作是否清除了过期数据\r\n      boolean removed = false;\r\n      // 获取当前 map 的散列表引用\r\n      Entry[] tab = table;\r\n      int len = tab.length;\r\n      do {\r\n          // 获取下一个索引，因为探测式返回的 slot 为 null\r\n          i = nextIndex(i, len);\r\n          Entry e = tab[i];\r\n          // 条件成立说明是过期的数据，key 被 gc 了\r\n          if (e != null && e.get() == null) {\r\n              // 【发现过期数据重置 n 为数组的长度】\r\n              n = len;\r\n              // 表示清理过过期数据\r\n              removed = true;\r\n              // 以当前过期的 slot 为开始节点 做一次探测式清理工作\r\n              i = expungeStaleEntry(i);\r\n          }\r\n          // 假设 table 长度为 16\r\n          // 16 >>> 1 ==> 8，8 >>> 1 ==> 4，4 >>> 1 ==> 2，2 >>> 1 ==> 1，1 >>> 1 ==> 0\r\n          // 连续经过这么多次循环【没有扫描到过期数据】，就停止循环，扫描到空 slot 不算，因为不是过期数据\r\n      } while ((n >>>= 1) != 0);\r\n      \r\n      // 返回清除标记\r\n      return removed;\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n\r\n参考视频：https://space.bilibili.com/457326371/\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 内存泄漏\r\n\r\nMemory leak：内存泄漏是指程序中动态分配的堆内存由于某种原因未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果，内存泄漏的堆积终将导致内存溢出\r\n\r\n* 如果 key 使用强引用：使用完 ThreadLocal ，threadLocal Ref 被回收，但是 threadLocalMap 的 Entry 强引用了 threadLocal，造成 threadLocal 无法被回收，无法完全避免内存泄漏\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824172101315.png\" alt=\"image-20230824172101315\" style=\"zoom:80%;\" />\r\n\r\n* 如果 key 使用弱引用：使用完 ThreadLocal ，threadLocal Ref 被回收，ThreadLocalMap 只持有 ThreadLocal 的弱引用，所以threadlocal 也可以被回收，此时 Entry 中的 key = null。但没有手动删除这个 Entry 或者 CurrentThread 依然运行，依然存在强引用链，value 不会被回收，而这块 value 永远不会被访问到，也会导致 value 内存泄漏\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824172141253.png\" alt=\"image-20230824172141253\" style=\"zoom:80%;\" />\r\n\r\n* 两个主要原因：\r\n\r\n  * 没有手动删除这个 Entry\r\n  * CurrentThread 依然运行\r\n\r\n根本原因：ThreadLocalMap 是 Thread的一个属性，**生命周期跟 Thread 一样长**，如果没有手动删除对应 Entry 就会导致内存泄漏\r\n\r\n解决方法：使用完 ThreadLocal 中存储的内容后将它 remove 掉就可以\r\n\r\nThreadLocal 内部解决方法：在 ThreadLocalMap 中的 set/getEntry 方法中，通过线性探测法对 key 进行判断，如果 key 为 null（ThreadLocal 为 null）会对 Entry 进行垃圾回收。所以**使用弱引用比强引用多一层保障**，就算不调用 remove，也有机会进行 GC\r\n\r\n\r\n\r\n***\r\n\r\n#### 补充：内存释放时机\r\n\r\n- 被动 GC 释放 key\r\n  - 仅是让 key 的内存释放，关联 value 的内存并不会释放\r\n- 懒惰被动释放 value\r\n  - get key 时，发现是 null key，则释放其 value 内存\r\n  - set key 时，会使用启发式扫描，清除临近的 null key 的 value 内存，启发次数与元素个数，是否发现 null key 有关\r\n- 主动 remove 释放 key，value\r\n  - 会同时释放 key，value 的内存，也会清除临近的 null key 的 value 内存\r\n  - 推荐使用它，因为一般使用 ThreadLocal 时都把它作为静态变量（即强引用），因此无法被动依靠 GC 回收\r\n\r\n> - threadLocal是弱引用作为key来存储的，当下面线程1一直处于运行状态，不断的插入元素，这样键值就会越来越多，这时只能等GC垃圾回收了，如果threadLocal设计成强引用就不能被垃圾回收了（即使别的地方都没有引用threadLocal，只要threadLocalMap使用强引用引用资源，那被引用的资源就得不到释放），所以弱引用引用资源将来没人引用了就会被回收，但值是强引用的，GC仅是让key的内存释放，后续还要根据 key 是否为 null来进一步释放值的内存\r\n> - GC垃圾回收时，把未被引用的threadLocal（a）清理掉，变为null，值还在；当新的threadLocal（c）去get这个key为Null的位置时，此时值就会被垃圾回收掉，变为Null；当get一个空闲位置时，map就会把当前新的threadLocal（d）作为key，但值为Null\r\n>\r\n> ![image-20230421195247137](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421195247137.png)\r\n>\r\n> - 当在被垃圾回收掉key的位置set（8）时，不光清理掉当前位置的值（清理并存储），还会把相邻位置也一起清理掉（9,10 的 k v），但离得比较远的位置就不会去清理（14）\r\n>\r\n> ![image-20230421195536553](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421195536553.png)\r\n>\r\n> - 一般情况是没有其他地方引用threadLocal就会被垃圾回收，key=Null，get，set发现Nullkey才会进一步清理value\r\n> - 实际情况是用静态变量来引用threadLocal对象，即静态变量跟这个对象为强引用，所以静态变量一直强引用使用对象，垃圾回收不了，即使threadLocal是弱引用，但是静态变量对threadLocal一直保持强引用状态，所以懒惰被动释放 value的两种方式是行不通的\r\n> - 使用remove主动清理直接将map的键值清理掉，前两种方式清理（get set）会产生内存泄露，需要用remove来及时清理；假设长时间运行的线程池资源（含threadLocal关联静态资源）没有即使清理的话，就会积累越来越多的键值资源，还有其他的静态变量强引用key，GC也没办法把它们回收，久而久之就会造成内存泄漏\r\n>\r\n> ![image-20230421200401064](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421200401064.png)\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n#### 变量传递\r\n\r\n##### 基本使用\r\n\r\n父子线程：创建子线程的线程是父线程，比如实例中的 main 线程就是父线程\r\n\r\nThreadLocal 中存储的是线程的局部变量，如果想**实现线程间局部变量传递**可以使用 InheritableThreadLocal 类\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    ThreadLocal<String> threadLocal = new InheritableThreadLocal<>();\r\n    threadLocal.set(\"父线程设置的值\");\r\n\r\n    new Thread(() -> System.out.println(\"子线程输出：\" + threadLocal.get())).start();\r\n}\r\n// 子线程输出：父线程设置的值\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 实现原理\r\n\r\nInheritableThreadLocal 源码：\r\n\r\n```java\r\npublic class InheritableThreadLocal<T> extends ThreadLocal<T> {\r\n    protected T childValue(T parentValue) {\r\n        return parentValue;\r\n    }\r\n    ThreadLocalMap getMap(Thread t) {\r\n       return t.inheritableThreadLocals;\r\n    }\r\n    void createMap(Thread t, T firstValue) {\r\n        t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);\r\n    }\r\n}\r\n```\r\n\r\n实现父子线程间的局部变量共享需要追溯到 Thread 对象的构造方法：\r\n\r\n```java\r\nprivate void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc,\r\n                  // 该参数默认是 true\r\n                  boolean inheritThreadLocals) {\r\n  \t// ...\r\n    Thread parent = currentThread();\r\n\r\n    // 判断父线程（创建子线程的线程）的 inheritableThreadLocals 属性不为 null\r\n    if (inheritThreadLocals && parent.inheritableThreadLocals != null) {\r\n        // 复制父线程的 inheritableThreadLocals 属性，实现父子线程局部变量共享\r\n        this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); \r\n    }\r\n    // ..\r\n}\r\n// 【本质上还是创建 ThreadLocalMap，只是把父类中的可继承数据设置进去了】\r\nstatic ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) {\r\n    return new ThreadLocalMap(parentMap);\r\n}\r\n```\r\n\r\n```java\r\nprivate ThreadLocalMap(ThreadLocalMap parentMap) {\r\n    // 获取父线程的哈希表\r\n    Entry[] parentTable = parentMap.table;\r\n    int len = parentTable.length;\r\n    setThreshold(len);\r\n    table = new Entry[len];\r\n\t// 【逐个复制父线程 ThreadLocalMap 中的数据】\r\n    for (int j = 0; j < len; j++) {\r\n        Entry e = parentTable[j];\r\n        if (e != null) {\r\n            ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();\r\n            if (key != null) {\r\n                // 调用的是 InheritableThreadLocal#childValue(T parentValue)\r\n                Object value = key.childValue(e.value);\r\n                Entry c = new Entry(key, value);\r\n                int h = key.threadLocalHashCode & (len - 1);\r\n                // 线性探测\r\n                while (table[h] != null)\r\n                    h = nextIndex(h, len);\r\n                table[h] = c;\r\n                size++;\r\n            }\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n参考文章：https://blog.csdn.net/feichitianxia/article/details/110495764\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n"},{"title":"并发编程整理版-内存","tags":["Synchronized","JMM","volatile","终止模式","Balking"],"categories":["Java","并发编程"],"author":"imklaus","excerpt":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Concurrent_Programming-Memory","content":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n## 内存\r\n\r\n### JMM\r\n\r\n#### 内存模型\r\n\r\nJava 内存模型是 Java Memory Model（JMM），本身是一种**抽象的概念**，实际上并不存在，描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式\r\n\r\nJMM 作用：\r\n\r\n* 屏蔽各种硬件和操作系统的内存访问差异，实现让 Java 程序在各种平台下都能达到一致的内存访问效果\r\n* 规定了线程和内存之间的一些关系\r\n\r\n根据 JMM 的设计，系统存在一个主内存（Main Memory），Java 中所有变量都存储在主存中，对于所有线程都是共享的；每条线程都有自己的工作内存（Working Memory），工作内存中保存的是主存中某些**变量的拷贝**，线程对所有变量的操作都是先对变量进行拷贝，然后在工作内存中进行，不能直接操作主内存中的变量；线程之间无法相互直接访问，线程间的通信（传递）必须通过主内存来完成\r\n\r\n![image-20230824170740642](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824170740642.png)\r\n\r\n主内存和工作内存：\r\n\r\n* 主内存：计算机的内存，也就是经常提到的 8G 内存，16G 内存，存储所有共享变量的值\r\n* 工作内存：存储该线程使用到的共享变量在主内存中的值的副本拷贝\r\n\r\n**JVM 和 JMM 之间的关系**：JMM 中的主内存、工作内存与 JVM 中的 Java 堆、栈、方法区等并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来：\r\n\r\n* 主内存主要对应于 Java 堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分区域\r\n* 从更低层次上说，主内存直接对应于物理硬件的内存，工作内存对应寄存器和高速缓存\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 内存交互\r\n\r\nJava 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作，每个操作都是**原子**的\r\n\r\n非原子协定：没有被 volatile 修饰的 long、double 外，默认按照两次 32 位的操作\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824170847246.png\" alt=\"image-20230824170847246\" style=\"zoom:80%;\" />\r\n\r\n* lock：作用于主内存，将一个变量标识为被一个线程独占状态（对应 monitorenter）\r\n* unclock：作用于主内存，将一个变量从独占状态释放出来，释放后的变量才可以被其他线程锁定（对应 monitorexit）\r\n* read：作用于主内存，把一个变量的值从主内存传输到工作内存中\r\n* load：作用于工作内存，在 read 之后执行，把 read 得到的值放入工作内存的变量副本中\r\n* use：作用于工作内存，把工作内存中一个变量的值传递给**执行引擎**，每当遇到一个使用到变量的操作时都要使用该指令\r\n* assign：作用于工作内存，把从执行引擎接收到的一个值赋给工作内存的变量\r\n* store：作用于工作内存，把工作内存的一个变量的值传送到主内存中\r\n* write：作用于主内存，在 store 之后执行，把 store 得到的值放入主内存的变量中\r\n\r\n\r\n\r\n参考文章：https://github.com/CyC2018/CS-Notes/blob/master/notes/Java%20%E5%B9%B6%E5%8F%91.md\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 三大特性\r\n\r\n##### 可见性\r\n\r\n:::warning Error Correction!!!\r\n\r\n以下可见性问题产生的根本原因已被推翻，详情请看https://imlklaus.github.io/posts/Java_Interview_Topics-Concurrent#%E5%8F%AF%E8%A7%81%E6%80%A7\r\n\r\n:::\r\n\r\n可见性：是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值\r\n\r\n存在不可见问题的根本原因是由于缓存的存在，线程持有的是共享变量的副本，无法感知其他线程对于共享变量的更改，导致读取的值不是最新的。但是 final 修饰的变量是**不可变**的，就算有缓存，也不会存在不可见的问题\r\n\r\nmain 线程对 run 变量的修改对于 t 线程不可见，导致了 t 线程无法停止：\r\n\r\n```java\r\nstatic boolean run = true;\t//添加volatile\r\npublic static void main(String[] args) throws InterruptedException {\r\n    Thread t = new Thread(()->{\r\n        while(run){\r\n        // ....\r\n        }\r\n\t});\r\n    t.start();\r\n    sleep(1);\r\n    run = false; // 线程t不会如预想的停下来\r\n}\r\n```\r\n\r\n**为什么无法退出该循环**\r\n\r\n- 初始状态， t 线程刚开始从**主内存**读取了 run 的值到**工作内存**。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145505.png)\r\n\r\n- 因为 t 线程要频繁从主内存中读取 run 的值，JIT 编译器会将 run 的值**缓存至自己工作内存**中的高速缓存中， 减少对主存中 run 的访问，提高效率\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145517.png)\r\n\r\n- 1 秒之后，main 线程修改了 run 的值，并同步至主存，而 t 是从自己工作内存中的高速缓存中读取这个变量 的值，结果永远是**旧值**\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145529.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 原子性\r\n\r\n原子性：不可分割，完整性，也就是说某个线程正在做某个具体业务时，中间不可以被分割，需要具体完成，要么同时成功，要么同时失败，保证指令不会受到线程上下文切换的影响 \r\n\r\n定义原子操作的使用规则：\r\n\r\n1. 不允许 read 和 load、store 和 write 操作之一单独出现，必须顺序执行，但是不要求连续\r\n2. 不允许一个线程丢弃 assign 操作，必须同步回主存\r\n3. 不允许一个线程无原因地（没有发生过任何 assign 操作）把数据从工作内存同步到主内存中\r\n4. 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（assign 或者 load）的变量，即对一个变量实施 use 和 store 操作之前，必须先自行 assign 和 load 操作\r\n5. 一个变量在同一时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一线程重复执行多次，多次执行 lock 后，只有**执行相同次数的 unlock** 操作，变量才会被解锁，**lock 和 unlock 必须成对出现**\r\n6. 如果对一个变量执行 lock 操作，将会**清空工作内存中此变量的值**，在执行引擎使用这个变量之前需要重新从主存加载\r\n7. 如果一个变量事先没有被 lock 操作锁定，则不允许执行 unlock 操作，也不允许去 unlock 一个被其他线程锁定的变量\r\n8. 对一个变量执行 unlock 操作之前，必须**先把此变量同步到主内存**中（执行 store 和 write 操作）\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 有序性\r\n\r\n有序性：在本线程内观察，所有操作都是有序的；在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序\r\n\r\nCPU 的基本工作是执行存储的指令序列，即程序，程序的执行过程实际上是不断地取出指令、分析指令、执行指令的过程，为了提高性能，编译器和处理器会对指令重排，一般分为以下三种：\r\n\r\n```java\r\n源代码 -> 编译器优化的重排 -> 指令并行的重排 -> 内存系统的重排 -> 最终执行指令\r\n```\r\n\r\n现代 CPU 支持多级指令流水线，几乎所有的冯•诺伊曼型计算机的 CPU，其工作都可以分为 5 个阶段：取指令、指令译码、执行指令、访存取数和结果写回，可以称之为**五级指令流水线**。CPU 可以在一个时钟周期内，同时运行五条指令的**不同阶段**（每个线程不同的阶段），本质上流水线技术并不能缩短单条指令的执行时间，但变相地提高了指令地吞吐率\r\n\r\n处理器在进行重排序时，必须要考虑**指令之间的数据依赖性**\r\n\r\n* 单线程环境也存在指令重排，由于存在依赖性，最终执行结果和代码顺序的结果一致\r\n* 多线程环境中线程交替执行，由于编译器优化重排，会获取其他线程处在不同阶段的指令同时执行\r\n\r\n补充知识：\r\n\r\n* 指令周期是取出一条指令并执行这条指令的时间，一般由若干个机器周期组成\r\n* 机器周期也称为 CPU 周期，一条指令的执行过程划分为若干个阶段（如取指、译码、执行等），每一阶段完成一个基本操作，完成一个基本操作所需要的时间称为机器周期\r\n* 振荡周期指周期性信号作周期性重复变化的时间间隔\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### cache\r\n\r\n#### 缓存机制\r\n\r\n##### 缓存结构\r\n\r\n在计算机系统中，CPU 高速缓存（CPU Cache，简称缓存）是用于减少处理器访问内存所需平均时间的部件；在存储体系中位于自顶向下的第二层，仅次于 CPU 寄存器；其容量远小于内存，但速度却可以接近处理器的频率\r\n\r\nCPU 处理器速度远远大于在主内存中的，为了解决速度差异，在它们之间架设了多级缓存，如 L1、L2、L3 级别的缓存，这些缓存离 CPU 越近就越快，将频繁操作的数据缓存到这里，加快访问速度\r\n\r\n![image-20230824170955611](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824170955611.png)\r\n\r\n| 从 CPU 到 | 大约需要的时钟周期                |\r\n| --------- | --------------------------------- |\r\n| 寄存器    | 1 cycle (4GHz 的 CPU 约为 0.25ns) |\r\n| L1        | 3~4 cycle                         |\r\n| L2        | 10~20 cycle                       |\r\n| L3        | 40~45 cycle                       |\r\n| 内存      | 120~240 cycle                     |\r\n\r\n\r\n\r\n##### 缓存使用\r\n\r\n当处理器发出内存访问请求时，会先查看缓存内是否有请求数据，如果存在（命中），则不用访问内存直接返回该数据；如果不存在（失效），则要先把内存中的相应数据载入缓存，再将其返回处理器\r\n\r\n缓存之所以有效，主要因为程序运行时对内存的访问呈现局部性（Locality）特征。既包括空间局部性（Spatial Locality），也包括时间局部性（Temporal Locality），有效利用这种局部性，缓存可以达到极高的命中率\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 伪共享\r\n\r\n**缓存以缓存行 cache line 为单位**，每个缓存行对应着一块内存，一般是 64 byte（8 个 long），在 CPU 从主存获取数据时，以 cache line 为单位加载，于是相邻的数据会一并加载到缓存中\r\n\r\n缓存会造成数据副本的产生，即同一份数据会缓存在不同核心的缓存行中，CPU 要保证数据的一致性，需要做到某个 CPU 核心更改了数据，其它 CPU 核心对应的**整个缓存行必须失效**，这就是伪共享\r\n\r\n![image-20230824171035903](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824171035903.png)\r\n\r\n解决方法：\r\n\r\n* padding：通过填充，让数据落在不同的 cache line 中\r\n\r\n* @Contended：原理参考 无锁 → Adder → 优化机制 → 伪共享\r\n\r\nLinux 查看 CPU 缓存行：\r\n\r\n* 命令：`cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size64`\r\n* 内存地址格式：[高位组标记] [低位索引] [偏移量]\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 缓存一致\r\n\r\n缓存一致性：当多个处理器运算任务都涉及到同一块主内存区域的时候，将可能导致各自的缓存数据不一样\r\n\r\n![image-20230824171115157](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824171115157.png)\r\n\r\nMESI（Modified Exclusive Shared Or Invalid）是一种广泛使用的**支持写回策略的缓存一致性协议**，CPU 中每个缓存行（caceh line）使用 4 种状态进行标记（使用额外的两位 bit 表示)：\r\n\r\n* M：被修改（Modified）\r\n\r\n  该缓存行只被缓存在该 CPU 的缓存中，并且是被修改过的，与主存中的数据不一致 (dirty)，该缓存行中的内存需要写回 (write back) 主存。该状态的数据再次被修改不会发送广播，因为其他核心的数据已经在第一次修改时失效一次\r\n\r\n  当被写回主存之后，该缓存行的状态会变成独享 (exclusive) 状态\r\n\r\n* E：独享的（Exclusive）\r\n\r\n  该缓存行只被缓存在该 CPU 的缓存中，是未被修改过的 (clear)，与主存中数据一致，修改数据不需要通知其他 CPU 核心，该状态可以在任何时刻有其它 CPU 读取该内存时变成共享状态 (shared)\r\n\r\n  当 CPU 修改该缓存行中内容时，该状态可以变成 Modified 状态\r\n\r\n* S：共享的（Shared）\r\n\r\n  该状态意味着该缓存行可能被多个 CPU 缓存，并且各个缓存中的数据与主存数据一致，当 CPU 修改该缓存行中，会向其它 CPU 核心广播一个请求，使该缓存行变成无效状态 (Invalid)，然后再更新当前 Cache 里的数据\r\n\r\n* I：无效的（Invalid）\r\n\r\n  该缓存是无效的，可能有其它 CPU 修改了该缓存行\r\n\r\n解决方法：各个处理器访问缓存时都遵循一些协议，在读写时要根据协议进行操作，协议主要有 MSI、MESI 等\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 处理机制\r\n\r\n单核 CPU 处理器会自动保证基本内存操作的原子性\r\n\r\n多核 CPU 处理器，每个 CPU 处理器内维护了一块内存，每个内核内部维护着一块缓存，当多线程并发读写时，就会出现缓存数据不一致的情况。处理器提供：\r\n\r\n* 总线锁定：当处理器要操作共享变量时，在 BUS 总线上发出一个 LOCK 信号，其他处理器就无法操作这个共享变量，该操作会导致大量阻塞，从而增加系统的性能开销（**平台级别的加锁**）\r\n* 缓存锁定：当处理器对缓存中的共享变量进行了操作，其他处理器有嗅探机制，将各自缓存中的该共享变量的失效，读取时会重新从主内存中读取最新的数据，基于 MESI 缓存一致性协议来实现\r\n\r\n有如下两种情况处理器不会使用缓存锁定：\r\n\r\n* 当操作的数据跨多个缓存行，或没被缓存在处理器内部，则处理器会使用总线锁定\r\n\r\n* 有些处理器不支持缓存锁定，比如：Intel 486 和 Pentium 处理器也会调用总线锁定\r\n\r\n总线机制：\r\n\r\n* 总线嗅探：每个处理器通过嗅探在总线上传播的数据来检查自己缓存值是否过期了，当处理器发现自己的缓存对应的内存地址的数据被修改，就**将当前处理器的缓存行设置为无效状态**，当处理器对这个数据进行操作时，会重新从内存中把数据读取到处理器缓存中\r\n\r\n* 总线风暴：当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心（**写传播**），CPU 需要每时每刻监听总线上的一切活动，但是不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个广播事件，不断的从主内存嗅探和 CAS 循环，无效的交互会导致总线带宽达到峰值；因此不要大量使用 volatile 关键字，使用 volatile、syschonized 都需要根据实际场景\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### volatile\r\n\r\n#### 同步机制\r\n\r\nvolatile 是 Java 虚拟机提供的**轻量级**的同步机制（三大特性）\r\n\r\n- 保证可见性\r\n- 不保证原子性\r\n- 保证有序性（禁止指令重排）\r\n\r\n性能：volatile 修饰的变量进行读操作与普通变量几乎没什么差别，但是写操作相对慢一些，因为需要在本地代码中插入很多内存屏障来保证指令不会发生乱序执行，但是开销比锁要小\r\n\r\nsynchronized 无法禁止指令重排和处理器优化，为什么可以保证有序性可见性\r\n\r\n* 加了锁之后，只能有一个线程获得到了锁，获得不到锁的线程就要阻塞，所以同一时间只有一个线程执行，相当于单线程，由于数据依赖性的存在，单线程的指令重排是没有问题的\r\n* 线程加锁前，将**清空工作内存**中共享变量的值，使用共享变量时需要从主内存中重新读取最新的值；线程解锁前，必须把共享变量的最新值**刷新到主内存**中（JMM 内存交互章节有讲）\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 指令重排\r\n\r\nvolatile 修饰的变量，可以禁用指令重排\r\n\r\n指令重排实例：\r\n\r\n* example 1：\r\n\r\n  ```java\r\n  public void mySort() {\r\n  \tint x = 11;\t//语句1\r\n  \tint y = 12;\t//语句2  谁先执行效果一样\r\n  \tx = x + 5;\t//语句3\r\n  \ty = x * x;\t//语句4\r\n  }\r\n  ```\r\n\r\n  执行顺序是：1 2 3 4、2 1 3 4、1 3 2 4\r\n\r\n  指令重排也有限制不会出现：4321，语句 4 需要依赖于 y 以及 x 的申明，因为存在数据依赖，无法首先执行\r\n\r\n* example 2：\r\n\r\n  ```java\r\n  int num = 0;\r\n  boolean ready = false;\r\n  // 线程1 执行此方法\r\n  public void actor1(I_Result r) {\r\n      if(ready) {\r\n      \tr.r1 = num + num;\r\n      } else {\r\n      \tr.r1 = 1;\r\n      }\r\n  }\r\n  // 线程2 执行此方法\r\n  public void actor2(I_Result r) {\r\n  \tnum = 2;\r\n  \tready = true;\r\n  }\r\n  ```\r\n\r\n  情况一：线程 1 先执行，ready = false，结果为 r.r1 = 1\r\n\r\n  情况二：线程 2 先执行 num = 2，但还没执行 ready = true，线程 1 执行，结果为 r.r1 = 1\r\n\r\n  情况三：线程 2 先执行 num = 2 和 ready = true，线程 1 执行，进入 if 分支结果为 r.r1 = 4\r\n\r\n  情况四：线程 2 先执行 ready = true，切换到线程 1，进入 if 分支为 r.r1 = 0，再切回线程 2 执行 num = 2，发生指令重排\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 底层原理\r\n\r\n##### 缓存一致\r\n\r\n使用 volatile 修饰的共享变量，底层通过汇编 lock 前缀指令进行缓存锁定，在线程修改完共享变量后写回主存，其他的 CPU 核心上运行的线程通过 CPU 总线嗅探机制会修改其**工作内存中的共享变量副本为失效状态**，读取时会重新从主内存中读取最新的数据\r\n\r\nlock 前缀指令就相当于内存屏障，Memory Barrier（Memory Fence）\r\n\r\n* 对 volatile 变量的写指令后会加入写屏障\r\n* 对 volatile 变量的读指令前会加入读屏障\r\n\r\n内存屏障有三个作用：\r\n\r\n- 确保对内存的读-改-写操作原子执行\r\n- 阻止屏障两侧的指令重排序\r\n- 强制把缓存中的脏数据写回主内存，让缓存行中相应的数据失效\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 内存屏障\r\n\r\n保证**可见性**：\r\n\r\n* 写屏障（sfence，Store Barrier）保证在该屏障之前的，对共享变量的改动，都同步到主存当中\r\n\r\n  ```java\r\n  public void actor2(I_Result r) {\r\n      num = 2;\r\n      ready = true; // ready 是 volatile 赋值带写屏障\r\n      // 写屏障 ▲▲▲\r\n  }\r\n  ```\r\n\r\n* 读屏障（lfence，Load Barrier）保证在该屏障之后的，对共享变量的读取，从主存刷新变量值，加载的是主存中最新数据\r\n\r\n  ```java\r\n  public void actor1(I_Result r) {\r\n      // 读屏障 ↓↓↓↓\r\n      // ready 是 volatile 读取值带读屏障\r\n      if(ready) {\r\n      \tr.r1 = num + num;\r\n      } else {\r\n      \tr.r1 = 1;\r\n      }\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20200608145713.png\" alt=\"img\" style=\"zoom:67%;\" />\r\n\r\n* 全能屏障：mfence（modify/mix Barrier），兼具 sfence 和 lfence 的功能\r\n\r\n保证**有序性**：\r\n\r\n* 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后\r\n* 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前\r\n\r\n![image-20230713210757338](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230713210757338.png)\r\n\r\n不能解决指令交错：\r\n\r\n* 写屏障仅仅是保证之后的读能够读到最新的结果，但不能保证其他线程的读跑到写屏障之前\r\n\r\n* 有序性的保证也只是保证了本线程内相关代码不被重排序\r\n\r\n  ```java\r\n  volatile i = 0;\r\n  new Thread(() -> {i++});\r\n  new Thread(() -> {i--});\r\n  ```\r\n\r\n  i++ 反编译后的指令：\r\n\r\n  ```java\r\n  0: iconst_1\t\t\t// 当int取值 -1~5 时，JVM采用iconst指令将常量压入栈中\r\n  1: istore_1\t\t\t// 将操作数栈顶数据弹出，存入局部变量表的 slot 1\r\n  2: iinc\t\t1, 1\t\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230713212314498.png\" alt=\"image-20230713212314498\" style=\"zoom:67%;\" />\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 交互规则\r\n\r\n对于 volatile 修饰的变量：\r\n\r\n* 线程对变量的 use 与 load、read 操作是相关联的，所以变量使用前必须先从主存加载\r\n* 线程对变量的 assign 与 store、write 操作是相关联的，所以变量使用后必须同步至主存\r\n* 线程 1 和线程 2 谁先对变量执行 read 操作，就会先进行 write 操作，防止指令重排\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 双端检锁\r\n\r\n##### 检锁机制\r\n\r\nDouble-Checked Locking：双端检锁机制\r\n\r\nDCL（双端检锁）机制不一定是线程安全的，原因是有指令重排的存在，加入 volatile 可以禁止指令重排\r\n\r\n```java\r\npublic final class Singleton {\r\n    private Singleton() { }\r\n    private static Singleton INSTANCE = null;\r\n    \r\n    public static Singleton getInstance() {\r\n        if(INSTANCE == null) { // t2，这里的判断不是线程安全的\r\n            // 首次访问会同步，而之后的使用没有 synchronized\r\n            synchronized(Singleton.class) {\r\n                // 这里是线程安全的判断，防止其他线程在当前线程等待锁的期间完成了初始化\r\n                if (INSTANCE == null) { \r\n                    INSTANCE = new Singleton();\r\n                }\r\n            }\r\n        }\r\n        return INSTANCE;\r\n    }\r\n}\r\n```\r\n\r\n不锁 INSTANCE 的原因：\r\n\r\n* INSTANCE 要重新赋值\r\n* INSTANCE 是 null，线程加锁之前需要获取对象的引用，设置对象头，null 没有引用\r\n\r\n实现特点： \r\n\r\n* 懒惰初始化\r\n* 首次使用 getInstance() 才使用 synchronized 加锁，后续使用时无需加锁\r\n* 第一个 if 使用了 INSTANCE 变量，是在同步块之外，但在多线程环境下会产生问题\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### DCL问题\r\n\r\ngetInstance 方法对应的字节码为：\r\n\r\n```java\r\n0: \tgetstatic \t\t#2 \t\t// Field INSTANCE:Ltest/Singleton;\r\n3: \tifnonnull \t\t37\r\n6: \tldc \t\t\t#3 \t\t// class test/Singleton\r\n8: \tdup\r\n9: \tastore_0\r\n10: monitorenter\r\n11: getstatic \t\t#2 \t\t// Field INSTANCE:Ltest/Singleton;\r\n14: ifnonnull 27\r\n17: new \t\t\t#3 \t\t// class test/Singleton\r\n20: dup\r\n21: invokespecial \t#4 \t\t// Method \"<init>\":()V\r\n24: putstatic \t\t#2 \t\t// Field INSTANCE:Ltest/Singleton;\r\n27: aload_0\r\n28: monitorexit\r\n29: goto 37\r\n32: astore_1\r\n33: aload_0\r\n34: monitorexit\r\n35: aload_1\r\n36: athrow\r\n37: getstatic \t\t#2 \t\t// Field INSTANCE:Ltest/Singleton;\r\n40: areturn\r\n```\r\n\r\n* 17 表示创建对象，将对象引用入栈 // new Singleton\r\n* 20 表示复制一份对象引用 // 引用地址\r\n* 21 表示利用一个对象引用，调用构造方法\r\n* 24 表示利用一个对象引用，赋值给 static INSTANCE\r\n\r\n**步骤 21 和 24 之间不存在数据依赖关系**，而且无论重排前后，程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的\r\n\r\n也许 jvm 会优化为：先执行 24，再执行 21。如果两个线程 t1，t2 按如下时间序列执行：\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230713215804212.png\" alt=\"image-20230713215804212\" style=\"zoom:67%;\" />\r\n\r\n> 关键在于 0: getstatic 这行代码在 monitor 控制之外，它就像之前举例中不守规则的人，可以越过 monitor 读取INSTANCE 变量的值；这时 t1 还未完全将构造方法执行完毕，如果在构造方法中要执行很多初始化操作，那么 t2 拿到的将是一个未初始化完毕的单例；对 INSTANCE 使用 volatile 修饰即可，可以禁用指令重排，但要注意在 JDK 5 以上的版本的 volatile 才会真正有效\r\n>\r\n> synchronized同步的代码块，具有排他性，一次只能被一个线程拥有，所以synchronized保证同一时刻，代码是单线程执行的。\r\n>\r\n> 因为as-if-serial语义的存在，单线程的程序能保证最终结果是有序的，但是不保证不会指令重排。\r\n>\r\n> 所以synchronized保证的有序是执行结果的有序性，而不是防止指令重排的有序性。synchronized确实可以保证共享变量的原子、可见、有序性，前提是共享变量完全交由synchronized来管理，不能留一部分出去，不然就脱离了synchronized的管理了\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 解决方法\r\n\r\n指令重排只会保证串行语义的执行一致性（单线程），但并不会保证多线程间的语义一致性\r\n\r\n引入 volatile，来保证出现指令重排的问题，从而保证单例模式的线程安全性：\r\n\r\n```java\r\nprivate static volatile SingletonDemo INSTANCE = null;\r\n```\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230713215851770.png\" alt=\"image-20230713215851770\" style=\"zoom: 67%;\" />\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### ha-be\r\n\r\nhappens-before 先行发生\r\n\r\nJava 内存模型具备一些先天的“有序性”，即不需要通过任何同步手段（volatile、synchronized 等）就能够得到安全的保证，这个通常也称为 happens-before 原则，它是可见性与有序性的一套规则总结，JMM 并不能保证一个线程的可见性和有序性，不符合 happens-before 规则\r\n\r\nhappens-before 规则：\r\n\r\n1. 程序次序规则 (Program Order Rule)：一个线程内，逻辑上书写在前面的操作先行发生于书写在后面的操作 ，因为多个操作之间有先后依赖关系，则不允许对这些操作进行重排序\r\n\r\n2. 锁定规则 (Monitor Lock Rule)：一个 unlock 操作先行发生于后面（时间的先后）对同一个锁的 lock 操作，所以线程解锁 之前对变量  m 的写（解锁前会刷新到主内存中），对于接下来对 m 加锁的其它线程对该变量的读可见\r\n\r\n3. **volatile 变量规则**  (Volatile Variable Rule)：对 volatile 变量的写操作先行发生于后面对这个变量的读\r\n\r\n4. 传递规则 (Transitivity)：具有传递性，如果操作 A 先行发生于操作 B，而操作 B 又先行发生于操作 C，则可以得出操作 A 先行发生于操作 C\r\n\r\n5. 线程启动规则 (Thread Start Rule)：Thread 对象的 start()方 法先行发生于此线程中的每一个操作\r\n\r\n   ```java\r\n   static int x = 10;//线程 start 前对变量的写，对该线程开始后对该变量的读可见\r\n   new Thread(()->{\tSystem.out.println(x);\t},\"t1\").start();\r\n   ```\r\n\r\n6. 线程中断规则 (Thread Interruption Rule)：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生\r\n\r\n7. 线程终止规则 (Thread Termination Rule)：线程中所有的操作都先行发生于线程的终止检测，可以通过 Thread.join() 方法结束、Thread.isAlive() 的返回值手段检测到线程已经终止执行\r\n\r\n8. 对象终结规则（Finaizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 设计模式\r\n\r\n#### 终止模式\r\n\r\n终止模式之两阶段终止模式：停止标记用 volatile 是为了保证该变量在多个线程之间的可见性\r\n\r\n```java\r\nclass TwoPhaseTermination {\r\n    // 监控线程\r\n    private Thread monitor;\r\n    // 停止标记\r\n    private volatile boolean stop = false;;\r\n\r\n    // 启动监控线程\r\n    public void start() {\r\n        monitor = new Thread(() -> {\r\n            while (true) {\r\n                Thread thread = Thread.currentThread();\r\n                if (stop) {\r\n                    System.out.println(\"后置处理\");\r\n                    break;\r\n                }\r\n                try {\r\n                    Thread.sleep(1000);// 睡眠\r\n                    System.out.println(thread.getName() + \"执行监控记录\");\r\n                } catch (InterruptedException e) {\r\n                   \tSystem.out.println(\"被打断，退出睡眠\");\r\n                }\r\n            }\r\n        });\r\n        monitor.start();\r\n    }\r\n\r\n    // 停止监控线程\r\n    public void stop() {\r\n        stop = true;\r\n        monitor.interrupt();// 让线程尽快退出Timed Waiting\r\n    }\r\n}\r\n// 测试\r\npublic static void main(String[] args) throws InterruptedException {\r\n    TwoPhaseTermination tpt = new TwoPhaseTermination();\r\n    tpt.start();\r\n    Thread.sleep(3500);\r\n    System.out.println(\"停止监控\");\r\n    tpt.stop();\r\n}\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### Balking\r\n\r\nBalking （犹豫）模式用在一个线程发现另一个线程或本线程已经做了某一件相同的事，那么本线程就无需再做了，直接结束返回\r\n\r\n```java\r\npublic class MonitorService {\r\n    // 用来表示是否已经有线程已经在执行启动了\r\n    private volatile boolean starting = false;\r\n    public void start() {\r\n        System.out.println(\"尝试启动监控线程...\");\r\n        synchronized (this) {\r\n            if (starting) {\r\n            \treturn;\r\n            }\r\n            starting = true;\r\n        }\r\n        // 真正启动监控线程...\r\n    }\r\n}\r\n```\r\n\r\n对比保护性暂停模式：保护性暂停模式用在一个线程等待另一个线程的执行结果，当条件不满足时线程等待\r\n\r\n例子：希望 doInit() 方法仅被调用一次，下面的实现出现的问题：\r\n\r\n* 当 t1 线程进入 init() 准备 doInit()，t2 线程进来，initialized 还为f alse，则 t2 就又初始化一次\r\n* volatile 适合一个线程写，其他线程读的情况，这个代码需要加锁\r\n\r\n```java\r\npublic class TestVolatile {\r\n    volatile boolean initialized = false;\r\n    \r\n    void init() {\r\n        if (initialized) {\r\n            return;\r\n        }\r\n    \tdoInit();\r\n    \tinitialized = true;\r\n    }\r\n    private void doInit() {\r\n    }\r\n}\r\n```\r\n\r\n> volatile不能保证代码的原子性，synchronized就可以\r\n\r\n------\r\n\r\n"},{"title":"并发编程整理版-同步器","tags":["AQS","ReentrantLock","ReentrantReadWriteLock","CountDownLatch","CyclicBarrier","Semaphore","Exchanger"],"categories":["Java","并发编程"],"author":"imklaus","excerpt":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Concurrent_Programming-Synchronizer","content":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n\r\n## 同步器\r\n\r\n### AQS\r\n\r\n#### 核心思想\r\n\r\nAQS：AbstractQueuedSynchronizer，中文意思是抽象队列同步器，是阻塞式锁和相关的同步器工具的框架，由 Doug Lea 设计，是 Java 并发包`java.util.concurrent`的核心框架类，许多同步类的实现都依赖于它，如 ReentrantLock、Semaphore、CountDownLatch 等。\r\n\r\nAQS 用状态属性来表示资源的状态（分**独占模式和共享模式**），子类需要定义如何维护这个状态，控制如何获取锁和释放锁\r\n\r\n* 独占模式是只有一个线程能够访问资源，如 ReentrantLock\r\n* 共享模式允许多个线程访问资源，如 Semaphore，ReentrantReadWriteLock 是组合式\r\n\r\nAQS 核心思想：\r\n\r\n* 如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置锁定状态\r\n\r\n* 请求的共享资源被占用，AQS 用队列实现线程阻塞等待以及被唤醒时锁分配的机制，将暂时获取不到锁的线程加入到队列中\r\n\r\n  整个过程通过维护一个 int 类型的状态和一个先进先出（FIFO）的队列，来实现对共享资源的管理。\r\n\r\n  ![image-20240612172349107](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20240612172349107.png)\r\n\r\nCLH 是一种基于单向链表的**高性能、公平的自旋锁**，AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配\r\n\r\n- 如果共享资源被占用，需要一种特定的阻塞等待唤醒机制来保证锁的分配，AQS 会将竞争共享资源失败的线程添加到一个 CLH 队列中。\r\n\r\n![image-20240612174239085](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20240612174239085.png)\r\n\r\n- 在 CLH 锁中，当一个线程尝试获取锁并失败时，它会将自己添加到队列的尾部并自旋，等待前一个节点的线程释放锁。\r\n\r\n![image-20240612174302996](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20240612174302996.png)\r\n\r\n***\r\n\r\n\r\n\r\n#### 设计原理\r\n\r\n设计原理：\r\n\r\n* 获取锁：\r\n\r\n  ```java\r\n  while(state 状态不允许获取) {\t// tryAcquire(arg)\r\n      if(队列中还没有此线程) {\r\n          入队并阻塞 park\r\n      }\r\n  }\r\n  当前线程出队\r\n  ```\r\n\r\n* 释放锁：\r\n\r\n  ```java\r\n  if(state 状态允许了) {\t// tryRelease(arg)\r\n  \t恢复阻塞的线程(s) unpark\r\n  }\r\n  ```\r\n\r\nAbstractQueuedSynchronizer 中 state 设计：\r\n\r\n* state 使用了 32bit int 来维护同步状态，独占模式 0 表示未加锁状态，大于 0 表示已经加锁状态\r\n\r\n  ```java\r\n  private volatile int state;\r\n  ```\r\n\r\n* state **使用 volatile 修饰配合 CAS** 保证其修改时的**可见性**\r\n\r\n* state 表示**线程重入的次数（独占模式）或者剩余许可数（共享模式）**\r\n\r\n* state API：\r\n\r\n  * `protected final int getState()`：获取 state 状态\r\n  * `protected final void setState(int newState)`：设置 state 状态\r\n  * `protected final boolean compareAndSetState(int expect,int update)`：**CAS** 安全设置 state\r\n\r\n封装线程的 Node 节点中 waitstate 设计：\r\n\r\n* 使用 **volatile 修饰配合 CAS** 保证其修改时的**可见性**\r\n\r\n* 表示 Node 节点的状态，有以下几种状态：\r\n\r\n  ```java\r\n  // 默认为 0\r\n  volatile int waitStatus;\r\n  // 由于超时或中断，此节点被取消，不会再改变状态\r\n  static final int CANCELLED =  1;\r\n  // 此节点后面的节点已（或即将）被阻止（通过park），【当前节点在释放或取消时必须唤醒后面的节点】\r\n  static final int SIGNAL    = -1;\r\n  // 此节点当前在条件队列中\r\n  static final int CONDITION = -2;\r\n  // 将releaseShared传播到其他节点\r\n  static final int PROPAGATE = -3;\r\n  ```\r\n\r\n阻塞恢复设计：\r\n\r\n* 使用 `park & unpark` 来实现线程的暂停和恢复，因为命令的先后顺序不影响结果\r\n* `park & unpark` 是针对线程的，而不是针对同步器的，因此控制粒度更为精细\r\n* park 线程可以通过 interrupt 打断\r\n\r\n队列设计：\r\n\r\n* 使用了 `FIFO` 先入先出队列，并不支持优先级队列，**同步队列是双向链表，便于出队入队**\r\n\r\n  ```java\r\n  // 头结点，指向哑元节点\r\n  private transient volatile Node head;\r\n  // 阻塞队列的尾节点，阻塞队列不包含头结点，从 head.next → tail 认为是阻塞队列\r\n  private transient volatile Node tail;\r\n  \r\n  static final class Node {\r\n      // 枚举：共享模式\r\n      static final Node SHARED = new Node();\r\n      // 枚举：独占模式\r\n      static final Node EXCLUSIVE = null;\r\n      // node 需要构建成 FIFO 队列，prev 指向前继节点\r\n      volatile Node prev;\r\n      // next 指向后继节点\r\n      volatile Node next;\r\n      // 当前 node 封装的线程\r\n      volatile Thread thread;\r\n      // 条件队列是单向链表，只有后继指针，条件队列使用该属性\r\n      Node nextWaiter;\r\n      ...\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824173120652.png\" alt=\"image-20230824173120652\" style=\"zoom:80%;\" />\r\n\r\n* 条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet，**条件队列是单向链表**\r\n\r\n  ````java\r\n   public class ConditionObject implements Condition, java.io.Serializable {\r\n       // 指向条件队列的第一个 node 节点\r\n       private transient Node firstWaiter;\r\n       // 指向条件队列的最后一个 node 节点\r\n       private transient Node lastWaiter;\r\n       ...\r\n   }\r\n  ````\r\n  \r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 模板对象\r\n\r\n同步器的设计是基于模板方法模式，该模式是基于继承的，主要是为了在不改变模板结构的前提下在子类中重新定义模板中的内容以实现复用代码\r\n\r\n* 使用者继承 `AbstractQueuedSynchronizer` 并重写指定的方法\r\n* 将 AQS 组合在自定义同步组件的实现中，并调用其模板方法，这些模板方法会调用使用者重写的方法\r\n\r\nAQS 使用了模板方法模式，自定义同步器时需要重写下面几个 AQS 提供的模板方法：\r\n\r\n```java\r\nisHeldExclusively()\t\t//该线程是否正在独占资源。只有用到condition才需要去实现它\r\ntryAcquire(int)\t\t\t//独占方式。尝试获取资源，成功则返回true，失败则返回false\r\ntryRelease(int)\t\t\t//独占方式。尝试释放资源，成功则返回true，失败则返回false\r\ntryAcquireShared(int)\t//共享方式。尝试获取资源。负数表示失败；0表示成功但没有剩余可用资源；正数表示成功且有剩余资源\r\ntryReleaseShared(int)\t//共享方式。尝试释放资源，成功则返回true，失败则返回false\r\n```\r\n\r\n* 默认情况下，每个方法都抛出 `UnsupportedOperationException`\r\n* 这些方法的实现必须是内部线程安全的\r\n* AQS 类中的其他方法都是 final ，所以无法被其他类使用，只有这几个方法可以被其他类使用\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 自定义\r\n\r\n自定义一个不可重入锁：\r\n\r\n```java\r\nclass MyLock implements Lock {\r\n    //独占锁 不可重入\r\n    class MySync extends AbstractQueuedSynchronizer {\r\n        @Override\r\n        protected boolean tryAcquire(int arg) {\r\n            if (compareAndSetState(0, 1)) {\r\n                // 加上锁 设置 owner 为当前线程\r\n                setExclusiveOwnerThread(Thread.currentThread());\r\n                return true;\r\n            }\r\n            return false;\r\n        }\r\n        @Override   //解锁\r\n        protected boolean tryRelease(int arg) {\r\n            setExclusiveOwnerThread(null);\r\n            setState(0);//volatile 修饰的变量放在后面，防止指令重排\r\n            return true;\r\n        }\r\n        @Override   //是否持有独占锁\r\n        protected boolean isHeldExclusively() {\r\n            return getState() == 1;\r\n        }\r\n        public Condition newCondition() {\r\n            return new ConditionObject();\r\n        }\r\n    }\r\n\r\n    private MySync sync = new MySync();\r\n\r\n    @Override   //加锁（不成功进入等待队列等待）\r\n    public void lock() {\r\n        sync.acquire(1);\r\n    }\r\n\r\n    @Override   //加锁 可打断\r\n    public void lockInterruptibly() throws InterruptedException {\r\n        sync.acquireInterruptibly(1);\r\n    }\r\n\r\n    @Override   //尝试加锁，尝试一次\r\n    public boolean tryLock() {\r\n        return sync.tryAcquire(1);\r\n    }\r\n\r\n    @Override   //尝试加锁，带超时\r\n    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {\r\n        return sync.tryAcquireNanos(1, unit.toNanos(time));\r\n    }\r\n    \r\n    @Override   //解锁\r\n    public void unlock() {\r\n        sync.release(1);\r\n    }\r\n    \r\n    @Override   //条件变量\r\n    public Condition newCondition() {\r\n        return sync.newCondition();\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Re-Lock\r\n\r\n#### 锁对比\r\n\r\nReentrantLock 相对于 synchronized 具备如下特点：\r\n\r\n1. 锁的实现：synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的\r\n2. 性能：新版本 Java 对 synchronized 进行了很多优化，synchronized 与 ReentrantLock 大致相同\r\n3. 使用：ReentrantLock 需要手动解锁，synchronized 执行完代码块自动解锁\r\n4. **可中断**：ReentrantLock 可中断，而 synchronized 不行\r\n5. **公平锁**：公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁\r\n   * ReentrantLock 可以设置公平锁，synchronized 中的锁是非公平的\r\n   * 不公平锁的含义是阻塞队列内公平，队列外非公平\r\n6. 锁超时：尝试获取锁，超时获取不到直接放弃，不进入阻塞队列\r\n   * ReentrantLock 可以设置超时时间，synchronized 会一直等待\r\n7. 锁绑定多个条件：一个 ReentrantLock 可以同时绑定多个 Condition 对象，更细粒度的唤醒线程\r\n8. 两者都是可重入锁\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 使用锁\r\n\r\n构造方法：`ReentrantLock lock = new ReentrantLock()`\r\n\r\nReentrantLock 类 API：\r\n\r\n* `public void lock()`：获得锁\r\n  * 如果锁没有被另一个线程占用，则将锁定计数设置为 1\r\n\r\n  * 如果当前线程已经保持锁定，则保持计数增加 1 \r\n\r\n  * 如果锁被另一个线程保持，则当前线程被禁用线程调度，并且在锁已被释放之前处于休眠状态\r\n\r\n* `public void unlock()`：尝试释放锁\r\n  * 如果当前线程是该锁的持有者，则保持计数递减\r\n  * 如果保持计数现在为零，则锁定被释放\r\n  * 如果当前线程不是该锁的持有者，则抛出异常\r\n\r\n基本语法：\r\n\r\n```java\r\n// 获取锁\r\nreentrantLock.lock();\r\ntry {\r\n    // 临界区\r\n} finally {\r\n\t// 释放锁\r\n\treentrantLock.unlock();\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 公平锁\r\n\r\n##### 基本使用\r\n\r\n构造方法：`ReentrantLock lock = new ReentrantLock(true)`\r\n\r\n```java\r\npublic ReentrantLock(boolean fair) {\r\n    sync = fair ? new FairSync() : new NonfairSync();\r\n}\r\n```\r\n\r\nReentrantLock 默认是不公平的：\r\n\r\n```java\r\npublic ReentrantLock() {\r\n    sync = new NonfairSync();\r\n}\r\n```\r\n\r\n说明：公平锁一般没有必要，会降低并发度\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 非公原理\r\n\r\n###### 加锁\r\n\r\nNonfairSync 继承自 AQS\r\n\r\n```java\r\npublic void lock() {\r\n    sync.lock();\r\n}\r\n```\r\n\r\n\r\n\r\n* 没有竞争：ExclusiveOwnerThread 属于 Thread-0，state 设置为 1\r\n\r\n  ```java\r\n  // ReentrantLock.NonfairSync#lock\r\n  final void lock() {\r\n      // 用 cas 尝试（仅尝试一次）将 state 从 0 改为 1, 如果成功表示【获得了独占锁】\r\n      if (compareAndSetState(0, 1))\r\n          // 设置当前线程为独占线程\r\n          setExclusiveOwnerThread(Thread.currentThread());\r\n      else\r\n          acquire(1);//失败进入\r\n  }\r\n  ```\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719155415862.png\" alt=\"image-20230719155415862\" style=\"zoom: 67%;\" />\r\n\r\n* 第一个竞争出现：Thread-1 执行，CAS 尝试将 state 由 0 改为 1，结果失败（第一次），进入 acquire 逻辑\r\n\r\n  ```java\r\n  // AbstractQueuedSynchronizer#acquire\r\n  public final void acquire(int arg) {\r\n      // tryAcquire 尝试获取锁失败时, 会调用 addWaiter 将当前线程封装成node入队，acquireQueued 阻塞当前线程，\r\n      // acquireQueued 返回 true 表示挂起过程中线程被中断唤醒过，false 表示未被中断过\r\n      if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\r\n          // 如果线程被中断了逻辑来到这，完成一次真正的打断效果\r\n          selfInterrupt();\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719155428092.png\" alt=\"image-20230719155428092\" style=\"zoom: 67%;\" />\r\n\r\n* 进入 tryAcquire 尝试获取锁逻辑，这时 state 已经是1，结果仍然失败（第二次），加锁成功有两种情况：\r\n\r\n  * 当前 AQS 处于无锁状态\r\n  * 加锁线程就是当前线程，说明发生了锁重入\r\n\r\n  ```java\r\n  // ReentrantLock.NonfairSync#tryAcquire\r\n  protected final boolean tryAcquire(int acquires) {\r\n      return nonfairTryAcquire(acquires);\r\n  }\r\n  // 抢占成功返回 true，抢占失败返回 false\r\n  final boolean nonfairTryAcquire(int acquires) {\r\n      final Thread current = Thread.currentThread();\r\n      // state 值\r\n      int c = getState();\r\n      // 条件成立说明当前处于【无锁状态】\r\n      if (c == 0) {\r\n          //如果还没有获得锁，尝试用cas获得，这里体现非公平性: 不去检查 AQS 队列是否有阻塞线程直接获取锁        \r\n      \tif (compareAndSetState(0, acquires)) {\r\n              // 获取锁成功设置当前线程为独占锁线程。\r\n              setExclusiveOwnerThread(current);\r\n              return true;\r\n           }    \r\n  \t}    \r\n     \t// 如果已经有线程获得了锁, 独占锁线程还是当前线程, 表示【发生了锁重入】\r\n  \telse if (current == getExclusiveOwnerThread()) {\r\n          // 更新锁重入的值\r\n          int nextc = c + acquires;\r\n          // 越界判断，当重入的深度很深时，会导致 nextc < 0，int值达到最大之后再 + 1 变负数\r\n          if (nextc < 0) // overflow\r\n              throw new Error(\"Maximum lock count exceeded\");\r\n          // 更新 state 的值，这里不使用 cas 是因为当前线程正在持有锁，所以这里的操作相当于在一个管程内\r\n          setState(nextc);\r\n          return true;\r\n      }\r\n      // 获取失败\r\n      return false;\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n* 接下来进入 addWaiter 逻辑，构造 Node 队列（不是阻塞队列），前置条件是当前线程获取锁失败，说明有线程占用了锁\r\n\r\n  * 图中黄色三角表示该 Node 的 waitStatus 状态，其中 0 为默认**正常状态**\r\n  * Node 的创建是懒惰的，其中第一个 Node 称为 **Dummy（哑元）或哨兵**，用来占位，并不关联线程\r\n\r\n  ```java\r\n  // AbstractQueuedSynchronizer#addWaiter，返回当前线程的 node 节点\r\n  private Node addWaiter(Node mode) {\r\n      // 将当前线程关联到一个 Node 对象上, 模式为独占模式   \r\n      Node node = new Node(Thread.currentThread(), mode);\r\n      Node pred = tail;\r\n      // 快速入队，如果 tail 不为 null，说明存在队列\r\n      if (pred != null) {\r\n          // 将当前节点的前驱节点指向 尾节点\r\n          node.prev = pred;\r\n          // 通过 cas 将 Node 对象加入 AQS 队列，成为尾节点，【尾插法】\r\n          if (compareAndSetTail(pred, node)) {\r\n              pred.next = node;// 双向链表\r\n              return node;\r\n          }\r\n      }\r\n      // 初始时队列为空，或者 CAS 失败进入这里\r\n      enq(node);\r\n      return node;\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // AbstractQueuedSynchronizer#enq\r\n  private Node enq(final Node node) {\r\n      // 自旋入队，必须入队成功才结束循环\r\n      for (;;) {\r\n          Node t = tail;\r\n          // 说明当前锁被占用，且当前线程可能是【第一个获取锁失败】的线程，【还没有建立队列】\r\n          if (t == null) {\r\n              // 设置一个【哑元节点】，头尾指针都指向该节点\r\n              if (compareAndSetHead(new Node()))\r\n                  tail = head;\r\n          } else {\r\n              // 自旋到这，普通入队方式，首先赋值尾节点的前驱节点【尾插法】\r\n              node.prev = t;\r\n              // 【在设置完尾节点后，才更新的原始尾节点的后继节点，所以此时从前往后遍历会丢失尾节点】\r\n              if (compareAndSetTail(t, node)) {\r\n                  //【此时 t.next  = null，并且这里已经 CAS 结束，线程并不是安全的，这是从前向后遍历唤醒会丢失尾节点的原因！】\r\n                  t.next = node;\r\n                  return t;\t// 返回当前 node 的前驱节点\r\n              }\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719155452096.png\" alt=\"image-20230719155452096\" style=\"zoom:70%;\" />\r\n\r\n* 线程节点加入队列成功，进入 `AbstractQueuedSynchronizer#acquireQueued` 逻辑阻塞线程\r\n\r\n  1.  acquireQueued 会在一个自旋中不断尝试获得锁，失败后进入 park 阻塞\r\n  2. 如果当前线程是在 head 节点后，会再次 tryAcquire 尝试获取锁，state 仍为 1 则失败（第三次）\r\n\r\n  ```java\r\n  final boolean acquireQueued(final Node node, int arg) {\r\n      // true 表示当前线程抢占锁失败，false 表示成功\r\n      boolean failed = true;\r\n      try {\r\n          // 中断标记，表示当前线程是否被中断\r\n          boolean interrupted = false;\r\n          for (;;) {\r\n              // 获得当前线程节点的前驱节点\r\n              final Node p = node.predecessor();\r\n              // 前驱节点是 head, FIFO 队列的特性表示轮到当前线程可以去获取锁\r\n              if (p == head && tryAcquire(arg)) {\r\n                  // 获取成功, 设置当前线程自己的 node 为 head\r\n                  setHead(node);\r\n                  p.next = null; // help GC\r\n                  // 表示抢占锁成功\r\n                  failed = false;\r\n                  // 返回当前线程是否被中断\r\n                  return interrupted;\r\n              }\r\n              // 判断是否应当 park，返回 false 后需要新一轮的循环，返回 true 进入条件二阻塞线程\r\n              if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\r\n                  // 条件二返回结果是当前线程是否被打断，没有被打断返回 false 不进入这里的逻辑\r\n                  // 【就算被打断了，也会继续循环，并不会返回】\r\n                  interrupted = true;\r\n          }\r\n      } finally {\r\n          // 【可打断模式下才会进入该逻辑】\r\n          if (failed)\r\n              cancelAcquire(node);\r\n      }\r\n  }\r\n  ```\r\n\r\n  3.  进入 shouldParkAfterFailedAcquire 逻辑，**将前驱 node 的 waitStatus 改为 -1**，返回 false；waitStatus 为 -1 的节点用来唤醒下一个节点\r\n\r\n  ```java\r\n  private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\r\n      int ws = pred.waitStatus;\r\n      // 表示前置节点是个可以唤醒当前节点的节点，返回 true\r\n      if (ws == Node.SIGNAL)\r\n          return true;\r\n      // 前置节点的状态处于取消状态，需要【删除前面所有取消的节点】, 返回到外层循环重试\r\n      if (ws > 0) {\r\n          do {\r\n              node.prev = pred = pred.prev;\r\n          } while (pred.waitStatus > 0);\r\n          // 获取到非取消的节点，连接上当前节点\r\n          pred.next = node;\r\n      \r\n      } else {\r\n          // 默认情况下 node 的 waitStatus 是 0，进入这里的逻辑\r\n          // 【设置上一个节点状态为 Node.SIGNAL】，返回外层循环重试\r\n          compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\r\n      }\r\n      // 返回不应该 park，再次尝试一次\r\n      return false;\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719155516878.png\" alt=\"image-20230719155516878\" style=\"zoom:70%;\" />\r\n\r\n  4. shouldParkAfterFailedAcquire 执行完毕回到 acquireQueued ，再次 tryAcquire 尝试获取锁，这时 state 仍为 1 获取失败（第四次）\r\n  5. 当再次进入 shouldParkAfterFailedAcquire 时，这时其前驱 node 的 waitStatus 已经是 -1 了，返回 true\r\n  6. 进入 parkAndCheckInterrupt， Thread-1 park（灰色表示）\r\n\r\n  ```java\r\n  private final boolean parkAndCheckInterrupt() {\r\n      // 阻塞当前线程，如果打断标记已经是 true, 则 park 会失效\r\n      LockSupport.park(this);\r\n      // 判断当前线程是否被打断，清除打断标记\r\n      return Thread.interrupted();\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719155528402.png\" alt=\"image-20230719155528402\" style=\"zoom:70%;\" />\r\n\r\n* 再有多个线程经历竞争失败后：\r\n\r\n  ![image-20230719155542494](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719155542494.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n###### 解锁\r\n\r\n`ReentrantLock#unlock`：释放锁\r\n\r\n```java\r\npublic void unlock() {\r\n    sync.release(1);\r\n}\r\n```\r\n\r\nThread-0 释放锁，进入 release 流程\r\n\r\n* 进入 tryRelease，设置 exclusiveOwnerThread 为 null，`state = 0`\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719155652604.png\" alt=\"image-20230719155652604\" style=\"zoom:67%;\" />\r\n\r\n* 当前队列不为 null，并且 head 的 `waitStatus = -1`，进入 unparkSuccessor\r\n\r\n  ```java\r\n  // AbstractQueuedSynchronizer#release\r\n  public final boolean release(int arg) {\r\n      // 尝试释放锁，tryRelease 返回 true 表示当前线程已经【完全释放锁，重入的释放了】\r\n      if (tryRelease(arg)) {\r\n          // 队列头节点\r\n          Node h = head;\r\n          // 头节点什么时候是空？没有发生锁竞争，没有竞争线程创建哑元节点\r\n          // 条件成立说明阻塞队列有等待线程，需要唤醒 head 节点后面的线程\r\n          if (h != null && h.waitStatus != 0)\r\n              unparkSuccessor(h);\r\n          return true;\r\n      }    \r\n      return false;\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // ReentrantLock.Sync#tryRelease\r\n  protected final boolean tryRelease(int releases) {\r\n      // 减去释放的值，可能重入\r\n      int c = getState() - releases;\r\n      // 如果当前线程不是持有锁的线程直接报错\r\n      if (Thread.currentThread() != getExclusiveOwnerThread())\r\n          throw new IllegalMonitorStateException();\r\n      // 是否已经完全释放锁\r\n      boolean free = false;\r\n      // 支持锁重入, 只有 state 减为 0, 才完全释放锁成功\r\n      if (c == 0) {\r\n          free = true;\r\n          setExclusiveOwnerThread(null);\r\n      }\r\n      // 当前线程就是持有锁线程，所以可以直接更新锁，不需要使用 CAS\r\n      setState(c);\r\n      return free;\r\n  }\r\n  ```\r\n\r\n* 进入 `AbstractQueuedSynchronizer#unparkSuccessor` 方法，唤醒当前节点的后继节点\r\n\r\n  * 找到队列中距离 head 最近的一个没取消的 Node，unpark 恢复其运行，本例中即为 Thread-1\r\n  * 回到 Thread-1 的 acquireQueued 流程\r\n\r\n  ```java\r\n  private void unparkSuccessor(Node node) {\r\n      // 当前节点的状态\r\n      int ws = node.waitStatus;    \r\n      if (ws < 0)        \r\n          // 【尝试重置状态为 0】，因为当前节点要完成对后续节点的唤醒任务了，不需要 -1 了\r\n          compareAndSetWaitStatus(node, ws, 0);    \r\n      // 找到需要 unpark 的节点，当前节点的下一个    \r\n      Node s = node.next;    \r\n      // 已取消的节点不能唤醒，需要找到距离头节点最近的非取消的节点\r\n      if (s == null || s.waitStatus > 0) {\r\n          s = null;\r\n          // AQS 队列【从后至前】找需要 unpark 的节点，直到 t == 当前的 node 为止，找不到就不唤醒了\r\n          for (Node t = tail; t != null && t != node; t = t.prev)\r\n              // 说明当前线程状态需要被唤醒\r\n              if (t.waitStatus <= 0)\r\n                  // 置换引用\r\n                  s = t;\r\n      }\r\n      // 【找到合适的可以被唤醒的 node，则唤醒线程】\r\n      if (s != null)\r\n          LockSupport.unpark(s.thread);\r\n  }\r\n  ```\r\n\r\n  **从后向前的唤醒的原因**：enq 方法中，节点是尾插法，首先赋值的是尾节点的前驱节点，此时前驱节点的 next 并没有指向尾节点，从前遍历会丢失尾节点\r\n\r\n  ```java\r\n  for (Node h = head; h != null && h != node; h = h.next)\r\n  ```\r\n\r\n  ![image-20240612222223326](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20240612222223326.png)\r\n\r\n* 唤醒的线程会从 park 位置开始执行，如果加锁成功（没有竞争），会设置\r\n\r\n  * exclusiveOwnerThread 为 Thread-1，`state = 1`\r\n  * head 指向刚刚 Thread-1 所在的 Node，该 Node 会清空 Thread\r\n  * 原本的 head 因为从链表断开，从而可被垃圾回收（图中有错误，原来的头节点的 waitStatus 被改为 0 了）\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719155754206.png\" alt=\"image-20230719155754206\" style=\"zoom: 67%;\" />\r\n\r\n* 如果这时有其它线程来竞争（**非公平**），例如这时有 Thread-4 来了并抢占了锁\r\n\r\n  * Thread-4 被设置为 exclusiveOwnerThread，state = 1\r\n  * Thread-1 再次进入 acquireQueued 流程，获取锁失败，重新进入 park 阻塞\r\n\r\n  ![image-20230719155831915](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719155831915.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 公平原理\r\n\r\n与非公平锁主要区别在于 tryAcquire 方法：先检查 AQS 队列中是否有前驱节点，没有才去 CAS 竞争\r\n\r\n```java\r\nstatic final class FairSync extends Sync {\r\n    private static final long serialVersionUID = -3000897897090466540L;\r\n    final void lock() {\r\n        acquire(1);\r\n    }\r\n\r\n    protected final boolean tryAcquire(int acquires) {\r\n        final Thread current = Thread.currentThread();\r\n        int c = getState();\r\n        if (c == 0) {\r\n            // 先检查 AQS 队列中是否有前驱节点, 没有(false)才去竞争\r\n            if (!hasQueuedPredecessors() &&\r\n                compareAndSetState(0, acquires)) {\r\n                setExclusiveOwnerThread(current);\r\n                return true;\r\n            }\r\n        }\r\n        // 锁重入\r\n        return false;\r\n    }\r\n}\r\n```\r\n\r\n```java\r\npublic final boolean hasQueuedPredecessors() {    \r\n    Node t = tail;\r\n    Node h = head;\r\n    Node s;    \r\n    // 头尾指向一个节点，链表为空，返回false\r\n    return h != t &&\r\n        // 头尾之间有节点，判断头节点的下一个是不是空\r\n        // 不是空进入最后的判断，第二个节点的线程是否是本线程，不是返回 true，表示当前节点有前驱节点\r\n        ((s = h.next) == null || s.thread != Thread.currentThread());\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 可重入\r\n\r\n可重入是指同一个线程如果首次获得了这把锁，那么它是这把锁的拥有者，因此有权利再次获取这把锁，如果不可重入锁，那么第二次获得锁时，自己也会被锁挡住，直接造成死锁\r\n\r\n源码解析参考：`nonfairTryAcquire(int acquires)) ` 和 `tryRelease(int releases)`\r\n\r\n```java\r\nstatic ReentrantLock lock = new ReentrantLock();\r\npublic static void main(String[] args) {\r\n    method1();\r\n}\r\npublic static void method1() {\r\n    lock.lock();\r\n    try {\r\n        System.out.println(Thread.currentThread().getName() + \" execute method1\");\r\n        method2();\r\n    } finally {\r\n        lock.unlock();\r\n    }\r\n}\r\npublic static void method2() {\r\n    lock.lock();\r\n    try {\r\n        System.out.println(Thread.currentThread().getName() + \" execute method2\");\r\n    } finally {\r\n        lock.unlock();\r\n    }\r\n}\r\n```\r\n\r\n在 Lock 方法加两把锁会是什么情况呢？\r\n\r\n* 加锁两次解锁两次：正常执行\r\n* 加锁两次解锁一次：程序直接卡死，线程不能出来，也就说明**申请几把锁，最后需要解除几把锁**\r\n* 加锁一次解锁两次：运行程序会直接报错\r\n\r\n```java\r\npublic void getLock() {\r\n    lock.lock();\r\n    lock.lock();\r\n    try {\r\n        System.out.println(Thread.currentThread().getName() + \"\\t get Lock\");\r\n    } finally {\r\n        lock.unlock();\r\n        //lock.unlock();\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 可打断\r\n\r\n##### 基本使用\r\n\r\n`public void lockInterruptibly()`：获得可打断的锁\r\n\r\n* 如果没有竞争此方法就会获取 lock 对象锁\r\n* 如果有竞争就进入阻塞队列，可以被其他线程用 interrupt 打断\r\n\r\n注意：如果是不可中断模式，那么即使使用了 interrupt 也不会让等待状态中的线程中断\r\n\r\n```java\r\npublic static void main(String[] args) throws InterruptedException {    \r\n    ReentrantLock lock = new ReentrantLock();    \r\n    Thread t1 = new Thread(() -> {        \r\n        try {            \r\n            System.out.println(\"尝试获取锁\");            \r\n            lock.lockInterruptibly();        \r\n        } catch (InterruptedException e) {            \r\n            System.out.println(\"没有获取到锁，被打断，直接返回\");            \r\n            return;        \r\n        }        \r\n        try {            \r\n            System.out.println(\"获取到锁\");        \r\n        } finally {            \r\n            lock.unlock();        \r\n        }    \r\n    }, \"t1\");    \r\n    lock.lock();    \r\n    t1.start();    \r\n    Thread.sleep(2000);    \r\n    System.out.println(\"主线程进行打断锁\");    \r\n    t1.interrupt();\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 实现原理\r\n\r\n* 不可打断模式：即使它被打断，仍会驻留在 AQS 阻塞队列中，一直要**等到获得锁后才能得知自己被打断**了\r\n\r\n  ```java\r\n  public final void acquire(int arg) {    \r\n      if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg))//阻塞等待        \r\n          // 如果acquireQueued返回true，打断状态 interrupted = true        \r\n          selfInterrupt();\r\n  }\r\n  static void selfInterrupt() {\r\n      // 知道自己被打断了，需要重新产生一次中断完成中断效果\r\n      Thread.currentThread().interrupt();\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  final boolean acquireQueued(final Node node, int arg) {    \r\n      try {        \r\n          boolean interrupted = false;        \r\n          for (;;) {            \r\n              final Node p = node.predecessor();            \r\n              if (p == head && tryAcquire(arg)) {                \r\n                  setHead(node);                \r\n                  p.next = null; // help GC                \r\n                  failed = false;                \r\n                  // 还是需要获得锁后, 才能返回打断状态\r\n                  return interrupted;            \r\n              }            \r\n              if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()){\r\n                  // 条件二中判断当前线程是否被打断，被打断返回true，设置中断标记为 true，【获取锁后返回】\r\n                  interrupted = true;  \r\n              }                  \r\n          } \r\n      } finally {\r\n          if (failed)\r\n              cancelAcquire(node);\r\n      }\r\n  }\r\n   private final boolean parkAndCheckInterrupt() {    \r\n       // 阻塞当前线程，如果打断标记已经是 true, 则 park 会失效\r\n       LockSupport.park(this);    \r\n       // 判断当前线程是否被打断，清除打断标记，被打断返回true\r\n       return Thread.interrupted();\r\n   }\r\n  ```\r\n\r\n* 可打断模式：`AbstractQueuedSynchronizer#acquireInterruptibly`，**被打断后会直接抛出异常**\r\n\r\n  ```java\r\n  public void lockInterruptibly() throws InterruptedException {    \r\n      sync.acquireInterruptibly(1);\r\n  }\r\n  public final void acquireInterruptibly(int arg) {\r\n      // 被其他线程打断了直接返回 false\r\n      if (Thread.interrupted())\r\n  \t\tthrow new InterruptedException();\r\n      if (!tryAcquire(arg))\r\n          // 没获取到锁，进入这里\r\n          doAcquireInterruptibly(arg);\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  private void doAcquireInterruptibly(int arg) throws InterruptedException {\r\n      // 返回封装当前线程的节点\r\n      final Node node = addWaiter(Node.EXCLUSIVE);\r\n      boolean failed = true;\r\n      try {\r\n          for (;;) {\r\n              //...\r\n              if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\r\n                  // 【在 park 过程中如果被 interrupt 会抛出异常】, 而不会再次进入循环获取锁后才完成打断效果\r\n                  throw new InterruptedException();\r\n          }    \r\n      } finally {\r\n          // 抛出异常前会进入这里\r\n          if (failed)\r\n              // 取消当前线程的节点\r\n              cancelAcquire(node);\r\n      }\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 取消节点出队的逻辑\r\n  private void cancelAcquire(Node node) {\r\n      // 判空\r\n      if (node == null)\r\n          return;\r\n  \t// 把当前节点封装的 Thread 置为空\r\n      node.thread = null;\r\n  \t// 获取当前取消的 node 的前驱节点\r\n      Node pred = node.prev;\r\n      // 前驱节点也被取消了，循环找到前面最近的没被取消的节点\r\n      while (pred.waitStatus > 0)\r\n          node.prev = pred = pred.prev;\r\n      \r\n  \t// 获取前驱节点的后继节点，可能是当前 node，也可能是 waitStatus > 0 的节点\r\n      Node predNext = pred.next;\r\n      \r\n  \t// 把当前节点的状态设置为 【取消状态 1】\r\n      node.waitStatus = Node.CANCELLED;\r\n      \r\n  \t// 条件成立说明当前节点是尾节点，把当前节点的前驱节点设置为尾节点\r\n      if (node == tail && compareAndSetTail(node, pred)) {\r\n          // 把前驱节点的后继节点置空，这里直接把所有的取消节点出队\r\n          compareAndSetNext(pred, predNext, null);\r\n      } else {\r\n          // 说明当前节点不是 tail 节点\r\n          int ws;\r\n          // 条件一成立说明当前节点不是 head.next 节点\r\n          if (pred != head &&\r\n              // 判断前驱节点的状态是不是 -1，不成立说明前驱状态可能是 0 或者刚被其他线程取消排队了\r\n              ((ws = pred.waitStatus) == Node.SIGNAL ||\r\n               // 如果状态不是 -1，设置前驱节点的状态为 -1\r\n               (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&\r\n              // 前驱节点的线程不为null\r\n              pred.thread != null) {\r\n              \r\n              Node next = node.next;\r\n              // 当前节点的后继节点是正常节点\r\n              if (next != null && next.waitStatus <= 0)\r\n                  // 把 前驱节点的后继节点 设置为 当前节点的后继节点，【从队列中删除了当前节点】\r\n                  compareAndSetNext(pred, predNext, next);\r\n          } else {\r\n              // 当前节点是 head.next 节点，唤醒当前节点的后继节点\r\n              unparkSuccessor(node);\r\n          }\r\n          node.next = node; // help GC\r\n      }\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 锁超时\r\n\r\n##### 基本使用\r\n\r\n`public boolean tryLock()`：尝试获取锁，获取到返回 true，获取不到直接放弃，不进入阻塞队列\r\n\r\n`public boolean tryLock(long timeout, TimeUnit unit)`：在给定时间内获取锁，获取不到就退出\r\n\r\n注意：tryLock 期间也可以被打断\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    ReentrantLock lock = new ReentrantLock();\r\n    Thread t1 = new Thread(() -> {\r\n        try {\r\n            if (!lock.tryLock(2, TimeUnit.SECONDS)) {\r\n                System.out.println(\"获取不到锁\");\r\n                return;\r\n            }\r\n        } catch (InterruptedException e) {\r\n            System.out.println(\"被打断，获取不到锁\");\r\n            return;\r\n        }\r\n        try {\r\n            log.debug(\"获取到锁\");\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }, \"t1\");\r\n    lock.lock();\r\n    System.out.println(\"主线程获取到锁\");\r\n    t1.start();\r\n    \r\n    Thread.sleep(1000);\r\n    try {\r\n        System.out.println(\"主线程释放了锁\");\r\n    } finally {\r\n        lock.unlock();\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 实现原理\r\n\r\n* 成员变量：指定超时限制的阈值，小于该值的线程不会被挂起\r\n\r\n  ```java\r\n  static final long spinForTimeoutThreshold = 1000L;\r\n  ```\r\n\r\n  超时时间设置的小于该值，就会被禁止挂起，因为阻塞在唤醒的成本太高，不如选择自旋空转\r\n\r\n* tryLock()\r\n\r\n  ```java\r\n  public boolean tryLock() {   \r\n      // 只尝试一次\r\n      return sync.nonfairTryAcquire(1);\r\n  }\r\n  ```\r\n\r\n* tryLock(long timeout, TimeUnit unit)\r\n\r\n  ```java\r\n  public final boolean tryAcquireNanos(int arg, long nanosTimeout) {\r\n      if (Thread.interrupted())        \r\n          throw new InterruptedException();    \r\n      // tryAcquire 尝试一次\r\n      return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);\r\n  }\r\n  protected final boolean tryAcquire(int acquires) {    \r\n      return nonfairTryAcquire(acquires);\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  private boolean doAcquireNanos(int arg, long nanosTimeout) {    \r\n      if (nanosTimeout <= 0L)\r\n          return false;\r\n      // 获取最后期限的时间戳\r\n      final long deadline = System.nanoTime() + nanosTimeout;\r\n      //...\r\n      try {\r\n          for (;;) {\r\n              //...\r\n              // 计算还需等待的时间\r\n              nanosTimeout = deadline - System.nanoTime();\r\n              if (nanosTimeout <= 0L)\t//时间已到     \r\n                  return false;\r\n              if (shouldParkAfterFailedAcquire(p, node) &&\r\n                  // 如果 nanosTimeout 大于该值，才有阻塞的意义，否则直接自旋会好点\r\n                  nanosTimeout > spinForTimeoutThreshold)\r\n                  LockSupport.parkNanos(this, nanosTimeout);\r\n              // 【被打断会报异常】\r\n              if (Thread.interrupted())\r\n                  throw new InterruptedException();\r\n          }    \r\n      }\r\n  }\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 哲学家就餐\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    Chopstick c1 = new Chopstick(\"1\");//...\r\n    Chopstick c5 = new Chopstick(\"5\");\r\n    new Philosopher(\"苏格拉底\", c1, c2).start();\r\n    new Philosopher(\"柏拉图\", c2, c3).start();\r\n    new Philosopher(\"亚里士多德\", c3, c4).start();\r\n    new Philosopher(\"赫拉克利特\", c4, c5).start();    \r\n    new Philosopher(\"阿基米德\", c5, c1).start();\r\n}\r\nclass Philosopher extends Thread {\r\n    Chopstick left;\r\n    Chopstick right;\r\n    public void run() {\r\n        while (true) {\r\n            // 尝试获得左手筷子\r\n            if (left.tryLock()) {\r\n                try {\r\n                    // 尝试获得右手筷子\r\n                    if (right.tryLock()) {\r\n                        try {\r\n                            System.out.println(\"eating...\");\r\n                            Thread.sleep(1000);\r\n                        } finally {\r\n                            right.unlock();\r\n                        }\r\n                    }\r\n                } finally {\r\n                    left.unlock();\r\n                }\r\n            }\r\n        }\r\n    }\r\n}\r\nclass Chopstick extends ReentrantLock {\r\n    String name;\r\n    public Chopstick(String name) {\r\n        this.name = name;\r\n    }\r\n    @Override\r\n    public String toString() {\r\n        return \"筷子{\" + name + '}';\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 条件变量\r\n\r\n##### 基本使用\r\n\r\nsynchronized 的条件变量，是当条件不满足时进入 WaitSet 等待；ReentrantLock 的条件变量比 synchronized 强大之处在于支持多个条件变量\r\n\r\nReentrantLock 类获取 Condition 对象：`public Condition newCondition()`\r\n\r\nCondition 类 API：\r\n\r\n* `void await()`：当前线程从运行状态进入等待状态，释放锁\r\n* `void signal()`：唤醒一个在 Condition 上等待的线程，但是必须获得与该 Condition 相关的锁\r\n\r\n使用流程：\r\n\r\n* **await / signal 前需要获得锁**\r\n* await 执行后，会释放锁进入 ConditionObject 等待\r\n* await 的线程被唤醒去重新竞争 lock 锁\r\n\r\n* **线程在条件队列被打断会抛出中断异常**\r\n\r\n* 竞争 lock 锁成功后，从 await 后继续执行\r\n\r\n```java\r\npublic static void main(String[] args) throws InterruptedException {    \r\n    ReentrantLock lock = new ReentrantLock();\r\n    //创建一个新的条件变量\r\n    Condition condition1 = lock.newCondition();\r\n    Condition condition2 = lock.newCondition();\r\n    new Thread(() -> {\r\n        try {\r\n            lock.lock();\r\n            System.out.println(\"进入等待\");\r\n            //进入休息室等待\r\n            condition1.await();\r\n            System.out.println(\"被唤醒了\");\r\n        } catch (InterruptedException e) {\r\n            e.printStackTrace();\r\n        } finally {\r\n            lock.unlock();\r\n        }    \r\n    }).start();\r\n    Thread.sleep(1000);\r\n    //叫醒\r\n    new Thread(() -> {\r\n        try {            \r\n            lock.lock();\r\n            //唤醒\r\n            condition2.signal();\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }).start();\r\n}\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 实现原理\r\n\r\n###### await\r\n\r\n总体流程是将 await 线程包装成 node 节点放入 ConditionObject 的条件队列，如果被唤醒就将 node 转移到 AQS 的执行阻塞队列，等待获取锁，**每个 Condition 对象都包含一个等待队列**\r\n\r\n* 开始 Thread-0 持有锁，调用 await，线程进入 ConditionObject 等待，直到被唤醒或打断，调用 await 方法的线程都是持锁状态的，所以说逻辑里**不存在并发**\r\n\r\n  ```java\r\n  public final void await() throws InterruptedException {\r\n       // 判断当前线程是否是中断状态，是就直接给个中断异常\r\n      if (Thread.interrupted())\r\n          throw new InterruptedException();\r\n      // 将调用 await 的线程包装成 Node，添加到条件队列并返回\r\n      Node node = addConditionWaiter();\r\n      // 完全释放节点持有的锁，因为其他线程唤醒当前线程的前提是【持有锁】\r\n      int savedState = fullyRelease(node);\r\n      \r\n      // 设置打断模式为没有被打断，状态码为 0\r\n      int interruptMode = 0;\r\n      \r\n      // 如果该节点还没有转移至 AQS 阻塞队列, park 阻塞，等待进入阻塞队列\r\n      while (!isOnSyncQueue(node)) {\r\n          LockSupport.park(this);\r\n          // 如果被打断，退出等待队列，对应的 node 【也会被迁移到阻塞队列】尾部，状态设置为 0\r\n          if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\r\n              break;\r\n      }\r\n      // 逻辑到这说明当前线程退出等待队列，进入【阻塞队列】\r\n      \r\n      // 尝试枪锁，释放了多少锁就【重新获取多少锁】，获取锁成功判断打断模式\r\n      if (acquireQueued(node, savedState) && interruptMode != THROW_IE)\r\n          interruptMode = REINTERRUPT;\r\n      \r\n      // node 在条件队列时 如果被外部线程中断唤醒，会加入到阻塞队列，但是并未设 nextWaiter = null\r\n      if (node.nextWaiter != null)\r\n          // 清理条件队列内所有已取消的 Node\r\n          unlinkCancelledWaiters();\r\n      // 条件成立说明挂起期间发生过中断\r\n      if (interruptMode != 0)\r\n          // 应用打断模式\r\n          reportInterruptAfterWait(interruptMode);\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 打断模式 - 在退出等待时重新设置打断状态\r\n  private static final int REINTERRUPT = 1;\r\n  // 打断模式 - 在退出等待时抛出异常\r\n  private static final int THROW_IE = -1;\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719164232726.png\" alt=\"image-20230719164232726\" style=\"zoom:80%;\" />\r\n\r\n* **创建新的 Node 状态为 -2（Node.CONDITION）**，关联 Thread-0，加入等待队列尾部\r\n\r\n  ```java\r\n  private Node addConditionWaiter() {\r\n      // 获取当前条件队列的尾节点的引用，保存到局部变量 t 中\r\n      Node t = lastWaiter;\r\n      // 当前队列中不是空，并且节点的状态不是 CONDITION（-2），说明当前节点发生了中断\r\n      if (t != null && t.waitStatus != Node.CONDITION) {\r\n          // 清理条件队列内所有已取消的 Node\r\n          unlinkCancelledWaiters();\r\n          // 清理完成重新获取 尾节点 的引用\r\n          t = lastWaiter;\r\n      }\r\n      // 创建一个关联当前线程的新 node, 设置状态为 CONDITION(-2)，添加至队列尾部\r\n      Node node = new Node(Thread.currentThread(), Node.CONDITION);\r\n      if (t == null)\r\n          firstWaiter = node;\t\t// 空队列直接放在队首【不用CAS因为执行线程是持锁线程，并发安全】\r\n      else\r\n          t.nextWaiter = node;\t// 非空队列队尾追加\r\n      lastWaiter = node;\t\t\t// 更新队尾的引用\r\n      return node;\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 清理条件队列内所有已取消（不是CONDITION）的 node，【链表删除的逻辑】\r\n  private void unlinkCancelledWaiters() {\r\n      // 从头节点开始遍历【FIFO】\r\n      Node t = firstWaiter;\r\n      // 指向正常的 CONDITION 节点\r\n      Node trail = null;\r\n      // 等待队列不空\r\n      while (t != null) {\r\n          // 获取当前节点的后继节点\r\n          Node next = t.nextWaiter;\r\n          // 判断 t 节点是不是 CONDITION 节点，条件队列内不是 CONDITION 就不是正常的\r\n          if (t.waitStatus != Node.CONDITION) { \r\n              // 不是正常节点，需要 t 与下一个节点断开\r\n              t.nextWaiter = null;\r\n              // 条件成立说明遍历到的节点还未碰到过正常节点\r\n              if (trail == null)\r\n                  // 更新 firstWaiter 指针为下个节点\r\n                  firstWaiter = next;\r\n              else\r\n                  // 让上一个正常节点指向 当前取消节点的 下一个节点，【删除非正常的节点】\r\n                  trail.nextWaiter = next;\r\n              // t 是尾节点了，更新 lastWaiter 指向最后一个正常节点\r\n              if (next == null)\r\n                  lastWaiter = trail;\r\n          } else {\r\n              // trail 指向的是正常节点 \r\n              trail = t;\r\n          }\r\n          // 把 t.next 赋值给 t，循环遍历\r\n          t = next; \r\n      }\r\n  }\r\n  ```\r\n\r\n* 接下来 Thread-0 进入 AQS 的 fullyRelease 流程，释放同步器上的锁\r\n\r\n  ```java\r\n  // 线程可能重入，需要将 state 全部释放\r\n  final int fullyRelease(Node node) {\r\n      // 完全释放锁是否成功，false 代表成功\r\n      boolean failed = true;\r\n      try {\r\n          // 获取当前线程所持有的 state 值总数\r\n          int savedState = getState();\r\n          // release -> tryRelease 解锁重入锁\r\n          if (release(savedState)) {\r\n              // 释放成功\r\n              failed = false;\r\n              // 返回解锁的深度\r\n              return savedState;\r\n          } else {\r\n              // 解锁失败抛出异常\r\n              throw new IllegalMonitorStateException();\r\n          }\r\n      } finally {\r\n          // 没有释放成功，将当前 node 设置为取消状态\r\n          if (failed)\r\n              node.waitStatus = Node.CANCELLED;\r\n      }\r\n  }\r\n  ```\r\n\r\n* fullyRelease 中会 unpark AQS 队列中的下一个节点竞争锁，假设 Thread-1 竞争成功\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719164258904.png\" alt=\"image-20230719164258904\" style=\"zoom:80%;\" />\r\n\r\n* Thread-0 进入 isOnSyncQueue 逻辑判断节点**是否移动到阻塞队列**，没有就 park 阻塞 Thread-0\r\n\r\n  ```java\r\n  final boolean isOnSyncQueue(Node node) {\r\n      // node 的状态是 CONDITION，signal 方法是先修改状态再迁移，所以前驱节点为空证明还【没有完成迁移】\r\n      if (node.waitStatus == Node.CONDITION || node.prev == null)\r\n          return false;\r\n      // 说明当前节点已经成功入队到阻塞队列，且当前节点后面已经有其它 node，因为条件队列的 next 指针为 null\r\n      if (node.next != null)\r\n          return true;\r\n  \t// 说明【可能在阻塞队列，但是是尾节点】\r\n      // 从阻塞队列的尾节点开始向前【遍历查找 node】，如果查找到返回 true，查找不到返回 false\r\n      return findNodeFromTail(node);\r\n  }\r\n  ```\r\n\r\n* await 线程 park 后如果被 unpark 或者被打断，都会进入 checkInterruptWhileWaiting 判断线程是否被打断：**在条件队列被打断的线程需要抛出异常**\r\n\r\n  ```java\r\n  private int checkInterruptWhileWaiting(Node node) {\r\n      // Thread.interrupted() 返回当前线程中断标记位，并且重置当前标记位 为 false\r\n      // 如果被中断了，根据是否在条件队列被中断的，设置中断状态码\r\n      return Thread.interrupted() ?(transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 这个方法只有在线程是被打断唤醒时才会调用\r\n  final boolean transferAfterCancelledWait(Node node) {\r\n      // 条件成立说明当前node一定是在条件队列内，因为 signal 迁移节点到阻塞队列时，会将节点的状态修改为 0\r\n      if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) {\r\n          // 把【中断唤醒的 node 加入到阻塞队列中】\r\n          enq(node);\r\n          // 表示是在条件队列内被中断了，设置为 THROW_IE 为 -1\r\n          return true;\r\n      }\r\n  \r\n      //执行到这里的情况：\r\n      //1.当前node已经被外部线程调用 signal 方法将其迁移到 阻塞队列 内了\r\n      //2.当前node正在被外部线程调用 signal 方法将其迁移至 阻塞队列 进行中状态\r\n      \r\n      // 如果当前线程还没到阻塞队列，一直释放 CPU\r\n      while (!isOnSyncQueue(node))\r\n          Thread.yield();\r\n  \r\n      // 表示当前节点被中断唤醒时不在条件队列了，设置为 REINTERRUPT 为 1\r\n      return false;\r\n  }\r\n  ```\r\n\r\n* 最后开始处理中断状态：\r\n\r\n  ```java\r\n  private void reportInterruptAfterWait(int interruptMode) throws InterruptedException {\r\n      // 条件成立说明【在条件队列内发生过中断，此时 await 方法抛出中断异常】\r\n      if (interruptMode == THROW_IE)\r\n          throw new InterruptedException();\r\n  \r\n      // 条件成立说明【在条件队列外发生的中断，此时设置当前线程的中断标记位为 true】\r\n      else if (interruptMode == REINTERRUPT)\r\n          // 进行一次自己打断，产生中断的效果\r\n          selfInterrupt();\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n###### signal\r\n\r\n* 假设 Thread-1 要来唤醒 Thread-0，进入 ConditionObject 的 doSignal 流程，**取得等待队列中第一个 Node**，即 Thread-0 所在 Node，必须持有锁才能唤醒, 因此 doSignal 内线程安全\r\n\r\n  ```java\r\n  public final void signal() {\r\n      // 判断调用 signal 方法的线程是否是独占锁持有线程\r\n      if (!isHeldExclusively())\r\n          throw new IllegalMonitorStateException();\r\n      // 获取条件队列中第一个 Node\r\n      Node first = firstWaiter;\r\n      // 不为空就将第该节点【迁移到阻塞队列】\r\n      if (first != null)\r\n          doSignal(first);\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 唤醒 - 【将没取消的第一个节点转移至 AQS 队列尾部】\r\n  private void doSignal(Node first) {\r\n      do {\r\n          // 成立说明当前节点的下一个节点是 null，当前节点是尾节点了，队列中只有当前一个节点了\r\n          if ((firstWaiter = first.nextWaiter) == null)\r\n              lastWaiter = null;\r\n          first.nextWaiter = null;\r\n      // 将等待队列中的 Node 转移至 AQS 队列，不成功且还有节点则继续循环\r\n      } while (!transferForSignal(first) && (first = firstWaiter) != null);\r\n  }\r\n  \r\n  // signalAll() 会调用这个函数，唤醒所有的节点\r\n  private void doSignalAll(Node first) {\r\n      lastWaiter = firstWaiter = null;\r\n      do {\r\n          Node next = first.nextWaiter;\r\n          first.nextWaiter = null;\r\n          transferForSignal(first);\r\n          first = next;\r\n      // 唤醒所有的节点，都放到阻塞队列中\r\n      } while (first != null);\r\n  }\r\n  ```\r\n\r\n* 执行 transferForSignal，**先将节点的 waitStatus 改为 0，然后加入 AQS 阻塞队列尾部**，将 Thread-3 的 waitStatus 改为 -1\r\n\r\n  ```java\r\n  // 如果节点状态是取消, 返回 false 表示转移失败, 否则转移成功\r\n  final boolean transferForSignal(Node node) {\r\n      // CAS 修改当前节点的状态，修改为 0，因为当前节点马上要迁移到阻塞队列了\r\n      // 如果状态已经不是 CONDITION, 说明线程被取消（await 释放全部锁失败）或者被中断（可打断 cancelAcquire）\r\n      if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))\r\n          // 返回函数调用处继续寻找下一个节点\r\n          return false;\r\n      \r\n      // 【先改状态，再进行迁移】\r\n      // 将当前 node 入阻塞队列，p 是当前节点在阻塞队列的【前驱节点】\r\n      Node p = enq(node);\r\n      int ws = p.waitStatus;\r\n      \r\n      // 如果前驱节点被取消或者不能设置状态为 Node.SIGNAL，就 unpark 取消当前节点线程的阻塞状态, \r\n      // 让 thread-0 线程竞争锁，重新同步状态\r\n      if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))\r\n          LockSupport.unpark(node.thread);\r\n      return true;\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719164353059.png\" alt=\"image-20230719164353059\" style=\"zoom:80%;\" />\r\n\r\n* Thread-1 释放锁，进入 unlock 流程\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### ReadWrite\r\n\r\n#### 读写锁\r\n\r\n独占锁：指该锁一次只能被一个线程所持有，对 ReentrantLock 和 Synchronized 而言都是独占锁\r\n\r\n共享锁：指该锁可以被多个线程所持有\r\n\r\nReentrantReadWriteLock 其**读锁是共享锁，写锁是独占锁**\r\n\r\n作用：多个线程同时读一个资源类没有任何问题，为了满足并发量，读取共享资源应该同时进行，但是如果一个线程想去写共享资源，就不应该再有其它线程可以对该资源进行读或写\r\n\r\n使用规则：\r\n\r\n* 加锁解锁格式：\r\n\r\n  ```java\r\n  r.lock();\r\n  try {\r\n      // 临界区\r\n  } finally {\r\n  \tr.unlock();\r\n  }\r\n  ```\r\n\r\n* 读-读能共存、读-写不能共存、写-写不能共存\r\n\r\n* 读锁不支持条件变量\r\n\r\n* **重入时升级不支持**：持有读锁的情况下去获取写锁会导致获取写锁永久等待，需要先释放读，再去获得写\r\n\r\n* **重入时降级支持**：持有写锁的情况下去获取读锁，造成只有当前线程会持有读锁，因为写锁会互斥其他的锁\r\n\r\n  ```java\r\n  w.lock();\r\n  try {\r\n      r.lock();// 降级为读锁, 释放写锁, 这样能够让其它线程读取缓存\r\n      try {\r\n          // ...\r\n      } finally{\r\n      \tw.unlock();// 要在写锁释放之前获取读锁\r\n      }\r\n  } finally{\r\n  \tr.unlock();\r\n  }\r\n  ```\r\n\r\n构造方法：\r\n\r\n* `public ReentrantReadWriteLock()`：默认构造方法，非公平锁\r\n* `public ReentrantReadWriteLock(boolean fair)`：true 为公平锁\r\n\r\n常用API：\r\n\r\n* `public ReentrantReadWriteLock.ReadLock readLock()`：返回读锁\r\n* `public ReentrantReadWriteLock.WriteLock writeLock()`：返回写锁\r\n* `public void lock()`：加锁\r\n* `public void unlock()`：解锁\r\n* `public boolean tryLock()`：尝试获取锁\r\n\r\n读读并发：\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    ReentrantReadWriteLock rw = new ReentrantReadWriteLock();\r\n    ReentrantReadWriteLock.ReadLock r = rw.readLock();\r\n    ReentrantReadWriteLock.WriteLock w = rw.writeLock();\r\n\r\n    new Thread(() -> {\r\n        r.lock();\r\n        try {\r\n            Thread.sleep(2000);\r\n            System.out.println(\"Thread 1 running \" + new Date());\r\n        } finally {\r\n            r.unlock();\r\n        }\r\n    },\"t1\").start();\r\n    new Thread(() -> {\r\n        r.lock();\r\n        try {\r\n            Thread.sleep(2000);\r\n            System.out.println(\"Thread 2 running \" + new Date());\r\n        } finally {\r\n            r.unlock();\r\n        }\r\n    },\"t2\").start();\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 缓存应用\r\n\r\n缓存更新时，是先清缓存还是先更新数据库\r\n\r\n* 先清缓存：可能造成刚清理缓存还没有更新数据库，线程直接查询了数据库更新过期数据到缓存\r\n\r\n* 先更新据库：可能造成刚更新数据库，还没清空缓存就有线程从缓存拿到了旧数据\r\n\r\n* 补充情况：查询线程 A 查询数据时恰好缓存数据由于时间到期失效，或是第一次查询\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719180125357.png\" alt=\"image-20230719180125357\" style=\"zoom:70%;\" />\r\n\r\n可以使用读写锁进行操作\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 实现原理\r\n\r\n##### 成员属性\r\n\r\n读写锁用的是同一个 Sycn 同步器，因此等待队列、state 等也是同一个，原理与 ReentrantLock 加锁相比没有特殊之处，不同是**写锁状态占了 state 的低 16 位，而读锁使用的是 state 的高 16 位**\r\n\r\n* 读写锁：\r\n\r\n  ```java\r\n  private final ReentrantReadWriteLock.ReadLock readerLock;\t\t\r\n  private final ReentrantReadWriteLock.WriteLock writerLock;\r\n  ```\r\n\r\n* 构造方法：默认是非公平锁，可以指定参数创建公平锁\r\n\r\n  ```java\r\n  public ReentrantReadWriteLock(boolean fair) {\r\n      // true 为公平锁\r\n      sync = fair ? new FairSync() : new NonfairSync();\r\n      // 这两个 lock 共享同一个 sync 实例，都是由 ReentrantReadWriteLock 的 sync 提供同步实现\r\n      readerLock = new ReadLock(this);\r\n      writerLock = new WriteLock(this);\r\n  }\r\n  ```\r\n\r\nSync 类的属性：\r\n\r\n* 统计变量：\r\n\r\n  ```java\r\n  // 用来移位\r\n  static final int SHARED_SHIFT   = 16;\r\n  // 高16位的1\r\n  static final int SHARED_UNIT    = (1 << SHARED_SHIFT);\r\n  // 65535，16个1，代表写锁的最大重入次数\r\n  static final int MAX_COUNT      = (1 << SHARED_SHIFT) - 1;\r\n  // 低16位掩码：0b 1111 1111 1111 1111，用来获取写锁重入的次数\r\n  static final int EXCLUSIVE_MASK = (1 << SHARED_SHIFT) - 1;\r\n  ```\r\n\r\n* 获取读写锁的次数：\r\n\r\n  ```java\r\n  // 获取读写锁的读锁分配的总次数\r\n  static int sharedCount(int c)    { return c >>> SHARED_SHIFT; }\r\n  // 写锁（独占）锁的重入次数\r\n  static int exclusiveCount(int c) { return c & EXCLUSIVE_MASK; }\r\n  ```\r\n\r\n* 内部类：\r\n\r\n  ```java\r\n  // 记录读锁线程自己的持有读锁的数量（重入次数），因为 state 高16位记录的是全局范围内所有的读线程获取读锁的总量\r\n  static final class HoldCounter {\r\n      int count = 0;\r\n      // Use id, not reference, to avoid garbage retention\r\n      final long tid = getThreadId(Thread.currentThread());\r\n  }\r\n  // 线程安全的存放线程各自的 HoldCounter 对象\r\n  static final class ThreadLocalHoldCounter extends ThreadLocal<HoldCounter> {\r\n      public HoldCounter initialValue() {\r\n          return new HoldCounter();\r\n      }\r\n  }\r\n  ```\r\n\r\n* 内部类实例：\r\n\r\n  ```java\r\n  // 当前线程持有的可重入读锁的数量，计数为 0 时删除\r\n  private transient ThreadLocalHoldCounter readHolds;\r\n  // 记录最后一个获取【读锁】线程的 HoldCounter 对象\r\n  private transient HoldCounter cachedHoldCounter;\r\n  ```\r\n\r\n* 首次获取锁：\r\n\r\n  ```java\r\n  // 第一个获取读锁的线程\r\n  private transient Thread firstReader = null;\r\n  // 记录该线程持有的读锁次数（读锁重入次数）\r\n  private transient int firstReaderHoldCount;\r\n  ```\r\n\r\n* Sync 构造方法：\r\n\r\n  ```java\r\n  Sync() {\r\n      readHolds = new ThreadLocalHoldCounter();\r\n      // 确保其他线程的数据可见性，state 是 volatile 修饰的变量，重写该值会将线程本地缓存数据【同步至主存】\r\n      setState(getState()); \r\n  }\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 加锁原理\r\n\r\n* t1 线程：w.lock（**写锁**），成功上锁 state = 0_1\r\n\r\n  ```java\r\n  // lock()  -> sync.acquire(1);\r\n  public void lock() {\r\n      sync.acquire(1);\r\n  }\r\n  public final void acquire(int arg) {\r\n      // 尝试获得写锁，获得写锁失败，将当前线程关联到一个 Node 对象上, 模式为独占模式 \r\n      if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\r\n          selfInterrupt();\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  protected final boolean tryAcquire(int acquires) {\r\n      Thread current = Thread.currentThread();\r\n      int c = getState();\r\n      // 获得低 16 位, 代表写锁的 state 计数\r\n      int w = exclusiveCount(c);\r\n      // 说明有读锁或者写锁\r\n      if (c != 0) {\r\n          // c != 0 and w == 0 表示有读锁，【读锁不能升级】，直接返回 false\r\n          // w != 0 说明有写锁，写锁的拥有者不是自己，获取失败\r\n          if (w == 0 || current != getExclusiveOwnerThread())\r\n              return false;\r\n          \r\n          // 执行到这里只有一种情况：【写锁重入】，所以下面几行代码不存在并发\r\n          if (w + exclusiveCount(acquires) > MAX_COUNT)\r\n              throw new Error(\"Maximum lock count exceeded\");\r\n          // 写锁重入, 获得锁成功，没有并发，所以不使用 CAS\r\n          setState(c + acquires);\r\n          return true;\r\n      }\r\n      \r\n      // c == 0，说明没有任何锁，判断写锁是否该阻塞，是 false 就尝试获取锁，失败返回 false\r\n      if (writerShouldBlock() || !compareAndSetState(c, c + acquires))\r\n          return false;\r\n      // 获得锁成功，设置锁的持有线程为当前线程\r\n      setExclusiveOwnerThread(current);\r\n      return true;\r\n  }\r\n  // 非公平锁 writerShouldBlock 总是返回 false, 无需阻塞\r\n  final boolean writerShouldBlock() {\r\n      return false; \r\n  }\r\n  // 公平锁会检查 AQS 队列中是否有前驱节点, 没有(false)才去竞争\r\n  final boolean writerShouldBlock() {\r\n      return hasQueuedPredecessors();\r\n  }\r\n  ```\r\n\r\n* t2 r.lock（**读锁**），进入 tryAcquireShared 流程：\r\n\r\n  * 返回 -1 表示失败\r\n  * 如果返回 0 表示成功\r\n  * 返回正数表示还有多少后继节点支持共享模式，读写锁返回 1\r\n\r\n  ```java\r\n  public void lock() {\r\n      sync.acquireShared(1);\r\n  }\r\n  public final void acquireShared(int arg) {\r\n      // tryAcquireShared 返回负数, 表示获取读锁失败\r\n      if (tryAcquireShared(arg) < 0)\r\n          doAcquireShared(arg);\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 尝试以共享模式获取\r\n  protected final int tryAcquireShared(int unused) {\r\n      Thread current = Thread.currentThread();\r\n      int c = getState();\r\n      // exclusiveCount(c) 代表低 16 位, 写锁的 state，成立说明有线程持有写锁\r\n      // 写锁的持有者不是当前线程，则获取读锁失败，【写锁允许降级】\r\n      if (exclusiveCount(c) != 0 && getExclusiveOwnerThread() != current)\r\n          return -1;\r\n      \r\n      // 高 16 位，代表读锁的 state，共享锁分配出去的总次数\r\n      int r = sharedCount(c);\r\n      // 读锁是否应该阻塞\r\n      if (!readerShouldBlock() &&\tr < MAX_COUNT &&\r\n          compareAndSetState(c, c + SHARED_UNIT)) {\t// 尝试增加读锁计数\r\n          // 加锁成功\r\n          // 加锁之前读锁为 0，说明当前线程是第一个读锁线程\r\n          if (r == 0) {\r\n              firstReader = current;\r\n              firstReaderHoldCount = 1;\r\n          // 第一个读锁线程是自己就发生了读锁重入\r\n          } else if (firstReader == current) {\r\n              firstReaderHoldCount++;\r\n          } else {\r\n              // cachedHoldCounter 设置为当前线程的 holdCounter 对象，即最后一个获取读锁的线程\r\n              HoldCounter rh = cachedHoldCounter;\r\n              // 说明还没设置 rh\r\n              if (rh == null || rh.tid != getThreadId(current))\r\n                  // 获取当前线程的锁重入的对象，赋值给 cachedHoldCounter\r\n                  cachedHoldCounter = rh = readHolds.get();\r\n              // 还没重入\r\n              else if (rh.count == 0)\r\n                  readHolds.set(rh);\r\n              // 重入 + 1\r\n              rh.count++;\r\n          }\r\n          // 读锁加锁成功\r\n          return 1;\r\n      }\r\n      // 逻辑到这 应该阻塞，或者 cas 加锁失败\r\n      // 会不断尝试 for (;;) 获取读锁, 执行过程中无阻塞\r\n      return fullTryAcquireShared(current);\r\n  }\r\n  // 非公平锁 readerShouldBlock 偏向写锁一些，看 AQS 阻塞队列中第一个节点是否是写锁，是则阻塞，反之不阻塞\r\n  // 防止一直有读锁线程，导致写锁线程饥饿\r\n  // true 则该阻塞, false 则不阻塞\r\n  final boolean readerShouldBlock() {\r\n      return apparentlyFirstQueuedIsExclusive();\r\n  }\r\n  final boolean readerShouldBlock() {\r\n      return hasQueuedPredecessors();\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  final int fullTryAcquireShared(Thread current) {\r\n      // 当前读锁线程持有的读锁次数对象\r\n      HoldCounter rh = null;\r\n      for (;;) {\r\n          int c = getState();\r\n          // 说明有线程持有写锁\r\n          if (exclusiveCount(c) != 0) {\r\n              // 写锁不是自己则获取锁失败\r\n              if (getExclusiveOwnerThread() != current)\r\n                  return -1;\r\n          } else if (readerShouldBlock()) {\r\n              // 条件成立说明当前线程是 firstReader，当前锁是读忙碌状态，而且当前线程也是读锁重入\r\n              if (firstReader == current) {\r\n                  // assert firstReaderHoldCount > 0;\r\n              } else {\r\n                  if (rh == null) {\r\n                      // 最后一个读锁的 HoldCounter\r\n                      rh = cachedHoldCounter;\r\n                      // 说明当前线程也不是最后一个读锁\r\n                      if (rh == null || rh.tid != getThreadId(current)) {\r\n                          // 获取当前线程的 HoldCounter\r\n                          rh = readHolds.get();\r\n                          // 条件成立说明 HoldCounter 对象是上一步代码新建的\r\n                          // 当前线程不是锁重入，在 readerShouldBlock() 返回 true 时需要去排队\r\n                          if (rh.count == 0)\r\n                              // 防止内存泄漏\r\n                              readHolds.remove();\r\n                      }\r\n                  }\r\n                  if (rh.count == 0)\r\n                      return -1;\r\n              }\r\n          }\r\n          // 越界判断\r\n          if (sharedCount(c) == MAX_COUNT)\r\n              throw new Error(\"Maximum lock count exceeded\");\r\n          // 读锁加锁，条件内的逻辑与 tryAcquireShared 相同\r\n          if (compareAndSetState(c, c + SHARED_UNIT)) {\r\n              if (sharedCount(c) == 0) {\r\n                  firstReader = current;\r\n                  firstReaderHoldCount = 1;\r\n              } else if (firstReader == current) {\r\n                  firstReaderHoldCount++;\r\n              } else {\r\n                  if (rh == null)\r\n                      rh = cachedHoldCounter;\r\n                  if (rh == null || rh.tid != getThreadId(current))\r\n                      rh = readHolds.get();\r\n                  else if (rh.count == 0)\r\n                      readHolds.set(rh);\r\n                  rh.count++;\r\n                  cachedHoldCounter = rh; // cache for release\r\n              }\r\n              return 1;\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n* 获取读锁失败，进入 `sync.doAcquireShared(1)` 流程开始阻塞，首先也是调用 addWaiter 添加节点，不同之处在于节点被设置为 `Node.SHARED` 模式而非 `Node.EXCLUSIVE` 模式，注意此时 t2 仍处于活跃状态\r\n\r\n  ```java\r\n  private void doAcquireShared(int arg) {\r\n      // 将当前线程关联到一个 Node 对象上, 模式为共享模式\r\n      final Node node = addWaiter(Node.SHARED);\r\n      boolean failed = true;\r\n      try {\r\n          boolean interrupted = false;\r\n          for (;;) {\r\n              // 获取前驱节点\r\n              final Node p = node.predecessor();\r\n              // 如果前驱节点就头节点就去尝试获取锁\r\n              if (p == head) {\r\n                  // 再一次尝试获取读锁\r\n                  int r = tryAcquireShared(arg);\r\n                  // r >= 0 表示获取成功\r\n                  if (r >= 0) {\r\n                      //【这里会设置自己为头节点，唤醒相连的后序的共享节点】\r\n                      setHeadAndPropagate(node, r);\r\n                      p.next = null; // help GC\r\n                      if (interrupted)\r\n                          selfInterrupt();\r\n                      failed = false;\r\n                      return;\r\n                  }\r\n              }\r\n              // 是否在获取读锁失败时阻塞      \t\t\t\t\t park 当前线程\r\n              if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\r\n                  interrupted = true;\r\n          }\r\n      } finally {\r\n          if (failed)\r\n              cancelAcquire(node);\r\n      }\r\n  }\r\n  ```\r\n\r\n  如果没有成功，在 doAcquireShared 内 `for (;;)` 循环一次，shouldParkAfterFailedAcquire 内把前驱节点的 waitStatus 改为 -1，再 for (;;) 循环一次尝试 tryAcquireShared，不成功在 parkAndCheckInterrupt() 处 park\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719190714986.png\" alt=\"image-20230719190714986\" style=\"zoom: 50%;\" />\r\n\r\n* 这种状态下，假设又有 `t3 r.lock`，`t4 w.lock`，这期间 t1 仍然持有锁，就变成了下面的样子\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719192612370.png\" alt=\"image-20230719192612370\" style=\"zoom:80%;\" />\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 解锁原理\r\n\r\n* t1 `w.unlock`， 写锁解锁\r\n\r\n  ```java\r\n  public void unlock() {\r\n      // 释放锁\r\n      sync.release(1);\r\n  }\r\n  public final boolean release(int arg) {\r\n      // 尝试释放锁\r\n      if (tryRelease(arg)) {\r\n          Node h = head;\r\n          // 头节点不为空并且不是等待状态不是 0，唤醒后继的非取消节点\r\n          if (h != null && h.waitStatus != 0)\r\n              unparkSuccessor(h);\r\n          return true;\r\n      }\r\n      return false;\r\n  }\r\n  protected final boolean tryRelease(int releases) {\r\n      if (!isHeldExclusively())\r\n          throw new IllegalMonitorStateException();\r\n      int nextc = getState() - releases;\r\n      // 因为可重入的原因, 写锁计数为 0, 才算释放成功\r\n      boolean free = exclusiveCount(nextc) == 0;\r\n      if (free)\r\n          setExclusiveOwnerThread(null);\r\n      setState(nextc);\r\n      return free;\r\n  }\r\n  ```\r\n\r\n* 唤醒流程 `sync.unparkSuccessor`，这时 t2 在 doAcquireShared 的 parkAndCheckInterrupt() 处恢复运行，继续循环，执行 tryAcquireShared 成功则让读锁计数加一\r\n\r\n* 接下来 t2 调用 `setHeadAndPropagate(node, 1)`，它原本所在节点被置为头节点；还会检查下一个节点是否是 shared，如果是则调用 `doReleaseShared()` 将 head 的状态从 -1 改为 0 并唤醒下一个节点，这时 t3 在 doAcquireShared 内 `parkAndCheckInterrupt()` 处恢复运行，**唤醒连续的所有的共享节点**\r\n\r\n  ```java\r\n  private void setHeadAndPropagate(Node node, int propagate) {\r\n      Node h = head; \r\n      // 设置自己为 head 节点\r\n      setHead(node);\r\n      // propagate 表示有共享资源（例如共享读锁或信号量），为 0 就没有资源\r\n      if (propagate > 0 || h == null || h.waitStatus < 0 ||\r\n          (h = head) == null || h.waitStatus < 0) {\r\n          // 获取下一个节点\r\n          Node s = node.next;\r\n          // 如果当前是最后一个节点，或者下一个节点是【等待共享读锁的节点】\r\n          if (s == null || s.isShared())\r\n              // 唤醒后继节点\r\n              doReleaseShared();\r\n      }\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  private void doReleaseShared() {\r\n      // 如果 head.waitStatus == Node.SIGNAL ==> 0 成功, 下一个节点 unpark\r\n  \t// 如果 head.waitStatus == 0 ==> Node.PROPAGATE\r\n      for (;;) {\r\n          Node h = head;\r\n          if (h != null && h != tail) {\r\n              int ws = h.waitStatus;\r\n              // SIGNAL 唤醒后继\r\n              if (ws == Node.SIGNAL) {\r\n                  // 因为读锁共享，如果其它线程也在释放读锁，那么需要将 waitStatus 先改为 0\r\n              \t// 防止 unparkSuccessor 被多次执行\r\n                  if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\r\n                      continue;  \r\n                  // 唤醒后继节点\r\n                  unparkSuccessor(h);\r\n              }\r\n              // 如果已经是 0 了，改为 -3，用来解决传播性\r\n              else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\r\n                  continue;                \r\n          }\r\n          // 条件不成立说明被唤醒的节点非常积极，直接将自己设置为了新的 head，\r\n          // 此时唤醒它的节点（前驱）执行 h == head 不成立，所以不会跳出循环，会继续唤醒新的 head 节点的后继节点\r\n          if (h == head)                   \r\n              break;\r\n      }\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719192838777.png\" alt=\"image-20230719192838777\" style=\"zoom:70%;\" />\r\n\r\n* 下一个节点不是 shared 了，因此不会继续唤醒 t4 所在节点\r\n\r\n* t2 读锁解锁，进入 `sync.releaseShared(1)` 中，调用 `tryReleaseShared(1)` 让计数减一，但计数还不为零，t3 同样让计数减一，计数为零，进入`doReleaseShared()` 将头节点从 -1 改为 0 并唤醒下一个节点\r\n\r\n  ```java\r\n  public void unlock() {\r\n      sync.releaseShared(1);\r\n  }\r\n  public final boolean releaseShared(int arg) {\r\n      if (tryReleaseShared(arg)) {\r\n          doReleaseShared();\r\n          return true;\r\n      }\r\n      return false;\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  protected final boolean tryReleaseShared(int unused) {\r\n  \r\n      for (;;) {\r\n          int c = getState();\r\n          int nextc = c - SHARED_UNIT;\r\n          // 读锁的计数不会影响其它获取读锁线程, 但会影响其它获取写锁线程，计数为 0 才是真正释放\r\n          if (compareAndSetState(c, nextc))\r\n              // 返回是否已经完全释放了 \r\n              return nextc == 0;\r\n      }\r\n  }\r\n  ```\r\n\r\n* t4 在 acquireQueued 中 parkAndCheckInterrupt 处恢复运行，再次 `for (;;)` 这次自己是头节点的临节点，并且没有其他节点竞争，`tryAcquire(1)` 成功，修改头结点，流程结束\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719192920793.png\" alt=\"image-20230719192920793\" style=\"zoom:70%;\" />\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### Stamped\r\n\r\nStampedLock：读写锁，该类自 JDK 8 加入，是为了进一步优化读性能\r\n\r\n特点：\r\n\r\n* 在使用读锁、写锁时都必须配合戳使用\r\n\r\n* StampedLock 不支持条件变量\r\n* StampedLock **不支持重入**\r\n\r\n基本用法\r\n\r\n* 加解读锁：\r\n\r\n  ```java\r\n  long stamp = lock.readLock();\r\n  lock.unlockRead(stamp);\t\t\t// 类似于 unpark，解指定的锁\r\n  ```\r\n\r\n* 加解写锁：\r\n\r\n  ```java\r\n  long stamp = lock.writeLock();\r\n  lock.unlockWrite(stamp);\r\n  ```\r\n\r\n* 乐观读，StampedLock 支持 `tryOptimisticRead()` 方法，读取完毕后做一次**戳校验**，如果校验通过，表示这期间没有其他线程的写操作，数据可以安全使用，如果校验没通过，需要重新获取读锁，保证数据一致性\r\n\r\n  ```java\r\n  long stamp = lock.tryOptimisticRead();\r\n  // 验戳\r\n  if(!lock.validate(stamp)){\r\n  \t// 锁升级\r\n  }\r\n  ```\r\n\r\n提供一个数据容器类内部分别使用读锁保护数据的 read() 方法，写锁保护数据的 write() 方法：\r\n\r\n* 读-读可以优化\r\n* 读-写优化读，补加读锁\r\n\r\n```java\r\npublic static void main(String[] args) throws InterruptedException {\r\n    DataContainerStamped dataContainer = new DataContainerStamped(1);\r\n    new Thread(() -> {\r\n    \tdataContainer.read(1000);\r\n    },\"t1\").start();\r\n    Thread.sleep(500);\r\n    \r\n    new Thread(() -> {\r\n        dataContainer.write(1000);\r\n    },\"t2\").start();\r\n}\r\n\r\nclass DataContainerStamped {\r\n    private int data;\r\n    private final StampedLock lock = new StampedLock();\r\n\r\n    public int read(int readTime) throws InterruptedException {\r\n        long stamp = lock.tryOptimisticRead();\r\n        System.out.println(new Date() + \" optimistic read locking\" + stamp);\r\n        Thread.sleep(readTime);\r\n        // 戳有效，直接返回数据\r\n        if (lock.validate(stamp)) {\r\n            Sout(new Date() + \" optimistic read finish...\" + stamp);\r\n            return data;\r\n        }\r\n\r\n        // 说明其他线程更改了戳，需要锁升级了，从乐观读升级到读锁\r\n        System.out.println(new Date() + \" updating to read lock\" + stamp);\r\n        try {\r\n            stamp = lock.readLock();\r\n            System.out.println(new Date() + \" read lock\" + stamp);\r\n            Thread.sleep(readTime);\r\n            System.out.println(new Date() + \" read finish...\" + stamp);\r\n            return data;\r\n        } finally {\r\n            System.out.println(new Date() + \" read unlock \" +  stamp);\r\n            lock.unlockRead(stamp);\r\n        }\r\n    }\r\n\r\n    public void write(int newData) {\r\n        long stamp = lock.writeLock();\r\n        System.out.println(new Date() + \" write lock \" + stamp);\r\n        try {\r\n            Thread.sleep(2000);\r\n            this.data = newData;\r\n        } catch (InterruptedException e) {\r\n            e.printStackTrace();\r\n        } finally {\r\n            System.out.println(new Date() + \" write unlock \" + stamp);\r\n            lock.unlockWrite(stamp);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### CountDown\r\n\r\n#### 基本使用\r\n\r\nCountDownLatch：计数器，用来进行线程同步协作，**等待所有线程完成**\r\n\r\n构造器：\r\n\r\n* `public CountDownLatch(int count)`：初始化唤醒需要的 down 几步\r\n\r\n常用API：\r\n\r\n* `public void await() `：让当前线程等待，必须 down 完初始化的数字才可以被唤醒，否则进入无限等待\r\n* `public void countDown()`：计数器进行减 1（down 1）\r\n\r\n应用：同步等待多个 Rest 远程调用结束\r\n\r\n```java\r\n// LOL 10人进入游戏倒计时\r\npublic static void main(String[] args) throws InterruptedException {\r\n    CountDownLatch latch = new CountDownLatch(10);\r\n    ExecutorService service = Executors.newFixedThreadPool(10);\r\n    String[] all = new String[10];\r\n    Random random = new Random();\r\n\r\n    for (int j = 0; j < 10; j++) {\r\n        int finalJ = j;//常量\r\n        service.submit(() -> {\r\n            for (int i = 0; i <= 100; i++) {\r\n                Thread.sleep(random.nextInt(100));\t//随机休眠\r\n                all[finalJ] = i + \"%\";\r\n                System.out.print(\"\\r\" + Arrays.toString(all));\t// \\r代表覆盖\r\n            }\r\n            latch.countDown();\r\n        });\r\n    }\r\n    latch.await();\r\n    System.out.println(\"\\n游戏开始\");\r\n    service.shutdown();\r\n}\r\n/*\r\n[100%, 100%, 100%, 100%, 100%, 100%, 100%, 100%, 100%, 100%]\r\n游戏开始\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 实现原理\r\n\r\n阻塞等待：\r\n\r\n* 线程调用 await() 等待其他线程完成任务：支持打断\r\n\r\n  ```java\r\n  public void await() throws InterruptedException {\r\n      sync.acquireSharedInterruptibly(1);\r\n  }\r\n  // AbstractQueuedSynchronizer#acquireSharedInterruptibly\r\n  public final void acquireSharedInterruptibly(int arg) throws InterruptedException {\r\n      // 判断线程是否被打断，抛出打断异常\r\n      if (Thread.interrupted())\r\n          throw new InterruptedException();\r\n      // 尝试获取共享锁，条件成立说明 state > 0，此时线程入队阻塞等待，等待其他线程获取共享资源\r\n      // 条件不成立说明 state = 0，此时不需要阻塞线程，直接结束函数调用\r\n      if (tryAcquireShared(arg) < 0)\r\n          doAcquireSharedInterruptibly(arg);\r\n  }\r\n  // CountDownLatch.Sync#tryAcquireShared\r\n  protected int tryAcquireShared(int acquires) {\r\n      return (getState() == 0) ? 1 : -1;\r\n  }\r\n  ```\r\n\r\n* 线程进入 AbstractQueuedSynchronizer#doAcquireSharedInterruptibly 函数阻塞挂起，等待 latch 变为 0：\r\n\r\n  ```java\r\n  private void doAcquireSharedInterruptibly(int arg) throws InterruptedException {\r\n      // 将调用latch.await()方法的线程 包装成 SHARED 类型的 node 加入到 AQS 的阻塞队列中\r\n      final Node node = addWaiter(Node.SHARED);\r\n      boolean failed = true;\r\n      try {\r\n          for (;;) {\r\n              // 获取当前节点的前驱节点\r\n              final Node p = node.predecessor();\r\n              // 前驱节点时头节点就可以尝试获取锁\r\n              if (p == head) {\r\n                  // 再次尝试获取锁，获取成功返回 1\r\n                  int r = tryAcquireShared(arg);\r\n                  if (r >= 0) {\r\n                      // 获取锁成功，设置当前节点为 head 节点，并且向后传播\r\n                      setHeadAndPropagate(node, r);\r\n                      p.next = null; // help GC\r\n                      failed = false;\r\n                      return;\r\n                  }\r\n              }\r\n              // 阻塞在这里\r\n              if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\r\n                  throw new InterruptedException();\r\n          }\r\n      } finally {\r\n          // 阻塞线程被中断后抛出异常，进入取消节点的逻辑\r\n          if (failed)\r\n              cancelAcquire(node);\r\n      }\r\n  }\r\n  ```\r\n\r\n* 获取共享锁成功，进入唤醒阻塞队列中与头节点相连的 SHARED 模式的节点：\r\n\r\n  ```java\r\n  private void setHeadAndPropagate(Node node, int propagate) {\r\n      Node h = head;\r\n      // 将当前节点设置为新的 head 节点，前驱节点和持有线程置为 null\r\n      setHead(node);\r\n  \t// propagate = 1，条件一成立\r\n      if (propagate > 0 || h == null || h.waitStatus < 0 || (h = head) == null || h.waitStatus < 0) {\r\n          // 获取当前节点的后继节点\r\n          Node s = node.next;\r\n          // 当前节点是尾节点时 next 为 null，或者后继节点是 SHARED 共享模式\r\n          if (s == null || s.isShared())\r\n              // 唤醒所有的等待共享锁的节点\r\n              doReleaseShared();\r\n      }\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n计数减一：\r\n\r\n* 线程进入 countDown() 完成计数器减一（释放锁）的操作\r\n\r\n  ```java\r\n  public void countDown() {\r\n      sync.releaseShared(1);\r\n  }\r\n  public final boolean releaseShared(int arg) {\r\n      // 尝试释放共享锁\r\n      if (tryReleaseShared(arg)) {\r\n          // 释放锁成功开始唤醒阻塞节点\r\n          doReleaseShared();\r\n          return true;\r\n      }\r\n      return false;\r\n  }\r\n  ```\r\n\r\n* 更新 state 值，每调用一次，state 值减一，当 state -1 正好为 0 时，返回 true\r\n\r\n  ```java\r\n  protected boolean tryReleaseShared(int releases) {\r\n      for (;;) {\r\n          int c = getState();\r\n          // 条件成立说明前面【已经有线程触发唤醒操作】了，这里返回 false\r\n          if (c == 0)\r\n              return false;\r\n          // 计数器减一\r\n          int nextc = c-1;\r\n          if (compareAndSetState(c, nextc))\r\n              // 计数器为 0 时返回 true\r\n              return nextc == 0;\r\n      }\r\n  }\r\n  ```\r\n\r\n* state = 0 时，当前线程需要执行**唤醒阻塞节点的任务**\r\n\r\n  ```java\r\n  private void doReleaseShared() {\r\n      for (;;) {\r\n          Node h = head;\r\n          // 判断队列是否是空队列\r\n          if (h != null && h != tail) {\r\n              int ws = h.waitStatus;\r\n              // 头节点的状态为 signal，说明后继节点没有被唤醒过\r\n              if (ws == Node.SIGNAL) {\r\n                  // cas 设置头节点的状态为 0，设置失败继续自旋\r\n                  if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\r\n                      continue;\r\n                  // 唤醒后继节点\r\n                  unparkSuccessor(h);\r\n              }\r\n              // 如果有其他线程已经设置了头节点的状态，重新设置为 PROPAGATE 传播属性\r\n              else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\r\n                  continue;\r\n          }\r\n          // 条件不成立说明被唤醒的节点非常积极，直接将自己设置为了新的head，\r\n          // 此时唤醒它的节点（前驱）执行 h == head 不成立，所以不会跳出循环，会继续唤醒新的 head 节点的后继节点\r\n          if (h == head)\r\n              break;\r\n      }\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### CyclicBarrier\r\n\r\n#### 基本使用\r\n\r\nCyclicBarrier：循环屏障，用来进行线程协作，等待线程满足某个计数，才能触发自己执行\r\n\r\n常用方法：\r\n\r\n* `public CyclicBarrier(int parties, Runnable barrierAction)`：用于在线程到达屏障 parties 时，执行 barrierAction\r\n  * parties：代表多少个线程到达屏障开始触发线程任务\r\n  * barrierAction：线程任务\r\n* `public int await()`：线程调用 await 方法通知 CyclicBarrier 本线程已经到达屏障\r\n\r\n与 CountDownLatch 的区别：CyclicBarrier 是可以重用的\r\n\r\n应用：可以实现多线程中，某个任务在等待其他线程执行完毕以后触发\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    ExecutorService service = Executors.newFixedThreadPool(2);\r\n    CyclicBarrier barrier = new CyclicBarrier(2, () -> {\r\n        System.out.println(\"task1 task2 finish...\");\r\n    });\r\n\r\n    for (int i = 0; i < 3; i++) { // 循环重用\r\n        service.submit(() -> {\r\n            System.out.println(\"task1 begin...\");\r\n            try {\r\n                Thread.sleep(1000);\r\n                barrier.await();    // 2 - 1 = 1\r\n            } catch (InterruptedException | BrokenBarrierException e) {\r\n                e.printStackTrace();\r\n            }\r\n        });\r\n\r\n        service.submit(() -> {\r\n            System.out.println(\"task2 begin...\");\r\n            try {\r\n                Thread.sleep(2000);\r\n                barrier.await();    // 1 - 1 = 0\r\n            } catch (InterruptedException | BrokenBarrierException e) {\r\n                e.printStackTrace();\r\n            }\r\n        });\r\n    }\r\n    service.shutdown();\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 实现原理\r\n\r\n##### 成员属性\r\n\r\n* 全局锁：利用可重入锁实现的工具类\r\n\r\n  ```java\r\n  // barrier 实现是依赖于Condition条件队列，condition 条件队列必须依赖lock才能使用\r\n  private final ReentrantLock lock = new ReentrantLock();\r\n  // 线程挂起实现使用的 condition 队列，当前代所有线程到位，这个条件队列内的线程才会被唤醒\r\n  private final Condition trip = lock.newCondition();\r\n  ```\r\n\r\n* 线程数量：\r\n\r\n  ```java\r\n  private final int parties;\t// 代表多少个线程到达屏障开始触发线程任务\r\n  private int count;\t\t\t// 表示当前“代”还有多少个线程未到位，初始值为 parties\r\n  ```\r\n\r\n* 当前代中最后一个线程到位后要执行的事件：\r\n\r\n  ```java\r\n  private final Runnable barrierCommand;\r\n  ```\r\n\r\n* 代：\r\n\r\n  ```java\r\n  // 表示 barrier 对象当前 代\r\n  private Generation generation = new Generation();\r\n  private static class Generation {\r\n      // 表示当前“代”是否被打破，如果被打破再来到这一代的线程 就会直接抛出 BrokenException 异常\r\n      // 且在这一代挂起的线程都会被唤醒，然后抛出 BrokerException 异常。\r\n      boolean broken = false;\r\n  }\r\n  ```\r\n\r\n* 构造方法：\r\n\r\n  ```java\r\n  public CyclicBarrie(int parties, Runnable barrierAction) {\r\n      // 因为小于等于 0 的 barrier 没有任何意义\r\n      if (parties <= 0) throw new IllegalArgumentException();\r\n  \r\n      this.parties = parties;\r\n      this.count = parties;\r\n      // 可以为 null\r\n      this.barrierCommand = barrierAction;\r\n  }\r\n  ```\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824174620257.png\" alt=\"image-20230824174620257\" style=\"zoom:80%;\" />\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 成员方法\r\n\r\n* await()：阻塞等待所有线程到位\r\n\r\n  ```java\r\n  public int await() throws InterruptedException, BrokenBarrierException {\r\n      try {\r\n          return dowait(false, 0L);\r\n      } catch (TimeoutException toe) {\r\n          throw new Error(toe); // cannot happen\r\n      }\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // timed：表示当前调用await方法的线程是否指定了超时时长，如果 true 表示线程是响应超时的\r\n  // nanos：线程等待超时时长，单位是纳秒\r\n  private int dowait(boolean timed, long nanos) {\r\n      final ReentrantLock lock = this.lock;\r\n      // 加锁\r\n      lock.lock();\r\n      try {\r\n          // 获取当前代\r\n          final Generation g = generation;\r\n  \r\n          // 【如果当前代是已经被打破状态，则当前调用await方法的线程，直接抛出Broken异常】\r\n          if (g.broken)\r\n              throw new BrokenBarrierException();\r\n  \t\t// 如果当前线程被中断了，则打破当前代，然后当前线程抛出中断异常\r\n          if (Thread.interrupted()) {\r\n              // 设置当前代的状态为 broken 状态，唤醒在 trip 条件队列内的线程\r\n              breakBarrier();\r\n              throw new InterruptedException();\r\n          }\r\n  \r\n          // 逻辑到这说明，当前线程中断状态是 false， 当前代的 broken 为 false（未打破状态）\r\n          \r\n          // 假设 parties 给的是 5，那么index对应的值为 4,3,2,1,0\r\n          int index = --count;\r\n          // 条件成立说明当前线程是最后一个到达 barrier 的线程，【需要开启新代，唤醒阻塞线程】\r\n          if (index == 0) {\r\n              // 栅栏任务启动标记\r\n              boolean ranAction = false;\r\n              try {\r\n                  final Runnable command = barrierCommand;\r\n                  if (command != null)\r\n                      // 启动触发的任务\r\n                      command.run();\r\n                  // run()未抛出异常的话，启动标记设置为 true\r\n                  ranAction = true;\r\n                  // 开启新的一代，这里会【唤醒所有的阻塞队列】\r\n                  nextGeneration();\r\n                  // 返回 0 因为当前线程是此代最后一个到达的线程，index == 0\r\n                  return 0;\r\n              } finally {\r\n                  // 如果 command.run() 执行抛出异常的话，会进入到这里\r\n                  if (!ranAction)\r\n                      breakBarrier();\r\n              }\r\n          }\r\n  \r\n          // 自旋，一直到条件满足、当前代被打破、线程被中断，等待超时\r\n          for (;;) {\r\n              try {\r\n                  // 根据是否需要超时等待选择阻塞方法\r\n                  if (!timed)\r\n                      // 当前线程释放掉 lock，【进入到 trip 条件队列的尾部挂起自己】，等待被唤醒\r\n                      trip.await();\r\n                  else if (nanos > 0L)\r\n                      nanos = trip.awaitNanos(nanos);\r\n              } catch (InterruptedException ie) {\r\n                  // 被中断后来到这里的逻辑\r\n                  \r\n                  // 当前代没有变化并且没有被打破\r\n                  if (g == generation && !g.broken) {\r\n                      // 打破屏障\r\n                      breakBarrier();\r\n                      // node 节点在【条件队列】内收到中断信号时 会抛出中断异常\r\n                      throw ie;\r\n                  } else {\r\n                      // 等待过程中代变化了，完成一次自我打断\r\n                      Thread.currentThread().interrupt();\r\n                  }\r\n              }\r\n  \t\t\t// 唤醒后的线程，【判断当前代已经被打破，线程唤醒后依次抛出 BrokenBarrier 异常】\r\n              if (g.broken)\r\n                  throw new BrokenBarrierException();\r\n  \r\n              // 当前线程挂起期间，最后一个线程到位了，然后触发了开启新的一代的逻辑\r\n              if (g != generation)\r\n                  return index;\r\n  \t\t\t// 当前线程 trip 中等待超时，然后主动转移到阻塞队列\r\n              if (timed && nanos <= 0L) {\r\n                  breakBarrier();\r\n                  // 抛出超时异常\r\n                  throw new TimeoutException();\r\n              }\r\n          }\r\n      } finally {\r\n          // 解锁\r\n          lock.unlock();\r\n      }\r\n  }\r\n  ```\r\n\r\n* breakBarrier()：打破 Barrier 屏障\r\n\r\n  ```java\r\n  private void breakBarrier() {\r\n      // 将代中的 broken 设置为 true，表示这一代是被打破了，再来到这一代的线程，直接抛出异常\r\n      generation.broken = true;\r\n      // 重置 count 为 parties\r\n      count = parties;\r\n      // 将在trip条件队列内挂起的线程全部唤醒，唤醒后的线程会检查当前是否是打破的，然后抛出异常\r\n      trip.signalAll();\r\n  }\r\n  ```\r\n\r\n* nextGeneration()：开启新的下一代 \r\n\r\n  ```java\r\n  private void nextGeneration() {\r\n      // 将在 trip 条件队列内挂起的线程全部唤醒\r\n      trip.signalAll();\r\n      // 重置 count 为 parties\r\n      count = parties;\r\n  \r\n      // 开启新的一代，使用一个新的generation对象，表示新的一代，新的一代和上一代【没有任何关系】\r\n      generation = new Generation();\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n参考视频：https://space.bilibili.com/457326371/\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### Semaphore\r\n\r\n#### 基本使用\r\n\r\nsynchronized 可以起到锁的作用，但某个时间段内，只能有一个线程允许执行\r\n\r\nSemaphore（信号量）用来限制能同时访问共享资源的线程上限，非重入锁\r\n\r\n构造方法：\r\n\r\n* `public Semaphore(int permits)`：permits 表示许可线程的数量（state）\r\n* `public Semaphore(int permits, boolean fair)`：fair 表示公平性，如果设为 true，下次执行的线程会是等待最久的线程\r\n\r\n常用API：\r\n\r\n* `public void acquire()`：表示获取许可\r\n* `public void release()`：表示释放许可，acquire() 和 release() 方法之间的代码为同步代码\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    // 1.创建Semaphore对象\r\n    Semaphore semaphore = new Semaphore(3);\r\n\r\n    // 2. 10个线程同时运行\r\n    for (int i = 0; i < 10; i++) {\r\n        new Thread(() -> {\r\n            try {\r\n                // 3. 获取许可\r\n                semaphore.acquire();\r\n                sout(Thread.currentThread().getName() + \" running...\");\r\n                Thread.sleep(1000);\r\n                sout(Thread.currentThread().getName() + \" end...\");\r\n            } catch (InterruptedException e) {\r\n                e.printStackTrace();\r\n            } finally {\r\n                // 4. 释放许可\r\n                semaphore.release();\r\n            }\r\n        }).start();\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 实现原理\r\n\r\n加锁流程：\r\n\r\n* Semaphore 的 permits（state）为 3，这时 5 个线程来获取资源\r\n\r\n  ```java\r\n  Sync(int permits) {\r\n      setState(permits);\r\n  }\r\n  ```\r\n\r\n  假设其中 Thread-1，Thread-2，Thread-4 CAS 竞争成功，permits 变为 0，而 Thread-0 和 Thread-3 竞争失败，进入 AQS 队列park 阻塞\r\n\r\n  ```java\r\n  // acquire() -> sync.acquireSharedInterruptibly(1)，可中断\r\n  public final void acquireSharedInterruptibly(int arg) {\r\n      if (Thread.interrupted())\r\n          throw new InterruptedException();\r\n      // 尝试获取通行证，获取成功返回 >= 0的值\r\n      if (tryAcquireShared(arg) < 0)\r\n          // 获取许可证失败，进入阻塞\r\n          doAcquireSharedInterruptibly(arg);\r\n  }\r\n  \r\n  // tryAcquireShared() -> nonfairTryAcquireShared()\r\n  // 非公平，公平锁会在循环内 hasQueuedPredecessors()方法判断阻塞队列是否有临头节点(第二个节点)\r\n  final int nonfairTryAcquireShared(int acquires) {\r\n      for (;;) {\r\n          // 获取 state ，state 这里【表示通行证】\r\n          int available = getState();\r\n          // 计算当前线程获取通行证完成之后，通行证还剩余数量\r\n          int remaining = available - acquires;\r\n          // 如果许可已经用完, 返回负数, 表示获取失败,\r\n          if (remaining < 0 ||\r\n              // 许可证足够分配的，如果 cas 重试成功, 返回正数, 表示获取成功\r\n              compareAndSetState(available, remaining))\r\n              return remaining;\r\n      }\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  private void doAcquireSharedInterruptibly(int arg) {\r\n      // 将调用 Semaphore.aquire 方法的线程，包装成 node 加入到 AQS 的阻塞队列中\r\n      final Node node = addWaiter(Node.SHARED);\r\n      // 获取标记\r\n      boolean failed = true;\r\n      try {\r\n          for (;;) {\r\n              final Node p = node.predecessor();\r\n              // 前驱节点是头节点可以再次获取许可\r\n              if (p == head) {\r\n                  // 再次尝试获取许可，【返回剩余的许可证数量】\r\n                  int r = tryAcquireShared(arg);\r\n                  if (r >= 0) {\r\n                      // 成功后本线程出队（AQS）, 所在 Node设置为 head\r\n                      // r 表示【可用资源数】, 为 0 则不会继续传播\r\n                      setHeadAndPropagate(node, r); \r\n                      p.next = null; // help GC\r\n                      failed = false;\r\n                      return;\r\n                  }\r\n              }\r\n              // 不成功, 设置上一个节点 waitStatus = Node.SIGNAL, 下轮进入 park 阻塞\r\n              if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\r\n                  throw new InterruptedException();\r\n          }\r\n      } finally {\r\n          // 被打断后进入该逻辑\r\n          if (failed)\r\n              cancelAcquire(node);\r\n      }\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  private void setHeadAndPropagate(Node node, int propagate) {    \r\n      Node h = head;\r\n      // 设置自己为 head 节点\r\n      setHead(node);\r\n      // propagate 表示有【共享资源】（例如共享读锁或信号量）\r\n      // head waitStatus == Node.SIGNAL 或 Node.PROPAGATE，doReleaseShared 函数中设置的\r\n      if (propagate > 0 || h == null || h.waitStatus < 0 ||\r\n          (h = head) == null || h.waitStatus < 0) {\r\n          Node s = node.next;\r\n          // 如果是最后一个节点或者是等待共享读锁的节点，做一次唤醒\r\n          if (s == null || s.isShared())\r\n              doReleaseShared();\r\n      }\r\n  }\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719211343768.png\" alt=\"image-20230719211343768\" style=\"zoom:80%;\" />\r\n\r\n* 这时 Thread-4 释放了 permits，状态如下\r\n\r\n  ```java\r\n  // release() -> releaseShared()\r\n  public final boolean releaseShared(int arg) {\r\n      // 尝试释放锁\r\n      if (tryReleaseShared(arg)) {\r\n          doReleaseShared();\r\n          return true;\r\n      }    \r\n      return false;\r\n  }\r\n  protected final boolean tryReleaseShared(int releases) {    \r\n      for (;;) {\r\n          // 获取当前锁资源的可用许可证数量\r\n          int current = getState();\r\n          int next = current + releases;\r\n          // 索引越界判断\r\n          if (next < current)            \r\n              throw new Error(\"Maximum permit count exceeded\");        \r\n          // 释放锁\r\n          if (compareAndSetState(current, next))            \r\n              return true;    \r\n      }\r\n  }\r\n  private void doReleaseShared() {    \r\n      // PROPAGATE 详解    \r\n      // 如果 head.waitStatus == Node.SIGNAL ==> 0 成功, 下一个节点 unpark\t\r\n      // 如果 head.waitStatus == 0 ==> Node.PROPAGATE\r\n  }\r\n  ```\r\n\r\n  ![image-20230719211353401](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230719211353401.png)\r\n\r\n* 接下来 Thread-0 竞争成功，permits 再次设置为 0，设置自己为 head 节点，并且 unpark 接下来的共享状态的 Thread-3 节点，但由于 permits 是 0，因此 Thread-3 在尝试不成功后再次进入 park 状态\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### PROPAGATE\r\n\r\n假设存在某次循环中队列里排队的结点情况为 `head(-1) → t1(-1) → t2(0)`，存在将要释放信号量的 T3 和 T4，释放顺序为先 T3 后 T4\r\n\r\n```java\r\n// 老版本代码\r\nprivate void setHeadAndPropagate(Node node, int propagate) {    \r\n    setHead(node);    \r\n    // 有空闲资源    \r\n    if (propagate > 0 && node.waitStatus != 0) {    \t\r\n        Node s = node.next;        \r\n        // 下一个        \r\n        if (s == null || s.isShared())            \r\n            unparkSuccessor(node);        \r\n    }\r\n}\r\n```\r\n\r\n正常流程：\r\n\r\n* T3 调用 releaseShared(1)，直接调用了 unparkSuccessor(head)，head.waitStatus 从 -1 变为 0\r\n* T1 由于 T3 释放信号量被唤醒，然后 T4 释放，唤醒 T2\r\n\r\nBUG 流程：\r\n\r\n* T3 调用 releaseShared(1)，直接调用了 unparkSuccessor(head)，head.waitStatus 从 -1 变为 0\r\n* T1 由于 T3 释放信号量被唤醒，调用 tryAcquireShared，返回值为 0（获取锁成功，但没有剩余资源量）\r\n* T1 还没调用 setHeadAndPropagate 方法，T4 调用 releaseShared(1)，此时 head.waitStatus 为 0（此时读到的 head 和 1 中为同一个 head），不满足条件，因此不调用 unparkSuccessor(head)\r\n* T1 获取信号量成功，调用 setHeadAndPropagate(t1.node, 0) 时，因为不满足 propagate > 0（剩余资源量 == 0），从而不会唤醒后继结点， **T2 线程得不到唤醒**\r\n\r\n\r\n\r\n更新后流程：\r\n\r\n* T3 调用 releaseShared(1)，直接调用了 unparkSuccessor(head)，head.waitStatus 从 -1 变为 0\r\n* T1 由于 T3 释放信号量被唤醒，调用 tryAcquireShared，返回值为 0（获取锁成功，但没有剩余资源量）\r\n\r\n* T1 还没调用 setHeadAndPropagate 方法，T4 调用 releaseShared()，此时 head.waitStatus 为 0（此时读到的 head 和 1 中为同一个 head），调用 doReleaseShared() 将等待状态置为 **PROPAGATE（-3）**\r\n* T1 获取信号量成功，调用 setHeadAndPropagate 时，读到 h.waitStatus < 0，从而调用 doReleaseShared() 唤醒 T2\r\n\r\n```java\r\nprivate void setHeadAndPropagate(Node node, int propagate) {    \r\n    Node h = head;\r\n    // 设置自己为 head 节点\r\n    setHead(node);\r\n    // propagate 表示有共享资源（例如共享读锁或信号量）\r\n    // head waitStatus == Node.SIGNAL 或 Node.PROPAGATE\r\n    if (propagate > 0 || h == null || h.waitStatus < 0 ||\r\n        (h = head) == null || h.waitStatus < 0) {\r\n        Node s = node.next;\r\n        // 如果是最后一个节点或者是等待共享读锁的节点，做一次唤醒\r\n        if (s == null || s.isShared())\r\n            doReleaseShared();\r\n    }\r\n}\r\n```\r\n\r\n```java\r\n// 唤醒\r\nprivate void doReleaseShared() {\r\n    // 如果 head.waitStatus == Node.SIGNAL ==> 0 成功, 下一个节点 unpark\t\r\n    // 如果 head.waitStatus == 0 ==> Node.PROPAGATE    \r\n    for (;;) {\r\n        Node h = head;\r\n        if (h != null && h != tail) {\r\n            int ws = h.waitStatus;\r\n            if (ws == Node.SIGNAL) {\r\n                // 防止 unparkSuccessor 被多次执行\r\n                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\r\n                    continue;\r\n                // 唤醒后继节点\r\n                unparkSuccessor(h);\r\n            }\r\n            // 如果已经是 0 了，改为 -3，用来解决传播性\r\n            else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\r\n                continue;\r\n        }\r\n        if (h == head)\r\n            break;\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Exchanger\r\n\r\nExchanger：交换器，是一个用于线程间协作的工具类，用于进行线程间的数据交换\r\n\r\n工作流程：两个线程通过 exchange 方法交换数据，如果第一个线程先执行 exchange() 方法，它会一直等待第二个线程也执行 exchange 方法，当两个线程都到达同步点时，这两个线程就可以交换数据\r\n\r\n常用方法：\r\n\r\n* `public Exchanger()`：创建一个新的交换器\r\n* `public V exchange(V x)`：等待另一个线程到达此交换点\r\n* `public V exchange(V x, long timeout, TimeUnit unit)`：等待一定的时间\r\n\r\n```java\r\npublic class ExchangerDemo {\r\n    public static void main(String[] args) {\r\n        // 创建交换对象（信使）\r\n        Exchanger<String> exchanger = new Exchanger<>();\r\n        new ThreadA(exchanger).start();\r\n        new ThreadB(exchanger).start();\r\n    } \r\n}\r\nclass ThreadA extends Thread{\r\n    private Exchanger<String> exchanger();\r\n    \r\n    public ThreadA(Exchanger<String> exchanger){\r\n        this.exchanger = exchanger;\r\n    }\r\n    \r\n    @Override\r\n    public void run() {\r\n        try{\r\n            sout(\"线程A，做好了礼物A，等待线程B送来的礼物B\");\r\n            //如果等待了5s还没有交换就死亡（抛出异常）！\r\n            String s = exchanger.exchange(\"礼物A\",5,TimeUnit.SECONDS);\r\n            sout(\"线程A收到线程B的礼物：\" + s);\r\n        } catch (Exception e) {\r\n            System.out.println(\"线程A等待了5s，没有收到礼物,最终就执行结束了!\");\r\n        }\r\n    }\r\n}\r\nclass ThreadB extends Thread{\r\n    private Exchanger<String> exchanger;\r\n    \r\n    public ThreadB(Exchanger<String> exchanger) {\r\n        this.exchanger = exchanger;\r\n    }\r\n    \r\n    @Override\r\n    public void run() {\r\n        try {\r\n            sout(\"线程B,做好了礼物B,等待线程A送来的礼物A.....\");\r\n            // 开始交换礼物。参数是送给其他线程的礼物!\r\n            sout(\"线程B收到线程A的礼物：\" + exchanger.exchange(\"礼物B\"));\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n"},{"title":"并发编程整理版-线程池","tags":["线程池","BlockingQueue","ThreadPoolExecutor","Executors","ScheduledThreadPoolExecutor","ForkJoin","享元模式"],"categories":["Java","并发编程"],"author":"imklaus","excerpt":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Concurrent_Programming-threadPool","content":"\r\n参考视频：[满神JUC并发编程全套教程](https://www.bilibili.com/video/BV16J411h7Rd)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n\r\n\r\n## 线程池\r\n\r\n### 基本概述\r\n\r\n线程池：一个容纳多个线程的容器，容器中的线程可以重复使用，省去了频繁创建和销毁线程对象的操作\r\n\r\n线程池作用：\r\n\r\n1. 降低资源消耗，减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务\r\n2. 提高响应速度，当任务到达时，如果有线程可以直接用，不会出现系统僵死\r\n3. 提高线程的可管理性，如果无限制的创建线程，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控\r\n\r\n线程池的核心思想：**线程复用**，同一个线程可以被重复使用，来处理多个任务\r\n\r\n池化技术 (Pool) ：一种编程技巧，核心思想是资源复用，在请求量大时能优化应用性能，降低系统频繁建连的资源开销\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 阻塞队列\r\n\r\n#### 基本介绍\r\n\r\n有界队列和无界队列：\r\n\r\n- 有界队列：有固定大小的队列，比如设定了固定大小的 LinkedBlockingQueue，又或者大小为 0\r\n\r\n- 无界队列：没有设置固定大小的队列，这些队列可以直接入队，直到溢出（超过 Integer.MAX_VALUE），所以相当于无界\r\n\r\njava.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现：**FIFO 队列** \r\n\r\n- ArrayBlockingQueue：由数组结构组成的有界阻塞队列\r\n- LinkedBlockingQueue：由链表结构组成的无界（默认大小 Integer.MAX_VALUE）的阻塞队列\r\n- PriorityBlockingQueue：支持优先级排序的无界阻塞队列\r\n- DelayedWorkQueue：使用优先级队列实现的延迟无界阻塞队列\r\n- SynchronousQueue：不存储元素的阻塞队列，每一个生产线程会阻塞到有一个 put 的线程放入元素为止\r\n- LinkedTransferQueue：由链表结构组成的无界阻塞队列\r\n- LinkedBlockingDeque：由链表结构组成的**双向**阻塞队列\r\n\r\n与普通队列（LinkedList、ArrayDeque、PriorityQueue等）的不同点在于阻塞队列中阻塞添加和阻塞删除方法，以及线程安全：\r\n\r\n- 阻塞添加 put()：当阻塞队列元素已满时，添加队列元素的线程会被阻塞，直到队列元素不满时才重新唤醒线程执行\r\n- 阻塞删除 take()：在队列元素为空时，删除队列元素的线程将被阻塞，直到队列不为空再执行删除操作（一般会返回被删除的元素)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 核心方法\r\n\r\n| 方法类型         | 抛出异常  | 特殊值   | 阻塞   | 超时                 |\r\n| ---------------- | --------- | -------- | ------ | -------------------- |\r\n| 插入（尾）       | add(e)    | offer(e) | put(e) | `offer(e,time,unit)` |\r\n| 移除（头）       | remove()  | poll()   | take() | `poll(time,unit)`    |\r\n| 检查（队首元素） | element() | peek()   | 不可用 | 不可用               |\r\n\r\n- 抛出异常组：\r\n  - 当阻塞队列满时：在往队列中 add 插入元素会抛出 IIIegalStateException: Queue full\r\n  - 当阻塞队列空时：再往队列中 remove 移除元素，会抛出 NoSuchException\r\n- 特殊值组：\r\n  - 插入方法：成功 true，失败 false\r\n  - 移除方法：成功返回出队列元素，队列没有就返回 null\r\n- 阻塞组：\r\n  - 当阻塞队列满时，生产者继续往队列里 put 元素，队列会一直阻塞生产线程直到队列有空间 put 数据或响应中断退出\r\n  - 当阻塞队列空时，消费者线程试图从队列里 take 元素，队列会一直阻塞消费者线程直到队列中有可用元素\r\n- 超时退出：\r\n  - 当阻塞队列满时，队列会阻塞生产者线程一定时间，超过限时后生产者线程会退出\r\n  - 当阻塞队列空时，队列会阻塞消费者线程一定时间，超过限时后消费者线程会退出\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 链表队列\r\n\r\n##### 入队出队\r\n\r\nLinkedBlockingQueue 源码：\r\n\r\n```java\r\npublic class LinkedBlockingQueue<E> extends AbstractQueue<E>\r\n\t\t\timplements BlockingQueue<E>, java.io.Serializable {\r\n\tstatic class Node<E> {\r\n        E item;\r\n        /**\r\n        * 下列三种情况之一\r\n        * - 真正的后继节点\r\n        * - 自己, 发生在出队时\r\n        * - null, 表示是没有后继节点, 是尾节点了\r\n        */\r\n        Node<E> next;\r\n\r\n        Node(E x) { item = x; }\r\n    }\r\n}\r\n```\r\n\r\n入队：**尾插法**\r\n\r\n- 初始化链表 `last = head = new Node<E>(null)`，**Dummy 节点用来占位**，item 为 null\r\n\r\n  ```java\r\n  public LinkedBlockingQueue(int capacity) {\r\n      // 默认是 Integer.MAX_VALUE\r\n      if (capacity <= 0) throw new IllegalArgumentException();\r\n      this.capacity = capacity;\r\n      last = head = new Node<E>(null);\r\n  }\r\n  ```\r\n\r\n- 当一个节点入队：\r\n\r\n  ```java\r\n  private void enqueue(Node<E> node) {\r\n      // 从右向左计算\r\n      last = last.next = node;\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230720202045345.png\" alt=\"image-20230720202045345\" style=\"zoom:80%;\" />\r\n\r\n- 再来一个节点入队 `last = last.next = node`\r\n\r\n出队：**出队头节点**，FIFO\r\n\r\n- 出队源码：\r\n\r\n  ```java\r\n  private E dequeue() {\r\n      Node<E> h = head;\r\n      // 获取临头节点\r\n      Node<E> first = h.next;\r\n      // 自己指向自己，help GC\r\n      h.next = h;\r\n      head = first;\r\n      // 出队的元素\r\n      E x = first.item;\r\n      // 【当前节点置为 Dummy 节点】\r\n      first.item = null;\r\n      return x;\r\n  }\r\n  ```\r\n\r\n- `h = head` → `first = h.next` \r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230720202208218.png\" alt=\"image-20230720202208218\" style=\"zoom:80%;\" />\r\n\r\n- `h.next = h` → `head = first`\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230720202231300.png\" alt=\"image-20230720202231300\" style=\"zoom:80%;\" />\r\n\r\n  - `first.item = null`：当前节点置为 Dummy 节点\r\n\r\n  \r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 加锁分析\r\n\r\n用了两把锁和 dummy 节点：\r\n\r\n- 用一把锁，同一时刻，最多只允许有一个线程（生产者或消费者，二选一）执行\r\n- 用两把锁，同一时刻，可以允许两个线程同时（一个生产者与一个消费者）执行\r\n  - 消费者与消费者线程仍然串行\r\n  - 生产者与生产者线程仍然串行\r\n\r\n线程安全分析：\r\n\r\n- 当节点总数大于 2 时（包括 dummy 节点），**putLock 保证的是 last 节点的线程安全，takeLock 保证的是 head 节点的线程安全**，两把锁保证了入队和出队没有竞争\r\n\r\n- 当节点总数等于 2 时（即一个 dummy 节点，一个正常节点）这时候，仍然是两把锁锁两个对象，不会竞争\r\n\r\n- 当节点总数等于 1 时（就一个 dummy 节点）这时 take 线程会被 notEmpty 条件阻塞，有竞争，会阻塞\r\n\r\n  ```java\r\n  // 用于 put(阻塞) offer(非阻塞)\r\n  private final ReentrantLock putLock = new ReentrantLock();\r\n  private final Condition notFull = putLock.newCondition();\t// 阻塞等待不满，说明已经满了\r\n  \r\n  // 用于 take(阻塞) poll(非阻塞)\r\n  private final ReentrantLock takeLock = new ReentrantLock();\r\n  private final Condition notEmpty = takeLock.newCondition();\t// 阻塞等待不空，说明已经是空的\r\n  ```\r\n\r\n入队出队：\r\n\r\n- put 操作：\r\n\r\n  ```java\r\n  public void put(E e) throws InterruptedException {\r\n      // 空指针异常\r\n      if (e == null) throw new NullPointerException();\r\n      int c = -1;\r\n      // 把待添加的元素封装为 node 节点\r\n      Node<E> node = new Node<E>(e);\r\n      // 获取全局生产锁\r\n      final ReentrantLock putLock = this.putLock;\r\n      // count 用来维护元素计数\r\n      final AtomicInteger count = this.count;\r\n      // 获取可打断锁，会抛出异常\r\n      putLock.lockInterruptibly();\r\n      try {\r\n      \t// 队列满了等待\r\n          while (count.get() == capacity) {\r\n              // 【等待队列不满时，就可以生产数据】，线程处于 Waiting\r\n              notFull.await();\r\n          }\r\n          // 有空位, 入队且计数加一，尾插法\r\n          enqueue(node);\r\n          // 返回自增前的数字\r\n          c = count.getAndIncrement();\r\n          // put 完队列还有空位, 唤醒其他生产 put 线程，唤醒一个减少竞争\r\n          if (c + 1 < capacity)\r\n              notFull.signal();\r\n      } finally {\r\n          // 解锁\r\n          putLock.unlock();\r\n      }\r\n      // c自增前是0，说明生产了一个元素，唤醒一个 take 线程\r\n      if (c == 0)\r\n          signalNotEmpty();\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  private void signalNotEmpty() {\r\n      final ReentrantLock takeLock = this.takeLock;\r\n      takeLock.lock();\r\n      try {\r\n          // 调用 notEmpty.signal()，而不是 notEmpty.signalAll() 是为了减少竞争，因为只剩下一个元素\r\n          notEmpty.signal();\r\n      } finally {\r\n          takeLock.unlock();\r\n      }\r\n  }\r\n  ```\r\n\r\n- take 操作：\r\n\r\n  ```java\r\n  public E take() throws InterruptedException {\r\n      E x;\r\n      int c = -1;\r\n      // 元素个数\r\n      final AtomicInteger count = this.count;\r\n      // 获取全局消费锁\r\n      final ReentrantLock takeLock = this.takeLock;\r\n      // 可打断锁\r\n      takeLock.lockInterruptibly();\r\n      try {\r\n          // 没有元素可以出队\r\n          while (count.get() == 0) {\r\n              // 【阻塞等待队列不空，就可以消费数据】，线程处于 Waiting\r\n              notEmpty.await();\r\n          }\r\n          // 出队，计数减一，FIFO，出队头节点\r\n          x = dequeue();\r\n          // 返回自减前的数字\r\n          c = count.getAndDecrement();\r\n          // 队列还有元素\r\n          if (c > 1)\r\n              // 唤醒一个消费take线程\r\n              notEmpty.signal();\r\n      } finally {\r\n          takeLock.unlock();\r\n      }\r\n      // c 是消费前的数据，消费前满了，消费一个后还剩一个空位，唤醒生产线程\r\n      if (c == capacity)\r\n          // 调用的是 notFull.signal() 而不是 notFull.signalAll() 是为了减少竞争\r\n          signalNotFull();\r\n      return x;\r\n  }\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 性能比较\r\n\r\n主要列举 LinkedBlockingQueue 与 ArrayBlockingQueue 的性能比较：\r\n\r\n- Linked 支持有界，Array 强制有界\r\n- Linked 实现是链表，Array 实现是数组\r\n- Linked 是懒惰的，而 Array 需要提前初始化 Node 数组\r\n- Linked 每次入队会生成新 Node，而 Array 的 Node 是提前创建好的\r\n- Linked 两把锁，Array 一把锁\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 同步队列\r\n\r\n##### 成员属性\r\n\r\nSynchronousQueue 是一个不存储元素的 BlockingQueue，**每一个生产者必须阻塞匹配到一个消费者**\r\n\r\n成员变量：\r\n\r\n- 运行当前程序的平台拥有 CPU 的数量：\r\n\r\n  ```java\r\n  static final int NCPUS = Runtime.getRuntime().availableProcessors()\r\n  ```\r\n\r\n- 指定超时时间后，当前线程最大自旋次数：\r\n\r\n  ```java\r\n  // 只有一个 CPU 时自旋次数为 0，所有程序都是串行执行，多核 CPU 时自旋 32 次是一个经验值\r\n  static final int maxTimedSpins = (NCPUS < 2) ? 0 : 32;\r\n  ```\r\n\r\n  自旋的原因：线程挂起唤醒需要进行上下文切换，涉及到用户态和内核态的转变，是非常消耗资源的。自旋期间线程会一直检查自己的状态是否被匹配到，如果自旋期间被匹配到，那么直接就返回了，如果自旋次数达到某个指标后，还是会将当前线程挂起\r\n\r\n- 未指定超时时间，当前线程最大自旋次数：\r\n\r\n  ```java\r\n  static final int maxUntimedSpins = maxTimedSpins * 16;\t// maxTimedSpins 的 16 倍\r\n  ```\r\n\r\n- 指定超时限制的阈值，小于该值的线程不会被挂起：\r\n\r\n  ```java\r\n  static final long spinForTimeoutThreshold = 1000L;\t// 纳秒\r\n  ```\r\n\r\n  超时时间设置的小于该值，就会被禁止挂起，阻塞再唤醒的成本太高，不如选择自旋空转\r\n\r\n- 转换器：\r\n\r\n  ```java\r\n  private transient volatile Transferer<E> transferer;\r\n  abstract static class Transferer<E> {\r\n      /**\r\n      * 参数一：可以为 null，null 时表示这个请求是一个 REQUEST 类型的请求，反之是一个 DATA 类型的请求\r\n      * 参数二：如果为 true 表示指定了超时时间，如果为 false 表示不支持超时，会一直阻塞到匹配或者被打断\r\n      * 参数三：超时时间限制，单位是纳秒\r\n      \r\n      * 返回值：返回值如果不为 null 表示匹配成功，DATA 类型的请求返回当前线程 put 的数据\r\n      * \t     如果返回 null，表示请求超时或被中断\r\n      */\r\n      abstract E transfer(E e, boolean timed, long nanos);\r\n  }\r\n  ```\r\n\r\n- 构造方法：\r\n\r\n  ```java\r\n  public SynchronousQueue(boolean fair) {\r\n      // fair 默认 false\r\n      // 非公平模式实现的数据结构是栈，公平模式的数据结构是队列\r\n      transferer = fair ? new TransferQueue<E>() : new TransferStack<E>();\r\n  }\r\n  ```\r\n\r\n- 成员方法：\r\n\r\n  ```java\r\n  public boolean offer(E e) {\r\n      if (e == null) throw new NullPointerException();\r\n      return transferer.transfer(e, true, 0) != null;\r\n  }\r\n  public E poll() {\r\n      return transferer.transfer(null, true, 0);\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n****\r\n\r\n\r\n\r\n##### 非公实现\r\n\r\nTransferStack 是非公平的同步队列，因为所有的请求都被压入栈中，栈顶的元素会最先得到匹配，造成栈底的等待线程饥饿\r\n\r\nTransferStack 类成员变量：\r\n\r\n- 请求类型：\r\n\r\n  ```java\r\n  // 表示 Node 类型为请求类型\r\n  static final int REQUEST = 0;\r\n  // 表示 Node 类型为数据类型\r\n  static final int DATA = 1;\r\n  // 表示 Node 类型为匹配中类型\r\n  // 假设栈顶元素为 REQUEST-NODE，当前请求类型为 DATA，入栈会修改类型为 FULFILLING 【栈顶 & 栈顶之下的一个node】\r\n  // 假设栈顶元素为 DATA-NODE，当前请求类型为 REQUEST，入栈会修改类型为 FULFILLING 【栈顶 & 栈顶之下的一个node】\r\n  static final int FULFILLING = 2;\r\n  ```\r\n\r\n- 栈顶元素：\r\n\r\n  ```java\r\n  volatile SNode head;\r\n  ```\r\n\r\n内部类 SNode：\r\n\r\n- 成员变量：\r\n\r\n  ```java\r\n  static final class SNode {\r\n      // 指向下一个栈帧\r\n      volatile SNode next; \r\n      // 与当前 node 匹配的节点\r\n      volatile SNode match;\r\n      // 假设当前node对应的线程自旋期间未被匹配成功，那么node对应的线程需要挂起，\r\n      // 挂起前 waiter 保存对应的线程引用，方便匹配成功后，被唤醒。\r\n      volatile Thread waiter;\r\n      \r\n      // 数据域，不为空表示当前 Node 对应的请求类型为 DATA 类型，反之则表示 Node 为 REQUEST 类型\r\n      Object item; \r\n      // 表示当前Node的模式 【DATA/REQUEST/FULFILLING】\r\n      int mode;\r\n  }\r\n  ```\r\n\r\n- 构造方法：\r\n\r\n  ```java\r\n  SNode(Object item) {\r\n      this.item = item;\r\n  }\r\n  ```\r\n\r\n- 设置方法：设置 Node 对象的 next 字段，此处**对 CAS 进行了优化**，提升了 CAS 的效率\r\n\r\n  ```java\r\n  boolean casNext(SNode cmp, SNode val) {\r\n      //【优化：cmp == next】，可以提升一部分性能。 cmp == next 不相等，就没必要走 cas指令。\r\n      return cmp == next && UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);\r\n  }\r\n  ```\r\n\r\n- 匹配方法：\r\n\r\n  ```java\r\n  boolean tryMatch(SNode s) {\r\n      // 当前 node 尚未与任何节点发生过匹配，CAS 设置 match 字段为 s 节点，表示当前 node 已经被匹配\r\n      if (match == null && UNSAFE.compareAndSwapObject(this, matchOffset, null, s)) {\r\n          // 当前 node 如果自旋结束，会 park 阻塞，阻塞前将 node 对应的 Thread 保留到 waiter 字段\r\n          // 获取当前 node 对应的阻塞线程\r\n          Thread w = waiter;\r\n          // 条件成立说明 node 对应的 Thread 正在阻塞\r\n          if (w != null) {\r\n              waiter = null;\r\n              // 使用 unpark 方式唤醒线程\r\n              LockSupport.unpark(w);\r\n          }\r\n          return true;\r\n      }\r\n      // 匹配成功返回 true\r\n      return match == s;\r\n  }\r\n  ```\r\n\r\n- 取消方法：\r\n\r\n  ```java\r\n  // 取消节点的方法\r\n  void tryCancel() {\r\n      // match 字段指向自己，表示这个 node 是取消状态，取消状态的 node，最终会被强制移除出栈\r\n      UNSAFE.compareAndSwapObject(this, matchOffset, null, this);\r\n  }\r\n  \r\n  boolean isCancelled() {\r\n      return match == this;\r\n  }\r\n  ```\r\n\r\nTransferStack 类成员方法：\r\n\r\n- snode()：填充节点方法\r\n\r\n  ```java\r\n  static SNode snode(SNode s, Object e, SNode next, int mode) {\r\n      // 引用指向空时，snode 方法会创建一个 SNode 对象 \r\n      if (s == null) s = new SNode(e);\r\n      // 填充数据\r\n      s.mode = mode;\r\n      s.next = next;\r\n      return s;\r\n  }\r\n  ```\r\n\r\n- transfer()：核心方法，请求匹配出栈，不匹配阻塞\r\n\r\n  ```java\r\n  E transfer(E e, boolean timed, long nanos) {\r\n  \t// 包装当前线程的 node\r\n      SNode s = null;\r\n      // 根据元素判断当前的请求类型\r\n      int mode = (e == null) ? REQUEST : DATA;\r\n  \t// 自旋\r\n      for (;;) {\r\n          // 获取栈顶指针\r\n          SNode h = head;\r\n         // 【CASE1】：当前栈为空或者栈顶 node 模式与当前请求模式一致无法匹配，做入栈操作\r\n          if (h == null || h.mode == mode) {\r\n              // 当前请求是支持超时的，但是 nanos <= 0 说明这个请求不支持 “阻塞等待”\r\n              if (timed && nanos <= 0) { \r\n                  // 栈顶元素是取消状态\r\n                  if (h != null && h.isCancelled())\r\n                      // 栈顶出栈，设置新的栈顶\r\n                      casHead(h, h.next);\r\n                  else\r\n                      // 表示【匹配失败】\r\n                      return null;\r\n              // 入栈\r\n              } else if (casHead(h, s = snode(s, e, h, mode))) {\r\n                  // 等待被匹配的逻辑，正常情况返回匹配的节点；取消情况返回当前节点，就是 s\r\n                  SNode m = awaitFulfill(s, timed, nanos);\r\n                  // 说明当前 node 是【取消状态】\r\n                  if (m == s) { \r\n                      // 将取消节点出栈\r\n                      clean(s);\r\n                      return null;\r\n                  }\r\n                  // 执行到这说明【匹配成功】了\r\n                  // 栈顶有节点并且 匹配节点还未出栈，需要协助出栈\r\n                  if ((h = head) != null && h.next == s)\r\n                      casHead(h, s.next);\r\n                  // 当前 node 模式为 REQUEST 类型，返回匹配节点的 m.item 数据域\r\n                  // 当前 node 模式为 DATA 类型：返回 node.item 数据域，当前请求提交的数据 e\r\n                  return (E) ((mode == REQUEST) ? m.item : s.item);\r\n              }\r\n          // 【CASE2】：逻辑到这说明请求模式不一致，如果栈顶不是 FULFILLING 说明没被其他节点匹配，【当前可以匹配】\r\n          } else if (!isFulfilling(h.mode)) {\r\n              // 头节点是取消节点，match 指向自己，协助出栈\r\n              if (h.isCancelled())\r\n                  casHead(h, h.next);\r\n              // 入栈当前请求的节点\r\n              else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) {\r\n                  for (;;) { \r\n                      // m 是 s 的匹配的节点\r\n                      SNode m = s.next;\r\n                      // m 节点在 awaitFulfill 方法中被中断，clean 了自己\r\n                      if (m == null) {\r\n                          // 清空栈\r\n                          casHead(s, null);\r\n                          s = null;\r\n                          // 返回到外层自旋中\r\n                          break;\r\n                      }\r\n                      // 获取匹配节点的下一个节点\r\n                      SNode mn = m.next;\r\n                      // 尝试匹配，【匹配成功】，则将 fulfilling 和 m 一起出栈，并且唤醒被匹配的节点的线程\r\n                      if (m.tryMatch(s)) {\r\n                          casHead(s, mn);\r\n                          return (E) ((mode == REQUEST) ? m.item : s.item);\r\n                      } else\r\n                          // 匹配失败，出栈 m\r\n                          s.casNext(m, mn);\r\n                  }\r\n              }\r\n          // 【CASE3】：栈顶模式为 FULFILLING 模式，表示【栈顶和栈顶下面的节点正在发生匹配】，当前请求需要做协助工作\r\n          } else {\r\n              // h 表示的是 fulfilling 节点，m 表示 fulfilling 匹配的节点\r\n              SNode m = h.next;\r\n              if (m == null)\r\n                  // 清空栈\r\n                  casHead(h, null);\r\n              else {\r\n                  SNode mn = m.next;\r\n                  // m 和 h 匹配，唤醒 m 中的线程\r\n                  if (m.tryMatch(h))\r\n                      casHead(h, mn);\r\n                  else\r\n                      h.casNext(m, mn);\r\n              }\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n- awaitFulfill()：阻塞当前线程等待被匹配，返回匹配的节点，或者被取消的节点\r\n\r\n  ```java\r\n  SNode awaitFulfill(SNode s, boolean timed, long nanos) {\r\n      // 等待的截止时间\r\n      final long deadline = timed ? System.nanoTime() + nanos : 0L;\r\n      // 当前线程\r\n      Thread w = Thread.currentThread();\r\n      // 表示当前请求线程在下面的 for(;;) 自旋检查的次数\r\n      int spins = (shouldSpin(s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0);\r\n      // 自旋检查逻辑：是否匹配、是否超时、是否被中断\r\n      for (;;) {\r\n          // 当前线程收到中断信号，需要设置 node 状态为取消状态\r\n          if (w.isInterrupted())\r\n              s.tryCancel();\r\n          // 获取与当前 s 匹配的节点\r\n          SNode m = s.match;\r\n          if (m != null)\r\n              // 可能是正常的匹配的，也可能是取消的\r\n              return m;\r\n          // 执行了超时限制就判断是否超时\r\n          if (timed) {\r\n              nanos = deadline - System.nanoTime();\r\n              // 【超时了，取消节点】\r\n              if (nanos <= 0L) {\r\n                  s.tryCancel();\r\n                  continue;\r\n              }\r\n          }\r\n          // 说明当前线程还可以进行自旋检查\r\n          if (spins > 0)\r\n              // 自旋一次 递减 1\r\n              spins = shouldSpin(s) ? (spins - 1) : 0;\r\n          // 说明没有自旋次数了\r\n          else if (s.waiter == null)\r\n              //【把当前 node 对应的 Thread 保存到 node.waiter 字段中，要阻塞了】\r\n              s.waiter = w;\r\n          // 没有超时限制直接阻塞\r\n          else if (!timed)\r\n              LockSupport.park(this);\r\n          // nanos > 1000 纳秒的情况下，才允许挂起当前线程\r\n          else if (nanos > spinForTimeoutThreshold)\r\n              LockSupport.parkNanos(this, nanos);\r\n      }\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  boolean shouldSpin(SNode s) {\r\n      // 获取栈顶\r\n      SNode h = head;\r\n      // 条件一成立说明当前 s 就是栈顶，允许自旋检查\r\n      // 条件二成立说明当前 s 节点自旋检查期间，又来了一个与当前 s 节点匹配的请求，双双出栈后条件会成立\r\n      // 条件三成立前提当前 s 不是栈顶元素，并且当前栈顶正在匹配中，这种状态栈顶下面的元素，都允许自旋检查\r\n      return (h == s || h == null || isFulfilling(h.mode));\r\n  }\r\n  ```\r\n\r\n- clear()：指定节点出栈\r\n\r\n  ```java\r\n  void clean(SNode s) {\r\n      // 清空数据域和关联线程\r\n      s.item = null;\r\n      s.waiter = null;\r\n      \r\n  \t// 获取取消节点的下一个节点\r\n      SNode past = s.next;\r\n      // 判断后继节点是不是取消节点，是就更新 past\r\n      if (past != null && past.isCancelled())\r\n          past = past.next;\r\n  \r\n      SNode p;\r\n      // 从栈顶开始向下检查，【将栈顶开始向下的 取消状态 的节点全部清理出去】，直到碰到 past 或者不是取消状态为止\r\n      while ((p = head) != null && p != past && p.isCancelled())\r\n          // 修改的是内存地址对应的值，p 指向该内存地址所以数据一直在变化\r\n          casHead(p, p.next);\r\n  \t// 说明中间遇到了不是取消状态的节点，继续迭代下去\r\n      while (p != null && p != past) {\r\n          SNode n = p.next;\r\n          if (n != null && n.isCancelled())\r\n              p.casNext(n, n.next);\r\n          else\r\n              p = n;\r\n      }\r\n  }\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 公平实现\r\n\r\nTransferQueue 是公平的同步队列，采用 FIFO 的队列实现，请求节点与队尾模式不同，需要与队头发生匹配\r\n\r\nTransferQueue 类成员变量：\r\n\r\n- 指向队列的 dummy 节点：\r\n\r\n  ```java\r\n  transient volatile QNode head;\r\n  ```\r\n\r\n- 指向队列的尾节点：\r\n\r\n  ```java\r\n  transient volatile QNode tail;\r\n  ```\r\n\r\n- 被清理节点的前驱节点：\r\n\r\n  ```java\r\n  transient volatile QNode cleanMe;\r\n  ```\r\n\r\n  入队操作是两步完成的，第一步是 `t.next = newNode`，第二步是 `tail = newNode`，所以队尾节点出队，是一种非常特殊的情况\r\n\r\nTransferQueue 内部类：\r\n\r\n- QNode：\r\n\r\n  ```java\r\n  static final class QNode {\r\n      // 指向当前节点的下一个节点\r\n      volatile QNode next;\r\n      // 数据域，Node 代表的是 DATA 类型 item 表示数据，否则 Node 代表的 REQUEST 类型，item == null\r\n      volatile Object item;\r\n      // 假设当前 node 对应的线程自旋期间未被匹配成功，那么 node 对应的线程需要挂起，\r\n      // 挂起前 waiter 保存对应的线程引用，方便匹配成功后被唤醒。\r\n      volatile Thread waiter;\r\n      // true 当前 Node 是一个 DATA 类型，false 表示当前 Node 是一个 REQUEST 类型\r\n      final boolean isData;\r\n  \r\n  \t// 构建方法\r\n      QNode(Object item, boolean isData) {\r\n          this.item = item;\r\n          this.isData = isData;\r\n      }\r\n  \r\n      // 尝试取消当前 node，取消状态的 node 的 item 域指向自己\r\n      void tryCancel(Object cmp) {\r\n          UNSAFE.compareAndSwapObject(this, itemOffset, cmp, this);\r\n      }\r\n  \r\n      // 判断当前 node 是否为取消状态\r\n      boolean isCancelled() {\r\n          return item == this;\r\n      }\r\n  \r\n      // 判断当前节点是否 “不在” 队列内，当 next 指向自己时，说明节点已经出队。\r\n      boolean isOffList() {\r\n          return next == this;\r\n      }\r\n  }\r\n  ```\r\n\r\nTransferQueue 类成员方法：\r\n\r\n- 设置头尾节点：\r\n\r\n  ```java\r\n  void advanceHead(QNode h, QNode nh) {\r\n      // 设置头指针指向新的节点，\r\n      if (h == head && UNSAFE.compareAndSwapObject(this, headOffset, h, nh))\r\n          // 老的头节点出队\r\n          h.next = h;\r\n  }\r\n  void advanceTail(QNode t, QNode nt) {\r\n      if (tail == t)\r\n          // 更新队尾节点为新的队尾\r\n          UNSAFE.compareAndSwapObject(this, tailOffset, t, nt);\r\n  }\r\n  ```\r\n\r\n- transfer()：核心方法\r\n\r\n  ```java\r\n  E transfer(E e, boolean timed, long nanos) {\r\n      // s 指向当前请求对应的 node\r\n      QNode s = null;\r\n      // 是否是 DATA 类型的请求\r\n      boolean isData = (e != null);\r\n  \t// 自旋\r\n      for (;;) {\r\n          QNode t = tail;\r\n          QNode h = head;\r\n          if (t == null || h == null)\r\n              continue;\r\n  \t\t// head 和 tail 同时指向 dummy 节点，说明是空队列\r\n          // 队尾节点与当前请求类型是一致的情况，说明阻塞队列中都无法匹配，\r\n          if (h == t || t.isData == isData) {\r\n              // 获取队尾 t 的 next 节点\r\n              QNode tn = t.next;\r\n              // 多线程环境中其他线程可能修改尾节点\r\n              if (t != tail)\r\n                  continue;\r\n              // 已经有线程入队了，更新 tail\r\n              if (tn != null) {\r\n                  advanceTail(t, tn);\r\n                  continue;\r\n              }\r\n              // 允许超时，超时时间小于 0，这种方法不支持阻塞等待\r\n              if (timed && nanos <= 0)\r\n                  return null;\r\n              // 创建 node 的逻辑\r\n              if (s == null)\r\n                  s = new QNode(e, isData);\r\n              // 将 node 添加到队尾\r\n              if (!t.casNext(null, s))\r\n                  continue;\r\n  \t\t\t// 更新队尾指针\r\n              advanceTail(t, s);\r\n              \r\n              // 当前节点 等待匹配....\r\n              Object x = awaitFulfill(s, e, timed, nanos);\r\n              \r\n              // 说明【当前 node 状态为 取消状态】，需要做出队逻辑\r\n              if (x == s) {\r\n                  clean(t, s);\r\n                  return null;\r\n              }\r\n  \t\t\t// 说明当前 node 仍然在队列内，匹配成功，需要做出队逻辑\r\n              if (!s.isOffList()) {\r\n                  // t 是当前 s 节点的前驱节点，判断 t 是不是头节点，是就更新 dummy 节点为 s 节点\r\n                  advanceHead(t, s);\r\n                  // s 节点已经出队，所以需要把它的 item 域设置为它自己，表示它是个取消状态\r\n                  if (x != null)\r\n                      s.item = s;\r\n                  s.waiter = null;\r\n              }\r\n              return (x != null) ? (E)x : e;\r\n  \t\t// 队尾节点与当前请求节点【互补匹配】\r\n          } else {\r\n              // h.next 节点，【请求节点与队尾模式不同，需要与队头发生匹配】，TransferQueue 是一个【公平模式】\r\n              QNode m = h.next;\r\n              // 并发导致其他线程修改了队尾节点，或者已经把 head.next 匹配走了\r\n              if (t != tail || m == null || h != head)\r\n                  continue;\r\n  \t\t\t// 获取匹配节点的数据域保存到 x\r\n              Object x = m.item;\r\n              // 判断是否匹配成功\r\n              if (isData == (x != null) ||\r\n                  x == m ||\r\n                  !m.casItem(x, e)) {\r\n                  advanceHead(h, m);\r\n                  continue;\r\n              }\r\n  \t\t\t// 【匹配完成】，将头节点出队，让这个新的头结点成为 dummy 节点\r\n              advanceHead(h, m);\r\n              // 唤醒该匹配节点的线程\r\n              LockSupport.unpark(m.waiter);\r\n              return (x != null) ? (E)x : e;\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n- `awaitFulfill()`：阻塞当前线程等待被匹配\r\n\r\n  ```java\r\n  Object awaitFulfill(QNode s, E e, boolean timed, long nanos) {\r\n      // 表示等待截止时间\r\n      final long deadline = timed ? System.nanoTime() + nanos : 0L;\r\n      Thread w = Thread.currentThread();\r\n      // 自选检查的次数\r\n      int spins = ((head.next == s) ? (timed ? maxTimedSpins : maxUntimedSpins) : 0);\r\n      for (;;) {\r\n          // 被打断就取消节点\r\n          if (w.isInterrupted())\r\n              s.tryCancel(e);\r\n          // 获取当前 Node 数据域\r\n          Object x = s.item;\r\n          \r\n          // 当前请求为 DATA 模式时：e 请求带来的数据\r\n          // s.item 修改为 this，说明当前 QNode 对应的线程 取消状态\r\n          // s.item 修改为 null 表示已经有匹配节点了，并且匹配节点拿走了 item 数据\r\n  \r\n          // 当前请求为 REQUEST 模式时：e == null\r\n          // s.item 修改为 this，说明当前 QNode 对应的线程 取消状态\r\n          // s.item != null 且 item != this  表示当前 REQUEST 类型的 Node 已经匹配到 DATA 了 \r\n          if (x != e)\r\n              return x;\r\n          // 超时检查\r\n          if (timed) {\r\n              nanos = deadline - System.nanoTime();\r\n              if (nanos <= 0L) {\r\n                  s.tryCancel(e);\r\n                  continue;\r\n              }\r\n          }\r\n          // 自旋次数减一\r\n          if (spins > 0)\r\n              --spins;\r\n          // 没有自旋次数了，把当前线程封装进去 waiter\r\n          else if (s.waiter == null)\r\n              s.waiter = w;\r\n          // 阻塞\r\n          else if (!timed)\r\n              LockSupport.park(this);\r\n          else if (nanos > spinForTimeoutThreshold)\r\n              LockSupport.parkNanos(this, nanos);\r\n      }\r\n  }\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 操作Pool\r\n\r\n#### 创建方式\r\n\r\n##### Executor\r\n\r\n存放线程的容器：\r\n\r\n```java\r\nprivate final HashSet<Worker> workers = new HashSet<Worker>();\r\n```\r\n\r\n构造方法：\r\n\r\n```java\r\npublic ThreadPoolExecutor(int corePoolSize,\r\n                          int maximumPoolSize,\r\n                          long keepAliveTime,\r\n                          TimeUnit unit,\r\n                          BlockingQueue<Runnable> workQueue,\r\n                          ThreadFactory threadFactory,\r\n                          RejectedExecutionHandler handler)\r\n```\r\n\r\n参数介绍：\r\n\r\n- corePoolSize：核心线程数，定义了最小可以同时运行的线程数量\r\n\r\n- maximumPoolSize：最大线程数，当队列中存放的任务达到队列容量时，当前可以同时运行的数量变为最大线程数，创建线程并立即执行最新的任务，与核心线程数之间的差值又叫救急线程数\r\n\r\n- keepAliveTime：救急线程最大存活时间，当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等到 `keepAliveTime` 时间超过销毁\r\n\r\n- unit：`keepAliveTime` 参数的时间单位\r\n\r\n- workQueue：阻塞队列，存放被提交但尚未被执行的任务\r\n\r\n- threadFactory：线程工厂，创建新线程时用到，可以为线程创建时起名字\r\n\r\n- handler：拒绝策略，线程到达最大线程数仍有新任务时会执行拒绝策略\r\n\r\n  RejectedExecutionHandler 下有 4 个实现类：\r\n\r\n  - AbortPolicy：让调用者抛出 RejectedExecutionException 异常，**默认策略**\r\n  - CallerRunsPolicy：让调用者运行的调节机制，将某些任务回退到调用者，从而降低新任务的流量\r\n  - DiscardPolicy：直接丢弃任务，不予任何处理也不抛出异常\r\n  - DiscardOldestPolicy：放弃队列中最早的任务，把当前任务加入队列中尝试再次提交当前任务\r\n\r\n  补充：其他框架拒绝策略\r\n\r\n  - Dubbo：在抛出 RejectedExecutionException 异常前记录日志，并 dump 线程栈信息，方便定位问题\r\n  - Netty：创建一个新线程来执行任务\r\n  - ActiveMQ：带超时等待（60s）尝试放入队列\r\n  - PinPoint：它使用了一个拒绝策略链，会逐一尝试策略链中每种拒绝策略\r\n\r\n工作原理：\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824172606265.png\" alt=\"image-20230824172606265\" style=\"zoom:80%;\" />\r\n\r\n1. 创建线程池，这时没有创建线程（**懒惰**），等待提交过来的任务请求，**调用 execute 方法才会创建线程**\r\n\r\n2. 当调用 execute() 方法添加一个请求任务时，线程池会做如下判断：\r\n   - 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务\r\n   - 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列\r\n   - 如果这时队列满了且正在运行的线程数量还小于 maximumPoolSize，那么会创建非核心线程**立刻运行这个任务**，对于阻塞队列中的任务不公平。这是因为创建每个 Worker（线程）对象会绑定一个初始任务，启动 Worker 时会优先执行\r\n   - 如果队列满了且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会启动饱和**拒绝策略**来执行\r\n3. 当一个线程完成任务时，会从队列中取下一个任务来执行\r\n\r\n4. 当一个线程空闲超过一定的时间（keepAliveTime）时，线程池会判断：如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉，所以线程池的所有任务完成后最终会收缩到 corePoolSize 大小\r\n\r\n\r\n\r\n图片来源：https://space.bilibili.com/457326371/\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### Executors\r\n\r\nExecutors 提供了四种线程池的创建：newCachedThreadPool、newFixedThreadPool、newSingleThreadExecutor、newScheduledThreadPool\r\n\r\n- newFixedThreadPool：创建一个拥有 n 个线程的线程池\r\n\r\n  ```java\r\n  public static ExecutorService newFixedThreadPool(int nThreads) {\r\n      return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS,\r\n                                    new LinkedBlockingQueue<Runnable>());\r\n  }\r\n  ```\r\n\r\n  - 核心线程数 == 最大线程数（没有救急线程被创建），因此也无需超时时间\r\n  - LinkedBlockingQueue 是一个单向链表实现的阻塞队列，默认大小为 `Integer.MAX_VALUE`，也就是无界队列，可以放任意数量的任务，在任务比较多的时候会导致 OOM（内存溢出）\r\n  - 适用于任务量已知，相对耗时的长期任务\r\n\r\n- newCachedThreadPool：创建一个可扩容的线程池\r\n\r\n  ```java\r\n  public static ExecutorService newCachedThreadPool() {\r\n      return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS,\r\n                                    new SynchronousQueue<Runnable>());\r\n  }\r\n  ```\r\n\r\n  - 核心线程数是 0， 最大线程数是 29 个 1，全部都是救急线程（60s 后可以回收），可能会创建大量线程，从而导致 **OOM**\r\n  - SynchronousQueue 作为阻塞队列，没有容量，对于每一个 take 的线程会阻塞直到有一个 put 的线程放入元素为止（类似一手交钱、一手交货）\r\n\r\n  - 适合任务数比较密集，但每个任务执行时间较短的情况\r\n\r\n- newSingleThreadExecutor：创建一个只有 1 个线程的单线程池\r\n\r\n  ```java\r\n  public static ExecutorService newSingleThreadExecutor() {\r\n      return new FinalizableDelegatedExecutorService\r\n          (new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,\r\n                                  new LinkedBlockingQueue<Runnable>()));\r\n  }\r\n  ```\r\n\r\n  - 保证所有任务按照**指定顺序执行**，线程数固定为 1，任务数多于 1 时会放入无界队列排队，任务执行完毕，这唯一的线程也不会被释放\r\n\r\n\r\n对比：\r\n\r\n- 创建一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施，线程池会新建一个线程，保证池的正常工作\r\n\r\n- `Executors.newSingleThreadExecutor()` 线程个数始终为 1，不能修改。`FinalizableDelegatedExecutorService` 应用的是装饰器模式，只对外暴露了 ExecutorService 接口，因此不能调用 ThreadPoolExecutor 中特有的方法\r\n\r\n  原因：父类不能直接调用子类中的方法，需要反射或者创建对象的方式，可以调用子类静态方法\r\n\r\n- `Executors.newFixedThreadPool(1)` 初始时为 1，可以修改。对外暴露的是 ThreadPoolExecutor 对象，可以强转后调用 setCorePoolSize 等方法进行修改\r\n\r\n![](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/JUC-newSingleThreadExecutor.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 开发要求\r\n\r\n阿里巴巴 `Java` 开发手册要求：\r\n\r\n- **线程资源必须通过线程池提供，不允许在应用中自行显式创建线程**\r\n\r\n  - 使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题\r\n\r\n\r\n  - 如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者过度切换的问题\r\n\r\n\r\n  - 线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式更加明确线程池的运行规则，规避资源耗尽的风险\r\n\r\n\r\n- Executors 返回的线程池对象弊端如下：\r\n\r\n  - FixedThreadPool 和 SingleThreadPool：请求队列长度为 `Integer.MAX_VALUE`，可能会堆积大量的请求，从而导致 OOM\r\n\r\n\r\n  - CacheThreadPool 和 ScheduledThreadPool：允许创建线程数量为 `Integer.MAX_VALUE`，可能会创建大量的线程，导致 OOM\r\n\r\n\r\n创建多大容量的线程池合适？\r\n\r\n- 一般来说池中**总线程数是核心池线程数量两倍**，确保当核心池有线程停止时，核心池外有线程进入核心池\r\n\r\n- 过小会导致程序不能充分地利用系统资源、容易导致饥饿\r\n\r\n- 过大会导致更多的线程上下文切换，占用更多内存\r\n\r\n\r\n上下文切换：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态，任务从保存到再加载的过程就是一次上下文切换\r\n\r\n核心线程数常用公式：\r\n\r\n- **CPU 密集型任务 (N+1)：** 这种任务消耗的是 CPU 资源，可以将核心线程数设置为 N (CPU 核心数) + 1，比 CPU 核心数多出来的一个线程是为了防止线程发生缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 某个核心就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间\r\n  - CPU 密集型简单理解就是利用 CPU 计算能力的任务比如在内存中对大量数据进行分析\r\n\r\n- **`I/O` 密集型任务：** 这种系统 CPU 处于阻塞状态，用大部分的时间来处理 `I/O` 交互，而线程在处理 `I/O` 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用，因此在 `I/O` 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N 或 `CPU 核数/ (1-阻塞系数)`，阻塞系数在 0.8~0.9 之间\r\n  - IO 密集型就是涉及到网络读取，文件读取此类任务 ，特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 提交方法\r\n\r\nExecutorService 类 API：\r\n\r\n| 方法                                                         | 说明                                                         |\r\n| ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| `void execute(Runnable command)`                             | 执行任务（Executor 类 API）                                  |\r\n| `Future<?> submit(Runnable task)`                            | 提交任务 task()                                              |\r\n| `Future submit(Callable<T> task)`                            | 提交任务 task，用返回值 Future 获得任务执行结果              |\r\n| `List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks)` | 提交 tasks 中所有任务                                        |\r\n| `List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks, long timeout, TimeUnit unit)` | 提交 tasks 中所有任务，超时时间针对所有task，超时会取消没有执行完的任务，并抛出超时异常 |\r\n| `T invokeAny(Collection<? extends Callable<T>> tasks)`       | 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消 |\r\n\r\nexecute 和 submit 都属于线程池的方法，对比：\r\n\r\n- execute 只能执行 Runnable 类型的任务，没有返回值； submit 既能提交 Runnable 类型任务也能提交 Callable 类型任务，底层是**封装成 FutureTask，然后调用 execute 执行**\r\n\r\n- execute 会直接抛出任务执行时的异常，submit 会吞掉异常，可通过 Future 的 get 方法将任务执行时的异常重新抛出\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 关闭方法\r\n\r\nExecutorService 类 API：\r\n\r\n| 方法                                                    | 说明                                                         |\r\n| ------------------------------------------------------- | ------------------------------------------------------------ |\r\n| `void shutdown()`                                       | 线程池状态变为 SHUTDOWN，等待任务执行完后关闭线程池，不会接收新任务，但已提交任务会执行完，而且也可以添加线程（不绑定任务） |\r\n| `List<Runnable> shutdownNow()`                          | 线程池状态变为 STOP，用 interrupt 中断正在执行的任务，直接关闭线程池，不会接收新任务，会将队列中的任务返回 |\r\n| `boolean isShutdown()`                                  | 不在 RUNNING 状态的线程池，此执行者已被关闭，方法返回 true   |\r\n| `boolean isTerminated()`                                | 线程池状态是否是 TERMINATED，如果所有任务在关闭后完成，返回 true |\r\n| `boolean awaitTermination(long timeout, TimeUnit unit)` | 调用 shutdown 后，由于调用线程不会等待所有任务运行结束，如果它想在线程池 TERMINATED 后做些事情，可以利用此方法等待 |\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 处理异常\r\n\r\nexecute 会直接抛出任务执行时的异常，submit 会吞掉异常，有两种处理方法\r\n\r\n方法 1：主动捉异常\r\n\r\n```java\r\nExecutorService executorService = Executors.newFixedThreadPool(1);\r\npool.submit(() -> {\r\n    try {\r\n        System.out.println(\"task1\");\r\n        int i = 1 / 0;\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n    }\r\n});\r\n```\r\n\r\n方法 2：使用 Future 对象\r\n\r\n```java\r\nExecutorService executorService = Executors.newFixedThreadPool(1);\r\nFuture<?> future = pool.submit(() -> {\r\n    System.out.println(\"task1\");\r\n    int i = 1 / 0;\r\n    return true;\r\n});\r\nSystem.out.println(future.get());\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 工作原理\r\n\r\n#### 状态信息\r\n\r\nThreadPoolExecutor 使用 int 的**高 3 位来表示线程池状态，低 29 位表示线程数量**。这些信息存储在一个原子变量 ctl 中，目的是将线程池状态与线程个数合二为一，这样就可以用一次 CAS 原子操作进行赋值\r\n\r\n- 状态表示：\r\n\r\n  ```java\r\n  // 高3位：表示当前线程池运行状态，除去高3位之后的低位：表示当前线程池中所拥有的线程数量\r\n  private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\r\n  // 表示在 ctl 中，低 COUNT_BITS 位，是用于存放当前线程数量的位\r\n  private static final int COUNT_BITS = Integer.SIZE - 3;\r\n  // 低 COUNT_BITS 位所能表达的最大数值，000 11111111111111111111 => 5亿多\r\n  private static final int CAPACITY   = (1 << COUNT_BITS) - 1;\r\n  ```\r\n\r\n  <img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230824172854832.png\" alt=\"image-20230824172854832\" style=\"zoom:80%;\" />\r\n\r\n- 四种状态：\r\n\r\n  ```java\r\n  // 111 000000000000000000，转换成整数后其实就是一个【负数】\r\n  private static final int RUNNING    = -1 << COUNT_BITS;\r\n  // 000 000000000000000000\r\n  private static final int SHUTDOWN   =  0 << COUNT_BITS;\r\n  // 001 000000000000000000\r\n  private static final int STOP       =  1 << COUNT_BITS;\r\n  // 010 000000000000000000\r\n  private static final int TIDYING    =  2 << COUNT_BITS;\r\n  // 011 000000000000000000\r\n  private static final int TERMINATED =  3 << COUNT_BITS;\r\n  ```\r\n\r\n  | 状态       | 高3位 | 接收新任务 | 处理阻塞任务队列 | 说明                                      |\r\n  | ---------- | ----- | ---------- | ---------------- | ----------------------------------------- |\r\n  | RUNNING    | 111   | Y          | Y                |                                           |\r\n  | SHUTDOWN   | 000   | N          | Y                | 不接收新任务，但处理阻塞队列剩余任务      |\r\n  | STOP       | 001   | N          | N                | 中断正在执行的任务，并抛弃阻塞队列任务    |\r\n  | TIDYING    | 010   | -          | -                | 任务全执行完毕，活动线程为 0 即将进入终结 |\r\n  | TERMINATED | 011   | -          | -                | 终止状态                                  |\r\n\r\n- 获取当前线程池运行状态：\r\n\r\n  ```java\r\n  // ~CAPACITY = ~000 11111111111111111111 = 111 000000000000000000000（取反）\r\n  // c == ctl = 111 000000000000000000111\r\n  // 111 000000000000000000111\r\n  // 111 000000000000000000000\r\n  // 111 000000000000000000000\t获取到了运行状态\r\n  private static int runStateOf(int c)     { return c & ~CAPACITY; }\r\n  ```\r\n\r\n- 获取当前线程池线程数量：\r\n\r\n  ```java\r\n  //        c = 111 000000000000000000111\r\n  // CAPACITY = 000 111111111111111111111\r\n  //            000 000000000000000000111 => 7\r\n  private static int workerCountOf(int c)  { return c & CAPACITY; }\r\n  ```\r\n\r\n- 重置当前线程池状态 ctl：\r\n\r\n  ```java\r\n  // rs 表示线程池状态，wc 表示当前线程池中 worker（线程）数量，相与以后就是合并后的状态\r\n  private static int ctlOf(int rs, int wc) { return rs | wc; }\r\n  ```\r\n\r\n- 比较当前线程池 ctl 所表示的状态：\r\n\r\n  ```java\r\n  // 比较当前线程池 ctl 所表示的状态，是否小于某个状态 s\r\n  // 状态对比：RUNNING < SHUTDOWN < STOP < TIDYING < TERMINATED\r\n  private static boolean runStateLessThan(int c, int s) { return c < s; }\r\n  // 比较当前线程池 ctl 所表示的状态，是否大于等于某个状态s\r\n  private static boolean runStateAtLeast(int c, int s) { return c >= s; }\r\n  // 小于 SHUTDOWN 的一定是 RUNNING，SHUTDOWN == 0\r\n  private static boolean isRunning(int c) { return c < SHUTDOWN; }\r\n  ```\r\n\r\n- 设置线程池 ctl：\r\n\r\n  ```java\r\n  // 使用 CAS 方式 让 ctl 值 +1 ，成功返回 true, 失败返回 false\r\n  private boolean compareAndIncrementWorkerCount(int expect) {\r\n      return ctl.compareAndSet(expect, expect + 1);\r\n  }\r\n  // 使用 CAS 方式 让 ctl 值 -1 ，成功返回 true, 失败返回 false\r\n  private boolean compareAndDecrementWorkerCount(int expect) {\r\n      return ctl.compareAndSet(expect, expect - 1);\r\n  }\r\n  // 将 ctl 值减一，do while 循环会一直重试，直到成功为止\r\n  private void decrementWorkerCount() {\r\n      do {} while (!compareAndDecrementWorkerCount(ctl.get()));\r\n  }\r\n  ```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 成员属性\r\n\r\n成员变量\r\n\r\n- **线程池中存放 Worker 的容器**：线程池没有初始化，直接往池中加线程即可\r\n\r\n  ```java\r\n  private final HashSet<Worker> workers = new HashSet<Worker>();\r\n  ```\r\n\r\n- 线程全局锁：\r\n\r\n  ```java\r\n  // 增加减少 worker 或者时修改线程池运行状态需要持有 mainLock\r\n  private final ReentrantLock mainLock = new ReentrantLock();\r\n  ```\r\n\r\n- 可重入锁的条件变量：\r\n\r\n  ```java\r\n  // 当外部线程调用 awaitTermination() 方法时，会等待当前线程池状态为 Termination 为止\r\n  private final Condition termination = mainLock.newCondition()\r\n  ```\r\n\r\n- 线程池相关参数：\r\n\r\n  ```java\r\n  private volatile int corePoolSize;\t\t\t\t// 核心线程数量\r\n  private volatile int maximumPoolSize;\t\t\t// 线程池最大线程数量\r\n  private volatile long keepAliveTime;\t\t\t// 空闲线程存活时间\r\n  private volatile ThreadFactory threadFactory;\t// 创建线程时使用的线程工厂，默认是 DefaultThreadFactory\r\n  private final BlockingQueue<Runnable> workQueue;// 【超过核心线程提交任务就放入 阻塞队列】\r\n  ```\r\n\r\n  ```java\r\n  private volatile RejectedExecutionHandler handler;\t// 拒绝策略，juc包提供了4中方式\r\n  private static final RejectedExecutionHandler defaultHandler = new AbortPolicy();// 默认策略\r\n  ```\r\n\r\n- 记录线程池相关属性的数值：\r\n\r\n  ```java\r\n  private int largestPoolSize;\t\t// 记录线程池生命周期内线程数最大值\r\n  private long completedTaskCount;\t// 记录线程池所完成任务总数，当某个 worker 退出时将完成的任务累加到该属性\r\n  ```\r\n\r\n- 控制**核心线程数量内的线程是否可以被回收**：\r\n\r\n  ```java\r\n  // false（默认）代表不可以，为 true 时核心线程空闲超过 keepAliveTime 也会被回收\r\n  // allowCoreThreadTimeOut(boolean value) 方法可以设置该值\r\n  private volatile boolean allowCoreThreadTimeOut;\r\n  ```\r\n\r\n内部类：\r\n\r\n- Worker 类：**每个 Worker 对象会绑定一个初始任务**，启动 Worker 时优先执行，这也是造成线程池不公平的原因。Worker 继承自 AQS，本身具有锁的特性，采用独占锁模式，`state = 0` 表示未被占用，`> 0` 表示被占用，`< 0` 表示初始状态不能被抢锁\r\n\r\n  ```java\r\n  private final class Worker extends AbstractQueuedSynchronizer implements Runnable {\r\n  \tfinal Thread thread;\t\t\t// worker 内部封装的工作线程\r\n      Runnable firstTask;\t\t\t\t// worker 第一个执行的任务，普通的 Runnable 实现类或者是 FutureTask\r\n      volatile long completedTasks;\t// 记录当前 worker 所完成任务数量\r\n      \r\n      // 构造方法\r\n      Worker(Runnable firstTask) {\r\n          // 设置AQS独占模式为初始化中状态，这个状态不能被抢占锁\r\n         \tsetState(-1);\r\n          // firstTask不为空时，当worker启动后，内部线程会优先执行firstTask，执行完后会到queue中去获取下个任务\r\n          this.firstTask = firstTask;\r\n          // 使用线程工厂创建一个线程，并且【将当前worker指定为Runnable】，所以thread启动时会调用 worker.run()\r\n          this.thread = getThreadFactory().newThread(this);\r\n      }\r\n      // 【不可重入锁】\r\n      protected boolean tryAcquire(int unused) {\r\n          if (compareAndSetState(0, 1)) {\r\n              setExclusiveOwnerThread(Thread.currentThread());\r\n              return true;\r\n          }\r\n          return false;\r\n      }\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  public Thread newThread(Runnable r) {\r\n      // 将当前 worker 指定为 thread 的执行方法，线程调用 start 会调用 r.run()\r\n      Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0);\r\n      if (t.isDaemon())\r\n          t.setDaemon(false);\r\n      if (t.getPriority() != Thread.NORM_PRIORITY)\r\n          t.setPriority(Thread.NORM_PRIORITY);\r\n      return t;\r\n  }\r\n  ```\r\n\r\n- 拒绝策略相关的内部类\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 成员方法\r\n\r\n##### 提交方法\r\n\r\n- `AbstractExecutorService#submit()`：提交任务，**把 Runnable 或 Callable 任务封装成 FutureTask 执行**，可以通过方法返回的任务对象，调用 get 阻塞获取任务执行的结果或者异常，源码分析在笔记的 Future 部分\r\n\r\n  ```java\r\n  public Future<?> submit(Runnable task) {\r\n      // 空指针异常\r\n      if (task == null) throw new NullPointerException();\r\n      // 把 Runnable 封装成未来任务对象，执行结果就是 null，也可以通过参数指定 FutureTask#get 返回数据\r\n      RunnableFuture<Void> ftask = newTaskFor(task, null);\r\n      // 执行方法\r\n      execute(ftask);\r\n      return ftask;\r\n  }\r\n  public <T> Future<T> submit(Callable<T> task) {\r\n      if (task == null) throw new NullPointerException();\r\n      // 把 Callable 封装成未来任务对象\r\n      RunnableFuture<T> ftask = newTaskFor(task);\r\n      // 执行方法\r\n      execute(ftask);\t\r\n      // 返回未来任务对象，用来获取返回值\r\n      return ftask;\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {\r\n      // Runnable 封装成 FutureTask，【指定返回值】\r\n      return new FutureTask<T>(runnable, value);\r\n  }\r\n  protected <T> RunnableFuture<T> newTaskFor(Callable<T> callable) {\r\n      // Callable 直接封装成 FutureTask\r\n      return new FutureTask<T>(callable);\r\n  }\r\n  ```\r\n\r\n- `execute()`：执行任务，**但是没有返回值，没办法获取任务执行结果**，出现异常会直接抛出任务执行时的异常。根据线程池中的线程数，选择添加任务时的处理方式\r\n\r\n  ```java\r\n  // command 可以是普通的 Runnable 实现类，也可以是 FutureTask，不能是 Callable\r\n  public void execute(Runnable command) {\r\n      // 非空判断\r\n      if (command == null)\r\n          throw new NullPointerException();\r\n    \t// 获取 ctl 最新值赋值给 c，ctl 高 3 位表示线程池状态，低位表示当前线程池线程数量。\r\n      int c = ctl.get();\r\n      // 【1】当前线程数量小于核心线程数，此次提交任务直接创建一个新的 worker，线程池中多了一个新的线程\r\n      if (workerCountOf(c) < corePoolSize) {\r\n          // addWorker 为创建线程的过程，会创建 worker 对象并且将 command 作为 firstTask，优先执行\r\n          if (addWorker(command, true))\r\n              return;\r\n          \r\n          // 执行到这条语句，说明 addWorker 一定是失败的，存在并发现象或者线程池状态被改变，重新获取状态\r\n          // SHUTDOWN 状态下也有可能创建成功，前提 firstTask == null 而且当前 queue 不为空（特殊情况）\r\n          c = ctl.get();\r\n      }\r\n      // 【2】执行到这说明当前线程数量已经达到核心线程数量 或者 addWorker 失败\r\n      // \t判断当前线程池是否处于running状态，成立就尝试将 task 放入到 workQueue 中\r\n      if (isRunning(c) && workQueue.offer(command)) {\r\n          int recheck = ctl.get();\r\n          // 条件一成立说明线程池状态被外部线程给修改了，可能是执行了 shutdown() 方法，该状态不能接收新提交的任务\r\n          // 所以要把刚提交的任务删除，删除成功说明提交之后线程池中的线程还未消费（处理）该任务\r\n          if (!isRunning(recheck) && remove(command))\r\n              // 任务出队成功，走拒绝策略\r\n              reject(command);\r\n          // 执行到这说明线程池是 running 状态，获取线程池中的线程数量，判断是否是 0\r\n          // 【担保机制】，保证线程池在 running 状态下，最起码得有一个线程在工作\r\n          else if (workerCountOf(recheck) == 0)\r\n              addWorker(null, false);\r\n      }\r\n      // 【3】offer失败说明queue满了\r\n      // 如果线程数量尚未达到 maximumPoolSize，会创建非核心 worker 线程直接执行 command，【这也是不公平的原因】\r\n      // 如果当前线程数量达到 maximumPoolSize，这里 addWorker 也会失败，走拒绝策略\r\n      else if (!addWorker(command, false))\r\n          reject(command);\r\n  }\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 添加线程\r\n\r\n- `prestartAllCoreThreads()`：**提前预热**，创建所有的核心线程\r\n\r\n  ```java\r\n  public int prestartAllCoreThreads() {\r\n      int n = 0;\r\n      while (addWorker(null, true))\r\n          ++n;\r\n      return n;\r\n  }\r\n  ```\r\n\r\n- `addWorker()`：**添加线程到线程池**，返回 true 表示创建 Worker 成功，且线程启动。首先判断线程池是否允许添加线程，允许就让线程数量 + 1，然后去创建 Worker 加入线程池\r\n\r\n  注意：SHUTDOWN 状态也能添加线程，但是要求新加的 Woker 没有 firstTask，而且当前 queue 不为空，所以创建一个线程来帮助线程池执行队列中的任务\r\n\r\n  ```java\r\n  // core == true 表示采用核心线程数量限制，false 表示采用 maximumPoolSize\r\n  private boolean addWorker(Runnable firstTask, boolean core) {\r\n      // 自旋【判断当前线程池状态是否允许创建线程】，允许就设置线程数量 + 1\r\n      retry:\r\n      for (;;) {\r\n          // 获取 ctl 的值\r\n          int c = ctl.get();\r\n          // 获取当前线程池运行状态\r\n          int rs = runStateOf(c);\t\r\n          \r\n          // 判断当前线程池状态【是否允许添加线程】\r\n          \r\n          // 当前线程池是 SHUTDOWN 状态，但是队列里面还有任务尚未处理完，需要处理完 queue 中的任务\r\n          // 【不允许再提交新的 task，所以 firstTask 为空，但是可以继续添加 worker】\r\n          if (rs >= SHUTDOWN && !(rs == SHUTDOWN && firstTask == null && !workQueue.isEmpty()))\r\n              return false;\r\n          for (;;) {\r\n              // 获取线程池中线程数量\r\n              int wc = workerCountOf(c);\r\n              // 条件一一般不成立，CAPACITY是5亿多，根据 core 判断使用哪个大小限制线程数量，超过了返回 false\r\n              if (wc >= CAPACITY || wc >= (core ? corePoolSize : maximumPoolSize))\r\n                  return false;\r\n              // 记录线程数量已经加 1，类比于申请到了一块令牌，条件失败说明其他线程修改了数量\r\n              if (compareAndIncrementWorkerCount(c))\r\n                  // 申请成功，跳出了 retry 这个 for 自旋\r\n                  break retry;\r\n              // CAS 失败，没有成功的申请到令牌\r\n              c = ctl.get();\r\n              // 判断当前线程池状态是否发生过变化，被其他线程修改了，可能其他线程调用了 shutdown() 方法\r\n              if (runStateOf(c) != rs)\r\n                  // 返回外层循环检查是否能创建线程，在 if 语句中返回 false\r\n                  continue retry;\r\n             \r\n          }\r\n      }\r\n      \r\n      //【令牌申请成功，开始创建线程】\r\n      \r\n  \t// 运行标记，表示创建的 worker 是否已经启动，false未启动  true启动\r\n      boolean workerStarted = false;\r\n      // 添加标记，表示创建的 worker 是否添加到池子中了，默认false未添加，true是添加。\r\n      boolean workerAdded = false;\r\n      Worker w = null;\r\n      try {\r\n          // 【创建 Worker，底层通过线程工厂 newThread 方法创建执行线程，指定了首先执行的任务】\r\n          w = new Worker(firstTask);\r\n          // 将新创建的 worker 节点中的线程赋值给 t\r\n          final Thread t = w.thread;\r\n          // 这里的判断为了防止 程序员自定义的 ThreadFactory 实现类有 bug，创造不出线程\r\n          if (t != null) {\r\n              final ReentrantLock mainLock = this.mainLock;\r\n              // 加互斥锁，要添加 worker 了\r\n              mainLock.lock();\r\n              try {\r\n                  // 获取最新线程池运行状态保存到 rs\r\n                  int rs = runStateOf(ctl.get());\r\n  \t\t\t\t// 判断线程池是否为RUNNING状态，不是再【判断当前是否为SHUTDOWN状态且firstTask为空，特殊情况】\r\n                  if (rs < SHUTDOWN || (rs == SHUTDOWN && firstTask == null)) {\r\n                      // 当线程start后，线程isAlive会返回true，这里还没开始启动线程，如果被启动了就需要报错\r\n                      if (t.isAlive())\r\n                          throw new IllegalThreadStateException();\r\n                      \r\n                      //【将新建的 Worker 添加到线程池中】\r\n                      workers.add(w);\r\n                      int s = workers.size();\r\n  \t\t\t\t\t// 当前池中的线程数量是一个新高，更新 largestPoolSize\r\n                      if (s > largestPoolSize)\r\n                          largestPoolSize = s;\r\n                      // 添加标记置为 true\r\n                      workerAdded = true;\r\n                  }\r\n              } finally {\r\n                  // 解锁啊\r\n                  mainLock.unlock();\r\n              }\r\n              // 添加成功就【启动线程执行任务】\r\n              if (workerAdded) {\r\n                  // Thread 类中持有 Runnable 任务对象，调用的是 Runnable 的 run ，也就是 FutureTask\r\n                  t.start();\r\n                  // 运行标记置为 true\r\n                  workerStarted = true;\r\n              }\r\n          }\r\n      } finally {\r\n          // 如果启动线程失败，做清理工作\r\n          if (! workerStarted)\r\n              addWorkerFailed(w);\r\n      }\r\n      // 返回新创建的线程是否启动\r\n      return workerStarted;\r\n  }\r\n  ```\r\n\r\n- `addWorkerFailed()`：清理任务\r\n\r\n  ```java\r\n  private void addWorkerFailed(Worker w) {\r\n      final ReentrantLock mainLock = this.mainLock;\r\n      // 持有线程池全局锁，因为操作的是线程池相关的东西\r\n      mainLock.lock();\r\n      try {\r\n          //条件成立需要将 worker 在 workers 中清理出去。\r\n          if (w != null)\r\n              workers.remove(w);\r\n          // 将线程池计数 -1，相当于归还令牌。\r\n          decrementWorkerCount();\r\n          // 尝试停止线程池\r\n          tryTerminate();\r\n      } finally {\r\n          //释放线程池全局锁。\r\n          mainLock.unlock();\r\n      }\r\n  }\r\n  ```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 运行方法\r\n\r\n- `Worker#run`：Worker 实现了 Runnable 接口，当线程启动时，会调用 Worker 的 run() 方法\r\n\r\n  ```java\r\n  public void run() {\r\n      // ThreadPoolExecutor#runWorker()\r\n      runWorker(this);\r\n  }\r\n  ```\r\n\r\n- `runWorker()`：线程启动就要**执行任务**，会一直 while 循环获取任务并执行\r\n\r\n  ```java\r\n  final void runWorker(Worker w) {\r\n      Thread wt = Thread.currentThread();\t\r\n      // 获取 worker 的 firstTask\r\n      Runnable task = w.firstTask;\r\n      // 引用置空，【防止复用该线程时重复执行该任务】\r\n      w.firstTask = null;\r\n      // 初始化 worker 时设置 state = -1，表示不允许抢占锁\r\n      // 这里需要设置 state = 0 和 exclusiveOwnerThread = null，开始独占模式抢锁\r\n      w.unlock();\r\n      // true 表示发生异常退出，false 表示正常退出。\r\n      boolean completedAbruptly = true;\r\n      try {\r\n          // firstTask 不是 null 就直接运行，否则去 queue 中获取任务\r\n          // 【getTask 如果是阻塞获取任务，会一直阻塞在take方法，直到获取任务，不会走返回null的逻辑】\r\n          while (task != null || (task = getTask()) != null) {\r\n              // worker 加锁，shutdown 时会判断当前 worker 状态，【根据独占锁状态判断是否空闲】\r\n              w.lock();\r\n              \r\n  \t\t\t// 说明线程池状态大于 STOP，目前处于 STOP/TIDYING/TERMINATION，此时给线程一个中断信号\r\n              if ((runStateAtLeast(ctl.get(), STOP) ||\r\n                   // 说明线程处于 RUNNING 或者 SHUTDOWN 状态，清除打断标记\r\n                   (Thread.interrupted() && runStateAtLeast(ctl.get(), STOP))) && !wt.isInterrupted())\r\n                  // 中断线程，设置线程的中断标志位为 true\r\n                  wt.interrupt();\r\n              try {\r\n                  // 钩子方法，【任务执行的前置处理】\r\n                  beforeExecute(wt, task);\r\n                  Throwable thrown = null;\r\n                  try {\r\n                      // 【执行任务】\r\n                      task.run();\r\n                  } catch (Exception x) {\r\n                   \t//.....\r\n                  } finally {\r\n                      // 钩子方法，【任务执行的后置处理】\r\n                      afterExecute(task, thrown);\r\n                  }\r\n              } finally {\r\n                  task = null;\t\t// 将局部变量task置为null，代表任务执行完成\r\n                  w.completedTasks++;\t// 更新worker完成任务数量\r\n                  w.unlock();\t\t\t// 解锁\r\n              }\r\n          }\r\n          // getTask()方法返回null时会走到这里，表示queue为空并且线程空闲超过保活时间，【当前线程执行退出逻辑】\r\n          completedAbruptly = false;\t\r\n      } finally {\r\n          // 正常退出 completedAbruptly = false\r\n         \t// 异常退出 completedAbruptly = true，【从 task.run() 内部抛出异常】时，跳到这一行\r\n          processWorkerExit(w, completedAbruptly);\r\n      }\r\n  }\r\n  ```\r\n\r\n- `unlock()`：重置锁\r\n\r\n  ```java\r\n  public void unlock() { release(1); }\r\n  public final boolean release(int arg) {\r\n      if (tryRelease(arg)) {\r\n          Node h = head;\r\n          if (h != null && h.waitStatus != 0)\r\n              unparkSuccessor(h);\r\n          return true;\r\n      }\r\n      return false;\r\n  }\r\n  // 外部不会直接调用这个方法 这个方法是 AQS 内调用的，外部调用 unlock 时触发此方法\r\n  protected boolean tryRelease(int unused) {\r\n      setExclusiveOwnerThread(null);\t\t// 设置持有者为 null\r\n      setState(0);\t\t\t\t\t\t// 设置 state = 0\r\n      return true;\r\n  }\r\n  ```\r\n\r\n- `getTask()`：获取任务，线程空闲时间超过 keepAliveTime 就会被回收，判断的依据是**当前线程阻塞获取任务超过保活时间**，方法返回 null 就代表当前线程要被回收了，返回到 runWorker 执行线程退出逻辑。线程池具有担保机制，对于 RUNNING 状态下的超时回收，要保证线程池中最少有一个线程运行，或者任务阻塞队列已经是空\r\n\r\n  ```java\r\n  private Runnable getTask() {\r\n      // 超时标记，表示当前线程获取任务是否超时，true 表示已超时\r\n      boolean timedOut = false; \r\n      for (;;) {\r\n          int c = ctl.get();\r\n          // 获取线程池当前运行状态\r\n          int rs = runStateOf(c);\r\n  \t\t\r\n          // 【tryTerminate】打断线程后执行到这，此时线程池状态为STOP或者线程池状态为SHUTDOWN并且队列已经是空\r\n          // 所以下面的 if 条件一定是成立的，可以直接返回 null，线程就应该退出了\r\n          if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {\r\n              // 使用 CAS 自旋的方式让 ctl 值 -1\r\n              decrementWorkerCount();\r\n              return null;\r\n          }\r\n          \r\n  \t\t// 获取线程池中的线程数量\r\n          int wc = workerCountOf(c);\r\n  \r\n          // 线程没有明确的区分谁是核心或者非核心线程，是根据当前池中的线程数量判断\r\n          \r\n          // timed = false 表示当前这个线程 获取task时不支持超时机制的，当前线程会使用 queue.take() 阻塞获取\r\n          // timed = true 表示当前这个线程 获取task时支持超时机制，使用 queue.poll(xxx,xxx) 超时获取\r\n          // 条件一代表允许回收核心线程，那就无所谓了，全部线程都执行超时回收\r\n          // 条件二成立说明线程数量大于核心线程数，当前线程认为是非核心线程，有保活时间，去超时获取任务\r\n          boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;\r\n          \r\n  \t\t// 如果线程数量是超过最大线程数，直接回收\r\n          // 如果当前线程【允许超时回收并且已经超时了】，就应该被回收了，由于【担保机制】还要做判断：\r\n          // \t  wc > 1 说明线程池还用其他线程，当前线程可以直接回收\r\n          //    workQueue.isEmpty() 前置条件是 wc = 1，【如果当前任务队列也是空了，最后一个线程就可以退出】\r\n          if ((wc > maximumPoolSize || (timed && timedOut)) && (wc > 1 || workQueue.isEmpty())) {\r\n              // 使用 CAS 机制将 ctl 值 -1 ,减 1 成功的线程，返回 null，代表可以退出\r\n              if (compareAndDecrementWorkerCount(c))\r\n                  return null;\r\n              continue;\r\n          }\r\n  \r\n          try {\r\n              // 根据当前线程是否需要超时回收，【选择从队列获取任务的方法】是超时获取或者阻塞获取\r\n              Runnable r = timed ?\r\n                  workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take();\r\n              // 获取到任务返回任务，【阻塞获取会阻塞到获取任务为止】，不会返回 null\r\n              if (r != null)\r\n                  return r;\r\n              // 获取任务为 null 说明超时了，将超时标记设置为 true，下次自旋时返回 null\r\n              timedOut = true;\r\n          } catch (InterruptedException retry) {\r\n              // 阻塞线程被打断后超时标记置为 false，【说明被打断不算超时】，要继续获取，直到超时或者获取到任务\r\n              // 如果线程池 SHUTDOWN（STOP!） 状态下的打断，会在循环获取任务前判断，返回 null\r\n              timedOut = false;\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n  > 核心线程阻塞获取队列任务，救急线程超时获取队列任务；设置allowCoreThreadTimeOut为true，都超时获取队列任务\r\n\r\n- `processWorkerExit()`：**线程退出线程池**，也有担保机制，保证队列中的任务被执行\r\n\r\n  ```java\r\n  // 正常退出 completedAbruptly = false，异常退出为 true\r\n  private void processWorkerExit(Worker w, boolean completedAbruptly) {\r\n      // 条件成立代表当前 worker 是发生异常退出的，task 任务执行过程中向上抛出异常了\r\n      if (completedAbruptly) \r\n          // 从异常时到这里 ctl 一直没有 -1，需要在这里 -1\r\n          decrementWorkerCount();\r\n  \r\n      final ReentrantLock mainLock = this.mainLock;\r\n      // 加锁\r\n      mainLock.lock();\r\n      try {\r\n          // 将当前 worker 完成的 task 数量，汇总到线程池的 completedTaskCount\r\n          completedTaskCount += w.completedTasks;\r\n  \t\t// 将 worker 从线程池中移除\r\n          workers.remove(w);\r\n      } finally {\r\n          mainLock.unlock();\t// 解锁\r\n      }\r\n  \t// 尝试停止线程池，唤醒下一个线程\r\n      tryTerminate();\r\n  \r\n      int c = ctl.get();\r\n      // 线程池不是停止状态就应该有线程运行【担保机制】\r\n      if (runStateLessThan(c, STOP)) {\r\n          // 正常退出的逻辑，是对空闲线程回收，不是执行出错\r\n          if (!completedAbruptly) {\r\n              // 根据是否回收核心线程确定【线程池中的线程数量最小值】\r\n              int min = allowCoreThreadTimeOut ? 0 : corePoolSize;\r\n              // 最小值为 0，但是线程队列不为空，需要一个线程来完成任务担保机制\r\n              if (min == 0 && !workQueue.isEmpty())\r\n                  min = 1;\r\n              // 线程池中的线程数量大于最小值可以直接返回\r\n              if (workerCountOf(c) >= min)\r\n                  return;\r\n          }\r\n          // 执行 task 时发生异常，有个线程因为异常终止了，需要添加\r\n          // 或者线程池中的数量小于最小值，这里要创建一个新 worker 加进线程池\r\n          addWorker(null, false);\r\n      }\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n****\r\n\r\n\r\n\r\n##### 停止方法\r\n\r\n- `shutdown()`：停止线程池\r\n\r\n  ```java\r\n  public void shutdown() {\r\n      final ReentrantLock mainLock = this.mainLock;\r\n      // 获取线程池全局锁\r\n      mainLock.lock();\r\n      try {\r\n          checkShutdownAccess();\r\n          // 设置线程池状态为 SHUTDOWN，如果线程池状态大于 SHUTDOWN，就不会设置直接返回\r\n          advanceRunState(SHUTDOWN);\r\n          // 中断空闲线程\r\n          interruptIdleWorkers();\r\n          // 空方法，子类可以扩展\r\n          onShutdown(); \r\n      } finally {\r\n          // 释放线程池全局锁\r\n          mainLock.unlock();\r\n      }\r\n      tryTerminate();\r\n  }\r\n  ```\r\n\r\n- `interruptIdleWorkers()`：shutdown 方法会**中断所有空闲线程**，根据是否可以获取 AQS 独占锁判断是否处于工作状态。线程之所以空闲是因为阻塞队列没有任务，不会中断正在运行的线程，所以 shutdown 方法会让所有的任务执行完毕\r\n\r\n  ```java\r\n  // onlyOne == true 说明只中断一个线程 ，false 则中断所有线程\r\n  private void interruptIdleWorkers(boolean onlyOne) {\r\n      final ReentrantLock mainLock = this.mainLock;\r\n      //持有全局锁\r\n      mainLock.lock();\r\n      try {\r\n          // 遍历所有 worker\r\n          for (Worker w : workers) {\r\n              // 获取当前 worker 的线程\r\n              Thread t = w.thread;\r\n              // 条件一成立：说明当前迭代的这个线程尚未中断\r\n              // 条件二成立：说明【当前worker处于空闲状态】，阻塞在poll或者take，因为worker执行task时是要加锁的\r\n              //           每个worker有一个独占锁，w.tryLock()尝试加锁，加锁成功返回 true\r\n              if (!t.isInterrupted() && w.tryLock()) {\r\n                  try {\r\n                      // 中断线程，处于 queue 阻塞的线程会被唤醒，进入下一次自旋，返回 null，执行退出逻辑\r\n                      t.interrupt();\r\n                  } catch (SecurityException ignore) {\r\n                  } finally {\r\n                      // 释放worker的独占锁\r\n                      w.unlock();\r\n                  }\r\n              }\r\n              // false，代表中断所有的线程\r\n              if (onlyOne)\r\n                  break;\r\n          }\r\n  \r\n      } finally {\r\n          // 释放全局锁\r\n          mainLock.unlock();\r\n      }\r\n  }\r\n  ```\r\n\r\n- `shutdownNow()`：直接关闭线程池，不会等待任务执行完成\r\n\r\n  ```java\r\n  public List<Runnable> shutdownNow() {\r\n      // 返回值引用\r\n      List<Runnable> tasks;\r\n      final ReentrantLock mainLock = this.mainLock;\r\n      // 获取线程池全局锁\r\n      mainLock.lock();\r\n      try {\r\n          checkShutdownAccess();\r\n          // 设置线程池状态为STOP\r\n          advanceRunState(STOP);\r\n          // 中断线程池中【所有线程】\r\n          interruptWorkers();\r\n          // 从阻塞队列中导出未处理的task\r\n          tasks = drainQueue();\r\n      } finally {\r\n          mainLock.unlock();\r\n      }\r\n  \r\n      tryTerminate();\r\n      // 返回当前任务队列中 未处理的任务。\r\n      return tasks;\r\n  }\r\n  ```\r\n\r\n- `tryTerminate()`：设置为 TERMINATED 状态 `if either (SHUTDOWN and pool and queue empty) or (STOP and pool empty)`\r\n\r\n  ```java\r\n  final void tryTerminate() {\r\n      for (;;) {\r\n          // 获取 ctl 的值\r\n          int c = ctl.get();\r\n          // 线程池正常，或者有其他线程执行了状态转换的方法，当前线程直接返回\r\n          if (isRunning(c) || runStateAtLeast(c, TIDYING) ||\r\n              // 线程池是 SHUTDOWN 并且任务队列不是空，需要去处理队列中的任务\r\n              (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty()))\r\n              return;\r\n          \r\n          // 执行到这里说明线程池状态为 STOP 或者线程池状态为 SHUTDOWN 并且队列已经是空\r\n          // 判断线程池中线程的数量\r\n          if (workerCountOf(c) != 0) {\r\n              // 【中断一个空闲线程】，在 queue.take() | queue.poll() 阻塞空闲\r\n              // 唤醒后的线程会在getTask()方法返回null，\r\n              // 执行 processWorkerExit 退出逻辑时会再次调用 tryTerminate() 唤醒下一个空闲线程\r\n              interruptIdleWorkers(ONLY_ONE);\r\n              return;\r\n          }\r\n  \t\t// 池中的线程数量为 0 来到这里\r\n          final ReentrantLock mainLock = this.mainLock;\r\n          // 加全局锁\r\n          mainLock.lock();\r\n          try {\r\n              // 设置线程池状态为 TIDYING 状态，线程数量为 0\r\n              if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) {\r\n                  try {\r\n                      // 结束线程池\r\n                      terminated();\r\n                  } finally {\r\n                      // 设置线程池状态为TERMINATED状态。\r\n                      ctl.set(ctlOf(TERMINATED, 0));\r\n                      // 【唤醒所有调用 awaitTermination() 方法的线程】\r\n                      termination.signalAll();\r\n                  }\r\n                  return;\r\n              }\r\n          } finally {\r\n  \t\t\t// 释放线程池全局锁\r\n              mainLock.unlock();\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### Future\r\n\r\n##### 线程使用\r\n\r\nFutureTask 未来任务对象，继承 Runnable、Future 接口，用于包装 Callable 对象，实现任务的提交\r\n\r\n```java\r\npublic static void main(String[] args) throws ExecutionException, InterruptedException {\r\n    FutureTask<String> task = new FutureTask<>(new Callable<String>() {\r\n        @Override\r\n        public String call() throws Exception {\r\n            return \"Hello World\";\r\n        }\r\n    });\r\n    new Thread(task).start();\t//启动线程\r\n    String msg = task.get();\t//获取返回任务数据\r\n    System.out.println(msg);\r\n}\r\n```\r\n\r\n构造方法：\r\n\r\n```java\r\npublic FutureTask(Callable<V> callable){\r\n\tthis.callable = callable;\t// 属性注入\r\n    this.state = NEW; \t\t\t// 任务状态设置为 new\r\n}\r\n```\r\n\r\n```java\r\npublic FutureTask(Runnable runnable, V result) {\r\n    // 适配器模式\r\n    this.callable = Executors.callable(runnable, result);\r\n    this.state = NEW;       \r\n}\r\npublic static <T> Callable<T> callable(Runnable task, T result) {\r\n    if (task == null) throw new NullPointerException();\r\n    // 使用适配器模式将 runnable 转换成 callable 接口，外部线程通过 get 获取\r\n    // 当前任务执行结果时，结果可能为 null 也可能为传进来的值，【传进来什么返回什么】\r\n    return new RunnableAdapter<T>(task, result);\r\n}\r\nstatic final class RunnableAdapter<T> implements Callable<T> {\r\n    final Runnable task;\r\n    final T result;\r\n    // 构造方法\r\n    RunnableAdapter(Runnable task, T result) {\r\n        this.task = task;\r\n        this.result = result;\r\n    }\r\n    public T call() {\r\n        // 实则调用 Runnable#run 方法\r\n        task.run();\r\n        // 返回值为构造 FutureTask 对象时传入的返回值或者是 null\r\n        return result;\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 成员属性\r\n\r\nFutureTask 类的成员属性：\r\n\r\n- 任务状态：\r\n\r\n  ```java\r\n  // 表示当前task状态\r\n  private volatile int state;\r\n  // 当前任务尚未执行\r\n  private static final int NEW          = 0;\r\n  // 当前任务正在结束，尚未完全结束，一种临界状态\r\n  private static final int COMPLETING   = 1;\r\n  // 当前任务正常结束\r\n  private static final int NORMAL       = 2;\r\n  // 当前任务执行过程中发生了异常，内部封装的 callable.run() 向上抛出异常了\r\n  private static final int EXCEPTIONAL  = 3;\r\n  // 当前任务被取消\r\n  private static final int CANCELLED    = 4;\r\n  // 当前任务中断中\r\n  private static final int INTERRUPTING = 5;\r\n  // 当前任务已中断\r\n  private static final int INTERRUPTED  = 6;\r\n  ```\r\n\r\n- 任务对象：\r\n\r\n  ```java\r\n  private Callable<V> callable;\t// Runnable 使用适配器模式伪装成 Callable\r\n  ```\r\n\r\n- **存储任务执行的结果**，这是 run 方法返回值是 void 也可以获取到执行结果的原因：\r\n\r\n  ```java\r\n  // 正常情况下：任务正常执行结束，outcome 保存执行结果，callable 返回值\r\n  // 非正常情况：callable 向上抛出异常，outcome 保存异常\r\n  private Object outcome; \r\n  ```\r\n\r\n- 执行当前任务的线程对象：\r\n\r\n  ```java\r\n  private volatile Thread runner;\t// 当前任务被线程执行期间，保存当前执行任务的线程对象引用\r\n  ```\r\n\r\n- **线程阻塞队列的头节点**：\r\n\r\n  ```java\r\n  // 会有很多线程去 get 当前任务的结果，这里使用了一种数据结构头插头取（类似栈）的一个队列来保存所有的 get 线程\r\n  private volatile WaitNode waiters;\r\n  ```\r\n\r\n- 内部类：\r\n\r\n  ```java\r\n  static final class WaitNode {\r\n      // 单向链表\r\n      volatile Thread thread;\r\n      volatile WaitNode next;\r\n      WaitNode() { thread = Thread.currentThread(); }\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 成员方法\r\n\r\nFutureTask 类的成员方法：\r\n\r\n- `FutureTask#run`：任务执行入口\r\n\r\n  ```java\r\n  public void run() {\r\n      //条件一：成立说明当前 task 已经被执行过了或者被 cancel 了，非 NEW 状态的任务，线程就不需要处理了\r\n      //条件二：线程是 NEW 状态，尝试设置当前任务对象的线程是当前线程，设置失败说明其他线程抢占了该任务，直接返回\r\n      if (state != NEW ||\r\n          !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread()))\r\n          return;\r\n      try {\r\n          // 执行到这里，当前 task 一定是 NEW 状态，而且【当前线程也抢占 task 成功】\r\n          Callable<V> c = callable;\r\n          // 判断任务是否为空，防止空指针异常；判断 state 状态，防止外部线程在此期间 cancel 掉当前任务\r\n          // 【因为 task 的执行者已经设置为当前线程，所以这里是线程安全的】\r\n          if (c != null && state == NEW) {\r\n              V result;\r\n              // true 表示 callable.run 代码块执行成功 未抛出异常\r\n              // false 表示 callable.run 代码块执行失败 抛出异常\r\n              boolean ran;\r\n              try {\r\n  \t\t\t\t// 【调用自定义的方法，执行结果赋值给 result】\r\n                  result = c.call();\r\n                  // 没有出现异常\r\n                  ran = true;\r\n              } catch (Throwable ex) {\r\n                  // 出现异常，返回值置空，ran 置为 false\r\n                  result = null;\r\n                  ran = false;\r\n                  // 设置返回的异常\r\n                  setException(ex);\r\n              }\r\n              // 代码块执行正常\r\n              if (ran)\r\n                  // 设置返回的结果\r\n                  set(result);\r\n          }\r\n      } finally {\r\n          // 任务执行完成，取消线程的引用，help GC\r\n          runner = null;\r\n          int s = state;\r\n          // 判断任务是不是被中断\r\n          if (s >= INTERRUPTING)\r\n              // 执行中断处理方法\r\n              handlePossibleCancellationInterrupt(s);\r\n      }\r\n  }\r\n  ```\r\n\r\n  `FutureTask#set`：设置正常返回值，首先将任务状态设置为 COMPLETING 状态代表完成中，逻辑执行完设置为 NORMAL 状态代表任务正常执行完成，最后唤醒 get() 阻塞线程\r\n\r\n  ```java\r\n  protected void set(V v) {\r\n      // CAS 方式设置当前任务状态为完成中，设置失败说明其他线程取消了该任务\r\n      if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {\r\n          // 【将结果赋值给 outcome】\r\n          outcome = v;\r\n          // 将当前任务状态修改为 NORMAL 正常结束状态。\r\n          UNSAFE.putOrderedInt(this, stateOffset, NORMAL);\r\n          finishCompletion();\r\n      }\r\n  }\r\n  ```\r\n\r\n  `FutureTask#setException`：设置异常返回值\r\n\r\n  ```java\r\n  protected void setException(Throwable t) {\r\n      if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {\r\n          // 赋值给返回结果，用来向上层抛出来的异常\r\n          outcome = t;\r\n          // 将当前任务的状态 修改为 EXCEPTIONAL\r\n          UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL);\r\n          finishCompletion();\r\n      }\r\n  }\r\n  ```\r\n\r\n  `FutureTask#finishCompletion`：**唤醒 get() 阻塞线程**\r\n\r\n  ```java\r\n  private void finishCompletion() {\r\n      // 遍历所有的等待的节点，q 指向头节点\r\n      for (WaitNode q; (q = waiters) != null;) {\r\n          // 使用cas设置 waiters 为 null，防止外部线程使用cancel取消当前任务，触发finishCompletion方法重复执行\r\n          if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {\r\n              // 自旋\r\n              for (;;) {\r\n                  // 获取当前 WaitNode 节点封装的 thread\r\n                  Thread t = q.thread;\r\n                  // 当前线程不为 null，唤醒当前 get() 等待获取数据的线程\r\n                  if (t != null) {\r\n                      q.thread = null;\r\n                      LockSupport.unpark(t);\r\n                  }\r\n                  // 获取当前节点的下一个节点\r\n                  WaitNode next = q.next;\r\n                  // 当前节点是最后一个节点了\r\n                  if (next == null)\r\n                      break;\r\n                  // 断开链表\r\n                  q.next = null; // help gc\r\n                  q = next;\r\n              }\r\n              break;\r\n          }\r\n      }\r\n      done();\r\n      callable = null;\t// help GC\r\n  }\r\n  ```\r\n\r\n  `FutureTask#handlePossibleCancellationInterrupt`：任务中断处理\r\n\r\n  ```java\r\n  private void handlePossibleCancellationInterrupt(int s) {\r\n      if (s == INTERRUPTING)\r\n          // 中断状态中\r\n          while (state == INTERRUPTING)\r\n              // 等待中断完成\r\n              Thread.yield();\r\n  }\r\n  ```\r\n\r\n- `FutureTask#get`：获取任务执行的返回值，执行 run 和 get 的不是同一个线程，一般有多个线程 get，只有一个线程 run\r\n\r\n  ```java\r\n  public V get() throws InterruptedException, ExecutionException {\r\n      // 获取当前任务状态\r\n      int s = state;\r\n      // 条件成立说明任务还没执行完成\r\n      if (s <= COMPLETING)\r\n          // 返回 task 当前状态，可能当前线程在里面已经睡了一会\r\n          s = awaitDone(false, 0L);\r\n      return report(s);\r\n  }\r\n  ```\r\n\r\n  `FutureTask#awaitDone`：**get 线程封装成 WaitNode 对象进入阻塞队列阻塞等待**\r\n\r\n  ```java\r\n  private int awaitDone(boolean timed, long nanos) throws InterruptedException {\r\n      // 0 不带超时\r\n      final long deadline = timed ? System.nanoTime() + nanos : 0L;\r\n      // 引用当前线程，封装成 WaitNode 对象\r\n      WaitNode q = null;\r\n      // 表示当前线程 waitNode 对象，是否进入阻塞队列\r\n      boolean queued = false;\r\n      // 【三次自旋开始休眠】\r\n      for (;;) {\r\n          // 判断当前 get() 线程是否被打断，打断返回 true，清除打断标记\r\n          if (Thread.interrupted()) {\r\n              // 当前线程对应的等待 node 出队，\r\n              removeWaiter(q);\r\n              throw new InterruptedException();\r\n          }\r\n  \t\t// 获取任务状态\r\n          int s = state;\r\n          // 条件成立说明当前任务执行完成已经有结果了\r\n          if (s > COMPLETING) {\r\n              // 条件成立说明已经为当前线程创建了 WaitNode，置空 help GC\r\n              if (q != null)\r\n                  q.thread = null;\r\n              // 返回当前的状态\r\n              return s;\r\n          }\r\n          // 条件成立说明当前任务接近完成状态，这里让当前线程释放一下 cpu ，等待进行下一次抢占 cpu\r\n          else if (s == COMPLETING) \r\n              Thread.yield();\r\n          // 【第一次自旋】，当前线程还未创建 WaitNode 对象，此时为当前线程创建 WaitNode对象\r\n          else if (q == null)\r\n              q = new WaitNode();\r\n          // 【第二次自旋】，当前线程已经创建 WaitNode 对象了，但是node对象还未入队\r\n          else if (!queued)\r\n              // waiters 指向队首，让当前 WaitNode 成为新的队首，【头插法】，失败说明其他线程修改了新的队首\r\n              queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q);\r\n          // 【第三次自旋】，会到这里，或者 else 内\r\n          else if (timed) {\r\n              nanos = deadline - System.nanoTime();\r\n              if (nanos <= 0L) {\r\n                  removeWaiter(q);\r\n                  return state;\r\n              }\r\n              // 阻塞指定的时间\r\n              LockSupport.parkNanos(this, nanos);\r\n          }\r\n          // 条件成立：说明需要阻塞\r\n          else\r\n              // 【当前 get 操作的线程被 park 阻塞】，除非有其它线程将唤醒或者将当前线程中断\r\n              LockSupport.park(this);\r\n      }\r\n  }\r\n  ```\r\n\r\n  `FutureTask#report`：封装运行结果，可以获取 run() 方法中设置的成员变量 outcome，**这是 run 方法的返回值是 void 也可以获取到任务执行的结果的原因**\r\n\r\n  ```java\r\n  private V report(int s) throws ExecutionException {\r\n      // 获取执行结果，是在一个 futuretask 对象中的属性，可以直接获取\r\n      Object x = outcome;\r\n      // 当前任务状态正常结束\r\n      if (s == NORMAL)\r\n          return (V)x;\t// 直接返回 callable 的逻辑结果\r\n      // 当前任务被取消或者中断\r\n      if (s >= CANCELLED)\r\n          throw new CancellationException();\t\t// 抛出异常\r\n      // 执行到这里说明自定义的 callable 中的方法有异常，使用 outcome 上层抛出异常\r\n      throw new ExecutionException((Throwable)x);\t\r\n  }\r\n  ```\r\n\r\n- `FutureTask#cancel`：任务取消，打断正在执行该任务的线程\r\n\r\n  ```java\r\n  public boolean cancel(boolean mayInterruptIfRunning) {\r\n      // 条件一：表示当前任务处于运行中或者处于线程池任务队列中\r\n      // 条件二：表示修改状态，成功可以去执行下面逻辑，否则返回 false 表示 cancel 失败\r\n      if (!(state == NEW &&\r\n            UNSAFE.compareAndSwapInt(this, stateOffset, NEW,\r\n                                     mayInterruptIfRunning ? INTERRUPTING : CANCELLED)))\r\n          return false;\r\n      try {\r\n          // 如果任务已经被执行，是否允许打断\r\n          if (mayInterruptIfRunning) {\r\n              try {\r\n                  // 获取执行当前 FutureTask 的线程\r\n                  Thread t = runner;\r\n                  if (t != null)\r\n                      // 打断执行的线程\r\n                      t.interrupt();\r\n              } finally {\r\n                  // 设置任务状态为【中断完成】\r\n                  UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED);\r\n              }\r\n          }\r\n      } finally {\r\n          // 唤醒所有 get() 阻塞的线程\r\n          finishCompletion();\r\n      }\r\n      return true;\r\n  }\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 任务调度\r\n\r\n#### Timer\r\n\r\nTimer 实现定时功能，Timer 的优点在于简单易用，但由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务\r\n\r\n```java\r\nprivate static void method1() {\r\n    Timer timer = new Timer();\r\n    TimerTask task1 = new TimerTask() {\r\n        @Override\r\n        public void run() {\r\n            System.out.println(\"task 1\");\r\n            //int i = 1 / 0;//任务一的出错会导致任务二无法执行\r\n            Thread.sleep(2000);\r\n        }\r\n    };\r\n    TimerTask task2 = new TimerTask() {\r\n        @Override\r\n        public void run() {\r\n            System.out.println(\"task 2\");\r\n        }\r\n    };\r\n    // 使用 timer 添加两个任务，希望它们都在 1s 后执行\r\n\t// 但由于 timer 内只有一个线程来顺序执行队列中的任务，因此任务1的延时，影响了任务2的执行\r\n    timer.schedule(task1, 1000);//17:45:56 c.ThreadPool [Timer-0] - task 1\r\n    timer.schedule(task2, 1000);//17:45:58 c.ThreadPool [Timer-0] - task 2\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### Scheduled\r\n\r\n任务调度线程池 ScheduledThreadPoolExecutor 继承 ThreadPoolExecutor：\r\n\r\n- 使用内部类 ScheduledFutureTask 封装任务\r\n- 使用内部类 DelayedWorkQueue 作为线程池队列\r\n- 重写 onShutdown 方法去处理 shutdown 后的任务\r\n- 提供 decorateTask 方法作为 ScheduledFutureTask 的修饰方法，以便开发者进行扩展\r\n\r\n构造方法：`Executors.newScheduledThreadPool(int corePoolSize)`\r\n\r\n```java\r\npublic ScheduledThreadPoolExecutor(int corePoolSize) {\r\n    // 最大线程数固定为 Integer.MAX_VALUE，保活时间 keepAliveTime 固定为 0\r\n    super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\r\n          // 阻塞队列是 DelayedWorkQueue\r\n          new DelayedWorkQueue());\r\n}\r\n```\r\n\r\n常用 API：\r\n\r\n- `ScheduledFuture<?> schedule(Runnable/Callable<V>, long delay, TimeUnit u)`：延迟执行任务\r\n- `ScheduledFuture<?> scheduleAtFixedRate(Runnable/Callable<V>, long initialDelay, long period, TimeUnit unit)`：定时执行周期任务，不考虑执行的耗时，参数为初始延迟时间、间隔时间、单位\r\n- `ScheduledFuture<?> scheduleWithFixedDelay(Runnable/Callable<V>, long initialDelay, long delay, TimeUnit unit)`：定时执行周期任务，考虑执行的耗时，参数为初始延迟时间、间隔时间、单位\r\n\r\n基本使用：\r\n\r\n- 延迟任务，但是出现异常并不会在控制台打印，也不会影响其他线程的执行\r\n\r\n  ```java\r\n  public static void main(String[] args){\r\n      // 线程池大小为1时也是串行执行\r\n      ScheduledExecutorService executor = Executors.newScheduledThreadPool(2);\r\n      // 添加两个任务，都在 1s 后同时执行\r\n      executor.schedule(() -> {\r\n      \tSystem.out.println(\"任务1，执行时间：\" + new Date());\r\n          //int i = 1 / 0;\r\n      \ttry { Thread.sleep(2000); } catch (InterruptedException e) { }\r\n      }, 1000, TimeUnit.MILLISECONDS);\r\n      \r\n      executor.schedule(() -> {\r\n      \tSystem.out.println(\"任务2，执行时间：\" + new Date());\r\n      }, 1000, TimeUnit.MILLISECONDS);\r\n  }\r\n  ```\r\n\r\n- 定时任务 scheduleAtFixedRate：**一次任务的启动到下一次任务的启动**之间只要大于等于间隔时间，抢占到 CPU 就会立即执行\r\n\r\n  ```java\r\n  public static void main(String[] args) {\r\n      ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);\r\n      System.out.println(\"start...\" + new Date());\r\n      \r\n      pool.scheduleAtFixedRate(() -> {\r\n          System.out.println(\"running...\" + new Date());\r\n          Thread.sleep(2000);\r\n      }, 1, 1, TimeUnit.SECONDS);\r\n  }\r\n  \r\n  /*start...Sat Apr 24 18:08:12 CST 2021\r\n  running...Sat Apr 24 18:08:13 CST 2021\r\n  running...Sat Apr 24 18:08:15 CST 2021\r\n  running...Sat Apr 24 18:08:17 CST 2021\r\n  ```\r\n\r\n- 定时任务 scheduleWithFixedDelay：**一次任务的结束到下一次任务的启动之间**等于间隔时间，抢占到 CPU 就会立即执行，这个方法才是真正的设置两个任务之间的间隔\r\n\r\n  ```java\r\n  public static void main(String[] args){\r\n      ScheduledExecutorService pool = Executors.newScheduledThreadPool(3);\r\n      System.out.println(\"start...\" + new Date());\r\n      \r\n      pool.scheduleWithFixedDelay(() -> {\r\n          System.out.println(\"running...\" + new Date());\r\n          Thread.sleep(2000);\r\n      }, 1, 1, TimeUnit.SECONDS);\r\n  }\r\n  /*start...Sat Apr 24 18:11:41 CST 2021\r\n  running...Sat Apr 24 18:11:42 CST 2021\r\n  running...Sat Apr 24 18:11:45 CST 2021\r\n  running...Sat Apr 24 18:11:48 CST 2021\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 成员属性\r\n\r\n##### 成员变量\r\n\r\n- shutdown 后是否继续执行周期任务：\r\n\r\n  ```java\r\n  private volatile boolean continueExistingPeriodicTasksAfterShutdown;\r\n  ```\r\n\r\n- shutdown 后是否继续执行延迟任务：\r\n\r\n  ```java\r\n  private volatile boolean executeExistingDelayedTasksAfterShutdown = true;\r\n  ```\r\n\r\n- 取消方法是否将该任务从队列中移除：\r\n\r\n  ```java\r\n  // 默认 false，不移除，等到线程拿到任务之后抛弃\r\n  private volatile boolean removeOnCancel = false;\r\n  ```\r\n\r\n- 任务的序列号，可以用来比较优先级：\r\n\r\n  ```java\r\n  private static final AtomicLong sequencer = new AtomicLong();\r\n  ```\r\n\r\n  \r\n\r\n***\r\n\r\n\r\n\r\n##### 延迟任务\r\n\r\nScheduledFutureTask 继承 FutureTask，实现 RunnableScheduledFuture 接口，具有延迟执行的特点，覆盖 FutureTask 的 run 方法来实现对**延时执行、周期执行**的支持。对于延时任务调用 `FutureTask#run`，而对于周期性任务则调用 `FutureTask#runAndReset` 并且在成功之后根据 `fixed-delay/fixed-rate` 模式来设置下次执行时间并重新将任务塞到工作队列\r\n\r\n在调度线程池中无论是 runnable 还是 callable，无论是否需要延迟和定时，所有的任务都会被封装成 ScheduledFutureTask\r\n\r\n成员变量：\r\n\r\n- 任务序列号：\r\n\r\n  ```java\r\n  private final long sequenceNumber;\r\n  ```\r\n\r\n- 执行时间：\r\n\r\n  ```java\r\n  private long time;\t\t\t// 任务可以被执行的时间，交付时间，以纳秒表示\r\n  private final long period;\t// 0 表示非周期任务，正数表示 fixed-rate 模式的周期，负数表示 fixed-delay 模式\r\n  ```\r\n\r\n  `fixed-rate`：两次开始启动的间隔，`fixed-delay`：一次执行结束到下一次开始启动\r\n\r\n- 实际的任务对象：\r\n\r\n  ```java\r\n  RunnableScheduledFuture<V> outerTask = this;\r\n  ```\r\n\r\n- 任务在队列数组中的索引下标：\r\n\r\n  ```java\r\n  // DelayedWorkQueue 底层使用的数据结构是最小堆，记录当前任务在堆中的索引，-1 代表删除\r\n  int heapIndex;\r\n  ```\r\n\r\n成员方法：\r\n\r\n- 构造方法：\r\n\r\n  ```java\r\n  ScheduledFutureTask(Runnable r, V result, long ns, long period) {\r\n      super(r, result);\r\n      // 任务的触发时间\r\n      this.time = ns;\r\n      // 任务的周期，多长时间执行一次\r\n      this.period = period;\r\n      // 任务的序号\r\n      this.sequenceNumber = sequencer.getAndIncrement();\r\n  }\r\n  ```\r\n\r\n- `compareTo()`：ScheduledFutureTask 根据执行时间 time 正序排列，如果执行时间相同，在按照序列号 sequenceNumber 正序排列，任务需要放入 DelayedWorkQueue，延迟队列中使用该方法按照从小到大进行排序\r\n\r\n  ```java\r\n  public int compareTo(Delayed other) {\r\n      if (other == this) // compare zero if same object\r\n          return 0;\r\n      if (other instanceof ScheduledFutureTask) {\r\n          // 类型强转\r\n          ScheduledFutureTask<?> x = (ScheduledFutureTask<?>)other;\r\n          // 比较者 - 被比较者的执行时间\r\n          long diff = time - x.time;\r\n          // 比较者先执行\r\n          if (diff < 0)\r\n              return -1;\r\n          // 被比较者先执行\r\n          else if (diff > 0)\r\n              return 1;\r\n          // 比较者的序列号小\r\n          else if (sequenceNumber < x.sequenceNumber)\r\n              return -1;\r\n          else\r\n              return 1;\r\n      }\r\n      // 不是 ScheduledFutureTask 类型时，根据延迟时间排序\r\n      long diff = getDelay(NANOSECONDS) - other.getDelay(NANOSECONDS);\r\n      return (diff < 0) ? -1 : (diff > 0) ? 1 : 0;\r\n  }\r\n  ```\r\n\r\n- `run()`：执行任务，非周期任务直接完成直接结束，**周期任务执行完后会设置下一次的执行时间，重新放入线程池的阻塞队列**，如果线程池中的线程数量少于核心线程，就会添加 Worker 开启新线程\r\n\r\n  ```java\r\n  public void run() {\r\n      // 是否周期性，就是判断 period 是否为 0\r\n      boolean periodic = isPeriodic();\r\n      // 根据是否是周期任务检查当前状态能否执行任务，不能执行就取消任务\r\n      if (!canRunInCurrentRunState(periodic))\r\n          cancel(false);\r\n      // 非周期任务，直接调用 FutureTask#run 执行\r\n      else if (!periodic)\r\n          ScheduledFutureTask.super.run();\r\n      // 周期任务的执行，返回 true 表示执行成功\r\n      else if (ScheduledFutureTask.super.runAndReset()) {\r\n          // 设置周期任务的下一次执行时间\r\n          setNextRunTime();\r\n          // 任务的下一次执行安排，如果当前线程池状态可以执行周期任务，加入队列，并开启新线程\r\n          reExecutePeriodic(outerTask);\r\n      }\r\n  }\r\n  ```\r\n\r\n  周期任务正常完成后**任务的状态不会变化**，依旧是 NEW，不会设置 outcome 属性。但是如果本次任务执行出现异常，会进入 setException 方法将任务状态置为异常，把异常保存在 outcome 中，方法返回 false，后续的该任务将不会再周期的执行\r\n\r\n  ```java\r\n  protected boolean runAndReset() {\r\n      // 任务不是新建的状态了，或者被别的线程执行了，直接返回 false\r\n      if (state != NEW ||\r\n          !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread()))\r\n          return false;\r\n      boolean ran = false;\r\n      int s = state;\r\n      try {\r\n          Callable<V> c = callable;\r\n          if (c != null && s == NEW) {\r\n              try {\r\n                  // 执行方法，没有返回值\r\n                  c.call();\r\n                  ran = true;\r\n              } catch (Throwable ex) {\r\n                  // 出现异常，把任务设置为异常状态，唤醒所有的 get 阻塞线程\r\n                  setException(ex);\r\n              }\r\n          }\r\n      } finally {\r\n  \t\t// 执行完成把执行线程引用置为 null\r\n          runner = null;\r\n          s = state;\r\n          // 如果线程被中断进行中断处理\r\n          if (s >= INTERRUPTING)\r\n              handlePossibleCancellationInterrupt(s);\r\n      }\r\n      // 如果正常执行，返回 true，并且任务状态没有被取消\r\n      return ran && s == NEW;\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 任务下一次的触发时间\r\n  private void setNextRunTime() {\r\n      long p = period;\r\n      if (p > 0)\r\n          // fixed-rate 模式，【时间设置为上一次执行任务的时间 + p】，两次任务执行的时间差\r\n          time += p;\r\n      else\r\n          // fixed-delay 模式，下一次执行时间是【当前这次任务结束的时间（就是现在） + delay 值】\r\n          time = triggerTime(-p);\r\n  }\r\n  ```\r\n\r\n- `reExecutePeriodic()`**：准备任务的下一次执行，重新放入阻塞任务队列**\r\n\r\n  ```java\r\n  // ScheduledThreadPoolExecutor#reExecutePeriodic\r\n  void reExecutePeriodic(RunnableScheduledFuture<?> task) {\r\n      if (canRunInCurrentRunState(true)) {\r\n          // 【放入任务队列】\r\n          super.getQueue().add(task);\r\n          // 如果提交完任务之后，线程池状态变为了 shutdown 状态，需要再次检查是否可以执行，\r\n          // 如果不能执行且任务还在队列中未被取走，则取消任务\r\n          if (!canRunInCurrentRunState(true) && remove(task))\r\n              task.cancel(false);\r\n          else\r\n              // 当前线程池状态可以执行周期任务，加入队列，并【根据线程数量是否大于核心线程数确定是否开启新线程】\r\n              ensurePrestart();\r\n      }\r\n  }\r\n  ```\r\n\r\n- `cancel()`：取消任务\r\n\r\n  ```java\r\n  public boolean cancel(boolean mayInterruptIfRunning) {\r\n      // 调用父类 FutureTask#cancel 来取消任务\r\n      boolean cancelled = super.cancel(mayInterruptIfRunning);\r\n      // removeOnCancel 用于控制任务取消后是否应该从阻塞队列中移除\r\n      if (cancelled && removeOnCancel && heapIndex >= 0)\r\n          // 从等待队列中删除该任务，并调用 tryTerminate() 判断是否需要停止线程池\r\n          remove(this);\r\n      return cancelled;\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 延迟队列\r\n\r\nDelayedWorkQueue 是支持延时获取元素的阻塞队列，内部采用优先队列 PriorityQueue（小根堆、满二叉树）存储元素\r\n\r\n其他阻塞队列存储节点的数据结构大都是链表，**延迟队列是数组**，所以延迟队列出队头元素后需要**让其他元素（尾）替换到头节点**，防止空指针异常\r\n\r\n成员变量：\r\n\r\n- 容量：\r\n\r\n  ```java\r\n  private static final int INITIAL_CAPACITY = 16;\t\t\t// 初始容量\r\n  private int size = 0;\t\t\t\t\t\t\t\t\t// 节点数量\r\n  private RunnableScheduledFuture<?>[] queue = \r\n      new RunnableScheduledFuture<?>[INITIAL_CAPACITY];\t// 存放节点\r\n  ```\r\n\r\n- 锁：\r\n\r\n  ```java\r\n  private final ReentrantLock lock = new ReentrantLock();\t// 控制并发\r\n  private final Condition available = lock.newCondition();// 条件队列\r\n  ```\r\n\r\n- 阻塞等待头节点的线程：线程池内的某个线程去 take() 获取任务时，如果延迟队列顶层节点不为 null（队列内有任务），但是节点任务还不到触发时间，线程就去检查**队列的 leader字段**是否被占用\r\n\r\n  - 如果未被占用，则当前线程占用该字段，然后当前线程到 available 条件队列指定超时时间 `堆顶任务.time - now()` 挂起\r\n  - 如果被占用，当前线程直接到 available 条件队列不指定超时时间的挂起\r\n\r\n  ```java\r\n  // leader 在 available 条件队列内是首元素，它超时之后会醒过来，然后再次将堆顶元素获取走，获取走之后，take()结束之前，会调用是 available.signal() 唤醒下一个条件队列内的等待者，然后释放 lock，下一个等待者被唤醒后去到 AQS 队列，做 acquireQueue(node) 逻辑\r\n  private Thread leader = null;\r\n  ```\r\n\r\n成员方法\r\n\r\n- `offer()`：插入节点\r\n\r\n  ```java\r\n  public boolean offer(Runnable x) {\r\n      // 判空\r\n      if (x == null)\r\n          throw new NullPointerException();\r\n      RunnableScheduledFuture<?> e = (RunnableScheduledFuture<?>)x;\r\n      // 队列锁，增加删除数据时都要加锁\r\n      final ReentrantLock lock = this.lock;\r\n      lock.lock();\r\n      try {\r\n          int i = size;\r\n          // 队列数量大于存放节点的数组长度，需要扩容\r\n          if (i >= queue.length)\r\n              // 扩容为原来长度的 1.5 倍\r\n              grow();\r\n          size = i + 1;\r\n          // 当前是第一个要插入的节点\r\n          if (i == 0) {\r\n              queue[0] = e;\r\n              // 修改 ScheduledFutureTask 的 heapIndex 属性，表示该对象在队列里的下标\r\n              setIndex(e, 0);\r\n          } else {\r\n              // 向上调整元素的位置，并更新 heapIndex \r\n              siftUp(i, e);\r\n          }\r\n          // 情况1：当前任务是第一个加入到 queue 内的任务，所以在当前任务加入到 queue 之前，take() 线程会直接\r\n          //\t\t到 available 队列不设置超时的挂起，并不会去占用 leader 字段，这时需会唤醒一个线程 让它去消费\r\n         \t// 情况2：当前任务【优先级最高】，原堆顶任务可能还未到触发时间，leader 线程设置超时的在 available 挂起\r\n          //\t\t原先的 leader 等待的是原先的头节点，所以 leader 已经无效，需要将 leader 线程唤醒，\r\n          //\t\t唤醒之后它会检查堆顶，如果堆顶任务可以被消费，则直接获取走，否则继续成为 leader 等待新堆顶任务\r\n          if (queue[0] == e) {\r\n              // 将 leader 设置为 null\r\n              leader = null;\r\n              // 直接随便唤醒等待头结点的阻塞线程\r\n              available.signal();\r\n          }\r\n      } finally {\r\n          lock.unlock();\r\n      }\r\n      return true;\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 插入新节点后对堆进行调整，进行节点上移，保持其特性【节点的值小于子节点的值】，小顶堆\r\n  private void siftUp(int k, RunnableScheduledFuture<?> key) {\r\n      while (k > 0) {\r\n          // 父节点，就是堆排序\r\n          int parent = (k - 1) >>> 1;\r\n          RunnableScheduledFuture<?> e = queue[parent];\r\n          // key 和父节点比，如果大于父节点可以直接返回，否则就继续上浮\r\n          if (key.compareTo(e) >= 0)\r\n              break;\r\n          queue[k] = e;\r\n          setIndex(e, k);\r\n          k = parent;\r\n      }\r\n      queue[k] = key;\r\n      setIndex(key, k);\r\n  }\r\n  ```\r\n\r\n- `poll()`：非阻塞获取头结点，**获取执行时间最近并且可以执行的**\r\n\r\n  ```java\r\n  // 非阻塞获取\r\n  public RunnableScheduledFuture<?> poll() {\r\n      final ReentrantLock lock = this.lock;\r\n      lock.lock();\r\n      try {\r\n          // 获取队头节点，因为是小顶堆\r\n          RunnableScheduledFuture<?> first = queue[0];\r\n          // 头结点为空或者的延迟时间没到返回 null\r\n          if (first == null || first.getDelay(NANOSECONDS) > 0)\r\n              return null;\r\n          else\r\n              // 头结点达到延迟时间，【尾节点成为替代节点下移调整堆结构】，返回头结点\r\n              return finishPoll(first);\r\n      } finally {\r\n          lock.unlock();\r\n      }\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  private RunnableScheduledFuture<?> finishPoll(RunnableScheduledFuture<?> f) {\r\n      // 获取尾索引\r\n      int s = --size;\r\n      // 获取尾节点\r\n      RunnableScheduledFuture<?> x = queue[s];\r\n      // 将堆结构最后一个节点占用的 slot 设置为 null，因为该节点要尝试升级成堆顶，会根据特性下调\r\n      queue[s] = null;\r\n      // s == 0 说明 当前堆结构只有堆顶一个节点，此时不需要做任何的事情\r\n      if (s != 0)\r\n          // 从索引处 0 开始向下调整\r\n          siftDown(0, x);\r\n      // 出队的元素索引设置为 -1\r\n      setIndex(f, -1);\r\n      return f;\r\n  }\r\n  ```\r\n\r\n- `take()`：阻塞获取头节点，读取当前堆中最小的也就是触发时间最近的任务\r\n\r\n  ```java\r\n  public RunnableScheduledFuture<?> take() throws InterruptedException {\r\n      final ReentrantLock lock = this.lock;\r\n      // 保证线程安全\r\n      lock.lockInterruptibly();\r\n      try {\r\n          for (;;) {\r\n              // 头节点\r\n              RunnableScheduledFuture<?> first = queue[0];\r\n              if (first == null)\r\n                  // 等待队列不空，直至有任务通过 offer 入队并唤醒\r\n                  available.await();\r\n              else {\r\n                  // 获取头节点的延迟时间是否到时\r\n                  long delay = first.getDelay(NANOSECONDS);\r\n                  if (delay <= 0)\r\n                      // 到达触发时间，获取头节点并调整堆，重新选择延迟时间最小的节点放入头部\r\n                      return finishPoll(first);\r\n                  \r\n                  // 逻辑到这说明头节点的延迟时间还没到\r\n                  first = null;\r\n                  // 说明有 leader 线程在等待获取头节点，当前线程直接去阻塞等待\r\n                  if (leader != null)\r\n                      available.await();\r\n                  else {\r\n                      // 没有 leader 线程，【当前线程作为leader线程，并设置头结点的延迟时间作为阻塞时间】\r\n                      Thread thisThread = Thread.currentThread();\r\n                      leader = thisThread;\r\n                      try {\r\n                          // 在条件队列 available 使用带超时的挂起（堆顶任务.time - now() 纳秒值..）\r\n                          available.awaitNanos(delay);\r\n                          // 到达阻塞时间时，当前线程会从这里醒来来\r\n                      } finally {\r\n                          // t堆顶更新，leader 置为 null，offer 方法释放锁后，\r\n                          // 有其它线程通过 take/poll 拿到锁,读到 leader == null，然后将自身更新为leader。\r\n                          if (leader == thisThread)\r\n                              // leader 置为 null 用以接下来判断是否需要唤醒后继线程\r\n                              leader = null;\r\n                      }\r\n                  }\r\n              }\r\n          }\r\n      } finally {\r\n          // 没有 leader 线程，头结点不为 null，唤醒阻塞获取头节点的线程，\r\n          // 【如果没有这一步，就会出现有了需要执行的任务，但是没有线程去执行】\r\n          if (leader == null && queue[0] != null)\r\n              available.signal();\r\n          lock.unlock();\r\n      }\r\n  }\r\n  ```\r\n\r\n- `remove()`：删除节点，堆移除一个元素的时间复杂度是 `O(log n)`，**延迟任务维护了 heapIndex**，直接访问的时间复杂度是 `O(1)`，从而可以更快的移除元素，任务在队列中被取消后会进入该逻辑\r\n\r\n  ```java\r\n  public boolean remove(Object x) {\r\n      final ReentrantLock lock = this.lock;\r\n      lock.lock();\r\n      try {\r\n          // 查找对象在队列数组中的下标\r\n          int i = indexOf(x);\r\n          // 节点不存在，返回 false\r\n          if (i < 0)\r\n              return false;\r\n  \t\t// 修改元素的 heapIndex，-1 代表删除\r\n          setIndex(queue[i], -1);\r\n          // 尾索引是长度-1\r\n          int s = --size;\r\n          // 尾节点作为替代节点\r\n          RunnableScheduledFuture<?> replacement = queue[s];\r\n          queue[s] = null;\r\n          // s == i 说明头节点就是尾节点，队列空了\r\n          if (s != i) {\r\n              // 向下调整\r\n              siftDown(i, replacement);\r\n              // 说明没发生调整\r\n              if (queue[i] == replacement)\r\n                  // 上移和下移不可能同时发生，替代节点大于子节点时下移，否则上移\r\n                  siftUp(i, replacement);\r\n          }\r\n          return true;\r\n      } finally {\r\n          lock.unlock();\r\n      }\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n****\r\n\r\n\r\n\r\n#### 成员方法\r\n\r\n##### 提交任务\r\n\r\n- `schedule()`：延迟执行方法，并指定执行的时间，默认是当前时间\r\n\r\n  ```java\r\n  public void execute(Runnable command) {\r\n      // 以零延时任务的形式实现\r\n      schedule(command, 0, NANOSECONDS);\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  public ScheduledFuture<?> schedule(Runnable command, long delay, TimeUnit unit) {\r\n      // 判空\r\n      if (command == null || unit == null) throw new NullPointerException();\r\n      // 没有做任何操作，直接将 task 返回，该方法主要目的是用于子类扩展，并且【根据延迟时间设置任务触发的时间点】\r\n      RunnableScheduledFuture<?> t = decorateTask(command, new ScheduledFutureTask<Void>(\r\n          \t\t\t\t\t\t\t\t\t\t\tcommand, null, triggerTime(delay, unit)));\r\n      // 延迟执行\r\n      delayedExecute(t);\r\n      return t;\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  // 返回【当前时间 + 延迟时间】，就是触发当前任务执行的时间\r\n  private long triggerTime(long delay, TimeUnit unit) {\r\n      // 设置触发的时间\r\n      return triggerTime(unit.toNanos((delay < 0) ? 0 : delay));\r\n  }\r\n  long triggerTime(long delay) {\r\n      // 如果 delay < Long.Max_VALUE/2，则下次执行时间为当前时间 +delay\r\n      // 否则为了避免队列中出现由于溢出导致的排序紊乱,需要调用overflowFree来修正一下delay\r\n      return now() + ((delay < (Long.MAX_VALUE >> 1)) ? delay : overflowFree(delay));\r\n  }\r\n  ```\r\n\r\n  overflowFree 的原因：如果某个任务的 delay 为负数，说明当前可以执行（其实早该执行了）。阻塞队列中维护任务顺序是基于 compareTo 比较的，比较两个任务的顺序会用 time 相减。那么可能出现一个 delay 为正数减去另一个为负数的 delay，结果上溢为负数，则会导致 compareTo 产生错误的结果\r\n\r\n  ```java\r\n  private long overflowFree(long delay) {\r\n      Delayed head = (Delayed) super.getQueue().peek();\r\n      if (head != null) {\r\n          long headDelay = head.getDelay(NANOSECONDS);\r\n          // 判断一下队首的delay是不是负数，如果是正数就不用管，怎么减都不会溢出\r\n          // 否则拿当前 delay 减去队首的 delay 来比较看，如果不出现上溢，排序不会乱\r\n  \t\t// 不然就把当前 delay 值给调整为 Long.MAX_VALUE + 队首 delay\r\n          if (headDelay < 0 && (delay - headDelay < 0))\r\n              delay = Long.MAX_VALUE + headDelay;\r\n      }\r\n      return delay;\r\n  }\r\n  ```\r\n\r\n- `scheduleAtFixedRate()`：定时执行，一次任务的启动到下一次任务的启动的间隔\r\n\r\n  ```java\r\n  public ScheduledFuture<?> scheduleAtFixedRate(Runnable command, long initialDelay, long period,\r\n                                                TimeUnit unit) {\r\n      if (command == null || unit == null)\r\n          throw new NullPointerException();\r\n      if (period <= 0)\r\n          throw new IllegalArgumentException();\r\n      // 任务封装，【指定初始的延迟时间和周期时间】\r\n      ScheduledFutureTask<Void> sft =new ScheduledFutureTask<Void>(command, null,\r\n                                        triggerTime(initialDelay, unit), unit.toNanos(period));\r\n      // 默认返回本身\r\n      RunnableScheduledFuture<Void> t = decorateTask(command, sft);\r\n      sft.outerTask = t;\r\n      // 开始执行这个任务\r\n      delayedExecute(t);\r\n      return t;\r\n  }\r\n  ```\r\n\r\n- `scheduleWithFixedDelay()`：定时执行，一次任务的结束到下一次任务的启动的间隔\r\n\r\n  ```java\r\n  public ScheduledFuture<?> scheduleWithFixedDelay(Runnable command, long initialDelay, long delay,\r\n                                                   TimeUnit unit) {\r\n      if (command == null || unit == null) \r\n          throw new NullPointerException();\r\n      if (delay <= 0)\r\n          throw new IllegalArgumentException();\r\n      // 任务封装，【指定初始的延迟时间和周期时间】，周期时间为 - 表示是 fixed-delay 模式\r\n      ScheduledFutureTask<Void> sft = new ScheduledFutureTask<Void>(command, null,\r\n                                        triggerTime(initialDelay, unit), unit.toNanos(-delay));\r\n      RunnableScheduledFuture<Void> t = decorateTask(command, sft);\r\n      sft.outerTask = t;\r\n      delayedExecute(t);\r\n      return t;\r\n  }\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 运行任务\r\n\r\n- `delayedExecute()`：**校验线程池状态**，延迟或周期性任务的主要执行方法\r\n\r\n  ```java\r\n  private void delayedExecute(RunnableScheduledFuture<?> task) {\r\n      // 线程池是 SHUTDOWN 状态，需要执行拒绝策略\r\n      if (isShutdown())\r\n          reject(task);\r\n      else {\r\n          // 把当前任务放入阻塞队列，因为需要【获取执行时间最近的】，当前任务需要比较\r\n          super.getQueue().add(task);\r\n          // 线程池状态为 SHUTDOWN 并且不允许执行任务了，就从队列删除该任务，并设置任务的状态为取消状态\r\n          if (isShutdown() && !canRunInCurrentRunState(task.isPeriodic()) && remove(task))\r\n              task.cancel(false);\r\n          else\r\n              // 可以执行\r\n              ensurePrestart();\r\n      }\r\n  }\r\n  ```\r\n\r\n- `ensurePrestart()`：**开启线程执行任务**\r\n\r\n  ```java\r\n  // ThreadPoolExecutor#ensurePrestart\r\n  void ensurePrestart() {\r\n      int wc = workerCountOf(ctl.get());\r\n      // worker数目小于corePoolSize，则添加一个worker。\r\n      if (wc < corePoolSize)\r\n          // 第二个参数 true 表示采用核心线程数量限制，false 表示采用 maximumPoolSize\r\n          addWorker(null, true);\r\n      // corePoolSize = 0的情况，至少开启一个线程，【担保机制】\r\n      else if (wc == 0)\r\n          addWorker(null, false);\r\n  }\r\n  ```\r\n\r\n- `canRunInCurrentRunState()`：任务运行时都会被调用以校验当前状态是否可以运行任务\r\n\r\n  ```java\r\n  boolean canRunInCurrentRunState(boolean periodic) {\r\n      // 根据是否是周期任务判断，在线程池 shutdown 后是否继续执行该任务，默认非周期任务是继续执行的\r\n      return isRunningOrShutdown(periodic ? continueExistingPeriodicTasksAfterShutdown :\r\n                                 executeExistingDelayedTasksAfterShutdown);\r\n  }\r\n  ```\r\n\r\n- `onShutdown()`：删除并取消工作队列中的不需要再执行的任务\r\n\r\n  ```java\r\n  void onShutdown() {\r\n      BlockingQueue<Runnable> q = super.getQueue();\r\n      // shutdown 后是否仍然执行延时任务\r\n      boolean keepDelayed = getExecuteExistingDelayedTasksAfterShutdownPolicy();\r\n      // shutdown 后是否仍然执行周期任务\r\n      boolean keepPeriodic = getContinueExistingPeriodicTasksAfterShutdownPolicy();\r\n      // 如果两者皆不可，则对队列中【所有任务】调用 cancel 取消并清空队列\r\n      if (!keepDelayed && !keepPeriodic) {\r\n          for (Object e : q.toArray())\r\n              if (e instanceof RunnableScheduledFuture<?>)\r\n                  ((RunnableScheduledFuture<?>) e).cancel(false);\r\n          q.clear();\r\n      }\r\n      else {\r\n          for (Object e : q.toArray()) {\r\n              if (e instanceof RunnableScheduledFuture) {\r\n                  RunnableScheduledFuture<?> t = (RunnableScheduledFuture<?>)e;\r\n                  // 不需要执行的任务删除并取消，已经取消的任务也需要从队列中删除\r\n                  if ((t.isPeriodic() ? !keepPeriodic : !keepDelayed) ||\r\n                      t.isCancelled()) {\r\n                      if (q.remove(t))\r\n                          t.cancel(false);\r\n                  }\r\n              }\r\n          }\r\n      }\r\n      // 因为任务被从队列中清理掉，所以需要调用 tryTerminate 尝试【改变线程池的状态】\r\n      tryTerminate();\r\n  }\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### ForkJoin\r\n\r\n`Fork/Join`：线程池的实现，体现是分治思想，适用于能够进行任务拆分的 CPU 密集型运算，用于**并行计算**\r\n\r\n任务拆分：将一个大任务拆分为算法上相同的小任务，直至不能拆分可以直接求解。跟递归相关的一些计算，如归并排序、斐波那契数列都可以用分治思想进行求解\r\n\r\n- `Fork/Join` 在**分治的基础上加入了多线程**，把每个任务的分解和合并交给不同的线程来完成，提升了运算效率\r\n\r\n- ForkJoin 使用 ForkJoinPool 来启动，是一个特殊的线程池，默认会创建与 CPU 核心数大小相同的线程池\r\n- 任务有返回值继承 RecursiveTask，没有返回值继承 RecursiveAction\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    ForkJoinPool pool = new ForkJoinPool(4);\r\n    System.out.println(pool.invoke(new MyTask(5)));\r\n    //拆分  5 + MyTask(4) --> 4 + MyTask(3) -->\r\n}\r\n\r\n// 1~ n 之间整数的和\r\nclass MyTask extends RecursiveTask<Integer> {\r\n    private int n;\r\n\r\n    public MyTask(int n) {\r\n        this.n = n;\r\n    }\r\n\r\n    @Override\r\n    public String toString() {\r\n        return \"MyTask{\" + \"n=\" + n + '}';\r\n    }\r\n\r\n    @Override\r\n    protected Integer compute() {\r\n        // 如果 n 已经为 1，可以求得结果了\r\n        if (n == 1) {\r\n            return n;\r\n        }\r\n        // 将任务进行拆分(fork)\r\n        MyTask t1 = new MyTask(n - 1);\r\n        t1.fork();\r\n        // 合并(join)结果\r\n        int result = n + t1.join();\r\n        return result;\r\n    }\r\n}\r\n```\r\n\r\n继续拆分优化：\r\n\r\n```java\r\nclass AddTask extends RecursiveTask<Integer> {\r\n    int begin;\r\n    int end;\r\n    public AddTask(int begin, int end) {\r\n        this.begin = begin;\r\n        this.end = end;\r\n    }\r\n    \r\n    @Override\r\n    public String toString() {\r\n        return \"{\" + begin + \",\" + end + '}';\r\n    }\r\n    \r\n    @Override\r\n    protected Integer compute() {\r\n        // 5, 5\r\n        if (begin == end) {\r\n            return begin;\r\n        }\r\n        // 4, 5  防止多余的拆分  提高效率\r\n        if (end - begin == 1) {\r\n            return end + begin;\r\n        }\r\n        // 1 5\r\n        int mid = (end + begin) / 2; // 3\r\n        AddTask t1 = new AddTask(begin, mid); // 1,3\r\n        t1.fork();\r\n        AddTask t2 = new AddTask(mid + 1, end); // 4,5\r\n        t2.fork();\r\n        int result = t1.join() + t2.join();\r\n        return result;\r\n    }\r\n}\r\n```\r\n\r\nForkJoinPool 实现了**工作窃取算法**来提高 CPU 的利用率：\r\n\r\n- 每个线程都维护了一个**双端队列**，用来存储需要执行的任务\r\n- 工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行\r\n- 窃取的必须是**最晚的任务**，避免和队列所属线程发生竞争，但是队列中只有一个任务时还是会发生竞争\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 享元模式\r\n\r\n享元模式（Flyweight pattern）： 用于减少创建对象的数量，以减少内存占用和提高性能，这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式\r\n\r\n异步模式：让有限的工作线程（Worker Thread）来轮流异步处理无限多的任务，也可将其归类为分工模式，典型实现就是线程池\r\n\r\n工作机制：享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象\r\n\r\n自定义连接池：\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    Pool pool = new Pool(2);\r\n    for (int i = 0; i < 5; i++) {\r\n        new Thread(() -> {\r\n            Connection con = pool.borrow();\r\n            try {\r\n                Thread.sleep(new Random().nextInt(1000));\r\n            } catch (InterruptedException e) {\r\n                e.printStackTrace();\r\n            }\r\n            pool.free(con);\r\n        }).start();\r\n    }\r\n}\r\nclass Pool {\r\n    //连接池的大小\r\n    private final int poolSize;\r\n    //连接对象的数组\r\n    private Connection[] connections;\r\n    //连接状态数组 0表示空闲  1表示繁忙\r\n    private AtomicIntegerArray states;  //int[] -> AtomicIntegerArray\r\n\r\n    //构造方法\r\n    public Pool(int poolSize) {\r\n        this.poolSize = poolSize;\r\n        this.connections = new Connection[poolSize];\r\n        this.states = new AtomicIntegerArray(new int[poolSize]);\r\n        for (int i = 0; i < poolSize; i++) {\r\n            connections[i] = new MockConnection(\"连接\" + (i + 1));\r\n        }\r\n    }\r\n\r\n    //使用连接\r\n    public Connection borrow() {\r\n        while (true) {\r\n            for (int i = 0; i < poolSize; i++) {\r\n                if (states.get(i) == 0) {\r\n                    if (states.compareAndSet(i, 0, 1)) {\r\n                        System.out.println(Thread.currentThread().getName() + \" borrow \" +  connections[i]);\r\n                        return connections[i];\r\n                    }\r\n                }\r\n            }\r\n            //如果没有空闲连接，当前线程等待\r\n            synchronized (this) {\r\n                try {\r\n                    System.out.println(Thread.currentThread().getName() + \" wait...\");\r\n                    this.wait();\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    //归还连接\r\n    public void free(Connection con) {\r\n        for (int i = 0; i < poolSize; i++) {\r\n            if (connections[i] == con) {//判断是否是同一个对象\r\n                states.set(i, 0);//不用cas的原因是只会有一个线程使用该连接\r\n                synchronized (this) {\r\n                    System.out.println(Thread.currentThread().getName() + \" free \" + con);\r\n                    this.notifyAll();\r\n                }\r\n                break;\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n\r\nclass MockConnection implements Connection {\r\n    private String name;\r\n    //.....\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n"},{"title":"设计模式之抽象责任链模式-Chain","tags":["Spring Boot","策略模式"],"categories":["Java","设计模式"],"author":"imklaus","excerpt":"\r\n\r\n## 责任链模式\r\n\r\n### 1. 什么是责任链\r\n\r\n责任链设计模式是一种行为型设计模式，其主要目的是解耦请求发送者和请求接收者，让多个对象都有机会处理请求，从而避免请求发送者和接收者之间的紧耦合。\r\n\r\n","link":"/posts/Design_Patterns-Chain","content":"\r\n\r\n## 责任链模式\r\n\r\n### 1. 什么是责任链\r\n\r\n责任链设计模式是一种行为型设计模式，其主要目的是解耦请求发送者和请求接收者，让多个对象都有机会处理请求，从而避免请求发送者和接收者之间的紧耦合。\r\n\r\n<!-- more -->\r\n\r\n责任链模式的核心是一个链式结构，链中每个节点代表一个处理者对象，请求先经过第一个节点处理，如果该节点能够处理请求，则直接返回处理结果；否则，请求继续往下一个节点传递，直到找到能够处理该请求的节点为止。整个过程类似于流水线上的多个工作站，每个工作站负责一项工作，如果自己处理不了，就将工作交给下一个工作站，直到整个工作完成。\r\n\r\n在责任链模式中，每个处理者对象都有一个指向下一个处理者对象的引用，这样就形成了一个处理者链。请求发送者只需要将请求发送给第一个节点即可，而不用关心请求会被哪个处理者对象处理。由于每个处理者对象都有机会处理请求，因此责任链模式可以实现请求的动态分配。\r\n\r\n### 2. 优缺点\r\n\r\n责任链模式的优点在于，它可以动态地添加、删除和调整处理者对象，从而灵活地构建处理链。同时，它也避免了请求发送者和接收者之间的紧耦合，增强了系统的灵活性和可扩展性。\r\n\r\n不过，责任链模式也有一定的缺点，例如如果处理链过长或者处理时间过长，可能会对系统性能产生一定的影响。\r\n\r\n### 3. 应用场景\r\n\r\n在实际应用中，责任链模式常用于请求的预处理、请求的过滤、请求的分发等场景。例如，可以使用责任链模式来实现权限校验、日志记录、异常处理、请求重试等功能。同时，也可以将责任链模式与其他设计模式结合起来，例如装饰器模式、工厂模式、观察者模式等，从而实现更复杂的功能。\r\n\r\n## 下单场景实战\r\n\r\n### 1. 下单前置校验\r\n\r\n在电商系统下单接口中，前置校验是非常重要的环节。下面是一个可能的校验步骤列表：\r\n\r\n- 检查商品信息是否存在，包括商品名称、价格、规格等信息。\r\n- 检查购买数量是否合法，是否超出了最大购买数量或最小购买数量的限制。\r\n- 检查商品库存是否充足，以确保库存足够满足购买者的需求。\r\n- 检查购买者的优惠券、积分等是否可以使用，以确保购买者能够享受相应的优惠或积分奖励。\r\n- 检查收货地址信息是否完整和准确，以确保商品能够顺利地送达给购买者。\r\n- 检查下单时间是否合法，例如检查购买者是否在限定的时间范围内下单。\r\n\r\n真实电商场景中，验证逻辑绝对不仅仅是这些，过之而无不及。\r\n\r\n对于完成这些前置校验逻辑，大部分程序员可能的代码思路如下：\r\n\r\n```java\r\npublic String createOrder(CreateOrderReqDTO xxx) {\r\n    // 检查商品信息是否存在，包括商品名称、价格、规格等信息\r\n  \t// 检查购买数量是否合法，是否超出了最大购买数量或最小购买数量的限制\r\n    // 检查商品库存是否充足，以确保库存足够满足购买者的需求\r\n    // 检查购买者的优惠券、积分等是否可以使用，以确保购买者能够享受相应的优惠或积分奖励\r\n    // 检查收货地址信息是否完整和准确，以确保商品能够顺利地送达给购买者\r\n    // 检查下单时间是否合法，例如检查购买者是否在限定的时间范围内下单\r\n    // ......\r\n}\r\n\r\npublic String createOrder(CreateOrderReqDTO xxx) {\r\n    // 检查商品信息是否存在，包括商品名称、价格、规格等信息\r\n  \t// 检查购买数量是否合法，是否超出了最大购买数量或最小购买数量的限制\r\n    // 检查商品库存是否充足，以确保库存足够满足购买者的需求\r\n    // 检查购买者的优惠券、积分等是否可以使用，以确保购买者能够享受相应的优惠或积分奖励\r\n    // 检查收货地址信息是否完整和准确，以确保商品能够顺利地送达给购买者\r\n    // 检查下单时间是否合法，例如检查购买者是否在限定的时间范围内下单\r\n    // ......\r\n}\r\n```\r\n\r\n解决前置校验需求需要实现一堆逻辑，常常需要写上几百上千行代码。\r\n\r\n为了避免这种代码臃肿的情况，我们可以运用责任链设计模式，对下单验证逻辑进行抽象。\r\n\r\n### 2. 责任链重构\r\n\r\n定义一个责任链处理器接口，所有子任务都实现该接口以处理具体的业务逻辑。\r\n\r\n同时，为了方便对责任链流程中的任务进行顺序处理，我们需要继承 Spring 框架中的排序接口 Ordered。这将有助于保证责任链中的任务顺序执行。\r\n\r\n```java\r\npublic interface OrderCreateChainHandler<T> extends Ordered {\r\n    \r\n    /**\r\n     * 执行责任链逻辑\r\n     *\r\n     * @param requestParam 责任链执行入参\r\n     */\r\n    void handler(T requestParam);\r\n}\r\n\r\npublic interface OrderCreateChainHandler<T> extends Ordered {\r\n    \r\n    /**\r\n     * 执行责任链逻辑\r\n     *\r\n     * @param requestParam 责任链执行入参\r\n     */\r\n    void handler(T requestParam);\r\n}\r\n```\r\n\r\n创建一个责任链上下文容器，用于存储与责任链相应的子任务。\r\n\r\n```java\r\npublic final class OrderCreateChainContext<T> implements CommandLineRunner {\r\n    \r\n    private final List<OrderCreateChainHandler> orderCreateChainHandlerContainer = new ArrayList();\r\n    \r\n    /**\r\n     * 责任链组件执行\r\n     *\r\n     * @param requestParam 请求参数\r\n     */\r\n    public void handler(T requestParam) {\r\n        // 此处根据 Ordered 实际值进行排序处理\r\n        orderCreateChainHandlerContainer.stream()\r\n                .sorted(Comparator.comparing(Ordered::getOrder)).forEach(each -> each.handler(requestParam));\r\n    }\r\n    \r\n    @Override\r\n    public void run(String... args) throws Exception {\r\n      \t// 通过 Spring 上下文容器，获取所有 CreateOrderChainContext Bean\r\n        Map<String, OrderCreateChainHandler> chainFilterMap = ApplicationContextHolder.getBeansOfType(OrderCreateChainHandler.class);\r\n      \t// 将对应 Bean 放入责任链上下文容器中\r\n        chainFilterMap.forEach((beanName, bean) -> orderCreateChainHandlerContainer.add(bean););\r\n    }\r\n}\r\n\r\npublic final class OrderCreateChainContext<T> implements CommandLineRunner {\r\n    \r\n    private final List<OrderCreateChainHandler> orderCreateChainHandlerContainer = new ArrayList();\r\n    \r\n    /**\r\n     * 责任链组件执行\r\n     *\r\n     * @param requestParam 请求参数\r\n     */\r\n    public void handler(T requestParam) {\r\n        // 此处根据 Ordered 实际值进行排序处理\r\n        orderCreateChainHandlerContainer.stream()\r\n                .sorted(Comparator.comparing(Ordered::getOrder)).forEach(each -> each.handler(requestParam));\r\n    }\r\n    \r\n    @Override\r\n    public void run(String... args) throws Exception {\r\n      \t// 通过 Spring 上下文容器，获取所有 CreateOrderChainContext Bean\r\n        Map<String, OrderCreateChainHandler> chainFilterMap = ApplicationContextHolder.getBeansOfType(OrderCreateChainHandler.class);\r\n      \t// 将对应 Bean 放入责任链上下文容器中\r\n        chainFilterMap.forEach((beanName, bean) -> orderCreateChainHandlerContainer.add(bean););\r\n    }\r\n}\r\n```\r\n\r\n实现 `OrderCreateChainHandler` 接口作为责任链处理器，每个具体的实现类负责执行特定的逻辑。\r\n\r\n```java\r\n// 订单创建参数必填检验\r\n@Component\r\npublic final class OrderCreateParamNotNullChainHandler implements OrderCreateChainHandler<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 0;\r\n    }\r\n}\r\n\r\n// 订单创建参数正确性检验\r\n@Component\r\npublic final class OrderCreateParamVerificationChainHandler implements OrderCreateChainHandler<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 1;\r\n    }\r\n}\r\n\r\n// 订单创建商品 SKU 库存验证\r\n@Component\r\npublic final class OrderCreateProductSkuStockChainHandler implements OrderCreateChainHandler<OrderCreateCommand> {\r\n\r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 2;\r\n    }\r\n}\r\n\r\n// 订单创建参数必填检验\r\n@Component\r\npublic final class OrderCreateParamNotNullChainHandler implements OrderCreateChainHandler<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 0;\r\n    }\r\n}\r\n\r\n// 订单创建参数正确性检验\r\n@Component\r\npublic final class OrderCreateParamVerificationChainHandler implements OrderCreateChainHandler<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 1;\r\n    }\r\n}\r\n\r\n// 订单创建商品 SKU 库存验证\r\n@Component\r\npublic final class OrderCreateProductSkuStockChainHandler implements OrderCreateChainHandler<OrderCreateCommand> {\r\n\r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 2;\r\n    }\r\n}\r\n```\r\n\r\n通过责任链模式优化，创建订单接口前置校验代码从上千行缩减为一行。\r\n\r\n```java\r\n@RequiredArgsConstructor\r\npublic class OrderServiceImpl implements OrderService {\r\n\r\n    private final OrderCreateChainContext<OrderCreateCommand> orderCreateChainContext;\r\n  \r\n    public String createOrder(OrderCreateCommand requestParam) {\r\n        // 责任链模式: 执行订单创建参数验证\r\n        orderCreateChainContext.handler(requestParam);\r\n    }\r\n}\r\n\r\n@RequiredArgsConstructor\r\npublic class OrderServiceImpl implements OrderService {\r\n\r\n    private final OrderCreateChainContext<OrderCreateCommand> orderCreateChainContext;\r\n  \r\n    public String createOrder(OrderCreateCommand requestParam) {\r\n        // 责任链模式: 执行订单创建参数验证\r\n        orderCreateChainContext.handler(requestParam);\r\n    }\r\n}\r\n```\r\n\r\n经过责任链模式的重构，你是否发现业务逻辑变得更加清晰易懂了？采用这种设计模式后，增加或删除相关的业务逻辑变得非常方便，不再需要担心更改上千行代码的几行代码，导致整个业务逻辑受到影响的情况。\r\n\r\n## 责任链抽象\r\n\r\n可能细心的小伙伴会发现一个问题，当业务使用越来越多的情况下，重复定义 `OrderCreateChainHandler` 以及 `OrderCreateChainContext` 会增加系统冗余代码量。\r\n\r\n可以考虑将这两个基础类抽象出来，作为基础组件库中的通用组件，供所有系统下的业务使用，从而避免代码冗余。\r\n\r\n如果想了解如何实现这一操作，请跟随马哥的思路继续往下阅读。\r\n\r\n### 1. 抽象基础类\r\n\r\n定义抽象责任链处理接口，等同于 `OrderCreateChainHandler`。\r\n\r\n```java\r\npublic interface AbstractChainHandler<T> extends Ordered {\r\n    \r\n    /**\r\n     * 执行责任链逻辑\r\n     *\r\n     * @param requestParam 责任链执行入参\r\n     */\r\n    void handler(T requestParam);\r\n    \r\n    /**\r\n     * @return 责任链组件标识\r\n     */\r\n    String mark();\r\n}\r\n\r\npublic interface AbstractChainHandler<T> extends Ordered {\r\n    \r\n    /**\r\n     * 执行责任链逻辑\r\n     *\r\n     * @param requestParam 责任链执行入参\r\n     */\r\n    void handler(T requestParam);\r\n    \r\n    /**\r\n     * @return 责任链组件标识\r\n     */\r\n    String mark();\r\n}\r\n```\r\n\r\n`mark` 方法是做什么的？接口增加 `mark` 方法，以便不同业务使用不同的标识。\r\n\r\n假设项目中有两个业务场景：订单下单和用户创建都需要责任链模式去验证，那么在业务中进行调用责任链时传递不同的 `mark` 方法参数即可。\r\n\r\n定义抽象责任链上下文，等同于 `OrderCreateChainContext`。可以看到保存责任链处理类的容器从 List 改为了 Map，这样可以方便扩展更多的不同业务责任链子类。\r\n\r\n假设项目中有两个业务场景：订单下单和用户创建都需要责任链模式去验证，`mark` 就是用来进行分组，在业务中进行调用责任链时传递不同的 `mark` 方法参数，通过该参数找到对应的一组责任链具体实现类集合。\r\n\r\n```java\r\npublic final class AbstractChainContext<T> implements CommandLineRunner {\r\n    \r\n    private final Map<String, List<AbstractChainHandler>> abstractChainHandlerContainer = Maps.newHashMap();\r\n    \r\n    /**\r\n     * 责任链组件执行\r\n     *\r\n     * @param requestParam 请求参数\r\n     */\r\n    public void handler(String mark, T requestParam) {\r\n        abstractChainHandlerContainer.get(mark).stream()\r\n                .sorted(Comparator.comparing(Ordered::getOrder)).forEach(each -> each.handler(requestParam));\r\n    }\r\n    \r\n    @Override\r\n    public void run(String... args) throws Exception {\r\n        // 获取 Spring IOC 容器中所有 AbstractChainHandler 接口实现\r\n        Map<String, AbstractChainHandler> chainFilterMap = ApplicationContextHolder.getBeansOfType(AbstractChainHandler.class);\r\n        chainFilterMap.forEach((beanName, bean) -> {\r\n            List<AbstractChainHandler> abstractChainHandlers = abstractChainHandlerContainer.get(bean.mark());\r\n            if (abstractChainHandlers == null) {\r\n                abstractChainHandlers = new ArrayList();\r\n            }\r\n            abstractChainHandlers.add(bean);\r\n            // 根据 mark 标识将责任链模式分类，放入责任链容器上下文中\r\n            abstractChainHandlerContainer.put(bean.mark(), abstractChainHandlers);\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n这两个接口已经被放置在基础组件库中，如果业务需要使用责任链模式，则无需重新定义。\r\n\r\n现在，让我们来看看业务代码需要编写哪些逻辑。\r\n\r\n### 2. 抽象业务接口\r\n\r\n让我们先进行头脑风暴，思考一下这个接口的用途是什么？\r\n\r\n```java\r\n// 订单创建责任链过滤器\r\npublic interface OrderCreateChainFilter<T extends OrderCreateCommand> extends AbstractChainHandler<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    default String mark() {\r\n        return OrderChainMarkEnum.ORDER_CREATE_FILTER.name();\r\n    }\r\n}\r\n\r\n// 订单创建责任链过滤器\r\npublic interface OrderCreateChainFilter<T extends OrderCreateCommand> extends AbstractChainHandler<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    default String mark() {\r\n        return OrderChainMarkEnum.ORDER_CREATE_FILTER.name();\r\n    }\r\n}\r\n```\r\n\r\n首先，如果没有 `OrderCreateChainFilter` 接口，会是什么样的场景？\r\n\r\n- 由于责任链处理子类都需要依赖顶级抽象接口，因此要想知道某个业务场景下有多少具体子类是相当困难的。\r\n- 由于责任链处理子类都需要实现 Mark 方法，实际上某一类责任链子类的 Mark 方法返回值是相同的。\r\n\r\n通过在业务层面上抽象出一个具体业务责任链接口，就能很好地解决上述两个问题。\r\n\r\n现在，让我们继续探讨责任链子类的编写。实际上，改动并不多，只需要将之前的 `OrderCreateChainHandler` 实现接口改为 `OrderCreateChainFilter` 即可。\r\n\r\n```java\r\n// 订单创建参数必填检验\r\n@Component\r\npublic final class OrderCreateParamNotNullChainHandler implements OrderCreateChainFilter<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 0;\r\n    }\r\n}\r\n\r\n// 订单创建参数正确性检验\r\n@Component\r\npublic final class OrderCreateParamVerificationChainHandler implements OrderCreateChainFilter<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 1;\r\n    }\r\n}\r\n\r\n// 订单创建商品 SKU 库存验证\r\n@Component\r\npublic final class OrderCreateProductSkuStockChainHandler implements OrderCreateChainFilter<OrderCreateCommand> {\r\n\r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 2;\r\n    }\r\n}\r\n\r\n// 订单创建参数必填检验\r\n@Component\r\npublic final class OrderCreateParamNotNullChainHandler implements OrderCreateChainFilter<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 0;\r\n    }\r\n}\r\n\r\n// 订单创建参数正确性检验\r\n@Component\r\npublic final class OrderCreateParamVerificationChainHandler implements OrderCreateChainFilter<OrderCreateCommand> {\r\n    \r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 1;\r\n    }\r\n}\r\n\r\n// 订单创建商品 SKU 库存验证\r\n@Component\r\npublic final class OrderCreateProductSkuStockChainHandler implements OrderCreateChainFilter<OrderCreateCommand> {\r\n\r\n    @Override\r\n    public void handler(OrderCreateCommand requestParam) {\r\n\t\t\t\t// 逻辑执行\r\n    }\r\n    \r\n    @Override\r\n    public int getOrder() {\r\n        return 2;\r\n    }\r\n}\r\n```\r\n\r\n### 3. 业务使用\r\n\r\n在具体业务场景中使用时，与之前相比并没有太大的差别。除了增加了 Mark 标识外，没有进行其他变更。\r\n\r\n```java\r\n@RequiredArgsConstructor\r\npublic class OrderServiceImpl implements OrderService {\r\n\r\n    private final AbstractChainContext<OrderCreateCommand> abstractChainContext;\r\n  \r\n    public String createOrder(OrderCreateCommand requestParam) {\r\n        // 责任链模式: 执行订单创建参数验证\r\n        abstractChainContext.handler(OrderChainMarkEnum.ORDER_CREATE_FILTER.name(), requestParam);\r\n    }\r\n}\r\n\r\n@RequiredArgsConstructor\r\npublic class OrderServiceImpl implements OrderService {\r\n\r\n    private final AbstractChainContext<OrderCreateCommand> abstractChainContext;\r\n  \r\n    public String createOrder(OrderCreateCommand requestParam) {\r\n        // 责任链模式: 执行订单创建参数验证\r\n        abstractChainContext.handler(OrderChainMarkEnum.ORDER_CREATE_FILTER.name(), requestParam);\r\n    }\r\n}\r\n```\r\n\r\n## 文末总结\r\n\r\n本文详细介绍了责任链模式的概念，并通过电商下单场景模拟了真实使用场景。\r\n\r\n为了复用责任链接口定义和上下文，我们通过抽象的方式将责任链门面接口加入到基础组件库中，实现快速接入责任链的目的。\r\n\r\n虽然在本文中，我们没有使用 boolean 类型的返回值，而是通过异常来终止流程，但在后续的增强中，我们可以考虑添加布尔类型的返回值。\r\n\r\n此外，我们还可以在 `AbstractChainHandler` 中增加是否异步执行的方法，以提高方法执行性能和减少接口响应时间。\r\n\r\n架构设计总是在不断演进，本文的设计也有优化和进步的空间，让我们继续探索责任链模式的更多可能性。"},{"title":"设计模式之抽象策略模式-Strategy","tags":["Spring Boot","策略模式"],"categories":["Java","设计模式"],"author":"imklaus","excerpt":"\r\n## 策略模式是什么\r\n\r\n策略模式在 GoF 的《设计模式》一书中，是这样定义的：\r\n\r\n> Define a family of algorithms, encapsulate each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it.\r\n>\r\n\r\n策略设计模式（Strategy Pattern）是一种面向对象设计模式，它定义了一系列算法，并将每个算法封装起来，使它们可以相互替换。这种模式使得算法可以独立于使用它们的客户端而变化。\r\n\r\n","link":"/posts/Design_Patterns-Strategy","content":"\r\n## 策略模式是什么\r\n\r\n策略模式在 GoF 的《设计模式》一书中，是这样定义的：\r\n\r\n> Define a family of algorithms, encapsulate each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it.\r\n>\r\n\r\n策略设计模式（Strategy Pattern）是一种面向对象设计模式，它定义了一系列算法，并将每个算法封装起来，使它们可以相互替换。这种模式使得算法可以独立于使用它们的客户端而变化。\r\n\r\n<!-- more -->\r\n\r\n策略设计模式包含三个主要的角色：\r\n\r\n> 1. 环境（Context）：持有一个策略对象，并调用其算法。\r\n> 2. 策略（Strategy）：定义了一组算法，并将每个算法封装起来，使它们可以相互替换。\r\n> 3. 具体策略（ConcreteStrategy）：实现了策略接口，提供了具体的算法实现。\r\n>\r\n\r\n在策略设计模式中，环境持有一个策略对象，并通过调用策略的算法来完成具体的任务。策略对象可以根据需要进行替换，从而实现不同的算法实现，并且可以在运行时动态地更改策略对象。\r\n\r\n看到上面的介绍可能不太明白策略模式具体为何物，这里会从最基本的代码说起，一步一步彻底掌握此模式。\r\n\r\n## 优惠类型实战\r\n\r\n下述代码可能大家都能联想出对应的业务，**根据对应的优惠类型，对价格作出相应的优惠。**\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1672473955617-630ff21a-2791-428d-bebd-bb953989f57d.png)\r\n\r\n这段代码是能够满足项目中业务需求的，而且很多已上线生产环境的代码也有这类代码。但是，这一段代码存在存在两个弊端：\r\n\r\n1. 代码的复杂性，正常业务代码逻辑肯定会比这个代码块复杂很多，这也就 **导致了 if-else 的分支以及代码数量过多**。这种方式可以通过将代码拆分成独立函数或者拆分成类来解决。\r\n2. 开闭原则，价格优惠肯定会 **随着不同的时期作出不同的改变**，或许新增、删除或修改。如果在一个函数中修改无疑是件恐怖的事情，想想可能多个开发者分别进行开发，杂乱无章的注释，混乱的代码逻辑等情况十有八九会发生。\r\n\r\n如何运用策略模式优化上述代码，使程序设计看着简约、可扩展等特性。\r\n\r\n1. 简化代码的复杂性，将不同的优惠类型定义为不同的策略算法实现类。\r\n2. 保证开闭原则，增加程序的健壮性以及可扩展性。\r\n\r\n将上述代码块改造为策略设计模式，大致需要三个步骤。\r\n\r\n1. 定义抽象策略接口，因为业务使用接口而不是具体的实现类的话，便可以灵活的替换不同的策略；\r\n2. 定义具体策略实现类，实现自抽象策略接口，其内部封装具体的业务实现；\r\n3. 定义策略工厂，封装创建策略实现（算法），对客户端屏蔽具体的创建细节。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1672473992392-4b6d78d6-47ab-4d98-afe7-110143827b6b.png)\r\n\r\n目前把抽象策略接口、具体的策略实现类以及策略工厂都已经创建了，现在可以看一下客户端需要如何调用，又是如何对客户端屏蔽具体实现细节的。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1672474008299-8d04739e-21e7-4c18-bf06-ca39a837ed9b.png)\r\n\r\n根据代码块图片得知，具体策略类是从策略工厂中获取，确实是取消了 if-else 设计，**在工厂中使用 Map 存储策略实现**。获取到策略类后执行具体的优惠策略方法就可以获取优惠后的金额。\r\n\r\n通过分析大家得知，目前这种设计确实将应用代码的复杂性降低了。**如果新增一个优惠策略，只需要新增一个策略算法实现类即可**。但是，添加一个策略算法实现，**意味着需要改动策略工厂中的代码**，还是不符合开闭原则。\r\n\r\n如何完整实现符合开闭原则的策略模式，需要借助 Spring 的帮助，详细案例请继续往下看。\r\n\r\n## 策略模式结合 Spring\r\n\r\n最近项目中设计的一个功能用到了策略模式，分为两类角色，笔者负责定义抽象策略接口以及策略工厂，不同的策略算法需要各个业务方去实现，可以联想到上文中的优惠券功能。因为是 Spring 项目，所以都是按照 Spring 的方式进行处理。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1672474038315-5988975f-07d4-452f-95d9-f8e7921915fe.png)\r\n\r\n可以看到，比对上面的示例代码，有两处明显的变化：\r\n\r\n1. 抽象策略接口中，新定义了 mark() 接口，此接口用来标示算法的唯一性；\r\n2. 具体策略实现类，使用 @Component 修饰，将对象本身交由 Spring 进行管理 。\r\n\r\n小贴士：为了阅读方便，mark() 返回直接使用字符串替代，读者朋友在返回标示时最好使用枚举定义。\r\n\r\n接下来继续查看抽象策略工厂如何改造，才能满足开闭原则。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1672474063847-3dacf3d3-dcdc-4219-9b74-47191e535764.png)\r\n\r\n通过 InitializingBean 接口实现中调用 IOC 容器查找对应策略实现，随后将策略实现 mark() 方法返回值作为 key， 策略实现本身作为 value 添加到 Map 容器中等待客户端的调用。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1672474079146-767a091f-05ec-4dd8-9d3d-379981a8d0bb.png)\r\n\r\n这里使用的 SpringBoot 测试类，注入策略工厂 Bean，通过策略工厂选择出具体的策略算法类，继而通过算法获取到优惠后的价格。\r\n\r\n总结下本小节，我们通过和 Spring 结合的方式，通过策略设计模式对文初的代码块进行了两块优化：应对代码的复杂性，让其满足开闭原则。\r\n\r\n更具体一些呢就是 **通过抽象策略算法类减少代码的复杂性，继而通过 Spring 的一些特性同时满足了开闭原则**，现在来了新需求只要添加新的策略类即可，健壮易扩展。\r\n\r\n## 策略模式优缺点\r\n\r\n策略设计模式的优点包括：\r\n\r\n1. 提高了代码的灵活性和可维护性：由于算法的实现与使用相分离，使得代码的灵活性和可维护性得到提高。当需要修改或添加新的算法时，只需要定义新的策略类，并将其传递给环境类即可，而无需修改环境类的代码。\r\n2. 提高了代码的复用性：策略设计模式将算法的实现封装在策略类中，使得算法可以被多个客户端重复使用，从而提高了代码的复用性。\r\n3. 可以动态地切换算法：策略设计模式将算法封装在策略类中，使得可以在运行时动态地更改算法，从而实现不同的功能和行为。这样可以使得程序更加灵活，适应不同的需求和变化。\r\n4. 算法实现与使用相分离：策略设计模式将算法的实现与使用相分离，使得代码更加清晰、简洁、易于维护和扩展。由于算法的实现被封装在策略类中，客户端只需要关注如何选择和使用不同的算法即可，这样可以使得代码更加易于理解和维护。\r\n5. 可以避免使用大量的条件语句：在某些情况下，需要根据不同的条件来选择不同的算法，这可能会导致代码中出现大量的条件语句，使得代码难以维护和扩展。而策略设计模式可以避免这种情况的发生，使得代码更加简洁和易于维护。\r\n\r\n需要注意的是，在使用策略设计模式时需要注意以下几点：\r\n\r\n1. 策略类之间应该是相互独立的，彼此之间不应该有任何依赖关系。这样才能确保算法的选择和替换可以在运行时动态地进行，同时也可以避免代码的耦合度过高。\r\n2. 策略接口应该尽可能地简单和通用，以便于不同的策略实现类可以共用同一个接口。这样可以提高代码的复用性和灵活性，同时也可以避免接口过于复杂和难以维护。\r\n3. 策略设计模式适用于需要在运行时动态切换算法的场景，如果算法的实现不需要动态切换，或者算法的实现较为简单，策略设计模式可能会显得过于复杂。因此，在选择使用策略设计模式时，需要根据具体的需求和场景进行判断和选择。\r\n4. 策略设计模式可以与其他设计模式结合使用，例如工厂方法模式、单例模式等。这样可以进一步提高代码的灵活性和可维护性，同时也可以避免代码的复杂度过高。\r\n\r\n## 框架源码应用\r\n\r\n自己用肯定觉得不够，必要时候还得看看设计开源框架源码的大佬们如何在代码中运用策略模式的。\r\n\r\n在马哥了解中，JDK、Spring、SpringMvc、Mybatis、Dubbo 等等都运用了策略设计模式，这里就以 Mybatis 举例说明。\r\n\r\nMybatis 中 Executor 代表执行器，负责增删改查的具体操作。其中用到了两种设计模式，模版方法以及策略模式。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1672474104169-3317d8bf-5313-470e-9626-4a317ccaf396.png)\r\n\r\n- Executor 代表了抽象策略接口，刚才说到的模版方法模式源自 BaseExecutor。\r\n- Configuration 代表策略工厂，负责创建具体的策略算法实现类。\r\n- SimpleExecuto、ReuseExecutor... 表示封装了具体的策略算法实现类。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1672474128984-76fc2c9a-91b8-4f34-8643-a64bd58bc4bf.png)\r\n\r\n上述代码块发生在 Configuration 类中创建执行器 Executor，通过 executorType 判断创建不同的策略算法。\r\n\r\n上述代码块并没有彻底消除 if-else，因为 Mybatis 中执行器策略基本是固定的，也就是说它只会有这些 if-else 判断，基本不会新增或修改。如果非要消除 if-else，可以这么搞，这里写一下伪代码。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1672474150395-2d817442-442a-4e13-9df8-1642324d57d8.png)\r\n\r\n这种方式叫做 **\"查表法\"**，通过策略工厂实现消除 if-else 分支。最后，Mybatis 太过详细的设计这里不再赘述，有兴趣的小伙伴可以去把源码下载啃一啃。\r\n\r\n到了这里可能有读者看出了问题，**策略模式就算消除了 if-else 但是如果添加新的策略类，不还是会违反开闭原则么？**\r\n\r\n没错，因为 Mybatis 本身没有引入 Spring 依赖，**所以没有办法借助 IOC 容器实现开闭原则**。Spring 是一种开闭原则解决方式，那还有没有别的解决方式？\r\n\r\n解决方式有很多，开闭原则核心就是 **对原有代码修改关闭，对新增代码开放**。可以通过扫描指定包下的自定义注解亦或者通过 instanceof 判断是否继承自某接口都可以。\r\n\r\n## 策略模式抽象\r\n\r\n可能细心的小伙伴会发现一个问题，当业务使用越来越多的情况下，重复定义 `DiscountStrategy` 以及 `DiscountStrategyFactory` 会增加系统冗余代码量。\r\n\r\n可以考虑将这两个基础类抽象出来，作为基础组件库中的通用组件，供所有系统下的业务使用，从而避免代码冗余。\r\n\r\n定义抽象策略处理接口，添加有返回值和无返回值接口。\r\n\r\n```java\r\n/**\r\n * 策略执行抽象\r\n */\r\npublic interface AbstractExecuteStrategy<REQUEST, RESPONSE> {\r\n    \r\n    /**\r\n     * 执行策略标识\r\n     */\r\n    String mark();\r\n    \r\n    /**\r\n     * 执行策略\r\n     *\r\n     * @param requestParam 执行策略入参\r\n     */\r\n    default void execute(REQUEST requestParam) {\r\n        \r\n    }\r\n    \r\n    /**\r\n     * 执行策略，带返回值\r\n     *\r\n     * @param requestParam 执行策略入参\r\n     * @return 执行策略后返回值\r\n     */\r\n    default RESPONSE executeResp(REQUEST requestParam) {\r\n        return null;\r\n    }\r\n}\r\n```\r\n\r\n添加策略选择器，通过订阅 Spring 初始化事件执行扫描所有策略模式接口执行器，并根据 mark 方法定义标识添加到 `abstractExecuteStrategyMap` 容器中。\r\n\r\n客户端在实际业务中使用 `AbstractStrategyChoose#choose` 即可完成策略模式实现。\r\n\r\n```java\r\n/**\r\n * 策略选择器\r\n */\r\npublic class AbstractStrategyChoose implements ApplicationListener<ApplicationInitializingEvent> {\r\n    \r\n    /**\r\n     * 执行策略集合\r\n     */\r\n    private final Map<String, AbstractExecuteStrategy> abstractExecuteStrategyMap = new HashMap<>();\r\n    \r\n    /**\r\n     * 根据 mark 查询具体策略\r\n     *\r\n     * @param mark 策略标识\r\n     * @return 实际执行策略\r\n     */\r\n    public AbstractExecuteStrategy choose(String mark) {\r\n        return Optional.ofNullable(abstractExecuteStrategyMap.get(mark)).orElseThrow(() -> new ServiceException(String.format(\"[%s] 策略未定义\", mark)));\r\n    }\r\n    \r\n    /**\r\n     * 根据 mark 查询具体策略并执行\r\n     *\r\n     * @param mark         策略标识\r\n     * @param requestParam 执行策略入参\r\n     * @param <REQUEST>    执行策略入参范型\r\n     */\r\n    public <REQUEST> void chooseAndExecute(String mark, REQUEST requestParam) {\r\n        AbstractExecuteStrategy executeStrategy = choose(mark);\r\n        executeStrategy.execute(requestParam);\r\n    }\r\n    \r\n    /**\r\n     * 根据 mark 查询具体策略并执行，带返回结果\r\n     *\r\n     * @param mark         策略标识\r\n     * @param requestParam 执行策略入参\r\n     * @param <REQUEST>    执行策略入参范型\r\n     * @param <RESPONSE>   执行策略出参范型\r\n     * @return\r\n     */\r\n    public <REQUEST, RESPONSE> RESPONSE chooseAndExecuteResp(String mark, REQUEST requestParam) {\r\n        AbstractExecuteStrategy executeStrategy = choose(mark);\r\n        return (RESPONSE) executeStrategy.executeResp(requestParam);\r\n    }\r\n    \r\n    @Override\r\n    public void onApplicationEvent(ApplicationInitializingEvent event) {\r\n        Map<String, AbstractExecuteStrategy> actual = ApplicationContextHolder.getBeansOfType(AbstractExecuteStrategy.class);\r\n        actual.forEach((beanName, bean) -> {\r\n            AbstractExecuteStrategy beanExist = abstractExecuteStrategyMap.get(bean.mark());\r\n            if (beanExist != null) {\r\n                throw new ServiceException(String.format(\"[%s] Duplicate execution policy\", bean.mark()));\r\n            }\r\n            abstractExecuteStrategyMap.put(bean.mark(), bean);\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n这两个实现已经被放置在基础组件库中，如果业务需要使用策略模式，则无需重新定义。\r\n\r\n\r\n\r\n## 策略模式实现\r\n\r\n### 列车座位选择器\r\n\r\n#### 购票时列车座位选择器\r\n\r\n```java\r\n@Slf4j\r\n@Component\r\n@RequiredArgsConstructor\r\npublic final class TrainSeatTypeSelector {\r\n\r\n    ......\r\n    private final AbstractStrategyChoose abstractStrategyChoose;\r\n\r\n    public List<TrainPurchaseTicketRespDTO> select(Integer trainType, PurchaseTicketReqDTO requestParam) {\r\n       ......\r\n            List<TrainPurchaseTicketRespDTO> aggregationResult = abstractStrategyChoose.chooseAndExecuteResp(buildStrategyKey, selectSeatDTO);\r\n\t   ......\r\n    }\r\n}\r\n```\r\n\r\n#### 抽象高铁购票模板基础服务\r\n\r\n```java\r\n@FunctionalInterface\r\npublic interface CommandLineRunner {\r\n    void run(String... args) throws Exception;\r\n}\r\n/**\r\n * 购票顶级抽象接口，为后续火车、高铁、汽车、飞机等出行工具规定行为约束\r\n */\r\npublic interface IPurchaseTicket {\r\n}\r\n\r\n\r\npublic abstract class AbstractTrainPurchaseTicketTemplate implements IPurchaseTicket, CommandLineRunner, AbstractExecuteStrategy<SelectSeatDTO, List<TrainPurchaseTicketRespDTO>> {\r\n\r\n    private DistributedCache distributedCache;\r\n    private String ticketAvailabilityCacheUpdateType;\r\n\r\n    /**\r\n     * 选择座位\r\n     *\r\n     * @param requestParam 购票请求入参\r\n     * @return 乘车人座位\r\n     */\r\n    protected abstract List<TrainPurchaseTicketRespDTO> selectSeats(SelectSeatDTO requestParam);\r\n\r\n    protected TrainSeatBaseDTO buildTrainSeatBaseDTO(SelectSeatDTO requestParam) {\r\n        return TrainSeatBaseDTO.builder()\r\n                .trainId(requestParam.getRequestParam().getTrainId())\r\n                .departure(requestParam.getRequestParam().getDeparture())\r\n                .arrival(requestParam.getRequestParam().getArrival())\r\n                .chooseSeatList(requestParam.getRequestParam().getChooseSeats())\r\n                .passengerSeatDetails(requestParam.getPassengerSeatDetails())\r\n                .build();\r\n    }\r\n\r\n    @Override\r\n    public List<TrainPurchaseTicketRespDTO> executeResp(SelectSeatDTO requestParam) {\r\n        List<TrainPurchaseTicketRespDTO> actualResult = selectSeats(requestParam);\r\n        // 扣减车厢余票缓存，扣减站点余票缓存\r\n        if (CollUtil.isNotEmpty(actualResult) && !StrUtil.equals(ticketAvailabilityCacheUpdateType, \"binlog\")) {\r\n            String trainId = requestParam.getRequestParam().getTrainId();\r\n            String departure = requestParam.getRequestParam().getDeparture();\r\n            String arrival = requestParam.getRequestParam().getArrival();\r\n            String keySuffix = StrUtil.join(\"_\", trainId, departure, arrival);\r\n            StringRedisTemplate stringRedisTemplate = (StringRedisTemplate) distributedCache.getInstance();\r\n            stringRedisTemplate.opsForHash().increment(TRAIN_STATION_REMAINING_TICKET + keySuffix, String.valueOf(requestParam.getSeatType()), -actualResult.size());\r\n        }\r\n        return actualResult;\r\n    }\r\n\r\n    @Override\r\n    public void run(String... args) throws Exception {\r\n        distributedCache = ApplicationContextHolder.getBean(DistributedCache.class);\r\n        ConfigurableEnvironment configurableEnvironment = ApplicationContextHolder.getBean(ConfigurableEnvironment.class);\r\n        ticketAvailabilityCacheUpdateType = configurableEnvironment.getProperty(\"ticket.availability.cache-update.type\", \"\");\r\n    }\r\n}\r\n```\r\n\r\n#### 高铁各座位类型购票组件\r\n\r\n```java\r\n/**\r\n * 高铁商务座购票组件\r\n */\r\n@Component\r\n@RequiredArgsConstructor\r\npublic class TrainBusinessClassPurchaseTicketHandler extends AbstractTrainPurchaseTicketTemplate {\r\n\r\n    private final SeatService seatService;\r\n\r\n    private static final Map<Character, Integer> SEAT_Y_INT = Map.of('A', 0, 'C', 1, 'F', 2);\r\n\r\n    @Override\r\n    public String mark() {\r\n        return VehicleTypeEnum.HIGH_SPEED_RAIN.getName() + VehicleSeatTypeEnum.BUSINESS_CLASS.getName();\r\n    }\r\n\r\n    @Override\r\n    protected List<TrainPurchaseTicketRespDTO> selectSeats(SelectSeatDTO requestParam) {\r\n        ......\r\n    }\r\n\t......\r\n}\r\n\r\n/**\r\n * 高铁一等座购票组件\r\n */\r\n@Component\r\n@RequiredArgsConstructor\r\npublic class TrainFirstClassPurchaseTicketHandler extends AbstractTrainPurchaseTicketTemplate {\r\n\r\n    private final SeatService seatService;\r\n\r\n    private static final Map<Character, Integer> SEAT_Y_INT = Map.of('A', 0, 'C', 1, 'D', 2, 'F', 3);\r\n\r\n    @Override\r\n    public String mark() {\r\n        return VehicleTypeEnum.HIGH_SPEED_RAIN.getName() + VehicleSeatTypeEnum.FIRST_CLASS.getName();\r\n    }\r\n\r\n    @Override\r\n    protected List<TrainPurchaseTicketRespDTO> selectSeats(SelectSeatDTO requestParam) {\r\n         ......\r\n    }\r\n\t......\r\n}\r\n/**\r\n * 高铁二等座购票组件\r\n */\r\n@Component\r\n@RequiredArgsConstructor\r\npublic class TrainSecondClassPurchaseTicketHandler extends AbstractTrainPurchaseTicketTemplate {\r\n\r\n    private final SeatService seatService;\r\n    private final DistributedCache distributedCache;\r\n\r\n    @Override\r\n    public String mark() {\r\n        return VehicleTypeEnum.HIGH_SPEED_RAIN.getName() + VehicleSeatTypeEnum.SECOND_CLASS.getName();\r\n    }\r\n\r\n    @Override\r\n    protected List<TrainPurchaseTicketRespDTO> selectSeats(SelectSeatDTO requestParam) {\r\n          ......\r\n    }\r\n\t......\r\n}\r\n```\r\n\r\n#### 应用选择器选择并执行具体策略处理器\r\n\r\n```java\r\n/**\r\n * 车票接口实现\r\n */\r\n@Slf4j\r\n@Service\r\n@RequiredArgsConstructor\r\npublic class TicketServiceImpl extends ServiceImpl<TicketMapper, TicketDO> implements TicketService {\r\n    private final TrainSeatTypeSelector trainSeatTypeSelector;\r\n    ......\r\n    @Override\r\n    @Transactional(rollbackFor = Throwable.class)\r\n    public TicketPurchaseRespDTO executePurchaseTickets(PurchaseTicketReqDTO requestParam) \t   {\r\n        ......\r\n        List<TrainPurchaseTicketRespDTO> trainPurchaseTicketResults = trainSeatTypeSelector.select(trainDO.getTrainType(), requestParam);\r\n        ......\r\n    }\r\n    ......\r\n}\r\n        \r\n```\r\n\r\n### 登录选择\r\n\r\n#### 账号登录\r\n\r\n##### 登录策略执行处理器\r\n\r\n```java\r\n@Component\r\n@AllArgsConstructor\r\npublic class AccountLoginCommandHandler implements AbstractExecuteStrategy<UserLoginCommand, UserLoginRespDTO> {\r\n    \r\n    private final DistributedCache distributedCache;\r\n    private final CustomerUserRepository customerUserRepository;\r\n    \r\n    @Override\r\n    public String mark() {\r\n        return UserLoginTypeEnum.USER_LOGIN_ACCOUNT.toString();\r\n    }\r\n    \r\n    @Override\r\n    public UserLoginRespDTO executeResp(UserLoginCommand requestParam) {\r\n        CustomerUser customerUser = CustomerUser.builder()\r\n                .accountNumber(new CustomerUserAccountNumber(requestParam.getAccountNumber()))\r\n                .password(new CustomerUserPassword(requestParam.getPassword()))\r\n                .build();\r\n        CustomerUser actual = customerUserRepository.findByAccountNumber(requestParam.getAccountNumber());\r\n        if (actual == null) {\r\n            throw new ClientException(\"用户名不存在\");\r\n        }\r\n        if (!Objects.equals(customerUser.getPassword(), actual.getPassword())) {\r\n            throw new ClientException(\"用户名密码错误\");\r\n        }\r\n        String accessToken = actual.generateAccessToken();\r\n        distributedCache.put(accessToken, JSON.toJSONString(actual), 30, TimeUnit.MINUTES);\r\n        return new UserLoginRespDTO(actual.getCustomerUserId(), actual.getUsername(), actual.getAccountNumber(), accessToken);\r\n    }\r\n}\r\n```\r\n\r\n#### 邮箱登录\r\n\r\n##### 登录策略执行处理器\r\n\r\n```java\r\n@Component\r\n@AllArgsConstructor\r\npublic class MailLoginCommandHandler implements AbstractExecuteStrategy<UserLoginCommand, UserLoginRespDTO> {\r\n    \r\n    private final DistributedCache distributedCache;\r\n    \r\n    private final CustomerUserRepository customerUserRepository;\r\n    \r\n    @Override\r\n    public String mark() {\r\n        return UserLoginTypeEnum.USER_LOGIN_MAIL.name();\r\n    }\r\n    \r\n    @Override\r\n    public UserLoginRespDTO executeResp(UserLoginCommand requestParam) {\r\n        CustomerUser customerUser = CustomerUser.builder().verifyCode(requestParam.getMailValidCode()).build();\r\n        // 获取缓存中的验证码\r\n        String verifyCode = distributedCache.get(CacheUtil.buildKey(LOGIN_USER_VERIFY_CODE, requestParam.getMail()), String.class);\r\n        // 检查验证码正确性\r\n        customerUser.checkoutValidCode(verifyCode);\r\n        CustomerUser actual = customerUserRepository.findByMail(requestParam.getMail());\r\n        String accessToken = actual.generateAccessToken();\r\n        //todo\r\n        distributedCache.put(accessToken, JSON.toJSONString(actual), 30, TimeUnit.MINUTES);\r\n        return new UserLoginRespDTO(actual.getCustomerUserId(), actual.getUsername(), actual.getAccountNumber(), accessToken);\r\n    }\r\n}\r\n```\r\n\r\n##### 抽象邮箱验证码发送\r\n\r\n```java\r\npublic abstract class AbstractMailVerifySender {\r\n    \r\n    @Value(\"${customer.user.register.verify.sender}\")\r\n    private String sender;\r\n    \r\n    @Value(\"${customer.user.register.verify.template-id}\")\r\n    private String templateId;\r\n    \r\n    @Resource\r\n    private MessageSendRemoteService messageSendRemoteService;\r\n    \r\n    @Resource\r\n    private DistributedCache distributedCache;\r\n    \r\n    /**\r\n     * 用户注册验证码超时时间\r\n     */\r\n    private static final long REGISTER_USER_VERIFY_CODE_TIMEOUT = 300000;\r\n    \r\n    /**\r\n     * 获取缓存前置 Key\r\n     *\r\n     * @return\r\n     */\r\n    protected abstract String getCachePrefixKey();\r\n    \r\n    /**\r\n     * 邮箱验证发送\r\n     *\r\n     * @param requestParam\r\n     */\r\n    public void mailVerifySend(UserVerifyCodeCommand requestParam) {\r\n        String verifyCode = RandomUtil.randomNumbers(6);\r\n        // 模板方法模式: 验证码放入缓存，并设置超时时间\r\n        distributedCache.put(CacheUtil.buildKey(getCachePrefixKey(), requestParam.getReceiver()), verifyCode, REGISTER_USER_VERIFY_CODE_TIMEOUT);\r\n        MailSendRemoteCommand remoteCommand = new MailSendRemoteCommand();\r\n        remoteCommand.setTitle(\"邮箱验证码提醒\")\r\n                .setReceiver(requestParam.getReceiver())\r\n                .setSender(sender)\r\n                .setTemplateId(templateId)\r\n                .setParamList(Lists.newArrayList(verifyCode));\r\n        messageSendRemoteService.mailMessageSend(remoteCommand);\r\n    }\r\n}\r\n```\r\n\r\n##### 用户注册使用邮箱验证策略执行处理器\r\n\r\n```java\r\n@Component\r\n@RequiredArgsConstructor\r\npublic class MailRegisterVerifyCommandHandler extends AbstractMailVerifySender implements AbstractExecuteStrategy<UserVerifyCodeCommand, Void> {\r\n    \r\n    @Override\r\n    public String mark() {\r\n        return \"customer_user_register_mail\";\r\n    }\r\n    \r\n    @Override\r\n    public void execute(UserVerifyCodeCommand requestParam) {\r\n        mailVerifySend(requestParam);\r\n    }\r\n    \r\n    @Override\r\n    protected String getCachePrefixKey() {\r\n        return CacheConstant.REGISTER_USER_VERIFY_CODE;\r\n    }\r\n}\r\n```\r\n\r\n##### 用户登录使用邮箱验证策略执行处理器\r\n\r\n```java\r\n@Component\r\npublic class MailLoginVerifyCommandHandler extends AbstractMailVerifySender implements AbstractExecuteStrategy<UserVerifyCodeCommand, Void> {\r\n    \r\n    @Override\r\n    public String mark() {\r\n        return \"customer_user_login_verify_mail\";\r\n    }\r\n    \r\n    @Override\r\n    public void execute(UserVerifyCodeCommand requestParam) {\r\n        mailVerifySend(requestParam);\r\n    }\r\n    \r\n    @Override\r\n    protected String getCachePrefixKey() {\r\n        return CacheConstant.LOGIN_USER_VERIFY_CODE;\r\n    }\r\n}\r\n```\r\n\r\n##### C 端用户接口选择并执行具体策略处理器\r\n\r\n```java\r\n@Service\r\n@AllArgsConstructor\r\npublic class CustomerUserServiceImpl implements CustomerUserService {\r\n    \r\n    private final DistributedCache distributedCache;\r\n    private final AbstractStrategyChoose abstractStrategyChoose;\r\n    private final CommandHandler<UserRegisterCommand, UserRegisterRespDTO> customerUserRegisterCommandHandler;\r\n    \r\n    @Override\r\n    public void verifyCodeSend(UserVerifyCodeCommand requestParam) {\r\n        String mark = requestParam.getType() + \"_\" + requestParam.getPlatform();\r\n        /**\r\n         * site\r\n         * {@link MailLoginVerifyCommandHandler}\r\n         * {@link MailRegisterVerifyCommandHandler}\r\n         * ...\r\n         */\r\n        // 策略模式: 根据 mark 选择用户登录或者注册逻辑\r\n        abstractStrategyChoose.chooseAndExecute(mark, requestParam);\r\n    }\r\n    \r\n    @Override\r\n    public UserRegisterRespDTO register(UserRegisterCommand requestParam) {\r\n        UserRegisterRespDTO result = customerUserRegisterCommandHandler.handler(requestParam);\r\n        return result;\r\n    }\r\n    \r\n    @Override\r\n    public UserLoginRespDTO login(UserLoginCommand requestParam) {\r\n        /**\r\n         * site\r\n         * {@link MailLoginCommandHandler}\r\n         */\r\n        return abstractStrategyChoose.chooseAndExecuteResp(requestParam.getLoginType(), requestParam);\r\n    }\r\n    \r\n    @Override\r\n    public UserLoginRespDTO checkLogin(String accessToken) {\r\n        return distributedCache.get(accessToken, UserLoginRespDTO.class);\r\n    }\r\n    \r\n    @Override\r\n    public void logout(String accessToken) {\r\n        if (StrUtil.isNotBlank(accessToken)) {\r\n            distributedCache.delete(accessToken);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n**C 端用户注册处理器**\r\n\r\n```java\r\n@Component\r\n@AllArgsConstructor\r\npublic class CustomerUserRegisterCommandHandler implements CommandHandler<UserRegisterCommand, UserRegisterRespDTO> {\r\n    \r\n    private final CustomerUserRepository customerUserRepository;\r\n    \r\n    private final CustomerUserToDTOAssembler customerUserAssembler;\r\n    \r\n    private final DistributedCache distributedCache;\r\n    \r\n    @Override\r\n    public UserRegisterRespDTO handler(UserRegisterCommand requestParam) {\r\n        CustomerUser customerUser = CustomerUser.builder()\r\n                .username(new CustomerUserName(requestParam.getUsername()))\r\n                .phone(new CustomerUserPhone(requestParam.getPhone()))\r\n                .accountNumber(new CustomerUserAccountNumber(requestParam.getAccountNumber()))\r\n                .password(new CustomerUserPassword(requestParam.getPassword()))\r\n                .mail(new CustomerUserMail(requestParam.getMail()))\r\n                .receiver(requestParam.getMail())\r\n                .verifyCode(requestParam.getMailValidCode())\r\n                .build();\r\n        // 获取缓存中的验证码\r\n        String buildKey = CacheUtil.buildKey(REGISTER_USER_VERIFY_CODE, customerUser.getReceiver());\r\n        String verifyCode = distributedCache.get(buildKey, String.class);\r\n        // 检查验证码正确性\r\n        customerUser.checkoutValidCode(verifyCode);\r\n        CustomerUser result = customerUserRepository.register(customerUser);\r\n        // 删除缓存验证码\r\n        distributedCache.delete(buildKey);\r\n        return customerUserAssembler.customerUserToUserRegisterRespDTO(result);\r\n    }\r\n}\r\n```\r\n\r\n## 文末总结\r\n\r\n总的来说，策略模式是一种非常有用的设计模式，它可以帮助我们在运行时动态地选择不同的算法实现，从而提高代码的灵活性、可维护性和可扩展性。\r\n\r\n通过将算法实现封装在不同的策略类中，并定义一个策略接口来描述算法，策略模式使得客户端可以独立于算法实现进行编程，同时也可以方便地更换算法实现或者添加新的算法实现。\r\n\r\n策略模式的优点包括提高代码的灵活性、可维护性、可扩展性和复用性，同时也可以避免使用大量的条件语句和提高代码的可读性。\r\n\r\n需要注意的是，在使用策略模式时需要遵循一些设计原则，例如开闭原则、单一职责原则和依赖倒置原则等，以确保代码的高内聚性和低耦合度。\r\n\r\n此外，策略模式适用于需要在运行时动态选择不同算法实现的场景，如果算法实现不需要动态切换或者算法实现较为简单，策略模式可能会显得过于复杂。\r\n\r\n因此，在使用策略模式时需要根据具体的需求和场景进行判断和选择。"},{"title":"如何使用线程池不容易出故障","tags":["线程池","BlockingQueue","ThreadPoolExecutor"],"categories":["Java","微系统与第三方框架"],"author":"imklaus","excerpt":"\r\n\r\n你是否在项目中使用线程池遇到过以下问题？\r\n\r\n- 创建线程池核心参数不好评估，随着业务流量的波动，极有可能出现生产故障。\r\n- 不支持优雅关闭，当项目关闭时，大量正在运行的线程池任务被丢弃。\r\n- 不支持运行时监控，使用过程中业务无响应，不知道是不是线程池引起。\r\n- 三方框架 RocketMQ、Dubbo 等线程池无法动态修改参数，修改后只能重启应用。\r\n","link":"/posts/DynamicThreadPool","content":"\r\n\r\n你是否在项目中使用线程池遇到过以下问题？\r\n\r\n- 创建线程池核心参数不好评估，随着业务流量的波动，极有可能出现生产故障。\r\n- 不支持优雅关闭，当项目关闭时，大量正在运行的线程池任务被丢弃。\r\n- 不支持运行时监控，使用过程中业务无响应，不知道是不是线程池引起。\r\n- 三方框架 RocketMQ、Dubbo 等线程池无法动态修改参数，修改后只能重启应用。\r\n<!-- more -->\r\n在真实业务场景中，线程池可能遇到的问题比这里描述的还要多，稀奇古怪。\r\n\r\n笔者所经历过的项目，因为业务对线程池参数没有合理配置，就触发过几起生产事故。大概在 21 年 6 月份左右，开始在网上搜索动态线程池的项目。\r\n\r\n在开源平台找了挺多动态线程池项目，从功能性以及健壮性而言，个人感觉不满足企业级应用。\r\n\r\n再加上当时看了美团动态线程的文章，就对这个技术方向比较感兴趣，所以决定自己来造一个轻量级的轮子。\r\n\r\n> 我觉得写一个偏中间件的框架，还能帮助用户解决实际问题，是一件很酷的事情。\r\n\r\nGitHub：[https://github.com/opengoofy/hippo4j(opens new window)](https://github.com/opengoofy/hippo4j)\r\n\r\nGitee：[https://gitee.com/opengoofy/hippo4j(opens new window)](https://gitee.com/opengoofy/hippo4j)\r\n\r\n## 核心功能\r\n\r\n通过对 JDK 线程池的增强，以及扩展三方框架底层线程池等功能，为业务系统提高线上运行保障能力。\r\n\r\nHippo4j 框架提供以下功能支持：\r\n\r\n1. 客户端应用运行时实时变更指定线程池核心参数，变更生效支持集群和单实例两种方式。\r\n2. 线程池运行时异常报警，比如：线程池活跃度、阻塞队列容量水位较高，触发了拒绝策略以及任务运行时间超长等。\r\n3. 定时任务（默认5秒）采集线程池运行数据，可上报 Prometheus、InfluxDB 等数据库，搭配 Grafana 做大屏展示。\r\n4. 运行过程中支持实时查看线程池当前运行状态以及线程池内线程的堆栈信息。\r\n5. 支持 Tomcat、Undertow 和 Jetty 容器线程池运行时查看和动态变更线程池配置。\r\n6. 支持 Dubbo、Hystrix、Kafka、RabbitMQ、RocketMQ 等客户端线程池运行时数据查看和动态变更线程池配置。\r\n\r\n## 应用场景\r\n\r\n### 1. 动态调参\r\n\r\nGoogle 或者百度搜索线程池和生产事故关键字，几页都放不下，这也间接说明了线程池是个很考验使用者技术功底的技术点。\r\n\r\n那有没有一些技巧或者技术来尽量规避线程池使用上的问题？比如：线程池的配置应该如何选择？\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20230329231743302.png)\r\n\r\n我觉得大家对于线程池参数的纠结点主要有两个，无外乎设置的线程数多了或者少了。\r\n\r\n- 如果预设的线程数或阻塞队列数量少了，当业务量上来，任务都在排队或者执行拒绝策略。\r\n- 如果超量设置线程池的参数，无疑会造成资源浪费。\r\n\r\n如果要修改运行中应用线程池参数，需要停止线上应用，调整成功后再发布，而这个过程异常的繁琐，如果能在运行中动态调整线程池的参数无疑会提高问题解决效率。\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20230327223406749.png)\r\n\r\nHippo4j 提供了应用线程池运行时变更核心参数的功能。而且，如果应用是集群部署，可以选择修改线程池某一实例，或者修改集群全部实例，运行时生效，不需要再重启服务。\r\n\r\n压测时可以使用 Hippo4j 动态调整线程池参数，判断线程池核心参数设置是否合理。对于开发测试来说，如果不满足可以随时调整。\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20220824085936059.png)\r\n\r\n### 2. 告警策略\r\n\r\n很多时候，线程池出故障的时候，系统已经发生了很严重的损失。有没有一种方式，在使用的线程池即将出现问题，但还算比较可控时，触发相关报警提示给用户，进而规避该问题？\r\n\r\nHippo4j 基于上述问题思考，集成了四种报警策略：\r\n\r\n- 活跃度：假设阈值设置 80%，线程池最大线程数 10，当线程数达到 8 发起报警。\r\n- 阻塞队列容量：假设阈值设置 80%，阻塞队列容量 100，当容量达到 80 发起报警。\r\n- 触发拒绝策略：当线程池任务触发了拒绝策略时，发起拒绝策略报警。\r\n- 任务运行超时：假设用户设置单个任务正常执行是 1000ms，实际执行超过该时间发起报警。\r\n\r\n支持钉钉、企业微信和飞书软件通知，下图以线程池任务运行超时报警举例：\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20220823201756259.png)\r\n\r\n### 3. 线程池监控\r\n\r\nHippo4j 线程池提供了两种监控方式：线程池运行时数据采集监控以及客户端线程池运行实时状态查看。\r\n\r\n1）线程池核心参数监控。\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20220912225813972.png)\r\n\r\n2）线程池实例运行时状态。\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20230309194103914.png)\r\n\r\n线程池运行时数据采集适合应用负责人巡查应用健康状态和排查问题时使用，实时状态适合排查多实例之间的运行数据状态。\r\n\r\n### 4. 框架底层线程池\r\n\r\n上面讲的动态线程池是业务中开发人员手动创建的线程池，比如下面这个：\r\n\r\n```java\r\n@Bean\r\n@DynamicThreadPool\r\npublic ThreadPoolExecutor messageConsumeDynamicExecutor() {\r\n  String threadPoolId = \"message-consume\";\r\n  return ThreadPoolBuilder.builder()\r\n    .threadFactory(threadPoolId)\r\n    .threadPoolId(threadPoolId)\r\n    .dynamicPool()\r\n    .build();\r\n}\r\n```\r\n\r\n而框架线程池指的是某些三方中间件底层使用到的线程池，比如 Dubbo、RocketMQ 等框架，这些底层框架为了增强性能选择使用线程池进行扩展。\r\n\r\n为什么要适配这些中间件框架的线程池？\r\n\r\n相信这是很多小伙伴的疑问。以 Dubbo 举例，当服务高并发调用时，如果 Dubbo 底层线程池没有经过个性化配置，极有可能导致线程池打满，最终导致无法提供服务。\r\n\r\n当遇到这种情况，可以使用 Hippo4j 对 Dubbo 线程池进行核心参数调整，避免生产故障时间持续。\r\n\r\n再举个例子，当 RocketMQ 消息积压时，可能大部分公司的解决方案是添加客户端应用节点。而这种方式虽然可以解决问题，但是问题也很明显，太复杂且资源浪费。完全可以调整 RocketMQ SDK 底层线程池的线程数来达到快速消费的逻辑，有效解决 MQ 消息堆积问题。\r\n\r\n目前 Hippo4j 已支持的三方中间件线程池列表：\r\n\r\n- Apache Dubbo\r\n- Alibaba Dubbo\r\n- Apache Kafka\r\n- Apache RocketMQ\r\n- RabbitMQ\r\n- SpringCloud Stream RocketMQ\r\n- SpringCloud Hystrix\r\n- Tomcat\r\n- Jetty\r\n- Undertow\r\n\r\n上述中间件线程池都可以在 Hippo4j 页面上操作核心参数动态变更以及监控功能，如下所示：\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20220824203003245.png)\r\n\r\n未来 Hippo4j 会支持更多三方框架线程池，如果你有好的想法也可以和我沟通，一起完善中间件框架适配。\r\n\r\n## 模块介绍\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20230328084009982.png)\r\n\r\n## 深入原理\r\n\r\n如果一上来就下载 Hippo4j 的源码来看，很容易迷失进去。这里给大家画了几张图，帮助大家在阅读源码时，能够抓紧主干分支，更快上手 Hippo4j 框架源码。\r\n\r\n### 1. 配置中心模式变更原理\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20230327223551109.png)\r\n\r\n### 2. 适配 SpringBoot 1.5 & 2.x\r\n\r\n![img](https://images-machen.oss-cn-beijing.aliyuncs.com/image-20230327223649631.png)\r\n\r\n### 3. 阅读源码优点\r\n\r\n如果您公司没有使用 Hippo4j 场景的话，我也建议去阅读下项目的底层原理，主要有以下几个原因：\r\n\r\n- 为了提高代码质量以及后续的扩展行为，运用多种设计模式实现高内聚、低耦合。\r\n- 框架底层依赖 Spring 框架运行，并在源码中大量使用 Spring 相关功能。\r\n- 运用 JUC 并发包下多种工具保障多线程运行安全，通过实际场景理解并发编程。\r\n- 借鉴主流开源框架 Nacos、Eureka 实现轻量级配置中心和注册中心功能。\r\n- 自定义 RPC 框架实现，封装 Netty 完成客户端/服务端网络通信优化。\r\n- 通过 CheckStyle、Spotless 等插件规范代码编写，保障高质量代码行为和代码样式。"},{"title":"秒杀","tags":["Spring Boot","Spring Cloud","token","Redis","Redisson","Schedule","RabbitMQ"],"categories":["Java","微系统与第三方框架"],"author":"imklaus","excerpt":"\r\n\r\n\r\n## 如何设计一个秒杀系统？\r\n\r\n- 高并发下如何设计秒杀系统？这是一个高频面试题。这个问题看似简单，但是里面的水很深，它考查的是高并发场景下，从前端到后端多方面的知识。\r\n\r\n\r\n\r\n- 秒杀一般出现在商城的促销活动中，指定了一定数量（比如：10个）的商品（比如：手机），以极低的价格（比如：0.1元），让大量用户参与活动，但只有极少数用户能够购买成功。这类活动商家绝大部分是不赚钱的，说白了是找个噱头宣传自己。\r\n\r\n\r\n\r\n- 虽说秒杀只是一个促销活动，但对技术要求不低。下面给大家总结一下设计秒杀系统需要注意的9个细节。\r\n\r\n![image-20230429153744600](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429153744600.png)\r\n","link":"/posts/Flash_killing","content":"\r\n\r\n\r\n## 如何设计一个秒杀系统？\r\n\r\n- 高并发下如何设计秒杀系统？这是一个高频面试题。这个问题看似简单，但是里面的水很深，它考查的是高并发场景下，从前端到后端多方面的知识。\r\n\r\n\r\n\r\n- 秒杀一般出现在商城的促销活动中，指定了一定数量（比如：10个）的商品（比如：手机），以极低的价格（比如：0.1元），让大量用户参与活动，但只有极少数用户能够购买成功。这类活动商家绝大部分是不赚钱的，说白了是找个噱头宣传自己。\r\n\r\n\r\n\r\n- 虽说秒杀只是一个促销活动，但对技术要求不低。下面给大家总结一下设计秒杀系统需要注意的9个细节。\r\n\r\n![image-20230429153744600](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429153744600.png)\r\n<!-- more -->\r\n\r\n\r\n\r\n### 1 瞬时高并发 \r\n\r\n- 一般在秒杀时间点（比如：12点）前几分钟，用户并发量才真正突增，达到秒杀时间点时，并发量会达到顶峰。\r\n\r\n\r\n\r\n- 但由于这类活动是大量用户抢少量商品的场景，必定会出现狼多肉少的情况，所以其实绝大部分用户秒杀会失败，只有极少部分用户能够成功。\r\n\r\n\r\n\r\n- 正常情况下，大部分用户会收到商品已经抢完的提醒，收到该提醒后，他们大概率不会在那个活动页面停留了，如此一来，用户并发量又会急剧下降。所以这个峰值持续的时间其实是非常短的，这样就会出现瞬时高并发的情况，下面用一张图直观的感受一下流量的变化：\r\n\r\n\r\n\r\n![image-20230429154129604](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429154129604.png)\r\n\r\n\r\n\r\n\r\n\r\n- 像这种瞬时高并发的场景，传统的系统很难应对，我们需要设计一套全新的系统。可以从以下几个方面入手：\r\n  1. 页面静态化\r\n  2. CDN加速\r\n  3. 缓存\r\n  4. mq异步处理\r\n  5. 限流\r\n  6. 分布式锁\r\n\r\n\r\n\r\n### 2 页面静态化 \r\n\r\n\r\n\r\n- 活动页面是用户流量的第一入口，所以是并发量最大的地方。\r\n\r\n\r\n\r\n- 如果这些流量都能直接访问服务端，恐怕服务端会因为承受不住这么大的压力，而直接挂掉。\r\n\r\n![image-20230429154425207](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429154425207.png)\r\n\r\n\r\n\r\n- 活动页面绝大多数内容是固定的，比如：商品名称、商品描述、图片等。为了减少不必要的服务端请求，通常情况下，会对活动页面做`静态化`处理。用户浏览商品等常规操作，并不会请求到服务端。只有到了秒杀时间点，并且用户主动点了秒杀按钮才允许访问服务端。\r\n\r\n\r\n\r\n![image-20230429154505896](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429154505896.png)\r\n\r\n\r\n\r\n- 这样能过滤大部分无效请求。\r\n\r\n\r\n\r\n- 但只做页面静态化还不够，因为用户分布在全国各地，有些人在北京，有些人在成都，有些人在深圳，地域相差很远，网速各不相同。\r\n\r\n\r\n\r\n- 如何才能让用户最快访问到活动页面呢？\r\n  - 这就需要使用CDN，它的全称是Content Delivery Network，即内容分发网络。\r\n\r\n\r\n\r\n![image-20230429154557367](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429154557367.png)\r\n\r\n\r\n\r\n> 使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。\r\n\r\n\r\n\r\n\r\n\r\n### 3 秒杀按钮 \r\n\r\n\r\n\r\n- 大部分用户怕错过秒杀时间点，一般会提前进入活动页面。此时看到的秒杀按钮是置灰，不可点击的。只有到了秒杀时间点那一时刻，秒杀按钮才会自动点亮，变成可点击的。\r\n\r\n\r\n\r\n- 但此时很多用户已经迫不及待了，通过不停刷新页面，争取在第一时间看到秒杀按钮的点亮。\r\n\r\n\r\n\r\n- 从前面得知，该活动页面是静态的。那么我们在静态页面中如何控制秒杀按钮，只在秒杀时间点时才点亮呢？\r\n  - 没错，使用js文件控制。\r\n\r\n\r\n\r\n- 为了性能考虑，一般会将css、js和图片等静态资源文件提前缓存到CDN上，让用户能够就近访问秒杀页面。\r\n\r\n\r\n\r\n- 看到这里，有些聪明的小伙伴，可能会问：CDN上的js文件是如何更新的？\r\n  - 秒杀开始之前，js标志为false，还有另外一个随机参数。\r\n\r\n![image-20230429154759471](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429154759471.png)\r\n\r\n\r\n\r\n- 当秒杀开始的时候系统会生成一个新的js文件，此时标志为true，并且随机参数生成一个新值，然后同步给CDN。由于有了这个随机参数，CDN不会缓存数据，每次都能从CDN中获取最新的js代码。\r\n\r\n![image-20230429154818790](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429154818790.png)\r\n\r\n\r\n\r\n> 此外，前端还可以加一个定时器，控制比如：10秒之内，只允许发起一次请求。如果用户点击了一次秒杀按钮，则在10秒之内置灰，不允许再次点击，等到过了时间限制，又允许重新点击该按钮。\r\n\r\n\r\n\r\n\r\n\r\n### 4 读多写少 \r\n\r\n\r\n\r\n- 在秒杀的过程中，系统一般会先查一下库存是否足够，如果足够才允许下单，写数据库。如果不够，则直接返回该商品已经抢完。\r\n\r\n\r\n\r\n- 由于大量用户抢少量商品，只有极少部分用户能够抢成功，所以绝大部分用户在秒杀时，库存其实是不足的，系统会直接返回该商品已经抢完。\r\n\r\n\r\n\r\n- 这是非常典型的：读多写少 的场景。\r\n\r\n\r\n\r\n![image-20230429155156269](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429155156269.png)\r\n\r\n\r\n\r\n- 如果有数十万的请求过来，同时通过数据库查缓存是否足够，此时数据库可能会挂掉。因为数据库的连接资源非常有限，比如：mysql，无法同时支持这么多的连接。\r\n\r\n\r\n\r\n- 而应该改用缓存，比如：redis。\r\n\r\n\r\n\r\n- 即便用了redis，也需要部署多个节点。\r\n\r\n![image-20230429155327734](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429155327734.png)\r\n\r\n\r\n\r\n\r\n\r\n### 5 缓存问题 \r\n\r\n\r\n\r\n- 通常情况下，我们需要在redis中保存商品信息，里面包含：商品id、商品名称、规格属性、库存等信息，同时数据库中也要有相关信息，毕竟缓存并不完全可靠。\r\n\r\n\r\n\r\n- 用户在点击秒杀按钮，请求秒杀接口的过程中，需要传入的商品id参数，然后服务端需要校验该商品是否合法。\r\n\r\n\r\n\r\n- 大致流程如下图所示：\r\n\r\n![image-20230429155407944](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429155407944.png)\r\n\r\n\r\n\r\n> - 根据商品id，先从缓存中查询商品，如果商品存在，则参与秒杀。如果不存在，则需要从数据库中查询商品，如果存在，则将商品信息放入缓存，然后参与秒杀。如果商品不存在，则直接提示失败。\r\n>\r\n> - 这个过程表面上看起来是OK的，但是如果深入分析一下会发现一些问题。\r\n\r\n\r\n\r\n#### 5.1 缓存击穿 \r\n\r\n\r\n\r\n- 比如商品A第一次秒杀时，缓存中是没有数据的，但数据库中有。虽说上面有如果从数据库中查到数据，则放入缓存的逻辑。\r\n\r\n\r\n\r\n- 然而，在高并发下，同一时刻会有大量的请求，都在秒杀同一件商品，这些请求同时去查缓存中没有数据，然后又同时访问数据库。结果悲剧了，数据库可能扛不住压力，直接挂掉。\r\n\r\n\r\n\r\n- 如何解决这个问题呢？\r\n  - 这就需要加锁，最好使用分布式锁。\r\n\r\n\r\n\r\n![image-20230429155613279](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429155613279.png)\r\n\r\n\r\n\r\n> - 当然，针对这种情况，最好在项目启动之前，先把缓存进行预热。即事先把所有的商品，同步到缓存中，这样商品基本都能直接从缓存中获取到，就不会出现缓存击穿的问题了。\r\n> - 是不是上面加锁这一步可以不需要了？\r\n>   - 表面上看起来，确实可以不需要。但如果缓存中设置的过期时间不对，缓存提前过期了，或者缓存被不小心删除了，如果不加速同样可能出现缓存击穿。\r\n>   - 其实这里加锁，相当于买了一份保险。\r\n\r\n\r\n\r\n#### 5.2 缓存穿透 \r\n\r\n\r\n\r\n- 如果有大量的请求传入的商品id，在缓存中和数据库中都不存在，这些请求不就每次都会穿透过缓存，而直接访问数据库了。\r\n\r\n\r\n\r\n- 由于前面已经加了锁，所以即使这里的并发量很大，也不会导致数据库直接挂掉。\r\n\r\n\r\n\r\n- 但很显然这些请求的处理性能并不好，有没有更好的解决方案？\r\n  - 这时可以想到布隆过滤器。\r\n\r\n\r\n\r\n![image-20230429160015188](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429160015188.png)\r\n\r\n\r\n\r\n- 系统根据商品id，先从布隆过滤器中查询该id是否存在，如果存在则允许从缓存中查询数据，如果不存在，则直接返回失败。\r\n\r\n\r\n\r\n- 虽说该方案可以解决缓存穿透问题，但是又会引出另外一个问题：布隆过滤器中的数据如何跟缓存中的数据保持一致？\r\n\r\n\r\n\r\n- 这就要求，如果缓存中数据有更新，则要及时同步到布隆过滤器中。如果数据同步失败了，还需要增加重试机制，而且跨数据源，能保证数据的实时一致性吗？\r\n  - 显然是不行的。\r\n\r\n- 所以布隆过滤器绝大部分使用在缓存数据更新很少的场景中。\r\n\r\n- 如果缓存数据更新非常频繁，又该如何处理呢？\r\n\r\n- 这时，就需要把不存在的商品id也缓存起来。\r\n\r\n\r\n\r\n![image-20230429160205059](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429160205059.png)\r\n\r\n\r\n\r\n> 下次，再有该商品id的请求过来，则也能从缓存中查到数据，只不过该数据比较特殊，表示商品不存在。需要特别注意的是，这种特殊缓存设置的超时时间应该尽量短一点。\r\n\r\n\r\n\r\n\r\n\r\n### 6 库存问题 \r\n\r\n\r\n\r\n- 对于库存问题看似简单，实则里面还是有些东西。\r\n\r\n\r\n\r\n- 真正的秒杀商品的场景，不是说扣完库存，就完事了，如果用户在一段时间内，还没完成支付，扣减的库存是要加回去的。\r\n\r\n\r\n\r\n- 所以，在这里引出了一个预扣库存的概念，预扣库存的主要流程如下：\r\n\r\n\r\n\r\n![image-20230429160545360](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429160545360.png)\r\n\r\n\r\n\r\n> 扣减库存中除了上面说到的预扣库存和回退库存之外，还需要特别注意的是库存不足和库存超卖问题。\r\n\r\n\r\n\r\n#### 6.1 数据库扣减库存 \r\n\r\n\r\n\r\n- 使用数据库扣减库存，是最简单的实现方案了，假设扣减库存的sql如下：\r\n\r\n```sql\r\nupdate product set stock=stock-1 where id=123;\r\n```\r\n\r\n- 这种写法对于扣减库存是没有问题的，但如何控制库存不足的情况下，不让用户操作呢？\r\n\r\n  - 这就需要在update之前，先查一下库存是否足够了。\r\n\r\n  - 伪代码如下：\r\n  \r\n  ```java\r\n  int stock = mapper.getStockById(123);\r\n  if(stock > 0) {\r\n    int count = mapper.updateStock(123);\r\n    if(count > 0) {\r\n      addOrder(123);\r\n    }\r\n  }\r\n  ```\r\n\r\n\r\n\r\n- 大家有没有发现这段代码的问题？\r\n\r\n  - 没错，查询操作和更新操作不是原子性的，会导致在并发的场景下，出现库存超卖的情况。\r\n\r\n\r\n  - 有人可能会说，这样好办，加把锁，不就搞定了，比如使用synchronized关键字。\r\n\r\n\r\n  - 确实，可以，但是性能不够好。\r\n\r\n\r\n  - 还有更优雅的处理方案，即基于数据库的乐观锁，这样会少一次数据库查询，而且能够天然的保证数据操作的原子性。\r\n\r\n\r\n  - 只需将上面的sql稍微调整一下：\r\n\r\n  ```sql\r\n  update product set stock=stock-1 where id=product and stock > 0;\r\n  ```\r\n\r\n> - 在sql最后加上：stock > 0，就能保证不会出现超卖的情况。\r\n>\r\n> - 但需要频繁访问数据库，我们都知道数据库连接是非常昂贵的资源。在高并发的场景下，可能会造成系统雪崩。而且，容易出现多个请求，同时竞争行锁的情况，造成相互等待，从而出现死锁的问题。\r\n>\r\n\r\n\r\n\r\n####  6.2 redis扣减库存 \r\n\r\n\r\n\r\n- redis的`incr`方法是原子性的，可以用该方法扣减库存。 伪代码如下：\r\n\r\n\r\n```java\r\n  boolean exist = redisClient.query(productId,userId);\r\n  if(exist) {\r\n    return -1;\r\n  }\r\n  int stock = redisClient.queryStock(productId);\r\n  if(stock <=0) {\r\n    return 0;\r\n  }\r\n  redisClient.incrby(productId, -1);\r\n  redisClient.add(productId,userId);\r\n  return 1;\r\n```\r\n\r\n\r\n\r\n- 代码流程如下：\r\n\r\n1. 先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。\r\n2. 查询库存，如果库存小于等于0，则直接返回0，表示库存不足。\r\n\r\n3. 如果库存充足，则扣减库存，然后将本次秒杀记录保存起来。然后返回1，表示成功。\r\n\r\n\r\n\r\n- 估计很多小伙伴，一开始都会按这样的思路写代码。但如果仔细想想会发现，这段代码有问题。\r\n\r\n\r\n- 有什么问题呢？\r\n\r\n  - 如果在高并发下，有多个请求同时查询库存，当时都大于0。由于查询库存和更新库存非原则操作，则会出现库存为负数的情况，即`库存超卖`。\r\n\r\n\r\n- 当然有人可能会说，加个`synchronized`不就解决问题？\r\n\r\n\r\n- 调整后代码如下：\r\n\r\n\r\n```java\r\nboolean exist = redisClient.query(productId,userId);\r\n   if(exist) {\r\n    return -1;\r\n   }\r\n   synchronized(this) {\r\n       int stock = redisClient.queryStock(productId);\r\n       if(stock <=0) {\r\n         return 0;\r\n       }\r\n       redisClient.incrby(productId, -1);\r\n       redisClient.add(productId,userId);\r\n   }\r\nreturn 1;\r\n```\r\n\r\n\r\n\r\n- 加`synchronized`确实能解决库存为负数问题，但是这样会导致接口性能急剧下降，每次查询都需要竞争同一把锁，显然不太合理。\r\n\r\n\r\n- 为了解决上面的问题，代码优化如下：\r\n\r\n\r\n```java\r\nboolean exist = redisClient.query(productId,userId);\r\nif(exist) {\r\n  return -1;\r\n}\r\nif(redisClient.incrby(productId, -1)<0) {\r\n  return 0;\r\n}\r\nredisClient.add(productId,userId);\r\nreturn 1;\r\n```\r\n\r\n\r\n\r\n- 该代码主要流程如下：\r\n\r\n\r\n1. 先判断该用户有没有秒杀过该商品，如果已经秒杀过，则直接返回-1。\r\n2. 扣减库存，判断返回值是否小于0，如果小于0，则直接返回0，表示库存不足。\r\n\r\n3. 如果扣减库存后，返回值大于或等于0，则将本次秒杀记录保存起来。然后返回1，表示成功。\r\n\r\n\r\n\r\n> - 该方案咋一看，好像没问题。\r\n>\r\n>   - 但如果在高并发场景中，有多个请求同时扣减库存，大多数请求的incrby操作之后，结果都会小于0。\r\n>\r\n>\r\n> - 虽说，库存出现负数，不会出现超卖的问题。但由于这里是预减库存，如果负数值负的太多的话，后面万一要回退库存时，就会导致库存不准。\r\n>\r\n>\r\n> - 那么，有没有更好的方案呢？\r\n>\r\n\r\n\r\n\r\n####  6.3 lua脚本扣减库存 \r\n\r\n\r\n\r\n- 我们都知道lua脚本，是能够保证原子性的，它跟redis一起配合使用，能够完美解决上面的问题。\r\n\r\n\r\n- lua脚本有段非常经典的代码：\r\n\r\n\r\n```java\r\nStringBuilder lua = new StringBuilder();\r\n  lua.append(\"if (redis.call('exists', KEYS[1]) == 1) then\");\r\n  lua.append(\"    local stock = tonumber(redis.call('get', KEYS[1]));\");\r\n  lua.append(\"    if (stock == -1) then\");\r\n  lua.append(\"        return 1;\");\r\n  lua.append(\"    end;\");\r\n  lua.append(\"    if (stock > 0) then\");\r\n  lua.append(\"        redis.call('incrby', KEYS[1], -1);\");\r\n  lua.append(\"        return stock;\");\r\n  lua.append(\"    end;\");\r\n  lua.append(\"    return 0;\");\r\n  lua.append(\"end;\");\r\n  lua.append(\"return -1;\");\r\n```\r\n\r\n\r\n\r\n- 该代码的主要流程如下：\r\n\r\n\r\n1. 先判断商品id是否存在，如果不存在则直接返回。\r\n2. 获取该商品id的库存，判断库存如果是-1，则直接返回，表示不限制库存。\r\n\r\n3. 如果库存大于0，则扣减库存。\r\n\r\n4. 如果库存等于0，是直接返回，表示库存不足。\r\n\r\n\r\n\r\n###  7 分布式锁 \r\n\r\n\r\n\r\n- 之前我提到过，在秒杀的时候，需要先从缓存中查商品是否存在，如果不存在，则会从数据库中查商品。如果数据库中有，则将该商品放入缓存中，然后返回。如果数据库中没有，则直接返回失败。\r\n\r\n\r\n- 大家试想一下，如果在高并发下，有大量的请求都去查一个缓存中不存在的商品，这些请求都会直接打到数据库。数据库由于承受不住压力，而直接挂掉。\r\n\r\n\r\n- 那么如何解决这个问题呢？\r\n\r\n  - 这就需要用redis分布式锁了。\r\n\r\n\r\n\r\n\r\n####  7.1 setNx加锁 \r\n\r\n\r\n\r\n- 使用redis的分布式锁，首先想到的是setNx命令。\r\n\r\n\r\n```java\r\nif (jedis.setnx(lockKey, val) == 1) {\r\n   jedis.expire(lockKey, timeout);\r\n}\r\n```\r\n\r\n\r\n\r\n- 用该命令其实可以加锁，但和后面的设置超时时间是分开的，并非原子操作。\r\n\r\n\r\n\r\n\r\n- 假如加锁成功了，但是设置超时时间失败了，该lockKey就变成永不失效的了。在高并发场景中，该问题会导致非常严重的后果。\r\n\r\n\r\n\r\n\r\n- 那么，有没有保证原子性的加锁命令呢？\r\n\r\n\r\n\r\n\r\n####  7.2 set加锁 \r\n\r\n\r\n\r\n- 使用redis的set命令，它可以指定多个参数。\r\n\r\n\r\n```java\r\nString result = jedis.set(lockKey, requestId, \"NX\", \"PX\", expireTime);\r\nif (\"OK\".equals(result)) {\r\n    return true;\r\n}\r\nreturn false;\r\n```\r\n\r\n其中：\r\n\r\n- lockKey：锁的标识\r\n\r\n- requestId：请求id\r\n\r\n- NX：只在键不存在时，才对键进行设置操作。\r\n\r\n- PX：设置键的过期时间为 millisecond 毫秒。\r\n\r\n- expireTime：过期时间 由于该命令只有一步，所以它是原子操作。\r\n\r\n\r\n\r\n\r\n####  7.3 释放锁 \r\n\r\n\r\n\r\n- 接下来，有些朋友可能会问：在加锁时，既然已经有了lockKey锁标识，为什么要需要记录requestId呢？\r\n\r\n  - 答：requestId是在释放锁的时候用的。\r\n\r\n\r\n\r\n\r\n- 在释放锁的时候，只能释放自己加的锁，不允许释放别人加的锁。\r\n\r\n\r\n\r\n\r\n- 这里为什么要用requestId，用userId不行吗？\r\n\r\n  - 答：如果用userId的话，假设本次请求流程走完了，准备删除锁。此时，巧合锁到了过期时间失效了。而另外一个请求，巧合使用的相同userId加锁，会成功。而本次请求删除锁的时候，删除的其实是别人的锁了。\r\n\r\n\r\n\r\n\r\n- 当然使用lua脚本也能避免该问题：\r\n\r\n\r\n```shell\r\nif redis.call('get', KEYS[1]) == ARGV[1] then \r\n return redis.call('del', KEYS[1]) \r\nelse \r\n  return 0 \r\nend\r\n```\r\n\r\n\r\n\r\n> 它能保证查询锁是否存在和删除锁是原子操作。\r\n>\r\n\r\n\r\n\r\n####  7.4 自旋锁 \r\n\r\n\r\n\r\n- 上面的加锁方法看起来好像没有问题，但如果你仔细想想，如果有1万的请求同时去竞争那把锁，可能只有一个请求是成功的，其余的9999个请求都会失败。\r\n\r\n\r\n\r\n\r\n- 在秒杀场景下，会有什么问题？\r\n\r\n  - 答：每1万个请求，有1个成功。再1万个请求，有1个成功。如此下去，直到库存不足。这就变成均匀分布的秒杀了，跟我们想象中的不一样。\r\n\r\n\r\n\r\n\r\n- 如何解决这个问题呢？\r\n\r\n  - 答：使用自旋锁。\r\n\r\n\r\n```java\r\ntry {\r\n  Long start = System.currentTimeMillis();\r\n  while(true) {\r\n      String result = jedis.set(lockKey, requestId, \"NX\", \"PX\", expireTime);\r\n     if (\"OK\".equals(result)) {\r\n        return true;\r\n     }\r\n     \r\n     long time = System.currentTimeMillis() - start;\r\n      if (time>=timeout) {\r\n          return false;\r\n      }\r\n      try {\r\n          Thread.sleep(50);\r\n      } catch (InterruptedException e) {\r\n          e.printStackTrace();\r\n      }\r\n  }\r\n} finally{\r\n    unlock(lockKey,requestId);\r\n}  \r\nreturn false;\r\n```\r\n\r\n\r\n\r\n> 在规定的时间，比如500毫秒内，自旋不断尝试加锁，如果成功则直接返回。如果失败，则休眠50毫秒，再发起新一轮的尝试。如果到了超时时间，还未加锁成功，则直接返回失败。\r\n>\r\n\r\n\r\n\r\n####  7.5 redisson \r\n\r\n\r\n\r\n- 除了上面的问题之外，使用redis分布式锁，还有锁竞争问题、续期问题、锁重入问题、多个redis实例加锁问题等。\r\n\r\n- [Redisson分布式锁的使用](https://imlklaus.github.io/posts/%E7%BC%93%E5%AD%98+%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%9C%A8java%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8#_3%E3%80%81redisson-%E5%AE%8C%E6%88%90%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81)\r\n\r\n\r\n\r\n\r\n\r\n\r\n###  8 mq异步处理 \r\n\r\n\r\n\r\n- 我们都知道在真实的秒杀场景中，有三个核心流程：\r\n\r\n\r\n![image-20230429164405754](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429164405754.png)\r\n\r\n\r\n\r\n- 而这三个核心流程中，真正并发量大的是秒杀功能，下单和支付功能实际并发量很小。所以，我们在设计秒杀系统时，有必要把下单和支付功能从秒杀的主流程中拆分出来，特别是下单功能要做成mq异步处理的。而支付功能，比如支付宝支付，是业务场景本身保证的异步。\r\n\r\n\r\n\r\n\r\n- 于是，秒杀后下单的流程变成如下：\r\n\r\n\r\n![image-20230429164509701](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429164509701.png)\r\n\r\n\r\n\r\n- 如果使用mq，需要关注以下几个问题：\r\n\r\n\r\n\r\n\r\n\r\n\r\n####  8.1 消息丢失问题 \r\n\r\n\r\n\r\n- 秒杀成功了，往mq发送下单消息的时候，有可能会失败。原因有很多，比如：网络问题、broker挂了、mq服务端磁盘问题等。这些情况，都可能会造成消息丢失。\r\n\r\n\r\n\r\n\r\n- 那么，如何防止消息丢失呢？\r\n\r\n  - 答：加一张消息发送表。\r\n\r\n\r\n\r\n\r\n![image-20230429164617994](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429164617994.png)\r\n\r\n\r\n\r\n- 在生产者发送mq消息之前，先把该条消息写入消息发送表，初始状态是待处理，然后再发送mq消息。消费者消费消息时，处理完业务逻辑之后，再回调生产者的一个接口，修改消息状态为已处理。\r\n\r\n\r\n\r\n\r\n- 如果生产者把消息写入消息发送表之后，再发送mq消息到mq服务端的过程中失败了，造成了消息丢失。\r\n\r\n\r\n\r\n\r\n- 这时候，要如何处理呢？\r\n\r\n  - 答：使用job，增加重试机制。\r\n\r\n\r\n\r\n\r\n![image-20230429164724585](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429164724585.png)\r\n\r\n\r\n\r\n> 用job每隔一段时间去查询消息发送表中状态为待处理的数据，然后重新发送mq消息。\r\n>\r\n\r\n\r\n\r\n\r\n\r\n####  8.2 重复消费问题 \r\n\r\n\r\n\r\n- 本来消费者消费消息时，在ack应答的时候，如果网络超时，本身就可能会消费重复的消息。但由于消息发送者增加了重试机制，会导致消费者重复消息的概率增大。\r\n\r\n\r\n\r\n\r\n- 那么，如何解决重复消息问题呢？\r\n\r\n  - 答：加一张消息处理表。\r\n\r\n\r\n![image-20230429164817906](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429164817906.png)\r\n\r\n\r\n\r\n\r\n\r\n> - 消费者读到消息之后，先判断一下消息处理表，是否存在该消息，如果存在，表示是重复消费，则直接返回。如果不存在，则进行下单操作，接着将该消息写入消息处理表中，再返回。\r\n>\r\n>\r\n> - 有个比较关键的点是：下单和写消息处理表，要放在同一个事务中，保证原子操作。\r\n>\r\n\r\n\r\n\r\n####  8.3 垃圾消息问题 \r\n\r\n\r\n\r\n- 这套方案表面上看起来没有问题，但如果出现了消息消费失败的情况。比如：由于某些原因，消息消费者下单一直失败，一直不能回调状态变更接口，这样job会不停的重试发消息。最后，会产生大量的垃圾消息。\r\n\r\n\r\n- 那么，如何解决这个问题呢？\r\n\r\n\r\n![image-20230429164937078](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429164937078.png)\r\n\r\n\r\n\r\n> - 每次在job重试时，需要先判断一下消息发送表中该消息的发送次数是否达到最大限制，如果达到了，则直接返回。如果没有达到，则将次数加1，然后发送消息。\r\n>\r\n> - 这样如果出现异常，只会产生少量的垃圾消息，不会影响到正常的业务。\r\n>\r\n\r\n\r\n\r\n####  8.4 延迟消费问题 \r\n\r\n\r\n\r\n- 通常情况下，如果用户秒杀成功了，下单之后，在15分钟之内还未完成支付的话，该订单会被自动取消，回退库存。\r\n\r\n\r\n\r\n\r\n- 那么，在15分钟内未完成支付，订单被自动取消的功能，要如何实现呢？\r\n\r\n  - 我们首先想到的可能是job，因为它比较简单。\r\n\r\n\r\n  - 但job有个问题，需要每隔一段时间处理一次，实时性不太好。\r\n\r\n\r\n\r\n\r\n- 还有更好的方案？\r\n\r\n  - 答：使用延迟队列。\r\n\r\n\r\n- 我们都知道rocketmq，自带了延迟队列的功能。\r\n\r\n\r\n\r\n\r\n![image-20230429165104965](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429165104965.png)\r\n\r\n\r\n\r\n- 下单时消息生产者会先生成订单，此时状态为待支付，然后会向延迟队列中发一条消息。达到了延迟时间，消息消费者读取消息之后，会查询该订单的状态是否为待支付。如果是待支付状态，则会更新订单状态为取消状态。如果不是待支付状态，说明该订单已经支付过了，则直接返回。\r\n\r\n\r\n\r\n\r\n- 还有个关键点，用户完成支付之后，会修改订单状态为已支付。\r\n\r\n\r\n\r\n\r\n![image-20230429165137323](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429165137323.png)\r\n\r\n\r\n\r\n\r\n\r\n###  9 如何限流？ \r\n\r\n\r\n\r\n- 通过秒杀活动，如果我们运气爆棚，可能会用非常低的价格买到不错的商品（这种概率堪比买福利彩票中大奖）。\r\n\r\n\r\n\r\n\r\n- 但有些高手，并不会像我们一样老老实实，通过秒杀页面点击秒杀按钮，抢购商品。他们可能在自己的服务器上，模拟正常用户登录系统，跳过秒杀页面，直接调用秒杀接口。\r\n\r\n\r\n\r\n\r\n- 如果是我们手动操作，一般情况下，一秒钟只能点击一次秒杀按钮。\r\n\r\n\r\n![image-20230429165212649](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429165212649.png)\r\n\r\n\r\n\r\n- 但是如果是服务器，一秒钟可以请求成上千接口。\r\n\r\n\r\n![image-20230429165302898](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429165302898.png)\r\n\r\n\r\n\r\n> - 这种差距实在太明显了，如果不做任何限制，绝大部分商品可能是被机器抢到，而非正常的用户，有点不太公平。\r\n>\r\n> - 所以，我们有必要识别这些非法请求，做一些限制。那么，我们该如何现在这些非法请求呢？\r\n>\r\n> - 目前有两种常用的限流方式：\r\n>\r\n>   - 1基于nginx限流\r\n>   - 2基于redis限流\r\n\r\n\r\n\r\n####  9.1 对同一用户限流 \r\n\r\n\r\n\r\n- 为了防止某个用户，请求接口次数过于频繁，可以只针对该用户做限制。\r\n\r\n\r\n![image-20230429165408344](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429165408344.png)\r\n\r\n\r\n\r\n> 限制同一个用户id，比如每分钟只能请求5次接口。\r\n>\r\n\r\n\r\n\r\n\r\n\r\n####  9.2 对同一ip限流 \r\n\r\n\r\n\r\n- 有时候只对某个用户限流是不够的，有些高手可以模拟多个用户请求，这种nginx就没法识别了。\r\n\r\n\r\n\r\n\r\n- 这时需要加同一ip限流功能。\r\n\r\n\r\n![image-20230429165439488](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429165439488.png)\r\n\r\n\r\n\r\n> - 限制同一个ip，比如每分钟只能请求5次接口。\r\n>\r\n> - 但这种限流方式可能会有误杀的情况，比如同一个公司或网吧的出口ip是相同的，如果里面有多个正常用户同时发起请求，有些用户可能会被限制住。\r\n>\r\n\r\n\r\n\r\n####  9.3 对接口限流 \r\n\r\n\r\n\r\n- 别以为限制了用户和ip就万事大吉，有些高手甚至可以使用代理，每次都请求都换一个ip。\r\n\r\n\r\n\r\n\r\n- 这时可以限制请求的接口总次数。\r\n\r\n\r\n![image-20230429165519105](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429165519105.png)\r\n\r\n\r\n\r\n> 在高并发场景下，这种限制对于系统的稳定性是非常有必要的。但可能由于有些非法请求次数太多，达到了该接口的请求上限，而影响其他的正常用户访问该接口。看起来有点得不偿失。\r\n>\r\n\r\n\r\n\r\n\r\n\r\n####  9.4 加验证码 \r\n\r\n\r\n\r\n- 相对于上面三种方式，加验证码的方式可能更精准一些，同样能限制用户的访问频次，但好处是不会存在误杀的情况。\r\n\r\n\r\n\r\n\r\n![image-20230429165554440](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429165554440.png)\r\n\r\n\r\n\r\n> - 通常情况下，用户在请求之前，需要先输入验证码。用户发起请求之后，服务端会去校验该验证码是否正确。只有正确才允许进行下一步操作，否则直接返回，并且提示验证码错误。\r\n>\r\n> - 此外，验证码一般是一次性的，同一个验证码只允许使用一次，不允许重复使用。\r\n>\r\n> - 普通验证码，由于生成的数字或者图案比较简单，可能会被破解。优点是生成速度比较快，缺点是有安全隐患。\r\n>\r\n> - 还有一个验证码叫做：移动滑块，它生成速度比较慢，但比较安全，是目前各大互联网公司的首选。\r\n>\r\n\r\n\r\n\r\n####  9.5 提高业务门槛 \r\n\r\n\r\n\r\n> - 上面说的加验证码虽然可以限制非法用户请求，但是有些影响用户体验。用户点击秒杀按钮前，还要先输入验证码，流程显得有点繁琐，秒杀功能的流程不是应该越简单越好吗？\r\n>\r\n> - 其实，有时候达到某个目的，不一定非要通过技术手段，通过业务手段也一样。\r\n>\r\n> - 12306刚开始的时候，全国人民都在同一时刻抢火车票，由于并发量太大，系统经常挂。后来，重构优化之后，将购买周期放长了，可以提前20天购买火车票，并且可以在9点、10、11点、12点等整点购买火车票。调整业务之后（当然技术也有很多调整），将之前集中的请求，分散开了，一下子降低了用户并发量。\r\n> - 回到这里，我们通过提高业务门槛，比如只有会员才能参与秒杀活动，普通注册用户没有权限。或者，只有等级到达3级以上的普通用户，才有资格参加该活动。\r\n>\r\n> - 这样简单的提高一点门槛，即使是黄牛党也束手无策，他们总不可能为了参加一次秒杀活动，还另外花钱充值会员吧？\r\n>\r\n\r\n\r\n\r\n\r\n\r\n## 秒杀系统项目实战\r\n\r\n### 1 秒杀业务概要\r\n\r\n\r\n\r\n- 秒杀具有瞬间高并发的特点，针对这一特点，必须要做到限流 + 异步 + 缓存（页面静态化） + 独立部署\r\n- 限流方式：\r\n  1. 前端限流，一些高并发的网站直接在前端页面开始限流，列如：小米的验证码\r\n  2. nginx限流，直接负载部分请求到错误的静态页面，令牌算法、漏斗算法\r\n  3. 网关限流、限流的过滤器\r\n  4. 代码中使用分布式信号量\r\n  5. rabbitmq限流（能者多劳 channel.basicQos(1)）保证发挥服务器的所用性能\r\n\r\n- 秒杀架构图\r\n\r\n![image-20230429224850779](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429224850779.png)\r\n\r\n\r\n\r\n### 2 秒杀流程\r\n\r\n- 参考京东秒杀流程\r\n- 见秒杀流程图\r\n\r\n\r\n\r\n- **秒杀方式一**\r\n\r\n![image-20230430003804352](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430003804352.png)\r\n\r\n\r\n\r\n- **秒杀方式二**\r\n\r\n![image-20230430003907398](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430003907398.png)\r\n\r\n\r\n\r\n\r\n\r\n### 3 秒杀核心业务\r\n\r\n#### 3.1 后台添加秒杀商品\r\n\r\n![image-20230430133519183](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430133519183.png)\r\n\r\n- 关联商品\r\n\r\n![image-20230430133622474](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430133622474.png)\r\n\r\n- 分页查询关联商品\r\n\r\n```java\r\n@Service(\"seckillSkuRelationService\")\r\npublic class SeckillSkuRelationServiceImpl extends ServiceImpl<SeckillSkuRelationDao, SeckillSkuRelationEntity> implements SeckillSkuRelationService {\r\n\r\n    @Override\r\n    public PageUtils queryPage(Map<String, Object> params) {\r\n        QueryWrapper<SeckillSkuRelationEntity> queryWrapper = new QueryWrapper<SeckillSkuRelationEntity>();\r\n        String promotionSessionId = (String) params.get(\"promotionSessionId\");\r\n        String key = (String) params.get(\"key\");\r\n        if (!StringUtils.isEmpty(key)){\r\n            queryWrapper.eq(\"sku_id\", key).or().eq(\"seckill_price\", key);\r\n        }\r\n        if (!StringUtils.isEmpty(promotionSessionId)){\r\n            //根据场次id进行查询\r\n            queryWrapper.eq(\"promotion_session_id\", promotionSessionId);\r\n        }\r\n\r\n        IPage<SeckillSkuRelationEntity> page = this.page(\r\n                new Query<SeckillSkuRelationEntity>().getPage(params),\r\n                queryWrapper\r\n        );\r\n\r\n        return new PageUtils(page);\r\n    }\r\n\r\n}\r\n```\r\n\r\n![image-20230430134014948](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430134014948.png)\r\n\r\n![image-20230430134032296](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430134032296.png)\r\n\r\n![image-20230430134056247](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430134056247.png)\r\n\r\n![image-20230430134613785](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430134613785.png)\r\n\r\n![image-20230430134650173](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430134650173.png)\r\n\r\n\r\n\r\n#### 定时任务\r\n\r\n##### 1.cron表达式\r\n\r\n语法：秒 分 时 日 月 周 年（Spring不支持）\r\n\r\nhttp://www.quartz-scheduler.org/documentation/quartz-2.3.0/tutorials/crontrigger.html\r\n\r\n![image-20230430135420949](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430135420949.png)\r\n\r\n特殊字符：\r\n\r\n- *（ “所有值”）-用于选择字段中的所有值。例如，分钟字段中的“  ”表示“每分钟”*。\r\n- ？（ “无特定值”）-当您需要在允许使用字符的两个字段之一中指定某个内容而在另一个不允许的字段中指定某些内容时很有用。例如，如果我希望在某个月的某个特定日期（例如，第10天）触发触发器，但不在乎一周中的哪一天发生，则将“ 10”设置为月字段，以及“？” 在“星期几”字段中。请参阅下面的示例以进行澄清。\r\n- --用于指定范围。例如，小时字段中的“ 10-12”表示“小时10、11和12”。\r\n- ， -用于指定其他值。例如，“星期几”字段中的“ MON，WED，FRI”表示“星期一，星期三和星期五的日子”。\r\n- / -用于指定增量。例如，秒字段中的“ 0/15”表示“秒0、15、30和45”。秒字段中的“ 5/15”表示“秒5、20、35和50”。您还可以在“ ”字符后指定“ /” -在这种情况下，“ ”等效于在“ /”之前使用“ 0”。每月日期字段中的“ 1/3”表示“从该月的第一天开始每三天触发一次”。\r\n- L（ “最后一个”）-在允许使用的两个字段中都有不同的含义。例如，“月”字段中的值“ L”表示“月的最后一天”，即非January年的1月31日，2月28日。如果单独用于星期几字段，则仅表示“ 7”或“ SAT”。但是，如果在星期几字段中使用另一个值，则表示“该月的最后xxx天”，例如“ 6L”表示“该月的最后一个星期五”。您还可以指定与该月最后一天的偏移量，例如“ L-3”，这表示日历月的倒数第三天。 使用“ L”选项时，不要指定列表或值的范围很重要，因为这样会导致混淆/意外结果。\r\n- W（ “工作日”）-用于指定最接近给定日期的工作日（星期一至星期五）。例如，如果您要指定“ 15W”作为“月日”字段的值，则含义是： “离月15日最近的工作日”。因此，如果15号是星期六，则触发器将在14号星期五触发。如果15日是星期日，则触发器将在16日星期一触发。如果15号是星期二，那么它将在15号星期二触发。但是，如果您将“ 1W”指定为月份的值，并且第一个是星期六，则触发器将在第3个星期一触发，因为它不会“跳过”一个月日的边界。仅当月份中的某天是一天，而不是范围或天数列表时，才可以指定“ W”字符。\r\n\r\n> “ L”和“ W”字符也可以在“月日”字段中组合以产生“ LW”，这表示“每月的最后一个工作日” 。\r\n\r\n- ＃ -用于指定每月的第“ XXX”天。例如，“星期几”字段中的值“ 6＃3”表示“该月的第三个星期五”（第6天=星期五，“＃3” =该月的第三个星期五）。其他示例：“ 2＃1” =该月的第一个星期一，“ 4＃5” =该月的第五个星期三。请注意，如果您指定“＃5”，并且该月的指定星期几中没有5个，则该月将不会触发。\r\n\r\n> 法定字符以及月份和星期几的名称不区分大小写。MON 与mon相同。\r\n\r\n\r\n\r\n\r\n\r\n##### 2.cron 示例\r\n\r\n| **Expression**             | **Meaning**                                                  |\r\n| -------------------------- | ------------------------------------------------------------ |\r\n| `0 0 12 * * ?`             | Fire at 12pm (noon) every day                                |\r\n| `0 15 10 ? * *`            | Fire at 10:15am every day                                    |\r\n| `0 15 10 * * ?`            | Fire at 10:15am every day                                    |\r\n| `0 15 10 * * ? *`          | Fire at 10:15am every day                                    |\r\n| `0 15 10 * * ? 2005`       | Fire at 10:15am every day during the year 2005               |\r\n| `0 * 14 * * ?`             | Fire every minute starting at 2pm and ending at 2:59pm, every day |\r\n| `0 0/5 14 * * ?`           | Fire every 5 minutes starting at 2pm and ending at 2:55pm, every day |\r\n| `0 0/5 14,18 * * ?`        | Fire every 5 minutes starting at 2pm and ending at 2:55pm, AND fire every 5 minutes starting at 6pm and ending at 6:55pm, every day |\r\n| `0 0-5 14 * * ?`           | Fire every minute starting at 2pm and ending at 2:05pm, every day |\r\n| `0 10,44 14 ? 3 WED`       | Fire at 2:10pm and at 2:44pm every Wednesday in the month of March. |\r\n| `0 15 10 ? * MON-FRI`      | Fire at 10:15am every Monday, Tuesday, Wednesday, Thursday and Friday |\r\n| `0 15 10 15 * ?`           | Fire at 10:15am on the 15th day of every month               |\r\n| `0 15 10 L * ?`            | Fire at 10:15am on the last day of every month               |\r\n| `0 15 10 L-2 * ?`          | Fire at 10:15am on the 2nd-to-last last day of every month   |\r\n| `0 15 10 ? * 6L`           | Fire at 10:15am on the last Friday of every month            |\r\n| `0 15 10 ? * 6L`           | Fire at 10:15am on the last Friday of every month            |\r\n| `0 15 10 ? * 6L 2002-2005` | Fire at 10:15am on every last friday of every month during the years 2002, 2003, 2004 and 2005 |\r\n| `0 15 10 ? * 6#3`          | Fire at 10:15am on the third Friday of every month           |\r\n| `0 0 12 1/5 * ?`           | Fire at 12pm (noon) every 5 days every month, starting on the first day of the month. |\r\n| `0 11 11 11 11 ?`          | Fire every November 11th at 11:11am.                         |\r\n\r\n\r\n\r\n##### 3.SpringBoot整合定时任务\r\n\r\n定时任务相关注解:\r\n\r\n```java\r\n@EnableAsync // 启用Spring异步任务支持\r\n@EnableScheduling // 启用Spring的计划任务执行功能\r\n@Async 异步\r\n@Scheduled(cron = \"* * * * * ?\")\r\n```\r\n\r\n代码：\r\n\r\n```java\r\n/**\r\n *\r\n * 定时任务\r\n *      1、@EnableScheduling 开启定时任务\r\n *      2、Scheduled 开启一个定时任务\r\n *      3、自动配置类 TaskSchedulingAutoConfiguration 属性绑定在TaskExecutionProperties\r\n *\r\n * 异步任务\r\n *      1、@EnableAsync 开启异步任务功能\r\n *      2、@Async 给希望异步执行的方法上标注\r\n *      3、自动配置类 TaskExecutionAutoConfiguration\r\n *\r\n */\r\n@Slf4j\r\n@Component\r\n@EnableAsync // 启用Spring异步任务支持\r\n@EnableScheduling // 启用Spring的计划任务执行功能\r\npublic class HelloSchedule {\r\n\r\n    /**\r\n     * 1、Spring中6位组成，不允许第7位的年\r\n     * 2、在周几的位置，1-7代表周一到周日：MON-SUN\r\n     * 3、定时任务应该阻塞，默认是阻塞的\r\n     *      1、可以让业务以异步的方式运行，自己提交到线程池\r\n     *          CompletableFuture.runAsync(() -> {\r\n     *              xxxService.hello();\r\n     *          })\r\n     *      2、支持定时任务线程池，设置 TaskSchedulingProperties\r\n     *          spring.task.scheduling.pool.size=5\r\n     *      3、让定时任务异步执行\r\n     *          异步执行\r\n     *     解决：使用异步 + 定时任务来完成定时任务不阻塞的功能\r\n     */\r\n//    @Async 异步\r\n//    @Scheduled(cron = \"* * * * * ?\")\r\n//    public void hello() {\r\n//        log.info(\"hello...\");\r\n//    }\r\n}\r\n```\r\n\r\n```properties\r\nspring.task.execution.pool.core-size=5\r\nspring.task.execution.pool.max-size=50\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n#### 3.2 秒杀商品上架\r\n\r\n- 定时上架秒杀商品\r\n\r\n```java\r\n/**\r\n *  * 秒杀商品的定时上架；\r\n *  *      每天晚上3点；上架最近三天需要秒杀的商品\r\n *  *      当天00:00:00 - 23:59:59\r\n *  *      明天天00:00:00 - 23:59:59\r\n *  *      后天00:00:00 - 23:59:59\r\n * @author Klaus\r\n * @date 2022/9/27\r\n */\r\n@Slf4j\r\n@Service\r\npublic class SeckillSkuScheduled {\r\n\r\n    @Autowired\r\n    SeckillService seckillService;\r\n\r\n    @Scheduled(cron = \"0 0 1/1 * * ? \")\r\n    public void uploadSeckillSkuLatest3Days(){\r\n         seckillService.uploadSeckillSkuLatest3Days();\r\n    }\r\n}\r\n```\r\n\r\n- 远程获取近三天秒杀商品\r\n\r\n```java\r\n@FeignClient(\"gulimall-coupon\")\r\npublic interface CouponFeignService {\r\n\r\n    @GetMapping(\"/coupon/seckillsession/latest3DaySession\")\r\n    R getLatest3DaySession();\r\n}\r\n```\r\n\r\n- 获取最近3天的秒杀活动场次接口\r\n- `org.klaus.zgg01mall.coupon.controller.SeckillSessionController#getLatest3DaySession`\r\n\r\n```java\r\n/**\r\n * 获取最近3天的秒杀活动场次\r\n * @return\r\n */\r\n@GetMapping(\"/latest3DaySession\")\r\npublic R getLatest3DaySession(){\r\n    List<SeckillSessionEntity> sessionEntities = seckillSessionService.getLatest3DaySession();\r\n    return R.ok().setData(sessionEntities);\r\n}\r\n```\r\n\r\n- 获取最近3天的秒杀活动场次方法实现及时间日期处理\r\n\r\n```java\r\n    @Autowired\r\n    SeckillSkuRelationService seckillSkuRelationService;\r\n\t/**\r\n     * 获取最近3天的秒杀活动场次\r\n     *\r\n     * @return\r\n     */\r\n    @Override\r\n    public List<SeckillSessionEntity> getLatest3DaySession() {\r\n        //获取最近三天信息\r\n\r\n        List<SeckillSessionEntity> list = this.list(new QueryWrapper<SeckillSessionEntity>\t().between(\"start_time\", startTime(), endTime()));\r\n        \r\n        return null;\r\n    }\r\n\tprivate String startTime() {\r\n        LocalDate now = LocalDate.now();\r\n        LocalTime min = LocalTime.MIN;\r\n        LocalDateTime start = LocalDateTime.of(now, min);\r\n        String format = start.format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"));\r\n        return format;\r\n    }\r\n\r\n    private String endTime() {\r\n        LocalDate now = LocalDate.now();\r\n        LocalDate localDate = now.plusDays(2);\r\n        LocalTime max = LocalTime.MAX;\r\n        LocalDateTime end = LocalDateTime.of(localDate, max);\r\n        String format = end.format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\"));\r\n        return format;\r\n    }\r\n```\r\n\r\n\r\n\r\n\r\n\r\n- 秒杀活动场次添加商品关联（不记入数据库）\r\n\r\n```java\r\n/**\r\n * 秒杀活动场次\r\n * \r\n * @author klaus\r\n * @email klaus@gmail.com\r\n * @date 2022-08-22 13:18:54\r\n */\r\n@Data\r\n@TableName(\"sms_seckill_session\")\r\npublic class SeckillSessionEntity implements Serializable {\r\n\t......\r\n\r\n   /**\r\n    * 所有秒杀活动商品关联\r\n    */\r\n   @TableField(exist = false)\r\n   private List<SeckillSkuRelationEntity> relationSkus;\r\n\r\n}\r\n```\r\n\r\n- 完善获取最近3天的秒杀活动场次方法实现\r\n- `org.klaus.zgg01mall.coupon.service.impl.SeckillSessionServiceImpl#getLatest3DaySession`\r\n\r\n![image-20230430142137405](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430142137405.png)\r\n\r\n```java\r\n/**\r\n * 获取最近3天的秒杀活动场次\r\n *\r\n * @return\r\n */\r\n@Override\r\npublic List<SeckillSessionEntity> getLatest3DaySession() {\r\n    //获取最近三天信息\r\n\r\n    List<SeckillSessionEntity> list = this.list(new QueryWrapper<SeckillSessionEntity>().between(\"start_time\", startTime(), endTime()));\r\n    if (list != null && list.size() > 0) {\r\n        List<SeckillSessionEntity> collect = list.stream().map(session -> {\r\n            //获取秒杀场次id\r\n            Long id = session.getId();\r\n            //根据秒杀场次id获取秒杀关联商品集合\r\n            List<SeckillSkuRelationEntity> skuRelationEntities = seckillSkuRelationService.list(new QueryWrapper<SeckillSkuRelationEntity>().eq(\"promotion_session_id\", id));\r\n            if (skuRelationEntities != null && skuRelationEntities.size() > 0) {\r\n                session.setRelationSkus(skuRelationEntities);\r\n            }\r\n            return session;\r\n        }).collect(Collectors.toList());\r\n        return collect;\r\n    }\r\n    return null;\r\n}\r\n```\r\n\r\n\r\n\r\n- 添加数据传输vo\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/28\r\n */\r\n@Data\r\npublic class SeckillSessionWithSkus {\r\n\r\n    private Long id;\r\n    /**\r\n     * 场次名称\r\n     */\r\n    private String name;\r\n    /**\r\n     * 每日开始时间\r\n     */\r\n    private Date startTime;\r\n    /**\r\n     * 每日结束时间\r\n     */\r\n    private Date endTime;\r\n    /**\r\n     * 启用状态\r\n     */\r\n    private Integer status;\r\n    /**\r\n     * 创建时间\r\n     */\r\n    private Date createTime;\r\n\r\n\r\n    private List<SeckillSkuVo> relationSkus;\r\n}\r\n```\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/28\r\n */\r\n@Data\r\npublic class SeckillSkuVo {\r\n\r\n    private Long id;\r\n    /**\r\n     * 活动id\r\n     */\r\n    private Long promotionId;\r\n    /**\r\n     * 活动场次id\r\n     */\r\n    private Long promotionSessionId;\r\n    /**\r\n     * 商品id\r\n     */\r\n    private Long skuId;\r\n    /**\r\n     * 秒杀价格\r\n     */\r\n    private BigDecimal seckillPrice;\r\n    /**\r\n     * 秒杀总量\r\n     */\r\n    private BigDecimal seckillCount;\r\n    /**\r\n     * 每人限购数量\r\n     */\r\n    private BigDecimal seckillLimit;\r\n    /**\r\n     * 排序\r\n     */\r\n    private Integer seckillSort;\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n- 秒杀商品定时上架流程\r\n\r\n![image-20230430004237857](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430004237857.png)\r\n\r\n- 秒杀服务远程调用扫描最近三天需要参与秒杀的活动方法实现\r\n- `org.klaus.zgg01mall.seckill.service.impl.SeckillServiceImpl#uploadSeckillSkuLatest3Days`\r\n\r\n```java\r\n@Override\r\npublic void uploadSeckillSkuLatest3Days() {\r\n    //1、扫描最近三天需要参与秒杀的活动\r\n    R r = couponFeignService.getLatest3DaySession();\r\n    if (r.getCode() == 0) {\r\n        //远程调用成功，上架商品\r\n        List<SeckillSessionWithSkus> sessionData = r.getData(new TypeReference<List<SeckillSessionWithSkus>>() {\r\n        });\r\n        if (sessionData != null && sessionData.size() > 0) {\r\n            //缓存到redis\r\n            //1、缓存活动信息\r\n            saveSessionInfos(sessionData);\r\n            //2、缓存活动的关联商品信息\r\n            saveSessionSkuInfos(sessionData);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n##### 1、缓存活动信息方法\r\n\r\n```java\r\n\tprivate final String SESSIONS_CACHE_PREFOX = \"seckill:sessions:\";\r\n\tprivate void saveSessionInfos(List<SeckillSessionWithSkus> sessions) {\r\n        if (sessions != null && sessions.size() > 0) {\r\n\r\n            sessions.stream().forEach(session -> {\r\n                long startTime = session.getStartTime().getTime();\r\n                long endTime = session.getEndTime().getTime();\r\n                String key = SESSIONS_CACHE_PREFOX + startTime + \"_\" + endTime;\r\n                    //key不存在进行缓存操作\r\n                    List<String> skuIds = session.getRelationSkus().stream().map(item -> item.getPromotionSessionId().toString() + \"_\" + item.getSkuId().toString()).collect(Collectors.toList());\r\n                    //缓存所有活动信息\r\n                    redisTemplate.opsForList().leftPushAll(key, skuIds);\r\n            });\r\n        }\r\n    }\r\n```\r\n\r\n\r\n\r\n- sku的详细信息及秒杀活动场次信息数据传输to\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/28\r\n */\r\n@Data\r\npublic class SeckillSkuRedisTo {\r\n\r\n    /**\r\n     * 活动id\r\n     */\r\n    private Long promotionId;\r\n    /**\r\n     * 活动场次id\r\n     */\r\n    private Long promotionSessionId;\r\n    /**\r\n     * 商品id\r\n     */\r\n    private Long skuId;\r\n\r\n    /**\r\n     * 商品秒杀随机码\r\n     */\r\n    private String randomCode;\r\n\r\n    /**\r\n     * 秒杀价格\r\n     */\r\n    private BigDecimal seckillPrice;\r\n    /**\r\n     * 秒杀总量\r\n     */\r\n    private BigDecimal seckillCount;\r\n    /**\r\n     * 每人限购数量\r\n     */\r\n    private BigDecimal seckillLimit;\r\n    /**\r\n     * 排序\r\n     */\r\n    private Integer seckillSort;\r\n\r\n\r\n    /**\r\n     * 当前商品秒杀的开始时间\r\n     */\r\n    private Long startTime;\r\n\r\n    /**\r\n     * 当前商品秒杀的结束时间\r\n     */\r\n    private Long endTime;\r\n    /**\r\n     * sku的详细信息\r\n     */\r\n    private SkuInfoVo skuInfoVo;\r\n}\r\n```\r\n\r\n- sku的详细信息数据传输vo\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/28\r\n */\r\n@Data\r\npublic class SkuInfoVo {\r\n    private Long skuId;\r\n    /**\r\n     * spuId\r\n     */\r\n    private Long spuId;\r\n    /**\r\n     * sku名称\r\n     */\r\n    private String skuName;\r\n    /**\r\n     * sku介绍描述\r\n     */\r\n    private String skuDesc;\r\n    /**\r\n     * 所属分类id\r\n     */\r\n    private Long catalogId;\r\n    /**\r\n     * 品牌id\r\n     */\r\n    private Long brandId;\r\n    /**\r\n     * 默认图片\r\n     */\r\n    private String skuDefaultImg;\r\n    /**\r\n     * 标题\r\n     */\r\n    private String skuTitle;\r\n    /**\r\n     * 副标题\r\n     */\r\n    private String skuSubtitle;\r\n    /**\r\n     * 价格\r\n     */\r\n    private BigDecimal price;\r\n    /**\r\n     * 销量\r\n     */\r\n    private Long saleCount;\r\n}\r\n```\r\n\r\n\r\n\r\n- 远程获取sku详细信息\r\n\r\n```java\r\n@FeignClient(\"gulimall-product\")\r\npublic interface ProductFeignService {\r\n\r\n    @RequestMapping(\"/product/skuinfo/info/{skuId}\")\r\n    R getSkuInfo(@PathVariable(\"skuId\") Long skuId);\r\n}\r\n```\r\n\r\n- 获取sku详细信息接口\r\n\r\n```java\r\n/**\r\n   * 信息\r\n   */\r\n  @RequestMapping(\"/info/{skuId}\")\r\n  //@RequiresPermissions(\"product:skuinfo:info\")\r\n  public R info(@PathVariable(\"skuId\") Long skuId){\r\nSkuInfoEntity skuInfo = skuInfoService.getById(skuId);\r\n\r\n      return R.ok().put(\"skuInfo\", skuInfo);\r\n  }\r\n```\r\n\r\n\r\n\r\n\r\n\r\n##### 2、缓存活动的关联商品信息\r\n\r\n- 引入redisson依赖使用分布式信号量\r\n\r\n```xml\r\n<!--以后使用redisson作为所有分布式锁，分布式对象等功能框架 -->\r\n<dependency>\r\n    <groupId>org.redisson</groupId>\r\n    <artifactId>redisson</artifactId>\r\n    <version>3.12.0</version>\r\n</dependency>\r\n```\r\n\r\n- 相关配置\r\n\r\n```properties\r\nspring.redis.host=192.168.10.103\r\n```\r\n\r\n- 配置类\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/7\r\n */\r\n@Configuration\r\npublic class MyRedissonConfig {\r\n\r\n    /**\r\n     * 所有对Redisson的使用都是通过RedissonClient对象\r\n     * @return\r\n     * @throws IOException\r\n     */\r\n    @Bean(destroyMethod=\"shutdown\")\r\n    public RedissonClient redisson() throws IOException {\r\n        //1、创建配置\r\n        //Redis url should start with redis:// or rediss://\r\n        Config config = new Config();\r\n        config.useSingleServer().setAddress(\"redis://192.168.10.103:6379\");\r\n\r\n        //2、根据config创建出Redisson实例\r\n        RedissonClient redissonClient = Redisson.create(config);\r\n        return redissonClient;\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n```java\r\nprivate final String SKUKILL_CACHE_PREFOX = \"seckill:skus:\";\r\n\r\nprivate final String SKU_STOCK_SEMAPHORE = \"seckill:stock:\";//+商品随机码\r\nprivate void saveSessionSkuInfos(List<SeckillSessionWithSkus> sessions) {\r\n\r\n    //准备hash操作\r\n    BoundHashOperations<String, Object, Object> ops = redisTemplate.boundHashOps(SKUKILL_CACHE_PREFOX);\r\n\r\n    if (sessions != null && sessions.size() > 0) {\r\n\r\n        sessions.stream().forEach(session -> {\r\n\r\n            String token = UUID.randomUUID().toString().replace(\"-\", \"\");\r\n\r\n\r\n            session.getRelationSkus().stream().forEach(seckillSkuVo -> {\r\n\r\n                    //key不存在进行缓存商品\r\n                    SeckillSkuRedisTo redisTo = new SeckillSkuRedisTo();\r\n                    //1、sku的基本数据\r\n                    R r = productFeignService.getSkuInfo(seckillSkuVo.getSkuId());\r\n                    if (r.getCode() == 0) {\r\n                        //远程调用成功\r\n                        SkuInfoVo skuInfo = r.getData(\"skuInfo\", new TypeReference<SkuInfoVo>() {\r\n                        });\r\n                        redisTo.setSkuInfoVo(skuInfo);\r\n                    }\r\n                    //2、sku的秒杀信息\r\n                    BeanUtils.copyProperties(seckillSkuVo, redisTo);\r\n\r\n                    //3、设置上当前商品的秒杀时间信息\r\n                    redisTo.setStartTime(session.getStartTime().getTime());\r\n                    redisTo.setEndTime(session.getEndTime().getTime());\r\n\r\n                    //4、随机码   seckill?skuId=1&key=fewqfwrgvrw\r\n                    redisTo.setRandomCode(token);\r\n\r\n                    String jsonString = JSON.toJSONString(redisTo);\r\n                    ops.put(seckillSkuVo.getPromotionSessionId().toString() + \"_\" + seckillSkuVo.getSkuId().toString(), jsonString);\r\n\r\n\r\n                    //秒杀请求进来先获取信号量，获取不到就无法执行数据库的所有方法了\r\n                    //如果当前这个场次的商品的库存信息已经上架就不需要上架\r\n                    //5、使用库存作为分布式的信号量 -> 限流；\r\n                    RSemaphore semaphore = redissonClient.getSemaphore(SKU_STOCK_SEMAPHORE + token);\r\n                    //商品可以秒杀的数量作为信号量\r\n                    semaphore.trySetPermits(seckillSkuVo.getSeckillCount().intValue());\r\n                \r\n            });\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n- 修改上架时间\r\n\r\n![image-20230430145943910](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430145943910.png)\r\n\r\n![image-20230430150003699](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430150003699.png)\r\n\r\n- 未做幂等性处理出现重复上架情况\r\n\r\n![image-20230430150132974](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430150132974.png)\r\n\r\n- 活动信息收集的是我们的skuId不是活动记录id\r\n\r\n```java\r\nList<String> skuIds = session.getRelationSkus().stream().map(item -> item.getSkuId().toString()).collect(Collectors.toList());\r\n```\r\n\r\n![image-20230430150728958](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430150728958.png)\r\n\r\n- 活动的关联商品信息key也为skuId\r\n\r\n```java\r\nops.put(seckillSkuVo.getSkuId().toString(), jsonString);\r\n```\r\n\r\n\r\n\r\n\r\n\r\n#### 分布式定时任务 \r\n\r\n\r\n\r\n##### 1.定时任务的问题 \r\n\r\n![image-20230429224924881](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429224924881.png)\r\n\r\n- 1）、同时执行导致的重复\r\n  - 由于同样的服务会部署多个节点，多个节点的定时任务代码可能同时启动。将同样的事情做了多次使用分布式锁。\r\n\r\n- 2）、任务拆分并发执行\r\n  - 使用 ElasticJob\r\n\r\n\r\n\r\n##### 2.扩展 - 分布式调整\r\n\r\nhttp://elasticjob.io/docs/elastic-job-cloud/00-overview/\r\n\r\n\r\n\r\n\r\n\r\n#### 3.3 幂等性保证\r\n\r\n```java\r\n/**\r\n *  * 秒杀商品的定时上架；\r\n *  *      每天晚上3点；上架最近三天需要秒杀的商品\r\n *  *      当天00:00:00 - 23:59:59\r\n *  *      明天天00:00:00 - 23:59:59\r\n *  *      后天00:00:00 - 23:59:59\r\n * @author Klaus\r\n * @date 2022/9/27\r\n */\r\n@Slf4j\r\n@Service\r\npublic class SeckillSkuScheduled {\r\n\r\n    @Autowired\r\n    SeckillService seckillService;\r\n\r\n    @Autowired\r\n    RedissonClient redissonClient;\r\n\r\n    private final String UPLOAD_LOCK = \"seckill:upload:lock\";\r\n\r\n    /**\r\n     * todo 幂等性处理\r\n     */\r\n//     @Scheduled(cron = \"*/5 * * * * ? \")\r\n    @Scheduled(cron = \"0 0 1/1 * * ? \")\r\n    public void uploadSeckillSkuLatest3Days(){\r\n        //1、重复上架无需处理\r\n        log.info(\"上架秒杀的商品信息...\");\r\n        //分布式锁。锁的业务执行完成，状态已经更新完成，释放锁以后，其他人获取到就会拿到最新的状态\r\n        RLock lock = redissonClient.getLock(UPLOAD_LOCK);\r\n        lock.lock(10, TimeUnit.SECONDS);\r\n        try {\r\n            seckillService.uploadSeckillSkuLatest3Days();\r\n\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n- 完善缓存活动信息方法\r\n\r\n```java\r\nprivate void saveSessionInfos(List<SeckillSessionWithSkus> sessions) {\r\n    if (sessions != null && sessions.size() > 0) {\r\n\r\n        sessions.stream().forEach(session -> {\r\n            long startTime = session.getStartTime().getTime();\r\n            long endTime = session.getEndTime().getTime();\r\n            String key = SESSIONS_CACHE_PREFOX + startTime + \"_\" + endTime;\r\n            Boolean hasKey = redisTemplate.hasKey(key);\r\n            if (!hasKey) {\r\n                //key不存在进行缓存操作\r\n                List<String> skuIds = session.getRelationSkus().stream().map(item -> item.getPromotionSessionId().toString() + \"_\" + item.getSkuId().toString()).collect(Collectors.toList());\r\n                //缓存所有活动信息\r\n                redisTemplate.opsForList().leftPushAll(key, skuIds);\r\n            }\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n- 完善缓存活动的关联商品信息\r\n\r\n```java\r\nprivate void saveSessionSkuInfos(List<SeckillSessionWithSkus> sessions) {\r\n\r\n    //准备hash操作\r\n    BoundHashOperations<String, Object, Object> ops = redisTemplate.boundHashOps(SKUKILL_CACHE_PREFOX);\r\n\r\n    if (sessions != null && sessions.size() > 0) {\r\n\r\n        sessions.stream().forEach(session -> {\r\n\r\n            String token = UUID.randomUUID().toString().replace(\"-\", \"\");\r\n\r\n\r\n            session.getRelationSkus().stream().forEach(seckillSkuVo -> {\r\n                if (!ops.hasKey(seckillSkuVo.getPromotionSessionId().toString() + \"_\" + seckillSkuVo.getSkuId().toString())) {\r\n                    //key不存在进行缓存商品\r\n                    SeckillSkuRedisTo redisTo = new SeckillSkuRedisTo();\r\n                    //1、sku的基本数据\r\n                    R r = productFeignService.getSkuInfo(seckillSkuVo.getSkuId());\r\n                    if (r.getCode() == 0) {\r\n                        //远程调用成功\r\n                        SkuInfoVo skuInfo = r.getData(\"skuInfo\", new TypeReference<SkuInfoVo>() {\r\n                        });\r\n                        redisTo.setSkuInfoVo(skuInfo);\r\n                    }\r\n                    //2、sku的秒杀信息 vo->to\r\n                    BeanUtils.copyProperties(seckillSkuVo, redisTo);\r\n\r\n                    //3、设置上当前商品的秒杀时间信息\r\n                    redisTo.setStartTime(session.getStartTime().getTime());\r\n                    redisTo.setEndTime(session.getEndTime().getTime());\r\n\r\n                    //4、随机码   seckill?skuId=1&key=fewqfwrgvrw\r\n                    redisTo.setRandomCode(token);\r\n\r\n                    String jsonString = JSON.toJSONString(redisTo);\r\n                    ops.put(seckillSkuVo.getPromotionSessionId().toString() + \"_\" + seckillSkuVo.getSkuId().toString(), jsonString);\r\n\r\n\r\n                    //秒杀请求进来先获取信号量，获取不到就无法执行数据库的所有方法了\r\n                    //如果当前这个场次的商品的库存信息已经上架就不需要上架\r\n                    //5、使用库存作为分布式的信号量 -> 限流；\r\n                    RSemaphore semaphore = redissonClient.getSemaphore(SKU_STOCK_SEMAPHORE + token);\r\n                    //商品可以秒杀的数量作为信号量\r\n                    semaphore.trySetPermits(seckillSkuVo.getSeckillCount().intValue());\r\n                }\r\n\r\n            });\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n#### 3.4 查询秒杀商品+页面渲染\r\n\r\n- 返回当前时间可以参与的秒杀商品信息接口\r\n\r\n```java\r\n@Controller\r\npublic class SeckillController {\r\n\r\n    @Autowired\r\n    SeckillService seckillService;\r\n\r\n    /**\r\n     * 返回当前时间可以参与的秒杀商品信息\r\n     * @return\r\n     */\r\n    @ResponseBody\r\n    @GetMapping(\"/currentSeckillSkus\")\r\n    public R getCurrentSeckillSkus(){\r\n        List<SeckillSkuRedisTo> tos = seckillService.getCurrentSeckillSkus();\r\n        return R.ok().setData(tos);\r\n    }\r\n```\r\n\r\n- 返回当前时间可以参与的秒杀商品信息方法实现\r\n\r\n```java\r\n/**\r\n     * 返回当前时间可以参与的秒杀商品信息\r\n     */\r\n    @Override\r\n    public List<SeckillSkuRedisTo> getCurrentSeckillSkus() {\r\n        //1、确定当前时间属于哪个秒杀场次\r\n        long time = System.currentTimeMillis();\r\n\r\n        Set<String> keys = redisTemplate.keys(SESSIONS_CACHE_PREFOX + \"*\");\r\n        for (String key : keys) {\r\n            //seckill:sessions:1664301600000_1664305200000->1664301600000_1664305200000\r\n            String replace = key.replace(SESSIONS_CACHE_PREFOX, \"\");\r\n            //[1664301600000 _ 1664305200000]\r\n            //        0             1\r\n            String[] s = replace.split(\"_\");\r\n            Long start = Long.parseLong(s[0]);\r\n            Long end = Long.parseLong(s[1]);\r\n            if (time >= start && time <= end) {\r\n                //当前时间在秒杀时间范围内\r\n                //2、获取这个秒杀场次需要的所有商品信息\r\n                List<String> range = redisTemplate.opsForList().range(key, -100, 100);\r\n                BoundHashOperations<String, String, String> hashOps = redisTemplate.boundHashOps(SKUKILL_CACHE_PREFOX);\r\n                assert range != null;\r\n                List<String> list = hashOps.multiGet(range);\r\n                if (list != null && list.size() > 0) {\r\n                    List<SeckillSkuRedisTo> collect = list.stream().map(item -> {\r\n                        SeckillSkuRedisTo skuRedisTo = JSON.parseObject((String) item, SeckillSkuRedisTo.class);\r\n//                        skuRedisTo.setRandomCode(null);当前秒杀开始就需要随机码\r\n\r\n                        return skuRedisTo;\r\n                    }).collect(Collectors.toList());\r\n                    return collect;\r\n                }\r\n                break;\r\n            }\r\n        }\r\n        return null;\r\n    }\r\n```\r\n\r\n![image-20230430152815352](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430152815352.png)\r\n\r\n\r\n\r\n![image-20230428202232121](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428202232121.png)\r\n\r\n\r\n\r\n- 商品服务远程查询秒杀信息\r\n- 远程接口\r\n\r\n```java\r\n@FeignClient(value = \"gulimall-seckill\", fallback = SeckillFeignServiceFallBack.class )\r\npublic interface SeckillFeignService {\r\n\r\n    @GetMapping(\"/sku/seckill/{skuId}\")\r\n    R getSkuSeckillInfo(@PathVariable(\"skuId\")Long skuId);\r\n}\r\n```\r\n\r\n- 获取秒杀信息接口\r\n\r\n```java\r\n@ResponseBody\r\n@GetMapping(\"/sku/seckill/{skuId}\")\r\npublic R getSkuSeckillInfo(@PathVariable(\"skuId\")Long skuId){\r\n    SeckillSkuRedisTo to = seckillService.getSkuSeckillInfo(skuId);\r\n\r\n    return R.ok().setData(to);\r\n}\r\n```\r\n\r\n- 获取秒杀信息方法实现（正则匹配BUG已修复）\r\n\r\n```java\r\n@Override\r\n    public SeckillSkuRedisTo getSkuSeckillInfo(Long skuId) {\r\n        //1、找到所有需要参与秒杀的商品的key\r\n        BoundHashOperations<String, String, String> hashOps = redisTemplate.boundHashOps(SKUKILL_CACHE_PREFOX);\r\n        Set<String> keys = hashOps.keys();\r\n        if (keys != null && keys.size() > 0) {\r\n            //todo 正则匹配2位数\r\n            String regx = \"\\\\d\\\\d_\" + skuId;\r\n            //创建匹配模式\r\n//            Pattern pattern = Pattern.compile(\"\\\\d_\");//匹配一个或多个数字字符\r\n            //2.选择匹配对象\r\n//            Matcher matcher = pattern.matcher(skuId.toString());\r\n\r\n            for (String key : keys) {\r\n                log.info(\"test:{}\",  Pattern.matches(regx, key));\r\n                // 6_4\r\n                if (Pattern.matches(regx, key)) {\r\n//                if (regx.matches(key)) {\r\n//                if (matcher.find()) {\r\n                    String json = hashOps.get(key);\r\n                    SeckillSkuRedisTo skuRedisTo = JSON.parseObject(json, SeckillSkuRedisTo.class);\r\n\r\n                    //处理随机码\r\n                    long current = System.currentTimeMillis();\r\n                    if (current >= skuRedisTo.getStartTime() && current <= skuRedisTo.getEndTime()) {\r\n\r\n                    } else {\r\n                        //在时间范围外直接置空\r\n                        skuRedisTo.setRandomCode(null);\r\n                    }\r\n                    return skuRedisTo;\r\n                }\r\n            }\r\n        }\r\n\r\n        return null;\r\n    }\r\n```\r\n\r\n- sku详情页获取商品（秒杀）详情接口\r\n\r\n```java\r\n/**\r\n * 展示当前sku的详情\r\n * @param skuId\r\n * @return\r\n */\r\n@GetMapping(\"/{skuId}.html\")\r\npublic String skuItem(@PathVariable(\"skuId\")Long skuId, Model model) throws ExecutionException, InterruptedException {\r\n\r\n\r\n    System.out.println(\"准备查询\" + skuId + \"详情\");\r\n    SkuItemVo vo = skuInfoService.item(skuId);\r\n    //页面渲染\r\n    model.addAttribute(\"item\", vo);\r\n\r\n    return \"item\";\r\n}\r\n```\r\n\r\n- 获取商品（秒杀）详情方法实现\r\n\r\n  - 秒杀详情数据传输vo\r\n\r\n  ```java\r\n  /**\r\n   * @author Klaus\r\n   * @date 2022/9/28\r\n   */\r\n  @Data\r\n  public class SeckillInfoVo {\r\n  \r\n      /**\r\n       * 活动id\r\n       */\r\n      private Long promotionId;\r\n      /**\r\n       * 活动场次id\r\n       */\r\n      private Long promotionSessionId;\r\n      /**\r\n       * 商品id\r\n       */\r\n      private Long skuId;\r\n  \r\n      /**\r\n       * 商品秒杀随机码\r\n       */\r\n      private String randomCode;\r\n  \r\n      /**\r\n       * 秒杀价格\r\n       */\r\n      private BigDecimal seckillPrice;\r\n      /**\r\n       * 秒杀总量\r\n       */\r\n      private BigDecimal seckillCount;\r\n      /**\r\n       * 每人限购数量\r\n       */\r\n      private BigDecimal seckillLimit;\r\n      /**\r\n       * 排序\r\n       */\r\n      private Integer seckillSort;\r\n  \r\n  \r\n  \r\n      /**\r\n       * 当前商品秒杀的开始时间\r\n       */\r\n      private Long startTime;\r\n  \r\n      /**\r\n       * 当前商品秒杀的结束时间\r\n       */\r\n      private Long endTime;\r\n  }\r\n  ```\r\n\r\n```java\r\n\t@Resource\r\n    SeckillFeignService seckillFeignService;\r\n\t@Override\r\n    public SkuItemVo item(Long skuId) throws ExecutionException, InterruptedException {\r\n        SkuItemVo skuItemVo = new SkuItemVo();\r\n\r\n        ......\r\n\r\n        CompletableFuture<Void> seckillFuture = CompletableFuture.runAsync(() -> {\r\n            // 秒杀信息\r\n            R r = seckillFeignService.getSkuSeckillInfo(skuId);\r\n            if (r.getCode() == 0) {\r\n                //远程调用成功\r\n                SeckillInfoVo data = r.getData(new TypeReference<SeckillInfoVo>() {\r\n                });\r\n                if (data != null) {\r\n                    skuItemVo.setSeckillInfo(data);\r\n                }\r\n            }\r\n        }, productThreadPoolExecutor);\r\n\r\n        //等待所有的任务都完成\r\n        CompletableFuture.allOf(saleAttrFuture, descFuture, baseAttrFuture, imageFuture, seckillFuture).get();\r\n\r\n        return skuItemVo;\r\n    }\r\n```\r\n\r\n\r\n\r\n![image-20230428202310827](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428202310827.png)\r\n\r\n![image-20230428202403297](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428202403297.png)\r\n\r\n\r\n\r\n\r\n\r\n#### 3.5 秒杀系统设计\r\n\r\n\r\n\r\n![image-20230429225031339](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429225031339.png)\r\n\r\n![image-20230429225211015](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429225211015.png)\r\n\r\n#### 3.6 登录检查\r\n\r\n- 引入Spring Session依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.session</groupId>\r\n    <artifactId>spring-session-data-redis</artifactId>\r\n</dependency>\r\n```\r\n\r\n- Session配置类\r\n\r\n```java\r\n@EnableRedisHttpSession\r\n@Configuration\r\npublic class GulimallSessionConfig {\r\n\r\n    @Bean\r\n    public CookieSerializer cookieSerializer(){\r\n        DefaultCookieSerializer cookieSerializer = new DefaultCookieSerializer();\r\n\r\n        cookieSerializer.setDomainName(\"gulimall.com\");\r\n        cookieSerializer.setCookieName(\"KLAUSSESSION\");\r\n        return cookieSerializer;\r\n    }\r\n\r\n    @Bean\r\n    public RedisSerializer<Object> springSessionDefaultRedisSerializer() {\r\n        return new GenericJackson2JsonRedisSerializer();\r\n    }\r\n}\r\n```\r\n\r\n- 相关配置\r\n\r\n```properties\r\nspring.session.store-type=REDIS\r\n```\r\n\r\n- 添加登录拦截器\r\n\r\n```java\r\n@Component\r\npublic class LoginUserInterceptor implements HandlerInterceptor {\r\n\r\n\r\n    public static ThreadLocal<MemberRespVo> loginUser = new ThreadLocal<>();\r\n\r\n    @Override\r\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\r\n\r\n        ///order/order/status/{orderSn}\r\n        String uri = request.getRequestURI();//  /order/order/status/\r\n        //                  路径匹配器\r\n        boolean match = new AntPathMatcher().match(\"/kill\", uri);\r\n\r\n        if (match){\r\n            //路径匹配进行登录拦截\r\n            MemberRespVo attribute = (MemberRespVo) request.getSession().getAttribute(AuthServerConstant.LOGIN_USER);\r\n            //判断用户是否登录\r\n            if (attribute != null){\r\n                //登录了\r\n                loginUser.set(attribute);\r\n                return true;\r\n            }else {\r\n                //未登录就去登录\r\n                request.getSession().setAttribute(\"msg\", \"请先进行登录\");\r\n                response.sendRedirect(\"http://auth.gulimall.com/login.html\");\r\n                return false;\r\n            }\r\n        }\r\n        return true;\r\n    }\r\n}\r\n```\r\n\r\n- 拦截器注册\r\n\r\n```java\r\n@Configuration\r\npublic class SeckillWebConfig implements WebMvcConfigurer {\r\n    @Autowired\r\n    LoginUserInterceptor loginUserInterceptor;\r\n\r\n\r\n    @Override\r\n    public void addInterceptors(InterceptorRegistry registry) {\r\n        registry.addInterceptor(loginUserInterceptor).addPathPatterns(\"/**\");\r\n    }\r\n}\r\n```\r\n\r\n- 秒杀抢购未登录提示\r\n\r\n![image-20230430155945442](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430155945442.png)\r\n\r\n- 未登录跳转到登录页\r\n\r\n![image-20230430160017370](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430160017370.png)\r\n\r\n\r\n\r\n\r\n\r\n#### 3.7 秒杀流程\r\n\r\n![image-20230430003907398](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430003907398.png)\r\n\r\n\r\n\r\n- 秒杀成功页接口\r\n\r\n```java\r\n@GetMapping(\"/kill\")\r\npublic String secKill(@RequestParam(\"killId\") String killId,\r\n                      @RequestParam(\"key\") String key,\r\n                      @RequestParam(\"num\") Integer num,\r\n                      Model model){\r\n    String orderSn = seckillService.kill(killId, key, num);\r\n    \r\n    model.addAttribute(\"orderSn\", orderSn);\r\n    //1、判断是否登录\r\n    return \"success\";\r\n}\r\n```\r\n\r\n- 秒杀订单信息数据传输公共to`org.klaus.common.to.mq.SeckillOrderTo`\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/29\r\n */\r\n@Data\r\npublic class SeckillOrderTo {\r\n\r\n    private String orderSn;//订单号\r\n\r\n    private Long promotionSessionId;//活动场次id\r\n\r\n    private Long skuId;//商品id\r\n\r\n\r\n    private BigDecimal seckillPrice;//秒杀价\r\n\r\n    private Integer num;//购买数量\r\n\r\n    private Long memberId;//会员id\r\n\r\n//    private List<String> skuAttrs;//商品属性集\r\n\r\n}\r\n```\r\n\r\n- 秒杀方法实现\r\n\r\n```java\r\n@Override\r\npublic String kill(String killId, String key, Integer num) {\r\n    long s1 = System.currentTimeMillis();\r\n    //获取当前登录的信息\r\n    MemberRespVo respVo = LoginUserInterceptor.loginUser.get();\r\n\r\n    //获取当前秒杀商品的详细信息\r\n    BoundHashOperations<String, String, String> hashOps = redisTemplate.boundHashOps(SKUKILL_CACHE_PREFOX);\r\n\r\n    String json = hashOps.get(killId);\r\n    if (StringUtils.isEmpty(json)) {\r\n        return null;\r\n    } else {\r\n        SeckillSkuRedisTo redis = JSON.parseObject(json, SeckillSkuRedisTo.class);\r\n        //1、校验合法性\r\n        Long startTime = redis.getStartTime();\r\n        Long endTime = redis.getEndTime();\r\n        long current = System.currentTimeMillis();\r\n\r\n        //过期时间\r\n        long ttl = endTime - current;\r\n        if (current >= startTime && current <= endTime) {\r\n            //2、校验随机码和商品id\r\n            String randomCode = redis.getRandomCode();\r\n            //   1_49\r\n            String seckillSkuId = redis.getPromotionSessionId() + \"_\" + redis.getSkuId();\r\n            if (randomCode.equals(key) && killId.equals(seckillSkuId)) {\r\n                //3、验证购物数量是否合理\r\n                if (num <= redis.getSeckillLimit().intValue()) {\r\n                    //4、验证这个人是否已经购买过。幂等性；如果秒杀成功，就去占位，userId_sessionId_skuId\r\n                    String redisKey = respVo.getId() + \"_\" + seckillSkuId;\r\n                    //自动过期                     SEINX 原子性\r\n                    Boolean aBoolean = redisTemplate.opsForValue().setIfAbsent(redisKey, num.toString(), ttl, TimeUnit.MILLISECONDS);\r\n                    if (aBoolean) {\r\n                        //占位成功说明从来没有买过\r\n                        RSemaphore semaphore = redissonClient.getSemaphore(SKU_STOCK_SEMAPHORE + randomCode);\r\n\r\n                        //120 ms ->  20ms\r\n                        boolean b = semaphore.tryAcquire(num);\r\n                        if (b) {\r\n                            //秒杀成功；\r\n                            //快速下单，发送MQ消息 10ms\r\n                            //创建随机订单号\r\n                            String timeId = IdWorker.getTimeId();\r\n                            SeckillOrderTo orderTo = new SeckillOrderTo();\r\n                            orderTo.setOrderSn(timeId);\r\n                            orderTo.setMemberId(respVo.getId());\r\n                            orderTo.setNum(num);\r\n                            orderTo.setPromotionSessionId(redis.getPromotionSessionId());\r\n                            orderTo.setSkuId(redis.getSkuId());\r\n                            orderTo.setSeckillPrice(redis.getSeckillPrice());\r\n\r\n                            //String exchange, String routingKey, Object message, MessagePostProcessor messagePostProcessor\r\n                            rabbitTemplate.convertAndSend(\"order-event-exchange\", \"order.seckill.order\", orderTo);\r\n                            long s2 = System.currentTimeMillis();\r\n                            log.info(\"耗时...{}\", (s2 - s1));\r\n                            //返回订单号\r\n                            return timeId;\r\n                        }\r\n                        //信号量为0时，虽然data为空，但缓存还会存一份\r\n                        redisTemplate.opsForValue().get(redisKey);\r\n                        return null;\r\n                    } else {\r\n                        //说明已经买过了\r\n                        return null;\r\n                    }\r\n\r\n                }\r\n            } else {\r\n                return null;\r\n            }\r\n        } else {\r\n            return null;\r\n        }\r\n    }\r\n    return null;\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n#### 3.8 秒杀效果+秒杀页面\r\n\r\n![image-20230430161527281](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230430161527281.png)\r\n\r\n- 引入RabbitMQ依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.boot</groupId>\r\n    <artifactId>spring-boot-starter-amqp</artifactId>\r\n</dependency>\r\n```\r\n\r\n- 相关配置\r\n\r\n```properties\r\nspring.rabbitmq.virtual-host=/\r\nspring.rabbitmq.host=192.168.10.103\r\n```\r\n\r\n- 配置RabbitMQ的Json序列化\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2022/9/20\r\n */\r\n@Configuration\r\npublic class MyRabbitConfig {\r\n\r\n    @Autowired\r\n    RabbitTemplate rabbitTemplate;\r\n\r\n    /**\r\n     * 使用JSON序列化机制，进行消息转换\r\n     * @return\r\n     */\r\n    @Bean\r\n    public MessageConverter messageConverter(){\r\n        return new Jackson2JsonMessageConverter();\r\n    }\r\n\r\n\r\n}\r\n```\r\n\r\n- 发送秒杀成功消息给订单服务\r\n\r\n```java\r\n//String exchange, String routingKey, Object message, MessagePostProcessor messagePostProcessor\r\nrabbitTemplate.convertAndSend(\"order-event-exchange\", \"order.seckill.order\", orderTo);\r\n```\r\n\r\n- 订单服务创建秒杀订单消息队列\r\n\r\n```java\r\n@Configuration\r\npublic class MyMQConfig {\r\n    \r\n    ......\r\n    \r\n    @Bean\r\n    public Exchange orderEventExchange(){\r\n        //String name, boolean durable, boolean autoDelete, Map<String, Object> arguments\r\n        return new TopicExchange(\"order-event-exchange\", true, false);\r\n    }\r\n    \r\n    ......\r\n    \r\n    /**\r\n     * 秒杀削峰队列\r\n     * @return\r\n     */\r\n    @Bean\r\n    public Queue orderSeckillOrderQueue(){\r\n        return new Queue(\"order.seckill.order.queue\", true, false, false);\r\n    }\r\n\r\n    @Bean\r\n    public Binding orderSeckillOrderBinding(){\r\n        return new Binding(\"order.seckill.order.queue\",\r\n                Binding.DestinationType.QUEUE,\r\n                \"order-event-exchange\",\r\n                \"order.seckill.order\", null);\r\n\r\n    }\r\n}\r\n```\r\n\r\n- 削峰队列监听器`org.klaus.zgg01mall.order.listener.OrderSeckillListener`\r\n\r\n```java\r\n/**\r\n * 削峰队列监听器\r\n * @author Klaus\r\n * @date 2023/4/28\r\n */\r\n@Slf4j\r\n@RabbitListener(queues = \"order.seckill.order.queue\")\r\n@Component\r\npublic class OrderSeckillListener {\r\n\r\n    @Autowired\r\n    OrderService orderService;\r\n\r\n    @RabbitHandler\r\n    public void listener(SeckillOrderTo seckillOrder, Channel channel, Message message) throws IOException {\r\n\r\n        try {\r\n            log.info(\"准备创建秒杀单的详细信息....\");\r\n            orderService.createSeckillOrder(seckillOrder);\r\n            //手动调用支付宝收单\r\n\r\n            //签收订单\r\n            channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);\r\n        } catch (Exception e) {\r\n\r\n            channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);\r\n        }\r\n\r\n    }\r\n}\r\n```\r\n\r\n- 创建秒杀订单方法实现`org.klaus.zgg01mall.order.service.impl.OrderServiceImpl#createSeckillOrder`\r\n\r\n```java\r\n\t@Override\r\n    public void createSeckillOrder(SeckillOrderTo seckillOrder) {\r\n        //todo 保存订单信息\r\n        OrderEntity orderEntity = new OrderEntity();\r\n        orderEntity.setOrderSn(seckillOrder.getOrderSn());\r\n        orderEntity.setMemberId(seckillOrder.getMemberId());\r\n\r\n        orderEntity.setStatus(OrderStatusEnum.CREATE_NEW.getCode());\r\n\r\n        BigDecimal amount = seckillOrder.getSeckillPrice().multiply(new BigDecimal(\"\" + seckillOrder.getNum()));\r\n        orderEntity.setPayAmount(amount);\r\n        orderEntity.setTotalAmount(amount);//todo\r\n\r\n        //保存订单\r\n        this.save(orderEntity);\r\n        //todo 保存订单项信息\r\n        OrderItemEntity itemEntity = new OrderItemEntity();\r\n        itemEntity.setOrderSn(seckillOrder.getOrderSn());\r\n        itemEntity.setRealAmount(amount);\r\n        //todo 获取当前sku的详细信息进行设置 seckillservice-> productFeignService.getSpuInfoBySkuId()\r\n        R r = productFeignService.getSpuInfoBySkuId(seckillOrder.getSkuId());\r\n        if (r.getCode() == 0) {\r\n            SpuInfoVo data = r.getData(new TypeReference<SpuInfoVo>() {\r\n            });\r\n            itemEntity.setSpuId(data.getId());\r\n            itemEntity.setSpuName(data.getSpuName());\r\n            itemEntity.setSpuBrand(data.getBrandId().toString());\r\n            itemEntity.setCategoryId(data.getCatalogId());\r\n\r\n\r\n\r\n        }\r\n        //1、找到所有需要参与秒杀的商品信息\r\n        R info = seckillFeignService.getSkuSeckillInfo(seckillOrder.getSkuId());\r\n        if (info.getCode() == 0){\r\n            SeckillSkuRedisTo data = info.getData(new TypeReference<SeckillSkuRedisTo>() {\r\n            });\r\n            itemEntity.setSkuName(data.getSkuInfoVo().getSkuTitle());\r\n            itemEntity.setSkuPic(data.getSkuInfoVo().getSkuDefaultImg());\r\n            //todo 销售属性组合\r\n\r\n        }\r\n\r\n\r\n        itemEntity.setSkuId(seckillOrder.getSkuId());\r\n        itemEntity.setSkuQuantity(seckillOrder.getNum());\r\n\r\n        //保存订单项\r\n        orderItemService.save(itemEntity);\r\n    }\r\n/**\r\n     * 保存订单数据\r\n     * @param order\r\n     */\r\n    private void saveOrder(OrderCreateTo order) {\r\n        OrderEntity orderEntity = order.getOrder();\r\n        orderEntity.setModifyTime(new Date());\r\n        //插入订单\r\n        this.save(orderEntity);\r\n\r\n        List<OrderItemEntity> orderItems = order.getOrderItems();\r\n        //seata不支持批量保存...且在高并发环境此业务不适用Seata\r\n        orderItemService.saveBatch(orderItems);\r\n//        for (OrderItemEntity orderItem : orderItems) {\r\n//            orderItemService.save(orderItem);\r\n//        }\r\n    }\r\n```\r\n\r\n- 准备秒杀（已登录）\r\n\r\n![image-20230428202310827](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428202310827.png)\r\n\r\n- 秒杀成功页\r\n\r\n![image-20230428203902875](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428203902875.png)\r\n\r\n- 去支付\r\n\r\n![image-20230428204012516](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428204012516.png)\r\n\r\n![image-20230428204042723](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428204042723.png)\r\n\r\n- 支付成功\r\n\r\n![image-20230428204055365](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428204055365.png)\r\n\r\n\r\n\r\n- 页面跳转同步通知页面路径 需http://格式的完整路径，不能加?id=123这类自定义参数，必须外网可以正常访问（配置内网穿透）\r\n\r\n![image-20230428204105232](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428204105232.png)\r\n\r\n- 同步通知，支付成功，一般跳转到成功页\r\n\r\n![image-20230428204113061](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428204113061.png)\r\n\r\n> 未开发秒杀订单超时/未付款/已取消\r\n>\r\n\r\n\r\n\r\n- 秒杀失败页面返回（秒杀占位key：userId_sessionId_skuId未过期，已被别人抢购了）\r\n\r\n[seckill.gulimall.com/kill?killId=20_61&key=83e8d796d84d4048b3c93608b30f8493&num=1](http://seckill.gulimall.com/kill?killId=20_61&key=83e8d796d84d4048b3c93608b30f8493&num=1)\r\n\r\n![image-20230428202441771](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428202441771.png)\r\n\r\n\r\n\r\n![image-20230428202629284](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428202629284.png)\r\n\r\n- 信号量限制抢购数量\r\n\r\n- 信号量每秒杀成功一次，信号量减一，seckill_count -> seckill_count - 1\r\n\r\n![image-20230428202717075](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428202717075.png)\r\n\r\n- 秒杀锁的过期是为long ttl = endTime - current;\r\n\r\n![image-20230428203528296](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230428203528296.png)\r\n\r\n\r\n\r\n \r\n\r\n\r\n\r\n\r\n\r\n### 4 秒杀（高并发）系统关注的问题 \r\n\r\n\r\n\r\n\r\n\r\n#### 4.1 服务单一职责+独立部署 \r\n\r\n\r\n\r\n- 秒杀服务即使自己扛不住压力，挂掉，不要影响别人\r\n\r\n\r\n\r\n#### 4.2 秒杀链接加密 \r\n\r\n\r\n\r\n- 防止恶意攻击模拟秒杀请求，1000次/s攻击 防止连接暴露，自己工作人员，提前秒杀商品\r\n\r\n\r\n\r\n#### 4.3 库存预热 + 快速扣减 \r\n\r\n\r\n\r\n- 提前把数据加载缓存中\r\n\r\n\r\n\r\n#### 4.4 动静分离 \r\n\r\n\r\n\r\n- nginx做好动静分离，保证秒杀和商品详情页的动态请求才打到后端的服务集群\r\n\r\n\r\n\r\n- 使用 CDN 网络，分担服务器压力\r\n\r\n\r\n\r\n#### 4.5 恶意请求拦截 \r\n\r\n\r\n\r\n- 识别非法攻击的请求并进行拦截\t，网关层\r\n\r\n\r\n\r\n#### 4.6 流量错峰 \r\n\r\n\r\n\r\n- 使用各种手段，将流量分担到更大宽度的时间点，比如验证码，加入购物车\r\n\r\n\r\n\r\n#### 4.7 限流 & 熔断 & 降级 \r\n\r\n\r\n\r\n- 前端限流 + 后端限流\r\n\r\n\r\n\r\n- 限制次数，限制总量，快速失败降级运行，熔断隔离防止雪崩\r\n\r\n\r\n\r\n#### 4.8 队列消峰 \r\n\r\n\r\n\r\n- 1万个请求，每个1000件被秒杀，双11所有秒杀成功的请求，进入队列，慢慢创建订单，扣减库存即可\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n### 5 限流 & 熔断 & 降级 \r\n\r\n"},{"title":"Valaxy+github-pages部署问题","tags":["valaxy"],"categories":["Valaxy Notes"],"author":"imklaus","excerpt":"\r\n## Using Valaxy+github to create a personal blog showing 404 errors{lang=\"en\"}\r\n\r\n::: en\r\nWhen setting up a personal blog, because the project name is not case sensitive when creating the repository, then deploy access to 404 as shown in the image below：![1](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20190917114816230.png)\r\n:::\r\n\r\n::: en\r\n\r\nBut if you set the project name in the repository to your github username +.github+.io, you'll be able to access it immediately It must be your github user name, which should be consistent with the github user name. If you do not want to access the address with the suffix.io, you can purchase a personal domain and deploy it in your github project settings\r\n\r\n:::\r\n\r\n# 利用Valaxy+github搭建个人博客显示404错误? {lang=\"zh-CN\"}\r\n\r\n::: zh-CN\r\n在搭建个人博客的时候，因为创建仓库设置项目名时没注意大小写，然后部署访问一直404。像下图这样：![1](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20190917114816230.png)\r\n\r\n:::\r\n\r\n\r\n\r\n::: zh-CN\r\n\r\n后来全部改成小写也没有用，翻盘重新安装也没有用。\r\n但是如果把仓库中设置的项目名设置为：你的github的用户名+.github+.io,马上就可以访问啦。一定要是你github的用户名，要和github的用户名保持一致，如果不想要这种后缀为.io的访问地址，后期可以购买一个个人域名部署上去。在你github项目的settings里面设置一下就好了。\r\n\r\n:::\r\n\r\n","link":"/posts/GitHub_Pages_Problem1","content":"\r\n## Using Valaxy+github to create a personal blog showing 404 errors{lang=\"en\"}\r\n\r\n::: en\r\nWhen setting up a personal blog, because the project name is not case sensitive when creating the repository, then deploy access to 404 as shown in the image below：![1](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20190917114816230.png)\r\n:::\r\n\r\n::: en\r\n\r\nBut if you set the project name in the repository to your github username +.github+.io, you'll be able to access it immediately It must be your github user name, which should be consistent with the github user name. If you do not want to access the address with the suffix.io, you can purchase a personal domain and deploy it in your github project settings\r\n\r\n:::\r\n\r\n# 利用Valaxy+github搭建个人博客显示404错误? {lang=\"zh-CN\"}\r\n\r\n::: zh-CN\r\n在搭建个人博客的时候，因为创建仓库设置项目名时没注意大小写，然后部署访问一直404。像下图这样：![1](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/20190917114816230.png)\r\n\r\n:::\r\n\r\n\r\n\r\n::: zh-CN\r\n\r\n后来全部改成小写也没有用，翻盘重新安装也没有用。\r\n但是如果把仓库中设置的项目名设置为：你的github的用户名+.github+.io,马上就可以访问啦。一定要是你github的用户名，要和github的用户名保持一致，如果不想要这种后缀为.io的访问地址，后期可以购买一个个人域名部署上去。在你github项目的settings里面设置一下就好了。\r\n\r\n:::\r\n\r\n<!-- more -->\r\n"},{"title":"利用valaxy+github+PicGo搭建github图床问题","tags":["valaxy"],"categories":["Valaxy Notes"],"author":"imklaus","excerpt":":::warning NEW CDN!!!\r\n\r\n> `https://gcore.jsdelivr.net/gh/ {{owner}}/{{repo}}@{{branch}}/{{path}}`\r\n\r\n\r\n:::\r\n\r\n\r\n\r\n::: details 已失效解决方法\r\n\r\n1. 利用valaxy+github搭建个人博客图片不显示?\r\n\r\n  - 使用图床传输图片\r\n    - 问题：使用牛七、Gitee图床均有问题\r\n\r\n2. 2023使用picgo + github搭建图床（typora）,解决jsdelivr问题\r\n\r\n:::\r\n\r\n","link":"/posts/GitHub_Pages_Problem2","content":":::warning NEW CDN!!!\r\n\r\n> `https://gcore.jsdelivr.net/gh/ {{owner}}/{{repo}}@{{branch}}/{{path}}`\r\n\r\n\r\n:::\r\n\r\n\r\n\r\n::: details 已失效解决方法\r\n\r\n1. 利用valaxy+github搭建个人博客图片不显示?\r\n\r\n  - 使用图床传输图片\r\n    - 问题：使用牛七、Gitee图床均有问题\r\n\r\n2. 2023使用picgo + github搭建图床（typora）,解决jsdelivr问题\r\n\r\n:::\r\n\r\n<!-- more -->\r\n\r\n## 一、图床是什么\r\n\r\n> **图床一般是指储存图片的服务器**\r\n>\r\n> 有国内和国外之分。国外的图床由于有空间距离等因素决定访问速度很慢影响图片显示速度。国内也分为单线空间、多线空间和cdn加速三种。\r\n>\r\n\r\n- 说人话： 就是把你博客，或者笔记中的图片存到云端上去，这样文本里面只留存图片链接\r\n\r\n\r\n- 举个例子：\r\n\r\n  -   写markdown笔记时，图片存储在本地，用相对路径或者绝对路径加载图片，如果要同步笔记或者迁移笔记的话，那么是不是要把图片也进行迁移，很麻烦。\r\n  -   有人会说可以直接复制整个目录结构，也麻烦不了太多。但是这样是不是将来在两个设备写markdown时，就需要总是同步图片，特别是如果本地写好博客，去发布时，图片链接又该如何让去解决，一张一张处理，效率显然太慢了。\r\n\r\n- **图床有什么效果**：例子中那些问题，图床就可以很好的解决\r\n\r\n  - 同步笔记时，利用iCloud，或者其他云盘，就可以直接同步markdown纯文本文件，不需要再考虑图片问题，笔记的体积还小，只需要存储markdown文本文件，去处理图片的体积。\r\n\r\n\r\n  - 博客也只需要，将markdown全选 + 复制 + 粘贴 + 发布就好了\r\n\r\n## 二、怎么搭建\r\n\r\n方法有很多，但是说到底还是选择用什么样的云存储，可以是自己用服务器写API来搭建，也可以使用大厂商提供的对象存储，还有就是本文的白嫖，白嫖**GitHub**。\r\n\r\n而**picgo**只是一个图床管理工具，帮助我们上传图片到图床。同样的应用还有upic，以及其他，都是同样的功能，但图床的方便一定少不了图床管理工具。picgo则是可以配合typora使用。\r\n\r\n### 1、配置GitHub\r\n\r\n- **（1）创建仓库**\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/c791d4e795611f0342ab5c879867dea2.png)\r\n\r\n- **（2）生成token私钥**\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/902ddd25b9976089fed18d3650d2c98d.png)\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/a86707f29b24f8e2e847dea8016bdcf4.png)\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/c866998186ee8f45c0ad5a58a157fcbe.png)\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/170e1d5c60cd35e54eabf62e150737e0.png)\r\n\r\n\r\n\r\n**ps: 得到的私钥要保存下来，后面github上无法查看**\r\n\r\n### 2、配置picgo\r\n\r\n[picgo下载](https://github.com/Molunerfinn/PicGo/releases)\r\n\r\n还需要配置node.js环境才可以使用。[node.js安装及环境配置](https://blog.csdn.net/weixin_44893902/article/details/121788104?ops_request_misc=%7B%22request%5Fid%22%3A%22167245108816782425141530%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&request_id=167245108816782425141530&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-121788104-null-null.142%5Ev68%5Econtrol,201%5Ev4%5Eadd_ask,213%5Ev2%5Et3_esquery_v1&utm_term=nodejs%E5%AE%89%E8%A3%85%E5%8F%8A%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE&spm=1018.2226.3001.4187)\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/f7fe908fcc004715cbf803737008a3cd.png)\r\n\r\n|      **名称**      |                     **填写**                     |\r\n| :----------------: | :----------------------------------------------: |\r\n|     设定仓库名     |                  用户名/仓库名                   |\r\n|     设定分支名     |              分支名，用户main就可以              |\r\n|     设定Token      |          这个就是GitHub配置的token私钥           |\r\n|    设定存储路径    |            相对于仓库来说，自定义填写            |\r\n| **设定自定义域名** | **重要！！！解决jsdelivr CDN加速问题 如下填写.** |\r\n\r\n**解决jsdelivr CDN加速问题**\r\n**这个现在失效了**：https://gcore.jsdelivr.net/gh/[github用户名]/[仓库名]@main\r\n\r\n改成：\r\n\r\n`https://gcore.jsdelivr.net/gh/[github用户名]/[仓库名]@main`\r\n@后面跟的是填写的分支名，一定要一致\r\n\r\n### 3、配置typora\r\n\r\n打开：**文件 -> 偏好设置 -> 图像**\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/275d2affc2d30b38d5f7289cb503d93c.png)\r\n\r\n使用：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/70709553f8512ad6322a703c40bee0ec.png)\r\n\r\n效果：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/707661c51dc34abd8a515b3e14dba868.png)\r\n\r\n> 从昨天开始Staticaly就提示过期了，导致我的一些站点中图片无法加载，索性今天就替换下\r\n>\r\n> 由于我的图床都是在github中，所以链接替换上还是比较容易的，以下是我找的几个可以替换的免费CDN：\r\n>\r\n> 官方：https://cdnjs.shssedu.ac.cn/github 【CDNJSCN 是一项免费开源 CDN (国内)搜索服务，CDNJS受到超过 全球 12.5% 网站的信任, 多达 2000 亿请求/月, 由 Cloudflare、loli.net、onmicrosoft.cn、cdn.chuqis.com、cdn.staticfile.org提供服务支持。】\r\n>\r\n> 替换：\r\n>\r\n> https://cdn.chuqis.com/\r\n>\r\n> https://gcore.jsdelivr.net/\r\n>\r\n> 还有一个国内的套Cloudflare的Staticaly：https://gcore.jsdelivr.net\r\n>\r\n> 如果你跟我一样图片是在github上的则替换格式为\r\n>\r\n> ```http\r\n> https://cdn.chuqis.com/gh/ {{owner}}/{{repo}}@{{branch}}/{{path}}\r\n> ```\r\n"},{"title":"Hello, Valaxy!","tags":["valaxy"],"categories":["Valaxy Notes"],"author":"imklaus","excerpt":"\r\n## What is Valaxy? {lang=\"en\"}\r\n\r\n::: en\r\nValaxy aims to be a next generation of static blogging frameworks/generators.\r\n:::\r\n\r\n## 什么是 Valaxy? {lang=\"zh-CN\"}\r\n\r\n::: zh-CN\r\nValaxy 的目标是成为新一代的静态博客框架/生成器。\r\n:::\r\n\r\nMore info see [valaxy.site](https://valaxy.site).\r\n\r\n```ts\r\n/**\r\n * User Config\r\n * do not use export const, because c12 will set as child property\r\n */\r\nexport default defineValaxyConfig<ThemeConfig>({\r\n  theme: 'yun',\r\n\r\n  themeConfig: {\r\n    banner: {\r\n      enable: true,\r\n      title: '云游君的小站',\r\n    },\r\n  },\r\n})\r\n```\r\n\r\n\r\n\r\n## 配置{lang=\"zh-CN\"}\r\n\r\n::: zh-CN\r\n\r\n结合https://valaxy.site/ 与 [超可爱！使用 Valaxy 搭建自己的博客 - -Yuumi's Blog-](https://www.yuumi.link/posts/valaxy)来看\r\n\r\n:::\r\n\r\n## Config{lang=\"en\"}\r\n\r\n::: en\r\n\r\nCombinedhttps://valaxy.site/ with [Super cute! Build your own Blog with Valaxy -Yuumi's Blog-](https://www.yuumi.link/posts/valaxy)\r\n\r\n:::\r\n","link":"/posts/hello-valaxy","content":"\r\n## What is Valaxy? {lang=\"en\"}\r\n\r\n::: en\r\nValaxy aims to be a next generation of static blogging frameworks/generators.\r\n:::\r\n\r\n## 什么是 Valaxy? {lang=\"zh-CN\"}\r\n\r\n::: zh-CN\r\nValaxy 的目标是成为新一代的静态博客框架/生成器。\r\n:::\r\n\r\nMore info see [valaxy.site](https://valaxy.site).\r\n\r\n```ts\r\n/**\r\n * User Config\r\n * do not use export const, because c12 will set as child property\r\n */\r\nexport default defineValaxyConfig<ThemeConfig>({\r\n  theme: 'yun',\r\n\r\n  themeConfig: {\r\n    banner: {\r\n      enable: true,\r\n      title: '云游君的小站',\r\n    },\r\n  },\r\n})\r\n```\r\n\r\n\r\n\r\n## 配置{lang=\"zh-CN\"}\r\n\r\n::: zh-CN\r\n\r\n结合https://valaxy.site/ 与 [超可爱！使用 Valaxy 搭建自己的博客 - -Yuumi's Blog-](https://www.yuumi.link/posts/valaxy)来看\r\n\r\n:::\r\n\r\n## Config{lang=\"en\"}\r\n\r\n::: en\r\n\r\nCombinedhttps://valaxy.site/ with [Super cute! Build your own Blog with Valaxy -Yuumi's Blog-](https://www.yuumi.link/posts/valaxy)\r\n\r\n:::\r\n<!-- more -->"},{"title":"接口幂等性","tags":["Spring Boot","token","Redis"],"categories":["Java","未分类"],"author":"imklaus","excerpt":"\r\n\r\n\r\n## 一、幂等性的意义\r\n\r\n### **1、什么是幂等性**\r\n\r\n- 看一下维基百科怎么说的：\r\n\r\n![image-20230429205227388](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429205227388.png)\r\n\r\n- **接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的**，不会因为多次点击而产生了副作用；比如说支付场景，用户购买了商品支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条......，这就没有保证接口的幂等性。\r\n","link":"/posts/Idempotence_of_interfaces","content":"\r\n\r\n\r\n## 一、幂等性的意义\r\n\r\n### **1、什么是幂等性**\r\n\r\n- 看一下维基百科怎么说的：\r\n\r\n![image-20230429205227388](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429205227388.png)\r\n\r\n- **接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的**，不会因为多次点击而产生了副作用；比如说支付场景，用户购买了商品支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条......，这就没有保证接口的幂等性。\r\n<!-- more -->\r\n\r\n> - 幂等是一个数学与计算机学概念，在数学中某一元运算为幂等时，其作用在任一元素两次后会和其作用一次的结果相同。\r\n> - 在计算机中编程中，一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数或幂等方法是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。\r\n\r\n### **2、什么是接口幂等性**\r\n\r\n- 在HTTP/1.1中，对幂等性进行了定义。它描述了一次和多次请求某一个资源对于资源本身应该具有同样的结果（网络超时等问题除外），即第一次请求的时候对资源产生了副作用，但是以后的多次请求都不会再对资源产生副作用。\r\n- 这里的副作用是不会对结果产生破坏或者产生不可预料的结果。也就是说，其任意多次执行对资源本身所产生的影响均与一次执行的影响相同。\r\n\r\n\r\n\r\n### **3、为什么需要实现幂等性**\r\n\r\n在接口调用时一般情况下都能正常返回信息不会重复提交，不过在遇见以下情况时可以就会出现问题，如：\r\n\r\n1. **前端重复提交表单：** 在填写一些表格时候，用户填写完成提交，很多时候会因网络波动没有及时对用户做出提交成功响应，致使用户认为没有成功提交，然后一直点提交按钮，这时就会发生重复提交表单请求。\r\n2. **用户恶意进行刷单：** 例如在实现用户投票这种功能时，如果用户针对一个用户进行重复提交投票，这样会导致接口接收到用户重复提交的投票信息，这样会使投票结果与事实严重不符。\r\n3. **接口超时重复提交：** 很多时候 HTTP 客户端工具都默认开启超时重试的机制，尤其是第三方调用接口时候，为了防止网络波动超时等造成的请求失败，都会添加重试机制，导致一个请求提交多次。\r\n4. **消息进行重复消费：** 当使用 MQ 消息中间件时候，如果发生消息中间件出现错误未及时提交消费信息，导致发生重复消费。\r\n\r\n> 使用幂等性最大的优势在于使接口保证任何幂等性操作，免去因重试等造成系统产生的未知的问题。\r\n\r\n\r\n\r\n### **4、引入幂等性后对系统的影响**\r\n\r\n幂等性是为了简化客户端逻辑处理，能放置重复提交等操作，但却增加了服务端的逻辑复杂性和成本，其主要是：\r\n\r\n1. 把并行执行的功能改为串行执行，降低了执行效率。\r\n2. 增加了额外控制幂等的业务逻辑，复杂化了业务功能；\r\n\r\n> 所以在使用时候需要考虑是否引入幂等性的必要性，根据实际业务场景具体分析，除了业务上的特殊要求外，一般情况下不需要引入的接口幂等性。\r\n\r\n\r\n\r\n## 二、Restful API 接口的幂等性\r\n\r\n现在流行的 Restful 推荐的几种 HTTP 接口方法中，分别存在幂等行与不能保证幂等的方法，如下：\r\n\r\n1. √ 满足幂等\r\n2. x 不满足幂等\r\n3. \\- 可能满足也可能不满足幂等，根据实际业务逻辑有关\r\n\r\n> Get\r\n>\r\n> √\r\n>\r\n> Get 方法用于获取资源。其一般不会也不应当对系统资源进行改变，所以是幂等的。\r\n\r\n> Post\r\n>\r\n> ×\r\n>\r\n> Post 方法一般用于创建新的资源。其每次执行都会新增数据，所以不是幂等的。\r\n\r\n> Put\r\n>\r\n> \\-\r\n>\r\n> Put 方法一般用于修改资源。该操作则分情况来判断是不是满足幂等，更新操作中直接根据某个值进行更新，也能保持幂等。不过执行累加操作的更新是非幂等。\r\n\r\n> Delete\r\n>\r\n> \\-\r\n>\r\n> Delete 方法一般用于删除资源。该操作则分情况来判断是不是满足幂等，当根据唯一值进行删除时，删除同一个数据多次执行效果一样。不过需要注意，带查询条件的删除则就不一定满足幂等了。例如在根据条件删除一批数据后，这时候新增加了一条数据也满足条件，然后又执行了一次删除，那么将会导致新增加的这条满足条件数据也被删除。\r\n\r\n\r\n\r\n## 三、哪些情况需要防止\r\n\r\n- 用户多次点击按钮\r\n- 用户页面回退再次提交\r\n- 微服务互相调用，由于网络问题，导致请求失败。feign 触发重试机制其他业务情况\r\n\r\n### 1、前端重复提交 \r\n\r\n- 用户注册，用户创建商品等操作，前端都会提交一些数据给后台服务，后台需要根据用户提交的数据在数据库中创建记录。如果用户不小心多点了几次，后端收到了好几次提交，这时就会在数据库中重复创建了多条记录。这就是接口没有幂等性带来的 bug。\r\n\r\n\r\n\r\n### 2、接口超时重试 \r\n\r\n- 对于给第三方调用的接口，有可能会因为网络原因而调用失败，这时，一般在设计的时候会对接口调用加上失败重试的机制。如果第一次调用已经执行了一半时，发生了网络异常。这时再次调用时就会因为脏数据的存在而出现调用异常。\r\n\r\n\r\n\r\n### 3、消息重复消费 \r\n\r\n- 在使用消息中间件来处理消息队列，且手动 ack 确认消息被正常消费时。如果消费者突然断开连接，那么已经执行了一半的消息会重新放回队列。\r\n- 当消息被其他消费者重新消费时，如果没有幂等性，就会导致消息重复消费时结果异常，如数据库重复数据，数据库数据冲突，资源重复等。\r\n\r\n\r\n\r\n## 四、什么情况下需要幂等\r\n\r\n以 SQL 为例，有些操作是天然幂等的。\r\n\r\n- `SELECT * FROM table WHER id=?`，无论执行多少次都不会改变状态，是天然的幂等。\r\n\r\n- `UPDATE tab1 SET col1=1 WHERE col2=2`，无论执行成功多少次状态都是一致的，也是幂等操作。\r\n- `delete from user where userid=1`，多次操作，结果一样，具备幂等性\r\n- `insert into user(userid,name) values(1,'a')` 如 userid 为唯一主键，即重复操作上面的业务，只会插入一条用户数据，具备幂等性。\r\n\r\n------\r\n\r\n- `UPDATE tab1 SET col1=col1+1 WHERE col2=2`，每次执行的结果都会发生变化，不是幂等的。\r\n- `insert into user(userid,name) values(1,'a')` 如 userid 不是主键，可以重复，那上面业务多次操作，数据都会新增多条，不具备幂等性。\r\n\r\n\r\n\r\n## 五、幂等解决方案\r\n\r\n### **1、token 机制**\r\n\r\n- 1、服务端提供了发送 token 的接口。我们在分析业务的时候，哪些业务是存在幂等问题的，就必须在执行业务前，先去获取 token，服务器会把 token 保存到 redis 中。\r\n\r\n- 2、然后调用业务接口请求时，把 token 携带过去，一般放在请求头部。\r\n\r\n- 3、服务器判断 token 是否存在 redis 中，存在表示第一次请求，然后删除 token,继续执行业务。\r\n\r\n- 4、如果判断 token 不存在 redis 中，就表示是重复操作，直接返回重复标记给 client，这样就保证了业务代码，不被重复执行。\r\n\r\n- 危险性：\r\n\r\n  - 1、先删除 token 还是后删除 token；\r\n\r\n    - (1)、先删除可能导致，业务确实没有执行，重试还带上之前 token，由于防重设计导致，请求还是不能执行。\r\n    - (2)、后删除可能导致，业务处理成功，但是服务闪断，出现超时，没有删除 token，别人继续重试，导致业务被执行两边\r\n    - (3)、我们最好设计为先删除 token，如果业务调用失败，就重新获取 token 再次请求。\r\n\r\n  - 2、Token 获取、比较和删除必须是原子性\r\n\r\n    - (1)、redis.get(token) 、token.equals、redis.del(token)如果这两个操作不是原子，可能导致，高并发下，都 get 到同样的数据，判断都成功，继续业务并发执行\r\n    - (2)、可以在 redis 使用 lua 脚本完成这个操作\r\n\r\n    ```shell\r\n    if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\r\n    ```\r\n\r\n\r\n\r\n\r\n> - 通过token 机制实现接口的幂等性,这是一种比较通用性的实现方法。\r\n>\r\n> - 示意图如下：\r\n>\r\n> ![image-20230429171130711](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429171130711.png)\r\n>\r\n> \r\n>\r\n> - 具体流程步骤：\r\n>\r\n>   - 1客户端会先发送一个请求去获取 token，服务端会生成一个全局唯一的 ID 作为 token 保存在 redis 中，同时把这个 ID 返回给客户端\r\n>\r\n>   - 2客户端第二次调用业务请求的时候必须携带这个 token\r\n>\r\n>   - 3服务端会校验这个 token，如果校验成功，则执行业务，并删除 redis 中的 token\r\n>\r\n>   - 4如果校验失败，说明 redis 中已经没有对应的 token，则表示重复操作，直接返回指定的结果给客户端\r\n>\r\n> - 注意：\r\n>\r\n>   - 1对 redis 中是否存在 token 以及删除的代码逻辑建议用 Lua 脚本实现，保证原子性\r\n>\r\n>   - 2全局唯一 ID 可以用百度的 uid-generator、美团的 Leaf 去生成\r\n\r\n\r\n\r\n### **2、各种锁机制**\r\n\r\n#### **1）、数据库悲观锁**\r\n\r\n`select * from xxxx where id = 1 for update;`\r\n悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，需要根据实际情况选用。\r\n另外要注意的是，id 字段一定是主键或者唯一索引，不然可能造成锁表的结果，处理起来会\r\n非常麻烦。\r\n\r\n\r\n\r\n#### **2）、数据库乐观锁**\r\n\r\n这种方法适合在更新的场景中：\r\n\r\n`update t_goods set count = count -1 , version = version + 1 where good_id=2 and version = 1`\r\n\r\n- 根据 version 版本，也就是在操作库存前先获取当前商品的 version 版本号，然后操作的时候带上此 version 号。我们梳理下，我们第一次操作库存时，得到 version 为 1，调用库存服务version 变成了 2；但返回给订单服务出现了问题，订单服务又一次发起调用库存服务，当订单服务传如的 version 还是 1，再执行上面的 sql 语句时，就不会执行；因为 version 已经变为 2 了，where 条件就不成立。这样就保证了不管调用几次，只会真正的处理一次。\r\n- 乐观锁主要使用于处理读多写少的问题\r\n\r\n\r\n\r\n#### **3）、业务层分布式锁**\r\n\r\n如果多个机器可能在同一时间同时处理相同的数据，比如多台机器定时任务都拿到了相同数\r\n据处理，我们就可以加分布式锁，锁定此数据，处理完成后释放锁。获取到锁的必须先判断\r\n这个数据是否被处理过。\r\n\r\n\r\n\r\n### **3、各种唯一约束**\r\n\r\n#### **1）、数据库唯一约束**\r\n\r\n- 插入数据，应该按照唯一索引进行插入，比如订单号，相同的订单就不可能有两条记录插入。我们在数据库层面防止重复。\r\n- 这个机制是利用了数据库的主键唯一约束的特性，解决了在 insert 场景时幂等问题。但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键。\r\n- 如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。\r\n\r\n> 这种实现方式是利用 mysql 唯一索引的特性。\r\n>\r\n> 示意图如下：\r\n>\r\n> ![image-20230429171314375](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429171314375.png)\r\n>\r\n> \r\n>\r\n> - 具体流程步骤：\r\n>   - 1建立一张去重表，其中某个字段需要建立唯一索引\r\n>   - 2客户端去请求服务端，服务端会将这次请求的一些信息插入这张去重表中\r\n>   - 3因为表中某个字段带有唯一索引，如果插入成功，证明表中没有这次请求的信息，则执行后续的业务逻辑\r\n>   - 4如果插入失败，则代表已经执行过当前请求，直接返回\r\n\r\n\r\n\r\n#### **2）、redis set 防重**\r\n\r\n很多数据需要处理，只能被处理一次，比如我们可以计算数据的 MD5 将其放入 redis 的 set，每次处理数据，先看这个 MD5 是否已经存在，存在就不处理。\r\n\r\n\r\n\r\n> - 这种实现方式是基于 SETNX 命令实现的\r\n> - SETNX key value：将 key 的值设为 value ，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。\r\n> - 该命令在设置成功时返回 1，设置失败时返回 0。\r\n>\r\n> 示意图如下：\r\n>\r\n> ![image-20230429171445789](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230429171445789.png)\r\n>\r\n> \r\n>\r\n> - 具体流程步骤：\r\n>   - 1客户端先请求服务端，会拿到一个能代表这次请求业务的唯一字段\r\n>   - 2将该字段以 SETNX 的方式存入 redis 中，并根据业务设置相应的超时时间\r\n>   - 3如果设置成功，证明这是第一次请求，则执行后续的业务逻辑\r\n>   - 4如果设置失败，则代表已经执行过当前请求，直接返回\r\n\r\n\r\n\r\n### **4、防重表**\r\n\r\n- 使用订单号 orderNo 做为去重表的唯一索引，把唯一索引插入去重表，再进行业务操作，且他们在同一个事务中。这个保证了重复请求时，因为去重表有唯一约束，导致请求失败，避免了幂等问题。这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。\r\n\r\n- 之前说的 redis 防重也算\r\n\r\n\r\n\r\n### **5、全局请求唯一 id**\r\n\r\n- 调用接口时，生成一个唯一 id，redis 将数据保存到集合中（去重），存在即处理过。\r\n- 可以使用 nginx 设置每一个请求的唯一 id；\r\n- `proxy_set_header X-Request-Id $request_id;`\r\n\r\n\r\n\r\n### 6、总结\r\n\r\n> - 这几种实现幂等的方式其实都是大同小异的，类似的还有使用状态机、悲观锁、乐观锁的方式来实现，都是比较简单的。\r\n> - 总之，当你去设计一个接口的时候，幂等都是首要考虑的问题，特别是当你负责设计转账、支付这种涉及到 money 的接口，你要格外注意喽！\r\n\r\n\r\n\r\n## 六、如何实现幂等性\r\n\r\n### **方案一：数据库唯一主键**\r\n\r\n**方案描述**\r\n\r\n数据库唯一主键的实现主要是利用数据库中主键唯一约束的特性，一般来说唯一主键比较适用于“插入”时的幂等性，其能保证一张表中只能存在一条带该唯一主键的记录。\r\n\r\n使用数据库唯一主键完成幂等性时需要注意的是，该主键一般来说并不是使用数据库中自增主键，而是使用分布式 ID 充当主键（可以参考 Java 中分布式 ID 的设计方案 这篇文章），这样才能能保证在分布式环境下 ID 的全局唯一性。\r\n\r\n**适用操作：**\r\n\r\n- 插入操作\r\n- 删除操作\r\n\r\n**使用限制：**\r\n\r\n- 需要生成全局唯一主键 ID；\r\n\r\n**主要流程：**\r\n\r\n![image-20230427153539838](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230427153539838.png)\r\n\r\n主要流程：\r\n\r\n1. ① 客户端执行创建请求，调用服务端接口。\r\n2. ② 服务端执行业务逻辑，生成一个分布式 ID，将该 ID 充当待插入数据的主键，然后执数据插入操作，运行对应的 SQL 语句。\r\n3. ③ 服务端将该条数据插入数据库中，如果插入成功则表示没有重复调用接口。如果抛出主键重复异常，则表示数据库中已经存在该条记录，返回错误信息到客户端。\r\n\r\n\r\n\r\n### **方案二：数据库乐观锁**\r\n\r\n**方案描述：**\r\n\r\n数据库乐观锁方案一般只能适用于执行“更新操作”的过程，我们可以提前在对应的数据表中多添加一个字段，充当当前数据的版本标识。这样每次对该数据库该表的这条数据执行更新时，都会将该版本标识作为一个条件，值为上次待更新数据中的版本标识的值。\r\n\r\n**适用操作：**\r\n\r\n- 更新操作\r\n\r\n**使用限制：**\r\n\r\n- 需要数据库对应业务表中添加额外字段；\r\n\r\n**描述示例：**\r\n\r\n![image-20230427153641136](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230427153641136.png)\r\n\r\n例如，存在如下的数据表中：\r\n\r\n1\r\n\r\n小米手机\r\n\r\n1000\r\n\r\n\r\n\r\n2\r\n\r\n苹果手机\r\n\r\n2500\r\n\r\n\r\n\r\n3\r\n\r\n华为手机\r\n\r\n1600\r\n\r\n> 为了每次执行更新时防止重复更新，确定更新的一定是要更新的内容，我们通常都会添加一个 version 字段记录当前的记录版本，这样在更新时候将该值带上，那么只要执行更新操作就能确定一定更新的是某个对应版本下的信息。\r\n\r\n1\r\n\r\n小米手机\r\n\r\n1000\r\n\r\n10\r\n\r\n\r\n\r\n2\r\n\r\n苹果手机\r\n\r\n2500\r\n\r\n21\r\n\r\n\r\n\r\n3\r\n\r\n华为手机\r\n\r\n1600\r\n\r\n5\r\n\r\n> 这样每次执行更新时候，都要指定要更新的版本号，如下操作就能准确更新 version=5 的信息：\r\n>\r\n> `UPDATE my_table SET price=price+50,version=version+1 WHERE id=1 AND version=5`\r\n>\r\n> 上面 WHERE 后面跟着条件 id=1 AND version=5 被执行后，id=1 的 version 被更新为 6，所以如果重复执行该条 SQL 语句将不生效，因为 id=1 AND version=5 的数据已经不存在，这样就能保住更新的幂等，多次更新对结果不会产生影响。\r\n\r\n\r\n\r\n### **方案三：防重 Token 令牌**\r\n\r\n**方案描述：**\r\n\r\n针对客户端连续点击或者调用方的超时重试等情况，例如提交订单，此种操作就可以用 Token 的机制实现防止重复提交。简单的说就是调用方在调用接口的时候先向后端请求一个全局 ID（Token），请求的时候携带这个全局 ID 一起请求（Token 最好将其放到 Headers 中），后端需要对这个 Token 作为 Key，用户信息作为 Value 到 Redis 中进行键值内容校验，如果 Key 存在且 Value 匹配就执行删除命令，然后正常执行后面的业务逻辑。如果不存在对应的 Key 或 Value 不匹配就返回重复执行的错误信息，这样来保证幂等操作。\r\n\r\n**适用操作：**\r\n\r\n1. 插入操作\r\n2. 更新操作\r\n3. 删除操作\r\n\r\n**使用限制：**\r\n\r\n1. 需要生成全局唯一 Token 串；\r\n2. 需要使用第三方组件 Redis 进行数据效验；\r\n\r\n**主要流程：**\r\n\r\n![image-20230427153655823](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230427153655823.png)\r\n\r\n1. ① 服务端提供获取 Token 的接口，该 Token 可以是一个序列号，也可以是一个分布式 ID 或者 UUID 串。\r\n2. ② 客户端调用接口获取 Token，这时候服务端会生成一个 Token 串。\r\n3. ③ 然后将该串存入 Redis 数据库中，以该 Token 作为 Redis 的键（注意设置过期时间）。\r\n4. ④ 将 Token 返回到客户端，客户端拿到后应存到表单隐藏域中。\r\n5. ⑤ 客户端在执行提交表单时，把 Token 存入到 Headers 中，执行业务请求带上该 Headers。\r\n6. ⑥ 服务端接收到请求后从 Headers 中拿到 Token，然后根据 Token 到 Redis 中查找该 key 是否存在。\r\n7. ⑦ 服务端根据 Redis 中是否存该 key 进行判断，如果存在就将该 key 删除，然后正常执行业务逻辑。如果不存在就抛异常，返回重复提交的错误信息。\r\n\r\n> 注意，在并发情况下，执行 Redis 查找数据与删除需要保证原子性，否则很可能在并发下无法保证幂等性。其实现方法可以使用分布式锁或者使用 Lua 表达式来注销查询与删除操作。\r\n\r\n\r\n\r\n### **方案四、下游传递唯一序列号**\r\n\r\n**方案描述：**\r\n\r\n- 所谓请求序列号，其实就是每次向服务端请求时候附带一个短时间内唯一不重复的序列号，该序列号可以是一个有序 ID，也可以是一个订单号，一般由下游生成，在调用上游服务端接口时附加该序列号和用于认证的 ID。\r\n\r\n- 当上游服务器收到请求信息后拿取该 序列号 和下游 认证ID 进行组合，形成用于操作 Redis 的 Key，然后到 Redis 中查询是否存在对应的 Key 的键值对，根据其结果：\r\n  1. 如果存在，就说明已经对该下游的该序列号的请求进行了业务处理，这时可以直接响应重复请求的错误信息。\r\n  2. 如果不存在，就以该 Key 作为 Redis 的键，以下游关键信息作为存储的值（例如下游商传递的一些业务逻辑信息），将该键值对存储到 Redis 中 ，然后再正常执行对应的业务逻辑即可。\r\n\r\n**适用操作：**\r\n\r\n1. 插入操作\r\n2. 更新操作\r\n3. 删除操作\r\n\r\n**使用限制：**\r\n\r\n1. 要求第三方传递唯一序列号；\r\n2. 需要使用第三方组件 Redis 进行数据效验；\r\n\r\n**主要流程：**\r\n\r\n\r\n\r\n![image-20230427153719484](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230427153719484.png)\r\n\r\n\r\n\r\n主要步骤：\r\n\r\n1. ① 下游服务生成分布式 ID 作为序列号，然后执行请求调用上游接口，并附带“唯一序列号”与请求的“认证凭据ID”。\r\n2. ② 上游服务进行安全效验，检测下游传递的参数中是否存在“序列号”和“凭据ID”。\r\n3. ③ 上游服务到 Redis 中检测是否存在对应的“序列号”与“认证ID”组成的 Key，如果存在就抛出重复执行的异常信息，然后响应下游对应的错误信息。如果不存在就以该“序列号”和“认证ID”组合作为 Key，以下游关键信息作为 Value，进而存储到 Redis 中，然后正常执行接来来的业务逻辑。\r\n\r\n> 上面步骤中插入数据到 Redis 一定要设置过期时间。这样能保证在这个时间范围内，如果重复调用接口，则能够进行判断识别。如果不设置过期时间，很可能导致数据无限量的存入 Redis，致使 Redis 不能正常工作。\r\n\r\n\r\n\r\n## 七、在项目中实现接口幂等\r\n\r\n这里使用防重 Token 令牌方案，该方案能保证在不同请求动作下的幂等性，实现逻辑可以看上面写的”防重 Token 令牌”方案，接下来写下实现这个逻辑的代码。\r\n\r\n\r\n\r\n### **1、Maven 引入相关依赖**\r\n\r\n这里使用 Maven 工具管理依赖，这里在 [pom.xml](http://pom.xml/) 中引入 SpringBoot、Redis、lombok 相关依赖。\r\n\r\n```xml\r\n\t<!--springboot web-->\r\n    <dependency>\r\n      <groupId>org.springframework.boot</groupId>\r\n      <artifactId>spring-boot-starter-web</artifactId>\r\n    </dependency>\r\n\r\n    <!--springboot data redis-->\r\n    <dependency>\r\n     <groupId>org.springframework.boot</groupId>\r\n     <artifactId>spring-boot-starter-data-redis</artifactId>\r\n    </dependency>\r\n\r\n\t<!--lombok-->\r\n    <dependency>\r\n      <groupId>org.projectlombok</groupId>\r\n      <artifactId>lombok</artifactId>\r\n    </dependency>\r\n```\r\n\r\n\r\n\r\n### **2、配置连接 Redis 的参数**\r\n\r\n在 application 配置文件中配置连接 Redis 的参数。Spring Boot 基础就不介绍了，最新教程推荐看下面的教程。\r\n\r\n```properties\r\nspring.redis.host=192.168.10.103\r\nspring.redis.port=6379\r\n```\r\n\r\n\r\n\r\n### **3、创建与验证 Token** \r\n\r\n创建用于操作 Token 相关的 Service 类，里面存在 Token 创建与验证方法，其中：\r\n\r\n1. **Token 创建方法：** 使用 UUID 工具创建 Token 串，设置以 “order:token:“+“Token串” 作为 Key，以用户id当成 Value，将信息存入 Redis 中。\r\n2. **Token 验证方法：** 接收 Token 串参数，加上 Key 前缀形成 Key，再传入 value 值，执行 Lua 表达式（Lua 表达式能保证命令执行的原子性）进行查找对应 Key 与删除操作。执行完成后验证命令的返回结果，如果结果不为空且非0，则验证成功，否则失败。\r\n\r\n```java\r\n/**\r\n * 订单确认页返回需要用到的数据\r\n *\r\n * @return\r\n */\r\n@Override\r\npublic OrderConfirmVo confirmOrder() throws ExecutionException, InterruptedException {\r\n    ...\r\n    //todo 5、防重令牌\r\n    String token = UUID.randomUUID().toString().replace(\"-\", \"\");\r\n    //给服务器一个令牌\r\n    redisTemplate.opsForValue().set(OrderConstant.USER_ORDER_TOKEN_PREFIX + \t\t             memberRespVo.getId(), token, 30, TimeUnit.MINUTES);\r\n    //给页面一个令牌\r\n    confirmVo.setOrderToken(token);\r\n    ...\r\n}    \r\n```\r\n\r\n```java\r\n/**\r\n * 下单\r\n */\r\n@Transactional\r\n@Override\r\npublic SubmitOrderResponseVo submitOrder(OrderSubmitVo vo) {\r\n    ...\r\n    //1、验证令牌【令牌的对比和删除必须保证原子性】\r\n    //0令牌失败 - 1删除成功(校验成功)\r\n    String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\";\r\n    String orderToken = vo.getOrderToken();\r\n    //原子验证令牌和删除令牌\r\n    Long result = redisTemplate.execute(\r\n                //脚本返回类型->0,1\r\n                new DefaultRedisScript<Long>(script, Long.class),\r\n                //将缓存中将要比对的key转为集合\r\n                Arrays.asList(OrderConstant.USER_ORDER_TOKEN_PREFIX + memberRespVo.getId()),\r\n                //传入要校验的值\r\n                orderToken);\r\n    if (result == 0L) {\r\n        //验证失败，设置错误状态码为1，key过期等情况\r\n        responseVo.setCode(1);\r\n        return responseVo;\r\n    } else {\r\n        //验证成功\r\n        ...\r\n    }\r\n}    \r\n```\r\n\r\n\r\n\r\n## 八、最后总结\r\n\r\n- 幂等性是开发当中很常见也很重要的一个需求，尤其是支付、订单等与金钱挂钩的服务，保证接口幂等性尤其重要。在实际开发中，我们需要针对不同的业务场景我们需要灵活的选择幂等性的实现方式：\r\n\r\n1. 对于下单等存在唯一主键的，可以使用“唯一主键方案”的方式实现。\r\n2. 对于更新订单状态等相关的更新场景操作，使用“乐观锁方案”实现更为简单。\r\n3. 对于上下游这种，下游请求上游，上游服务可以使用“下游传递唯一序列号方案”更为合理。\r\n4. 类似于前端重复提交、重复下单、没有唯一ID号的场景，可以通过 Token 与 Redis 配合的“防重 Token 方案”实现更为快捷。\r\n\r\n> 上面只是给与一些建议，再次强调一下，实现幂等性需要先理解自身业务需求，根据业务逻辑来实现这样才合理，处理好其中的每一个结点细节，完善整体的业务流程设计，才能更好的保证系统的正常运行。最后做一个简单总结\r\n\r\n> 数据库唯一主键\r\n>\r\n> 插入操作 删除操作\r\n>\r\n> 简单\r\n>\r\n> \\- 只能用于插入操作；- 只能用于存在唯一主键场景；\r\n\r\n> 数据库乐观锁\r\n>\r\n> 更新操作\r\n>\r\n> 简单\r\n>\r\n> \\- 只能用于更新操作；- 表中需要额外添加字段；\r\n\r\n> 请求序列号\r\n>\r\n> 插入操作 更新操作 删除操作\r\n>\r\n> 简单\r\n>\r\n> \\- 需要保证下游生成唯一序列号；- 需要 Redis 第三方存储已经请求的序列号；\r\n\r\n> 防重 Token 令牌\r\n>\r\n> 插入操作 更新操作 删除操作\r\n>\r\n> 适中\r\n>\r\n> \\- 需要 Redis 第三方存储生成的 Token 串；\r\n\r\n\r\n\r\n\r\n\r\n"},{"title":"Java面试专题-基础篇","tags":["ArrayList","LinkedList","HashMap","Hashtable","Singleton"],"categories":["Java","面试"],"author":"imklaus","excerpt":"\r\n参考视频：[满神Java面试专题](https://www.bilibili.com/video/BV15b4y117RJ)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Java_Interview_Topics-Basic","content":"\r\n参考视频：[满神Java面试专题](https://www.bilibili.com/video/BV15b4y117RJ)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n\r\n## 1. ArrayList\r\n\r\n**要求**\r\n\r\n- 掌握 ArrayList 扩容规则\r\n\r\n**扩容规则**\r\n\r\n1. **ArrayList()** 会使用**长度为零**的数组\r\n\r\n![image-20230418114304421](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418114304421.png)\r\n\r\n2. **ArrayList(int initialCapacity)** 会使用**指定容量**的数组\r\n\r\n![image-20230418114403174](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418114403174.png)\r\n\r\n3. public ArrayList(Collection<? extends E> c) 会使用 c 的大小作为数组容量\r\n\r\n![image-20230418114502997](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418114502997.png)\r\n\r\n4. add(Object o) 首次扩容为 10，再次扩容为上次容量的 1.5 倍\r\n\r\n- 第一次添加数组，数组为0，发生第一次扩容\r\n- 第一个元素放入新数组索引0，新数组替换旧数组(首次为0)\r\n\r\n![image-20230418115017704](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418115017704.png)\r\n\r\n- 再次扩容为上次容量的 1.5 倍，完成扩容并添加元素，新数组替换旧数组，旧数组没人引用就会被垃圾回收\r\n\r\n![image-20230418115545132](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418115545132.png)\r\n\r\n- 以后扩容按上次容量+上次容量右移1位\r\n\r\n![image-20230418115811928](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418115811928.png)\r\n\r\n- 此方式为调用的add方法得到的扩容结果\r\n\r\n![image-20230418120314176](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418120314176.png)\r\n\r\n5.  addAll(Collection c) 没有元素时，扩容为 Math.max(10, 实际元素个数)，有元素时为 Math.max(原容量 1.5 倍, 实际元素个数)\r\n\r\n![image-20230418120611741](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418120611741.png)\r\n\r\n- 第一次空数组扩容(元素个数<10)\r\n\r\n![image-20230418120727097](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418120727097.png)\r\n\r\n- 第一次空数组扩容(10<元素个数<15，此时会拿当前元素个数与当前容量下次扩容的容量二者之间的较大值作为当前容量)\r\n\r\n![image-20230418121100137](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418121100137.png)\r\n\r\n- 第一次非空数组扩容(规则一样)\r\n\r\n![image-20230418121501578](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418121501578.png)\r\n\r\n![image-20230418121608015](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418121608015.png)\r\n\r\n其中第 4 点必须知道，其它几点视个人情况而定\r\n\r\n**提示**\r\n\r\n- 测试代码见 `day01.list.TestArrayList` ，这里不再列出\r\n- 要**注意**的是，示例中用反射方式来更直观地反映 ArrayList 的扩容特征，但从 JDK 9 由于模块化的影响，对反射做了较多限制，需要在运行测试代码时添加 VM 参数 `--add-opens java.base/java.util=ALL-UNNAMED` 方能运行通过，后面的例子都有相同问题\r\n\r\n> ***代码说明***\r\n>\r\n> - day01.list.TestArrayList#arrayListGrowRule 演示了 add(Object) 方法的扩容规则，输入参数 n 代表打印多少次扩容后的数组长度\r\n\r\n### 补充\r\n\r\n> **addAll扩容机制**：添加元素后的元素个数与下一次扩容数作比较\r\n> 0->10:3个->10,11->11;10->15:13->15,16->16\r\n\r\n## 2. Iterator\r\n\r\n**要求**\r\n\r\n- 掌握什么是 Fail-Fast、什么是 Fail-Safe\r\n\r\nFail-Fast 与 Fail-Safe\r\n\r\n- ArrayList 是 fail-fast 的典型代表，遍历的同时不能修改，尽快失败\r\n- fail-fast 一旦发现遍历的同时其它人来修改，则立刻抛异常\r\n\r\n![image-20230418133457466](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418133457466.png)\r\n\r\n- fail-fast实现原理\r\n\r\n![image-20230418135557765](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418135557765.png)\r\n\r\n- CopyOnWriteArrayList 是 fail-safe 的典型代表，遍历的同时可以修改，原理是读写分离\r\n- fail-safe 发现遍历的同时其它人来修改，应当能有应对策略，例如牺牲一致性来让整个遍历运行完成\r\n\r\n![image-20230418133702722](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418133702722.png)\r\n\r\n- fail-safe实现原理\r\n\r\n![image-20230418142258054](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418142258054.png)\r\n\r\n**提示**\r\n\r\n- 测试代码见 `day01.list.FailFastVsFailSafe`，这里不再列出\r\n\r\n- 第一次笔记：\r\n\r\n  - **fail-fast:**\r\n\r\n    - ​    1.调用迭代器Iterator构造方法并初始化成员变量\r\n\r\n    - ​    2.检查：expectedModCount(迭代一开始记录的修改次数)与modCount(外面list的修改次数)做对比，不等则抛异常\r\n\r\n  - **fail-safe:**\r\n    - ​    list.add中每次调用add方法时都会把旧的数组拷贝一份，并让长度加一，把新加的元素放到扩容数组(新数组)最后一个位置，即添加和遍历的数组不同，互不干扰\r\n\r\n- 第二次笔记：\r\n\r\n  - **failfast**：\r\n    - 增强for循环开始前的修改次数（crud）modCount\r\n    - expectedModCount初始值=modCount\r\n    - 每次遍历元素前（迭代）都检查以上的值是否相等，在遍历期间并发修改了，等遍历下个元素时就会抛出异常\r\n\r\n  - **failsafe**：\r\n    - iterator遍历集合，list.add方法每次添加元素，都会拷贝一份原集合并让容量加一，在并发修改时迭代器是不知道，遍历的还是原集合，即添加是一个集合，遍历是另一个集合\r\n\r\n## 3. LinkedList VS **ArrayList**\r\n\r\n**要求**\r\n\r\n- 能够说清楚 LinkedList 对比 ArrayList 的区别，并重视纠正部分错误的认知\r\n\r\n![image-20230418144031416](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418144031416.png)\r\n\r\n- 两者查询元素内容的时间复杂度都是O(n)，都不太适合用来查询，查询可以选择更高效的数据结构，如HashMap、TreeMap等\r\n\r\n\r\n**LinkedList**\r\n\r\n1. 基于双向链表，无需连续内存\r\n\r\n![image-20230418143629513](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418143629513.png)\r\n\r\n2. 随机访问慢（要沿着链表遍历）\r\n\r\n![image-20230418143509162](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418143509162.png)\r\n\r\n3. 头尾插入删除性能高\r\n4. 占用内存多\r\n\r\n**ArrayList**\r\n\r\n1. 基于数组，需要连续内存\r\n\r\n![image-20230418143617488](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418143617488.png)\r\n\r\n2. 随机访问快（指根据下标访问）\r\n\r\n![image-20230418143527810](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418143527810.png)\r\n\r\n3. 尾部插入、删除性能可以，其它部分插入、删除都会移动数据，因此性能会低\r\n\r\n![image-20230418144640481](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418144640481.png)\r\n\r\n4. 可以利用 cpu 缓存，局部性原理（将读取变量和其相邻的变量也一次读到CPU缓存中）\r\n\r\n\r\n\r\n\r\n\r\n> ***代码说明***\r\n>\r\n> - day01.list.ArrayListVsLinkedList#randomAccess 对比随机访问性能\r\n>\r\n> ![image-20230418143722912](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418143722912.png)\r\n>\r\n> - day01.list.ArrayListVsLinkedList#addMiddle 对比向中间插入性能\r\n> - day01.list.ArrayListVsLinkedList#addFirst 对比头部插入性能\r\n> - day01.list.ArrayListVsLinkedList#addLast 对比尾部插入性能\r\n>\r\n> ![image-20230418145338167](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418145338167.png)\r\n>\r\n> - day01.list.ArrayListVsLinkedList#linkedListSize 打印一个 LinkedList 占用内存\r\n> - day01.list.ArrayListVsLinkedList#arrayListSize 打印一个 ArrayList 占用内存\r\n>\r\n> ![image-20230418153454935](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418153454935.png)\r\n>\r\n> ![image-20230418150308326](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418150308326.png)\r\n>\r\n> - CPU进行计算的数据还是来自内存中的，比如进行加法运算，首先将内存中a的变量的读取到CPU的寄存器中，然后将b的值读到另一个寄存器中，数据都有了就进行接下来的加法运算，计算后的结果也会写到内存中的c变量，这样就完成了一次加法运算的计算过程，在这个计算过程里瓶颈在于内存变量的读和写上，因为内存的读写效率是非常低的，读一次、写一次大约需要花几百纳秒，对于CPU来讲这个时间是非常漫长的，CPU执行一次计算是少于纳秒级别的，也许花了不到1纳秒就完成了，但等待数据读进来写出去就要花费成百倍的时间，显然是不可接受的；\r\n>\r\n> - 因此需要在CPU与内存之间加入CPU缓存，这个缓存的读写性能就比内存高很多了，CPU缓存又分为1级、2级、3级缓存，速度快的能达到10纳秒，速度慢的也能到达几十纳秒，对比内存的几百纳秒就快了很多\r\n>\r\n> ![image-20230418151824705](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418151824705.png)\r\n>\r\n> - 局部性原理\r\n>   - 往缓存中读数据时的一种规则，一种优化措施\r\n>   - 将某个数据以及它相邻的数据都读取到缓存中，它会出于这样一种假设，当读取某个变量时，它相邻的变量也会有很大几率被访问到，即拿到某个元素后，有很大几率会遍历数组，即可以直接在缓存中遍历了，无需再到内存中遍历\r\n>\r\n> ![image-20230418152143557](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418152143557.png)\r\n>\r\n> - 链表的局部性原理就不可行，因为第一个元素与第二个元素相邻的有点远\r\n>\r\n> ![image-20230418152725657](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418152725657.png)\r\n>\r\n> - CPU缓存的空间也是有限的，如果将2和3也读到缓存，就会把之前的数据清空掉了，因此链表就不能很好的配合CPU缓存(局部性原理)来提升性能\r\n>\r\n> ![image-20230418152845212](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418152845212.png)\r\n\r\n## 4. HashMap\r\n\r\n**要求**\r\n\r\n- 掌握 HashMap 的基本数据结构\r\n- 掌握树化\r\n- 理解索引计算方法、二次 hash 的意义、容量对索引计算的影响\r\n- 掌握 put 流程、扩容、扩容因子\r\n- 理解并发使用 HashMap 可能导致的问题\r\n- 理解 key 的设计\r\n\r\n### 1）基本数据结构\r\n\r\n- 1.7 数组 + 链表\r\n- 1.8 数组 + （链表 | 红黑树）\r\n\r\n> 更形象的演示，见资料中的 hash-demo.jar，运行需要 jdk14 以上环境，进入 jar 包目录，执行下面命令\r\n>\r\n> ```\r\n> java -jar --add-exports java.base/jdk.internal.misc=ALL-UNNAMED hash-demo.jar\r\n> ```\r\n\r\n### 2）树化与退化\r\n\r\n**树化意义**\r\n\r\n- 红黑树用来避免 DoS 攻击，防止链表超长时性能下降，树化应当是偶然情况，是保底策略\r\n- hash 表的查找，更新的时间复杂度是 $O(1)$，而红黑树的查找，更新的时间复杂度是 $O(log_2n)$ ，TreeNode 占用空间也比普通 Node 的大，如非必要，尽量还是使用链表\r\n- hash 值如果足够随机，则在 hash 表内按泊松分布，在负载因子 0.75 的情况下，长度超过 8 的链表出现概率是 0.00000006，树化阈值选择 8 就是为了让树化几率足够小\r\n\r\n**树化规则**\r\n\r\n- 当链表长度超过树化阈值 8 时，先尝试扩容来减少链表长度，如果数组容量已经 >=64，才会进行树化\r\n\r\n**退化规则**\r\n\r\n- 情况1：在扩容时如果拆分树时，树元素个数 <= 6 则会退化链表\r\n- 情况2：remove 树节点时，若 root、root.left、root.right、root.left.left 有一个为 null ，也会退化为链表\r\n\r\n### 3）索引计算\r\n\r\n- 前置知识\r\n\r\n  - 与运算（&）\r\n  \r\n  ```java\r\n  参加运算的两个数据，按二进制位进行“与”运算。\r\n  \r\n  运算规则：0&0=0;   0&1=0;    1&0=0;     1&1=1;\r\n  \r\n  即：两位同时为“1”，结果才为“1”，否则为0\r\n  \r\n  例如：3&5  即 0000 0011 & 0000 0101 = 0000 0001   因此，3&5的值得1。\r\n  \r\n  例如：9&5  即 0000 1001 (9的二进制补码)&00000101 (5的二进制补码) =00000001 (1的二进制补码)可见9&5=1。\r\n  ```\r\n  \r\n  - 或运算（|）\r\n  \r\n    ```\r\n    参加运算的两个对象，按二进制位进行“或”运算。\r\n    \r\n    运算规则：0|0=0；   0|1=1；   1|0=1；    1|1=1；\r\n    \r\n    即 ：参加运算的两个对象只要有一个为1，其值为1。\r\n    \r\n    例如:3|5　即 0000 0011 | 0000 0101 = 0000 0111   因此，3|5的值得7。　\r\n    \r\n    例如：9|5可写算式如下： 00001001|00000101 =00001101 (十进制为13)可见9|5=13\r\n    ```\r\n  \r\n    \r\n  \r\n  - 异或运算（^）\r\n  \r\n  ```java\r\n  参加运算的两个数据，按二进制位进行“异或”运算。\r\n  \r\n  运算规则：0^0=0；   0^1=1；   1^0=1；   1^1=0；\r\n  \r\n  即：参加运算的两个对象，如果两个相应位为“异”（值不同），则该位结果为1，否则为0。\r\n  \r\n  例如：9^5可写成算式如下： 00001001^00000101=00001100 (十进制为12)可见9^5=12   \r\n  ```\r\n\r\n\r\n\r\n  ```java\r\n   01010(10)\r\n   10000(16)\r\n   11010(26)\r\n  ----------(10&16 = 0)\r\n  ----------(26&16 = 16)\r\n  newHash = 16+10     \r\n  ```\r\n\r\n```java\r\n8421码指的是四位二进制数，从0000~1001，分别代表十进制0~9，其每位的权分别为$2^3$（8）、$2^2$（4）、$2^1$（2）、$2^0$（1）。除了8421码外，类似的还有5421码。\r\n```\r\n\r\n  - 索引如何计算？hashCode都有了，为何还要提供hash()方法？数组容量为何是2的n次幂？\r\n\r\n\r\n**索引计算方法**（**为了配合容量是 2 的 n 次幂的优化手段** ）\r\n\r\n- 首先，计算对象的 hashCode()\r\n\r\n- 再进行调用 HashMap 的 hash() 方法进行二次哈希\r\n  - 二次 hash() 是为了综合高位数据，让哈希分布更为均匀；**计算hashCode的值越随机，hashCode分布得越均匀，链表就越不会有过长的情况**\r\n  \r\n    - HashMap1.8二次hash\r\n  \r\n    ![image-20230418201334955](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418201334955.png)\r\n  \r\n    - HashMap1.7二次hash\r\n  \r\n    ![image-20230418201418625](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418201418625.png)\r\n  \r\n  - hashCode足够均匀\r\n  \r\n  ![image-20230418202517544](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418202517544.png)\r\n  \r\n  - hashCode选取不够好，不够随机\r\n  \r\n  ![image-20230418202727603](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418202727603.png)\r\n  \r\n  ![image-20230418202829734](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418202829734.png)\r\n  \r\n  - 进行二次hash扰动函数，使得hashCode分布更均匀，防止超长链表的产生\r\n  \r\n  ![image-20230418203040744](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418203040744.png)\r\n  \r\n  ![image-20230418203513964](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418203513964.png)\r\n  \r\n- 最后 & (capacity – 1) 得到索引（容量capacity必须为2的n次幂）\r\n\r\n![image-20230418195049973](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418195049973.png)\r\n\r\n**数组容量为何是 2 的 n 次幂**\r\n\r\n![image-20230418195337120](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418195337120.png)\r\n\r\n1. 计算索引时效率更高：如果是 2 的 n 次幂可以使用位与运算代替取模\r\n2. 扩容时重新计算索引效率更高： hash & oldCap == 0 的元素留在原来位置 ，否则新位置 = 旧位置 + oldCap =  10  + 16\r\n\r\n![image-20230418204559461](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418204559461.png)\r\n\r\n**注意**\r\n\r\n- 二次 hash 是为了配合 **容量是 2 的 n 次幂** 这一设计前提，如果 hash 表的容量不是 2 的 n 次幂，则不必二次 hash，即想要更好的hash分布性，容量值就选择质数\r\n\r\n![image-20230418210235261](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418210235261.png)\r\n\r\n- **容量是 2 的 n 次幂** 这一设计计算索引效率更好（追求性能），但 hash 的分散性就不好，需要二次 hash 来作为补偿，没有采用这一设计的典型例子是 Hashtable，以下为 Hashtable 的扩容规律\r\n\r\n![image-20230418210834027](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418210834027.png)\r\n\r\n### 4）put 与扩容\r\n\r\n**put 流程**\r\n\r\n- 1.8put流程\r\n\r\n![image-20230419110228837](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419110228837.png)\r\n\r\n1. HashMap 是懒惰创建数组的，首次使用才创建数组\r\n2. 计算索引（桶下标）\r\n3. 如果桶下标还没人占用，创建 Node 占位返回\r\n4. 如果桶下标已经有人占用\r\n   1. 已经是 TreeNode 走红黑树的添加或更新逻辑\r\n   2. 是普通 Node，走链表的添加或更新逻辑，如果链表长度超过树化阈值，走树化逻辑\r\n5. 返回前检查容量是否超过阈值，一旦超过进行扩容\r\n\r\n**1.7 与 1.8 的区别**\r\n\r\n1. 链表插入节点时\r\n\r\n   1. 1.7 是头插法\r\n\r\n   ![image-20230419110745737](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419110745737.png)\r\n\r\n   2. 1.8 是尾插法\r\n\r\n   ![image-20230419110538952](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419110538952.png)\r\n\r\n2. 1.7 是大于等于阈值且没有空位时才扩容\r\n\r\n   ![image-20230419112014919](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419112014919.png)\r\n\r\n3. 而 1.8 是大于阈值就扩容\r\n\r\n4. 1.8 在扩容计算 Node 索引时，会优化\r\n\r\n   - hash & oldCap == 0 的元素留在原来位置 ，否则新位置 = 旧位置 + oldCap =  10  + 16\r\n\r\n**扩容（加载）因子为何默认是 0.75f**\r\n\r\n1. 在空间占用与查询时间之间取得较好的权衡\r\n2. 大于这个值，空间节省了，但链表就会比较长影响性能\r\n\r\n   ![image-20230419112518996](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419112518996.png)\r\n\r\n3. 小于这个值，冲突减少了，但扩容就会更频繁，空间占用也更多\r\n\r\n![image-20230419112817313](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419112817313.png)\r\n\r\n> 计算桶下标：hash()→`(hashcode >>> 16 ^ hashcode )&(capacity-1)`\r\n> capacity为2的n次幂，计算索引效率更高，但哈希分布不均匀；capacity为质数时哈希分布均匀（hashtable）。\r\n> hashmap1.8:超过容量扩容阈值（＞¾），先创建扩容新数组再将数据迁移到新数组；链表插入方式为尾插法\r\n> 1.7:链表插入方式为头插法；\r\n\r\n### 5）并发问题\r\n\r\n1.7链表迁移过程(a和b迁移前后都是同一个对象，只是改变了它们的一些引用地址，并没有发生对象的创建)\r\n\r\n![image-20230419121302636](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419121302636.png)\r\n\r\n**扩容死链（1.7 会存在）**\r\n\r\n1.7 源码如下：\r\n\r\n```java\r\nvoid transfer(Entry[] newTable, boolean rehash) {\r\n    int newCapacity = newTable.length;\r\n    for (Entry<K,V> e : table) {\r\n        while(null != e) {\r\n            Entry<K,V> next = e.next;\r\n            if (rehash) {\r\n                e.hash = null == e.key ? 0 : hash(e.key);\r\n            }\r\n            int i = indexFor(e.hash, newCapacity);\r\n            e.next = newTable[i];\r\n            newTable[i] = e;\r\n            e = next;\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n- e 和 next 都是局部变量，用来指向当前节点和下一个节点\r\n- 线程1（绿色）的临时变量 e 和 next 刚引用了这俩节点，还未来得及移动节点，发生了线程切换，由线程2（蓝色）完成扩容和迁移\r\n\r\n![image-20210831084325075](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831084325075.png)\r\n\r\n- 线程2 扩容完成，由于头插法，链表顺序颠倒。但线程1 的临时变量 e 和 next 还引用了这俩节点，还要再来一遍迁移\r\n\r\n![image-20210831084723383](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831084723383.png)\r\n\r\n- 第一次循环\r\n  - 循环接着线程切换前运行，注意此时 e 指向的是节点 a，next 指向的是节点 b\r\n  - e 头插 a 节点，注意图中画了两份 a 节点，但事实上只有一个（为了不让箭头特别乱画了两份）\r\n\r\n  ![image-20210831084855348](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831084855348.png)\r\n\r\n  - 当循环结束是 e 会指向 next 也就是 b 节点\r\n\r\n![image-20230419121935915](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419121935915.png)\r\n\r\n\r\n\r\n\r\n\r\n- 第二次循环\r\n  - 第二轮开始，next 指向了节点 a\r\n  - e 头插节点 b\r\n  \r\n  ![image-20210831085329449](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831085329449.png)\r\n  \r\n  - 当循环结束时，e 指向 next 也就是节点 a\r\n\r\n![image-20230419122220312](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419122220312.png)\r\n\r\n\r\n\r\n- 第三次循环\r\n  - next 指向了 null\r\n  \r\n  ![image-20230419133332478](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419133332478.png)\r\n  \r\n  - e 头插节点 a，**a 的 next 指向了 b**（之前 a.next 一直是 null），b 的 next 指向 a，死链已成\r\n  \r\n  ![image-20210831085543224](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831085543224.png)\r\n  \r\n  - 当循环结束时，e 指向 next 也就是 null，因此第四次循环时会正常退出\r\n\r\n![image-20230419133643654](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419133643654.png)\r\n\r\n**数据错乱（1.7，1.8 都会存在）**\r\n\r\n- 代码参考 `day01.map.HashMapMissData`，具体调试步骤参考视频\r\n\r\n![image-20230419115103985](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419115103985.png)\r\n\r\n> ***补充代码说明***\r\n>\r\n> - day01.map.HashMapDistribution 演示 map 中链表长度符合泊松分布\r\n> - day01.map.DistributionAffectedByCapacity 演示容量及 hashCode 取值对分布的影响\r\n>   - day01.map.DistributionAffectedByCapacity#hashtableGrowRule 演示了 Hashtable 的扩容规律\r\n>   - day01.sort.Utils#randomArray 如果 hashCode 足够随机，容量是否是 2 的 n 次幂影响不大\r\n>   - day01.sort.Utils#lowSameArray 如果 hashCode 低位一样的多，容量是 2 的 n 次幂会导致分布不均匀\r\n>   - day01.sort.Utils#evenArray 如果 hashCode 偶数的多，容量是 2 的 n 次幂会导致分布不均匀\r\n>   - 由此得出对于容量是 2 的 n 次幂的设计来讲，二次 hash 非常重要\r\n> - day01.map.HashMapVsHashtable 演示了对于同样数量的单词字符串放入 HashMap 和 Hashtable 分布上的区别\r\n\r\n### 6）key 的设计\r\n\r\n**key 的设计要求**\r\n\r\n1. HashMap 的 key 可以为 null，但 Map 的其他实现则不然\r\n2. 作为 key 的对象，必须实现 hashCode 和 equals，并且 **key 的内容不能修改（不可变）**\r\n   - 重写hashCode方法是为了让我们的key在整个HashMap中有更好的分布性，提高查询性能\r\n   - 重写equals方法是为了将来如果计算两个对象的key的索引都一样，进一步需要用equals进行比较，看看是不是两个相同的对象\r\n   - 两个对象的hashCode相等，equals不一定相等；两个对象的equals相等，hashCode一定相等\r\n\r\n3. key 的 hashCode 应该有良好的散列性\r\n\r\n如果 key 可变，例如修改了 age 会导致再次查询时查询不到，因此平时用整数、字符串等作为key，这些类的内容不可变\r\n\r\n![image-20230419134838699](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419134838699.png)\r\n\r\n```java\r\npublic class HashMapMutableKey {\r\n    public static void main(String[] args) {\r\n        HashMap<Student, Object> map = new HashMap<>();\r\n        Student stu = new Student(\"张三\", 18);\r\n        map.put(stu, new Object());\r\n\r\n        System.out.println(map.get(stu));\r\n\r\n        stu.age = 19;\r\n        System.out.println(map.get(stu));\r\n    }\r\n\r\n    static class Student {\r\n        String name;\r\n        int age;\r\n\r\n        public Student(String name, int age) {\r\n            this.name = name;\r\n            this.age = age;\r\n        }\r\n\r\n        public String getName() {\r\n            return name;\r\n        }\r\n\r\n        public void setName(String name) {\r\n            this.name = name;\r\n        }\r\n\r\n        public int getAge() {\r\n            return age;\r\n        }\r\n\r\n        public void setAge(int age) {\r\n            this.age = age;\r\n        }\r\n\r\n        @Override\r\n        public boolean equals(Object o) {\r\n            if (this == o) return true;\r\n            if (o == null || getClass() != o.getClass()) return false;\r\n            Student student = (Student) o;\r\n            return age == student.age && Objects.equals(name, student.name);\r\n        }\r\n\r\n        @Override\r\n        public int hashCode() {\r\n            return Objects.hash(name, age);\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n**String 对象的 hashCode() 设计**\r\n\r\n- 目标是达到较为均匀的散列效果，每个字符串的 hashCode 足够独特\r\n- 字符串中的每个字符都可以表现为一个数字，称为 $S_i$，其中 i 的范围是 0 ~ n - 1\r\n- 散列公式为：$S_0∗31^{n-1}+S_1∗31^{n-2}+… S_i∗31^{n-1-i}+…S_{n-1}∗31^0$\r\n- 31 代入公式有较好的散列特性，并且 31 * h 可以被优化为\r\n  - 即 $32 ∗h -h$\r\n  - 即 $2^5 ∗h -h$\r\n  - 即 $h≪5 -h$\r\n\r\n![image-20230419135639704](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419135639704.png)\r\n\r\n## 4.1. HashMap-快速查找\r\n\r\n- ArrayList查找效率较低\r\n\r\n![image-20230418161635803](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418161635803.png)\r\n\r\n- HashMap通过索引计算直接找到元素(hash运算)，无链表情况查找时间复杂度为O(1)，有链表情况就看链表长度了，时间复杂度为O(n)\r\n\r\n![image-20230418161857746](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418161857746.png)\r\n\r\n## 4.2. HashMap-链表过长的解决方案\r\n\r\n- 形成链表：keys相同的固定hash；keys的hash%容量相同\r\n\r\n### 4.2.1.扩容\r\n\r\n- 正常情况\r\n\r\n![image-20230418162855531](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418162855531.png)\r\n\r\n![image-20230418162904156](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418162904156.png)\r\n\r\n![image-20230418162909932](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418162909932.png)\r\n\r\n- 极端情况，只能树化为红黑树了\r\n\r\n![image-20230418162935840](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418162935840.png)\r\n\r\n### 4.2.2. 树化\r\n\r\n- 链表->红黑树：当容量为16，在某个桶下标形成链表的8个元素添加元素，仅进行扩容为32，再添加扩容到64才会树化\r\n\r\n![image-20230418164530243](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418164530243.png)\r\n\r\n![image-20230418165555721](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418165555721.png)\r\n\r\n- 满足树化条件(容量>=64且链表长度>8)，红黑树父节点左侧都是比它小的元素，右侧都是比它大的元素，子节点同理，hash码相同时才比较，按照key的字符串值比较，查找的时间复杂度为O(log2(n))\r\n\r\n![image-20230418165707584](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418165707584.png)\r\n\r\n- 链表长度是可能出现超过8的情况\r\n\r\n![image-20230418170758857](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418170758857.png)\r\n\r\n\r\n\r\n#### 红黑树的意义-树化阈值\r\n\r\n- 为何要用红黑树，为何一上来不树化，树化阈值为何是8，何时会树化，何时会退化为链表？\r\n\r\n  - 因为链表较长时会影响整个HashMap的性能，1.8之后引入红黑树，即使链表较长也不会对性能有太大的影响\r\n\r\n  - 链表->红黑树：当容量为16，在某个桶下标形成链表的8个元素添加元素，仅进行扩容为32，再添加扩容到64才会树化\r\n  - 链表短的时候，链表性能大于红黑树，链表长时性能才远远不如红黑树，且红黑树占用内存比链表大得多，非必要不树化\r\n  - 红黑树是一种非正常情况，下图为23W多个正常单词的hash分布情况，若没有刻意构造hash码，在负载因子0.75的情况下，链表出现8的概率非常低，为0.00000006\r\n\r\n  ![image-20230418181214309](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418181214309.png)\r\n\r\n  - 红黑树用来避免 DoS 攻击，防止链表超长时性能下降，树化应当是偶然情况，是保底策略\r\n\r\n\r\n\r\n#### 树退化链表-情况1\r\n\r\n- 在扩容时如果拆分树时，树元素个数 <= 6 则会退化链表\r\n\r\n![image-20230418183806555](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418183806555.png)\r\n\r\n- 在扩容时如果拆分树时，树元素个数 > 6 则不会退化链表\r\n\r\n![image-20230418184454141](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418184454141.png)\r\n\r\n\r\n\r\n#### 树退化链表-情况2\r\n\r\n- remove 树节点时，若 root(爷)、root.left(左孩子)、root.right(右孩子)、root.left.left(左孙子) 有一个为 null ，也会退化为链表\r\n\r\n![image-20230418192832140](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418192832140.png)\r\n\r\n- 例子2\r\n\r\n![image-20230418193518600](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230418193518600.png)\r\n\r\n\r\n\r\n\r\n\r\n## 5. 单例模式\r\n\r\n**要求**\r\n\r\n- 掌握五种单例模式的实现方式\r\n- 理解为何 DCL 实现时要使用 volatile 修饰静态变量\r\n- 了解 jdk 中用到单例的场景\r\n\r\n### **饿汉式**\r\n\r\n- 提前创建单例对象\r\n\r\n![image-20230419141144975](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419141144975.png)\r\n\r\n- 实现Serializable接口利用反射破坏单例\r\n\r\n![image-20230419141539054](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419141539054.png)\r\n\r\n- 反序列化破坏单例\r\n\r\n![image-20230419142100218](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419142100218.png)\r\n\r\n```java\r\npublic class Singleton1 implements Serializable {\r\n    private Singleton1() {\r\n        if (INSTANCE != null) {\r\n            throw new RuntimeException(\"单例对象不能重复创建\");\r\n        }\r\n        System.out.println(\"private Singleton1()\");\r\n    }\r\n\r\n    private static final Singleton1 INSTANCE = new Singleton1();\r\n\r\n    public static Singleton1 getInstance() {\r\n        return INSTANCE;\r\n    }\r\n\r\n    public static void otherMethod() {\r\n        System.out.println(\"otherMethod()\");\r\n    }\r\n\r\n    public Object readResolve() {\r\n        return INSTANCE;\r\n    }\r\n}\r\n```\r\n\r\n- 构造方法抛出异常是防止反射破坏单例\r\n\r\n![image-20230419141740516](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419141740516.png)\r\n\r\n- `readResolve()` 是防止反序列化破坏单例\r\n\r\n![image-20230419142253512](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419142253512.png)\r\n\r\n- unsafe破坏单例\r\n\r\n![image-20230419142613493](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419142613493.png)\r\n\r\n### **枚举饿汉式**\r\n\r\n- 枚举类一加载并初始化，就会把枚举对象创建出来\r\n\r\n![image-20230419143438750](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419143438750.png)\r\n\r\n![image-20230419143148474](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419143148474.png)\r\n\r\n```java\r\npublic enum Singleton2 {\r\n    INSTANCE;\r\n\r\n    private Singleton2() {\r\n        System.out.println(\"private Singleton2()\");\r\n    }\r\n\r\n    @Override\r\n    public String toString() {\r\n        return getClass().getName() + \"@\" + Integer.toHexString(hashCode());\r\n    }\r\n\r\n    public static Singleton2 getInstance() {\r\n        return INSTANCE;\r\n    }\r\n\r\n    public static void otherMethod() {\r\n        System.out.println(\"otherMethod()\");\r\n    }\r\n}\r\n```\r\n\r\n- 枚举饿汉式能天然防止反射、反序列化破坏单例\r\n\r\n![image-20230419144121454](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419144121454.png)\r\n\r\n![image-20230419143856798](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419143856798.png)\r\n\r\n![image-20230419143639529](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419143639529.png)\r\n\r\n- unsafe依旧可以破坏枚举单例\r\n\r\n![image-20230419144327173](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419144327173.png)\r\n\r\n![image-20230419144146527](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419144146527.png)\r\n\r\n### **懒汉式**\r\n\r\n- 第一次调用getInstance方法时才创建单例对象(非线程安全)\r\n\r\n![image-20230419144620623](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419144620623.png)\r\n\r\n```java\r\npublic class Singleton3 implements Serializable {\r\n    private Singleton3() {\r\n        System.out.println(\"private Singleton3()\");\r\n    }\r\n\r\n    private static Singleton3 INSTANCE = null;\r\n\r\n    // Singleton3.class  synchronized加在方法上，性能不是特别好，因为单例对象创建好以后，其他线程来访问该同步方法时无需再加锁了，后续的操作不用再进行同步和互斥保护了，不然就影响性能了，只有首次创建单例是才进行线程安全的保护\r\n    public static synchronized Singleton3 getInstance() {\r\n        if (INSTANCE == null) {\r\n            INSTANCE = new Singleton3();\r\n        }\r\n        return INSTANCE;\r\n    }\r\n\r\n    public static void otherMethod() {\r\n        System.out.println(\"otherMethod()\");\r\n    }\r\n\r\n}\r\n```\r\n\r\n- 其实只有首次创建单例对象时才需要同步，但该代码实际上每次调用都会同步\r\n- 因此有了下面的双检锁改进\r\n\r\n### **双检锁懒汉式**\r\n\r\n- 少了内层判断还是会重复创建对象\r\n\r\n![image-20230419145814990](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419145814990.png)\r\n\r\n```java\r\npublic class Singleton4 implements Serializable {\r\n    private Singleton4() {\r\n        System.out.println(\"private Singleton4()\");\r\n    }\r\n\r\n    private static volatile Singleton4 INSTANCE = null; // 可见性，有序性\r\n\r\n    public static Singleton4 getInstance() {\r\n        if (INSTANCE == null) {\r\n            synchronized (Singleton4.class) {\r\n                if (INSTANCE == null) {\r\n                    INSTANCE = new Singleton4();\r\n                }\r\n            }\r\n        }\r\n        return INSTANCE;\r\n    }\r\n\r\n    public static void otherMethod() {\r\n        System.out.println(\"otherMethod()\");\r\n    }\r\n}\r\n```\r\n\r\n![image-20230419145942353](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419145942353.png)\r\n\r\n\r\n\r\n![image-20230419151419398](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419151419398.png)\r\n\r\n为何必须加 volatile：\r\n\r\n- `INSTANCE = new Singleton4()` 不是原子的，分成 3 步：创建对象、调用构造、给静态变量赋值，其中后两步可能被指令重排序优化，变成先赋值、再调用构造\r\n- 如果线程1 先执行了赋值，线程2 执行到第一个 `INSTANCE == null` 时发现 INSTANCE 已经不为 null，此时就会返回一个未完全构造的对象\r\n\r\n![image-20230419153459527](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419153459527.png)\r\n\r\n### **内部类懒汉式**\r\n\r\n```java\r\npublic class Singleton5 implements Serializable {\r\n    private Singleton5() {\r\n        System.out.println(\"private Singleton5()\");\r\n    }\r\n\r\n    private static class Holder {\r\n        static Singleton5 INSTANCE = new Singleton5();\r\n    }\r\n\r\n    public static Singleton5 getInstance() {\r\n        return Holder.INSTANCE;\r\n    }\r\n\r\n    public static void otherMethod() {\r\n        System.out.println(\"otherMethod()\");\r\n    }\r\n}\r\n```\r\n\r\n![image-20230419154215932](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419154215932.png)\r\n\r\n- 避免了双检锁的缺点\r\n\r\n> volatile修饰共享变量可以解决指令重排序(懒汉单例-DCL(双检索))\r\n> 给静态变量赋值肯定会放到静态代码块里执行，静态代码块里的代码由JVM来保证，则饿汉式不用考虑线程安全问题，枚举饿汉式同理\r\n\r\n### **JDK 中单例的体现**\r\n\r\n- Runtime 体现了饿汉式单例\r\n\r\n![image-20230419154748392](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419154748392.png)\r\n\r\n- Console 体现了双检锁懒汉式单例\r\n\r\n![image-20230419154859774](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419154859774.png)\r\n\r\n- Collections 中的 EmptyNavigableSet 内部类懒汉式单例\r\n\r\n![image-20230419155254327](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419155254327.png)\r\n\r\n![image-20230419155346324](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419155346324.png)\r\n\r\n- 其他内部类懒汉式例子\r\n\r\n![image-20230419155525101](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419155525101.png)\r\n\r\n![image-20230419155558145](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419155558145.png)\r\n\r\n- ReverseComparator.REVERSE_ORDER 内部类懒汉式单例\r\n\r\n![image-20230419155823830](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419155823830.png)\r\n\r\n- Comparators.NaturalOrderComparator.INSTANCE 枚举饿汉式单例\r\n\r\n![image-20230419160119770](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419160119770.png)"},{"title":"Java面试专题-并发篇","tags":["线程池","JUC","Lock","Synchronized","volatile","ConcurrentHashMap","ThreadLocal"],"categories":["Java","面试"],"author":"imklaus","excerpt":"\r\n参考视频：[满神Java面试专题](https://www.bilibili.com/video/BV15b4y117RJ)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Java_Interview_Topics-Concurrent","content":"\r\n参考视频：[满神Java面试专题](https://www.bilibili.com/video/BV15b4y117RJ)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n## 1. 线程状态\r\n\r\n**要求**\r\n\r\n* 掌握 Java 线程六种状态\r\n* 掌握 Java 线程状态转换\r\n* 能理解五种状态与六种状态两种说法的区别\r\n\r\n### **六种状态及转换**\r\n\r\n![image-20210831090722658](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831090722658.png)\r\n\r\n分别是\r\n\r\n* 新建\r\n  * 当一个线程对象被创建，但还未调用 start 方法时处于**新建**状态\r\n  * 此时未与操作系统底层线程关联，仅仅是一个Java对象，没有跟真正的线程关联，所以此时这个线程不会被操作系统分配CPU去执行代码\r\n* **可运行**(只有该状态才会被操作系统分配CPU去执行代码，其他状态都不行)\r\n  * 调用了 start 方法，就会由**新建**进入**可运行**\r\n  * 此时与底层线程关联，由操作系统分配CPU调度执行\r\n* 终结\r\n  * 线程内代码已经执行完毕，由**可运行**进入**终结**，线程生命周期走到尽头\r\n  * 此时会取消与底层线程关联，相关资源得到释放\r\n\r\n![image-20230419193409233](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419193409233.png)\r\n\r\n* 阻塞\r\n  * 当获取锁失败后，由**可运行**进入 Monitor 的阻塞队列**阻塞**，此时不占用 cpu 时间\r\n  * 当持锁线程释放锁时，会按照一定规则唤醒阻塞队列中的**阻塞**线程，唤醒后的线程进入**可运行**状态\r\n\r\n![image-20230419200454852](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419200454852.png)\r\n\r\n* 等待\r\n  * 当获取锁成功后，但由于条件不满足，调用了 wait() 方法，此时从**可运行**状态释放锁进入 Monitor 等待集合**等待**，同样不占用 cpu 时间\r\n  * 当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的**等待**线程，恢复为**可运行**状态\r\n\r\n![image-20230419202459021](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419202459021.png)\r\n\r\n* 有时限等待\r\n  * 当获取锁成功后，但由于条件不满足，调用了 wait(long) 方法，此时从**可运行**状态释放锁进入 Monitor 等待集合进行**有时限等待**，同样不占用 cpu 时间\r\n  * 当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的**有时限等待**线程，恢复为**可运行**状态，并重新去竞争锁\r\n  * 如果等待超时，也会从**有时限等待**状态恢复为**可运行**状态，并重新去竞争锁\r\n  * 还有一种情况是调用 sleep(long) 方法也会从**可运行**状态进入**有时限等待**状态，但与 Monitor 无关，不需要主动唤醒，超时时间到自然恢复为**可运行**状态\r\n\r\n> ***其它情况（只需了解）***\r\n>\r\n> * 可以用 interrupt() 方法打断**等待**、**有时限等待**的线程，让它们恢复为**可运行**状态\r\n> * park，unpark 等方法也可以让线程等待和唤醒\r\n\r\n### **五种状态**\r\n\r\n五种状态的说法来自于操作系统层面的划分\r\n\r\n![image-20210831092652602](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831092652602.png)\r\n\r\n* 运行态：分到 cpu 时间，能真正执行线程内代码的\r\n* 就绪态：有资格分到 cpu 时间，但还未轮到它的\r\n* 阻塞态：没资格分到 cpu 时间的\r\n  * 涵盖了 java 状态中提到的**阻塞**、**等待**、**有时限等待**\r\n  * 多出了阻塞 I/O，指线程在调用阻塞 I/O 时，实际活由 I/O 设备完成，此时线程无事可做，只能干等\r\n* 新建与终结态：与 java 中同名状态类似，不再啰嗦\r\n\r\n> 注意：Java中的RUNNABLE涵盖了就绪、运行、阻塞I/O\r\n>\r\n\r\n## 2. 线程池\r\n\r\n**要求**\r\n\r\n* 掌握线程池的 7 大核心参数\r\n\r\n**七大参数**\r\n\r\n1. corePoolSize 核心线程数目 - 池中会保留的最多线程数(核心线程是可以为0的，即所有线程执行完任务后都不保留，都属于救急线程)\r\n2. maximumPoolSize 最大线程数目 - 核心线程+救急线程的最大数目\r\n3. keepAliveTime 生存时间 - 救急线程的生存时间，生存时间内没有新任务，此线程资源会释放\r\n4. unit 时间单位 - 救急线程的生存时间单位，如秒、毫秒等\r\n5. workQueue - 当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建救急线程执行任务\r\n6. threadFactory 线程工厂 - 可以定制线程对象的创建，例如设置线程名字、是否是守护线程等\r\n7. handler 拒绝策略 - 当所有线程都在繁忙，workQueue 也放满时，会触发拒绝策略\r\n   1. 抛异常 java.util.concurrent.ThreadPoolExecutor.AbortPolicy\r\n   \r\n   ![image-20230419211920493](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419211920493.png)\r\n   \r\n   2. 由调用者执行任务 java.util.concurrent.ThreadPoolExecutor.CallerRunsPolicy\r\n   \r\n   ![image-20230419211952479](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419211952479.png)\r\n   \r\n   3. 丢弃任务 java.util.concurrent.ThreadPoolExecutor.DiscardPolicy\r\n   \r\n   ![image-20230419212004898](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419212004898.png)\r\n   \r\n   4. 丢弃最早排队任务 java.util.concurrent.ThreadPoolExecutor.DiscardOldestPolicy\r\n   \r\n   ![image-20230419212017158](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419212017158.png)\r\n\r\n![image-20210831093204388](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831093204388.png)\r\n\r\n> ***代码说明***\r\n>\r\n> day02.TestThreadPoolExecutor 以较为形象的方式演示了线程池的核心组成\r\n\r\n![image-20230419212807609](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419212807609.png)\r\n\r\n## 3. wait vs sleep\r\n\r\n**要求**\r\n\r\n* 能够说出二者区别\r\n\r\n**一个共同点，三个不同点**\r\n\r\n共同点\r\n\r\n* wait() ，wait(long) 和 sleep(long) 的效果都是让当前线程暂时放弃 CPU 的使用权，进入阻塞状态\r\n\r\n不同点\r\n\r\n* 方法归属不同\r\n  * sleep(long) 是 Thread 的静态方法\r\n  * 而 wait()，wait(long) 都是 Object 的成员方法，每个对象都有\r\n\r\n* 醒来时机不同\r\n  * 执行 sleep(long) 和 wait(long) 的线程都会在等待相应毫秒后醒来\r\n  * wait(long) 和 wait() 还可以被 notify 唤醒，wait() 如果不唤醒就一直等下去\r\n  * 它们都可以被打断唤醒（Thread调用interrupt方法进行打断）\r\n\r\n  ![image-20230419215548435](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419215548435.png)\r\n  \r\n* 锁特性不同（重点）\r\n  * wait 方法的调用必须先获取 wait 对象的锁，而 sleep 则无此限制\r\n  \r\n  ![image-20230419214540929](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419214540929.png)\r\n  \r\n  * wait 方法执行后会释放对象锁，允许其它线程获得该对象锁（我放弃 cpu，但你们还可以用）\r\n  \r\n  ![image-20230419214940875](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419214940875.png)\r\n  \r\n  * 而 sleep 如果在 synchronized 代码块中执行，并不会释放对象锁（我放弃 cpu，你们也用不了）\r\n\r\n![image-20230419215217674](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230419215217674.png)\r\n\r\n## 4. lock vs synchronized\r\n\r\n**要求**\r\n\r\n* 掌握 lock 与 synchronized 的区别\r\n* 理解 ReentrantLock 的公平、非公平锁\r\n* 理解 ReentrantLock 中的条件变量\r\n\r\n**三个层面**\r\n\r\n不同点\r\n\r\n* 语法层面\r\n  * synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现\r\n  * Lock 是接口，源码由 jdk 提供，用 java 语言实现\r\n  * 使用 synchronized 时，退出同步代码块锁会自动释放，而使用 Lock 时，需要手动调用 unlock 方法释放锁\r\n* 功能层面\r\n  * 二者均属于悲观锁、都具备基本的互斥、同步、锁重入功能\r\n  * Lock 提供了许多 synchronized 不具备的功能，例如获取等待状态、公平锁(通常情况，吞吐量并不如非公平锁，插队效率更高)、可打断、可超时、多条件变量\r\n  * Lock 有适合不同场景的实现，如 ReentrantLock， ReentrantReadWriteLock（读多写少场景）\r\n* 性能层面\r\n  * 在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖\r\n  * 在竞争激烈时，Lock 的实现通常会提供更好的性能\r\n\r\n**公平锁**\r\n\r\n* 公平锁的公平体现\r\n  * **已经处在阻塞队列**中的线程（不考虑超时）始终都是公平的，先进先出\r\n  * 公平锁是指**未处于阻塞队列**中的线程来争抢锁，如果队列不为空，则老实到队尾等待\r\n  * 非公平锁是指**未处于阻塞队列**中的线程来争抢锁，与队列头唤醒的线程去竞争，谁抢到算谁的\r\n* 公平锁会降低吞吐量，一般不用\r\n\r\n**条件变量**\r\n\r\n* ReentrantLock 中的条件变量功能类似于普通 synchronized 的 wait，notify，用在当线程获得锁后，发现条件不满足时，临时等待的链表结构\r\n* 与 synchronized 的等待集合不同之处在于，ReentrantLock 中的条件变量可以有多个，可以实现更精细的等待、唤醒控制\r\n\r\n> ***代码说明***\r\n>\r\n> * day02.TestReentrantLock 用较为形象的方式演示 ReentrantLock 的内部结构\r\n> * 部分源码\r\n>\r\n> ```java\r\n> // --add-opens java.base/java.util.concurrent=ALL-UNNAMED --add-opens java.base/java.util.concurrent.locks=ALL-UNNAMED\r\n> public class TestReentrantLock {\r\n>     static final MyReentrantLock LOCK = new MyReentrantLock(true);\r\n> \r\n>     static Condition c1 = LOCK.newCondition(\"c1\");\r\n>     static Condition c2 = LOCK.newCondition(\"c2\");\r\n> \r\n>     static volatile boolean stop = false;\r\n> \r\n>     public static void main(String[] args) throws InterruptedException, IOException {\r\n>         learnLock();\r\n>     }\r\n> \r\n>     private static void learnLock() throws InterruptedException {\r\n>         System.out.println(LOCK);\r\n>         new MyThread(() -> {\r\n>             LOCK.lock();\r\n>             get(\"t\").debug(\"acquire lock...\");\r\n>         }, \"t1\").start();\r\n> \r\n>         Thread.sleep(100);\r\n>         new MyThread(() -> {\r\n>             LOCK.lock();\r\n>             get(\"t\").debug(\"acquire lock...\");\r\n>         }, \"t2\").start();\r\n> \r\n>         Thread.sleep(100);\r\n>         new MyThread(() -> {\r\n>             LOCK.lock();\r\n>             get(\"t\").debug(\"acquire lock...\");\r\n>         }, \"t3\").start();\r\n> \r\n>         Thread.sleep(100);\r\n>         new MyThread(() -> {\r\n>             LOCK.lock();\r\n>             get(\"t\").debug(\"acquire lock...\");\r\n>         }, \"t4\").start();\r\n>     }\r\n> \r\n>     private static void fairVsUnfair() throws InterruptedException {\r\n>         new MyThread(() -> {\r\n>             LOCK.lock();\r\n>             get(\"t\").debug(\"acquire lock...\");\r\n>             sleep1s();\r\n>             LOCK.unlock();\r\n>         }, \"t1\").start();\r\n> \r\n>         Thread.sleep(100);\r\n>         new MyThread(() -> {\r\n>             LOCK.lock();\r\n>             get(\"t\").debug(\"acquire lock...\");\r\n>             sleep1s();\r\n>             LOCK.unlock();\r\n>         }, \"t2\").start();\r\n> \r\n>         Thread.sleep(100);\r\n>         new MyThread(() -> {\r\n>             LOCK.lock();\r\n>             get(\"t\").debug(\"acquire lock...\");\r\n>             sleep1s();\r\n>             LOCK.unlock();\r\n>         }, \"t3\").start();\r\n> \r\n>         Thread.sleep(100);\r\n>         new MyThread(() -> {\r\n>             LOCK.lock();\r\n>             get(\"t\").debug(\"acquire lock...\");\r\n>             sleep1s();\r\n>             LOCK.unlock();\r\n>         }, \"t4\").start();\r\n> \r\n>         get(\"t\").debug(\"{}\", LOCK);\r\n> \r\n>         while (!stop) {\r\n>             new Thread(() -> {\r\n>                 try {\r\n>                     //\t\t\t\ttryLock底层总是非公平锁\r\n>                     boolean b = LOCK.tryLock(10, TimeUnit.MILLISECONDS);\r\n>                     if (b) {\r\n>                         System.out.println(Thread.currentThread().getName() + \" acquire lock...\");\r\n>                         stop = true;\r\n>                         sleep1s();\r\n>                         LOCK.unlock();\r\n>                     }\r\n>                 } catch (InterruptedException e) {\r\n>                     e.printStackTrace();\r\n>                 }\r\n>             }).start();\r\n>         }\r\n>     }\r\n> \r\n>     private static void sleep1s() {\r\n>         try {\r\n>             Thread.sleep(1000);\r\n>         } catch (InterruptedException e) {\r\n>             e.printStackTrace();\r\n>         }\r\n>     }\r\n> \t\r\n>     \r\n>     private static class MyReentrantLock extends ReentrantLock {\r\n>         private final Map<String, Condition> conditions = new HashMap<>();\r\n> \r\n>         public MyReentrantLock(boolean fair) {\r\n>             super(fair);\r\n>         }\r\n>         \r\n> \t\t//条件变量方法\r\n>         public Condition newCondition(String name) {\r\n>             Condition condition = super.newCondition();\r\n>             conditions.put(name, condition);\r\n>             return condition;\r\n>         }\r\n>         ...\r\n>     }\r\n>     ...\r\n> }\r\n> ```\r\n\r\n### lock阻塞\r\n\r\n![image-20230420144129519](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420144129519.png)\r\n\r\n### lock可重入锁\r\n\r\n![image-20230420150140265](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420150140265.png)\r\n\r\n### lock非公平锁（其他线程插队等待队列里的线程）\r\n\r\n![image-20230420151242795](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420151242795.png)\r\n\r\n### lock公平锁（线程正常排队等待）\r\n\r\n![image-20230420151341412](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420151341412.png)\r\n\r\n### lock条件变量\r\n\r\n![image-20230420153536495](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420153536495.png)\r\n\r\n## 5. volatile\r\n\r\n**要求**\r\n\r\n* 掌握线程安全要考虑的三个问题\r\n  * 线程安全要考虑三个方面:可见性、有序性、原子性\r\n    * 可见性指，一个线程对共享变量修改，另一个线程能看到最新的结果\r\n    * 有序性指，一个线程内代码按编写顺序执行\r\n    * 原子性指，一个线程内多行代码以一个整体运行，期间不能有其它线程的代码插队\r\n\r\n* 掌握 volatile 能解决哪些问题\r\n\r\n### **原子性**\r\n\r\n* 起因：多线程下，不同线程的**指令发生了交错**导致的共享变量的读写混乱\r\n* 解决：用悲观锁或乐观锁解决\r\n* volatile 并不能解决原子性\r\n\r\n![image-20230420155844698](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420155844698.png)\r\n\r\n### **可见性**\r\n\r\n- 网上对可见性的说法\r\n\r\n![image-20230420160254650](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420160254650.png)\r\n\r\n- 上图说法显然是错误的，因为线程1、2都能读取到线程0的修改stop的最新值\r\n\r\n![image-20230420163639173](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420163639173.png)\r\n\r\n* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致的对共享变量所做的修改另外的线程看不到\r\n* 解决：用 volatile 修饰共享变量，能够防止编译器等优化发生，让一个线程对共享变量的修改对另一个线程可见\r\n* JIT：Java的即时编译器，是JVM的重要组成部分，主要责任是负责代码优化，任何一条JAVA代码最终会翻译成JAVA的字节码指令，但这个JAVA的字节码指令还不能够交给CPU来执行，它还有一个叫做解释器的组件，这个解释器的组件会把JAVA的字节码指令逐行翻译成机器码，这个机器码才交给CPU，CPU才能认识，这样效率较低，因此JIT的组件对一些**热点**的字节码进行优化，例如**频繁调用的代码**，**反复执行的循环**等。使用volatile修饰变量，就是超过循环阈值或方法调用次数也不进行优化，直接放行\r\n\r\n![image-20230420163540235](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420163540235.png)\r\n\r\n### **有序性**\r\n\r\n![image-20230420165059904](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420165059904.png)\r\n\r\n* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致指令的实际执行顺序与编写顺序不一致\r\n* 解决：用 volatile 修饰共享变量会在读、写共享变量时加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止重排序的效果\r\n* 注意：\r\n  * **volatile 变量写**加的屏障是阻止上方其它写操作越过屏障排到 **volatile 变量写**之下\r\n  * **volatile 变量读**加的屏障是阻止下方其它读操作越过屏障排到 **volatile 变量读**之上\r\n  * volatile 读写加入的屏障只能防止同一线程内的指令重排\r\n\r\n![image-20230420170038976](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420170038976.png)\r\n\r\n![image-20230420165605009](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420165605009.png)\r\n\r\n> ***代码说明***\r\n>\r\n> * day02.threadsafe.AddAndSubtract 演示原子性\r\n> * day02.threadsafe.ForeverLoop 演示可见性\r\n>   * 注意：本例经实践检验是编译器优化导致的可见性问题\r\n> * day02.threadsafe.Reordering 演示有序性\r\n>   * 需要打成 jar 包后测试\r\n>\r\n> ![image-20230420165537915](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230420165537915.png)\r\n>\r\n> * 请同时参考视频讲解\r\n\r\n### 补充\r\n\r\n> - 可见性问题补充\r\n>\r\n>   - 相比synchronized的加锁方式来解决共享变量的内存可见性问题，volatile就是更轻量的选择，它没有上下文切换的额外开销成本。\r\n>\r\n>   - volatile可以确保对某个变量的更新对其他线程马上可见，一个变量被声明为volatile 时，线程在写入变量时不会把值缓存在寄存器或者其他地方，而是会把值刷新回主内存 当其它线程读取该共享变量，会从主内存重新获取最新值，而不是使用当前线程的本地内存中的值。\r\n>\r\n>   - 例如，我们声明一个 volatile 变量 volatile int x = 0，线A修改x=1，修改完之后就会把新的值刷新回主内存，线程B读取x的时候，就会清空本地内存变量，然后再从主内存获取最新值。\r\n>\r\n>   ![image-20230421001513641](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421001513641.png)\r\n>\r\n> - 有序性问题补充\r\n>\r\n>   - 重排序可以分为编译器重排序和处理器重排序，valatile保证有序性，就是通过分别限制这两种类型的重排序。\r\n>\r\n>   ![image-20230421001703874](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421001703874.png)\r\n>\r\n>   - 为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。\r\n>\r\n>     - 1.在每个volatile写操作的前面插入一个 StoreStore 屏障\r\n>     - 2.在每个volatile写操作的后面插入一个 StoreLoad 屏障\r\n>     - 3.在每个volatile读操作的后面插入一个 LoadLoad 屏障\r\n>     - 4.在每个volatile读操作的后面插入一个 LoadStore 屏障\r\n>\r\n>     ![image-20230421001911421](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421001911421.png)\r\n>\r\n>     ![image-20230421001923758](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421001923758.png)\r\n\r\n\r\n\r\n## 6. 悲观锁 vs 乐观锁\r\n\r\n**要求**\r\n\r\n* 掌握悲观锁和乐观锁的区别\r\n\r\n**对比悲观锁与乐观锁**\r\n\r\n* 悲观锁的代表是 synchronized 和 Lock 锁\r\n  * 其核心思想是【线程只有占有了锁，才能去操作共享变量，每次只有一个线程占锁成功，**获取锁失败的线程，都得停下来等待**】\r\n  * 线程从运行到阻塞、再从阻塞到唤醒，涉及线程上下文切换，如果频繁发生，影响性能\r\n    * 线程上下文切换：线程从运行都阻塞，把线程当前运行的状态记录下来，线程执行到第几行代码了，当前有哪些局部变量等都得记录，下次再把你从阻塞状态唤醒时，会把这些信息进行恢复，接着上次中断的地方继续向下运行，整个过程称为线程上下文切换\r\n  * 实际上，线程在获取 synchronized 和 Lock 锁时，如果锁已被占用，都会做几次重试操作，减少阻塞的机会\r\n    *  线程在获取synchronized和Lock锁时，若锁已被占用，都会做几次重试操作，重试期间，锁未被释放，就不用进入阻塞状态，减少一次上下文切换，即减少阻塞的机会  \r\n* 乐观锁的代表是 AtomicInteger，使用 cas 来保证原子性\r\n  * 其核心思想是【无需加锁，每次只有一个线程能成功修改共享变量，**其它失败的线程不需要停止，不断重试直至成功**】\r\n  * 由于线程一直运行，不需要阻塞，因此不涉及线程上下文切换\r\n  * 它需要多核 cpu 支持，且线程数不应超过 cpu 核数（必须有独立CPU来执行你的循环或不断重试的代码）\r\n    * 若没有多核CPU执行，即使抢占锁失败的线程不想停下来也得停下来，因为没有多余CPU执行，虽然不会进入阻塞状态，但会进行上下文切换，到一边歇着去\r\n\r\n> ***代码说明***\r\n>\r\n> * day02.SyncVsCas 演示了分别使用乐观锁和悲观锁解决原子赋值\r\n>\r\n> * 请同时参考视频讲解（使用AtomicInteger更底层的Unsafe来讲解乐观锁，对于乐观锁来讲，能够保证在修改的共享变量时的修改操作是原子操作）\r\n>\r\n> * CAS乐观锁需要和volatile配合使用，通过可见性来判断变量是否发生改变，虽然cas可以保证原子性，但还要通过volatile来保证你能看到共享变量的最新值\r\n>\r\n>  ```java\r\n>   \t...\r\n>       //AtomicInteger的底层\r\n>   \tstatic final Unsafe U = Unsafe.getUnsafe();\r\n>   \t//计算偏移量\r\n>       static final long BALANCE = U.objectFieldOffset(Account.class, \"balance\");\r\n> \r\n>       static class Account {\r\n>           volatile int balance = 10;\r\n>       }\r\n>   ...\r\n>   Account account = new Account();\r\n>   int o = account.balance;\r\n>   int n = o + 5;\r\n>   //选择整型类型，若没有其他线程干扰，只要在10的基础上加5就成功了；若在修改的过程中有其他线程干扰(把共享变量balance的最新值修改成了100)，那如果在10的基础上加5了就会把共享变量的最新值(100)给覆盖了，所以此方法会在修改共享变量之前将旧值与共享变量的最新值进行比较，若相等则没有别的线程干扰就修改成功，反之则修改失败\r\n>   U.compareAndSetInt(account，BALANCE，o，n));\r\n>   =>compareAndSetInt(Object o,//要修改的对象 \r\n>                     long offset,//偏移量\r\n>                     int expected,//旧值\r\n>                     //新值\r\n>                     int x);\r\n> \r\n>  ```\r\n>\r\n> ![image-20230421135939880](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421135939880.png)\r\n>\r\n> - 悲观锁synchronized解决指令的交错问题（指令重排序），用阻止指令交错的方式来保证我们对共享变量的安全访问；synchronized用互斥的方式让整个同步代码块以整体的形式执行，执行期间其他线程不能执行，都被阻塞住\r\n>\r\n> ![image-20230421140903810](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421140903810.png)\r\n>\r\n> - 乐观锁cas会产生指令交错现象，多线程下，有一个线程修改了共享变量10为15，这时线程切换到另一个，循环第一次判断出来共享变量与初始值10不一样，退出当前循环再进行循环，此时可以获取到共享变量的最新值15，值修改可以成功为10结束循环；\r\n> - 乐观锁(cas)没有互斥，可以并行执行，谁先执行谁后执行都无所谓，指令交错也无所所谓，但它可以通过比较并交换的原则，看看你更新时，判断这个值有没有被别人修改过，未修改才修改成功，反之这次更新失败，失败后重试(再次循环)，再获取最新值，在最新值的基础上进行操作，这样就能保证共享变量的正确性\r\n>\r\n> ![image-20230421142308669](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421142308669.png)\r\n\r\n\r\n\r\n## 7. Hashtable vs ConcurrentHashMap\r\n\r\n**要求**\r\n\r\n* 掌握 Hashtable 与 ConcurrentHashMap 的区别\r\n* 掌握 ConcurrentHashMap 在不同版本的实现区别\r\n\r\n> 更形象的演示，见资料中的 hash-demo.jar，运行需要 jdk14 以上环境，进入 jar 包目录，执行下面命令\r\n>\r\n> ```\r\n> java -jar --add-exports java.base/jdk.internal.misc=ALL-UNNAMED hash-demo.jar\r\n> ```\r\n\r\n**Hashtable 对比 ConcurrentHashMap**\r\n\r\n* Hashtable 与 ConcurrentHashMap 都是线程安全的 Map 集合\r\n* Hashtable 并发度低，整个 Hashtable 对应一把锁，同一时刻，只能有一个线程操作它\r\n\r\n  - hashtable扩容因子为0.75，扩容后为原容量*2+1，而且容量一般为质数，有很好的hash分布性，即不会进行二次hash（hash取正再求模）\r\n\r\n  ![image-20230421144116018](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421144116018.png)\r\n\r\n* ConcurrentHashMap 并发度高，整个 ConcurrentHashMap 对应多把锁，只要线程访问的是不同锁，那么不会冲突\r\n\r\n### **ConcurrentHashMap 1.7**\r\n\r\n* 数据结构：`Segment(大数组) + HashEntry(小数组) + 链表`，每个 Segment 对应一把锁，如果多个线程访问不同的 Segment，则不会冲突\r\n* 并发度：Segment 数组大小即并发度，决定了同一时刻最多能有多少个线程并发访问。Segment 数组不能扩容，意味着并发度在 ConcurrentHashMap 创建时就固定了\r\n* 索引计算\r\n  * 假设大数组长度是 $2^m$，key 在大数组内的索引是 key 的二次 hash 值的高 m 位\r\n  * 假设小数组长度是 $2^n$，key 在小数组内的索引是 key 的二次 hash 值的低 n 位\r\n* 扩容：每个小数组的扩容相对独立，**小数组在超过扩容因子时会触发扩容，每次扩容翻倍**\r\n* Segment[0] 原型：首次创建其它小数组时，会以此原型为依据，数组长度，扩容因子都会以原型为准\r\n\r\n> - concurrenthashmap1.7：外面整个数组为一个segment数组，里面每个元素套一个小数组hashentry，等价于普通hashmap的数据结构，将来如果索引冲突了就构成一个链表\r\n>\r\n> ![image-20230421145625451](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421145625451.png)\r\n>\r\n> - 并发度clevel值的多少决定currentHashMap的并发性，容量capacity的大小决定小数组HashEntry的初始大小（capacity/clevel,最小值为2），扩容因子factor决定的是小数组HashEntry的扩容（超过0.75触发扩容）；\r\n>\r\n> ![image-20230421145926326](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421145926326.png)\r\n>\r\n> ![image-20230421145801226](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421145801226.png)\r\n>\r\n> - key的索引根据二次hash的高四位作为（1100->12）索引值，索引是指segment的索引；clevel为32就高五位取值；以二次hash的最低位作为entry数组中的索引\r\n>\r\n> ![image-20230421153206829](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421153206829.png)\r\n>\r\n> ![image-20230421152252653](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421152252653.png)\r\n>\r\n> ![image-20230421152804268](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421152804268.png)\r\n>\r\n> - segment数组的并发度clevel一旦确定，就不会扩容，不管元素个数是多少，小数组会根据扩容因子来扩容，扩容容量翻倍，链表插入方式为头插法，这里的头插法并不会造成死链，因为每个线程操作Segment数组都会加上锁，别的线程不能访问，每个小数组会根据各自的元素个数来各自扩容，互不干扰\r\n>\r\n> ![image-20230421153848810](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421153848810.png)\r\n>\r\n> - segment[0]原型是创建segment数组的初始entry，大小根据capacity和clevel决定（capacity/clevel，最小值为2），只要是创建出来的HashEntry小数组都会根据Segment[0]中的小数组作为原型，把它的大小、扩容因子等拿来借用，这也体现了设计模式中的原型模式\r\n>\r\n> ![image-20230421154813557](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421154813557.png)\r\n>\r\n> - 饿汉式初始化：底层已经调用了构造方法，构造方法一调用，Segment数组包括里面的Segment[0]HashEntry小数组就已经被创建来了，是一个饿汉式的初始化（并没有put元素）\r\n\r\n### **ConcurrentHashMap 1.8**\r\n\r\n* 数据结构：`Node 数组 + 链表或红黑树`，数组的每个头节点作为锁，如果多个线程访问的头节点不同，则不会冲突。首次生成头节点时如果发生竞争，利用 cas 而非 syncronized，进一步提升性能\r\n* 并发度：Node 数组有多大，并发度就有多大，与 1.7 不同，Node 数组可以扩容\r\n* 扩容条件：Node 数组满 3/4 时就会扩容\r\n* 调用无参构造创建数组，默认容量为16；插入方式为尾插法\r\n\r\n![image-20230421160157919](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421160157919.png)\r\n\r\n* 扩容单位：以链表为单位从后向前迁移链表，迁移完成的将旧数组头节点替换为 ForwardingNode\r\n* 扩容时并发 get\r\n  * 根据是否为 ForwardingNode 来决定是在新数组查找还是在旧数组查找，不会阻塞\r\n  * 如果链表长度超过 1，则需要对节点进行复制（创建新节点），怕的是节点迁移后 next 指针改变\r\n  * 如果链表最后几个元素扩容后索引不变，则节点无需复制\r\n* 扩容时并发 put\r\n  * 如果 put 的线程与扩容线程操作的链表是同一个，put 线程会阻塞\r\n  * 如果 put 的线程操作的链表还未迁移完成，即头节点不是 ForwardingNode，则可以并发执行\r\n  * 如果 put 的线程操作的链表已经迁移完成，即头结点是 ForwardingNode，则可以协助扩容\r\n* 与 1.7 相比是懒汉式初始化（第一次put元素时才会创建底层的数据结构）\r\n* capacity 代表预估的元素个数，capacity / factory 来计算出初始数组大小，需要贴近 $2^n$ \r\n* loadFactor 只在计算初始数组大小时被使用，之后扩容固定为 3/4\r\n* 超过树化阈值时的扩容问题，如果容量已经是 64，直接树化，否则在原来容量基础上做 3 轮扩容\r\n\r\n> - 一开始调用构造方法时，数组还没创建出来，当插入元素时数组才会创建，即是一种懒汉式初始化，只要>=扩容因子0.75才会扩容，\r\n> - 有参构造设定capacity初始值为16，它假定你初始时放入16个元素，数组多大你看着办，数组长度满足$2^n$，此时插入元素时，它会你插入16/16>0.75，超过扩容阈值，这时触发扩容，数组长度为32（*¾=24），这样就满足条件16/32<0.75，即只要capacity初始值为12（12/16=0.75）<=capacity<=16插入元素就会触发扩容为32，0<=capacity<12就是初始容量16，capacity的大小决定初始数组的大小\r\n> - 初始数组扩容因子factor只是用来初始化的，调用currentHashMap的构造方法时才会用来配合计算我们的数组长度该有多大，即在创建数组时，扩容因子factor为0.5（capacity=8 / 初始数组长度固定=16），数组创建出来后将来插入元素还是按照0.75来扩容（factor只是第一次构造时用来计算一下，以后就不用它了，还是按照满0.75来扩容）\r\n>\r\n> ![image-20230421170444242](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421170444242.png)\r\n>\r\n> - 多线程下put元素（同一个index），在b线程put后抢占锁后sleep10s，c线程要想put并抢占锁需要等待b休眠结束（阻塞），是一种互斥锁；\r\n>\r\n> ![image-20230421174746167](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421174746167.png)\r\n>\r\n> - put不同的index可以并行执行，互不干扰\r\n>\r\n> ![image-20230421174944947](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421174944947.png)\r\n>\r\n> - 扩容时，是从后往前处理元素的迁移，迁移完标记forwardingNode（没元素也标记），全部迁移完，旧数组索引就全是标记表示迁移结束\r\n>\r\n> ![image-20230421175854195](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421175854195.png)\r\n>\r\n> - 迁移过程中，get元素（非链表），只要标记了forwardingNode的索引且迁移过元素，就去新数组去获取，即不会被阻塞，可以并发运行；当在迁移链表过程中去get元素，此时迁移前后的元素是不一样的，元素的前后指针和索引发生改变，因此在迁移时大多数情况都会把链表元素重新创建，不能用同一个对象（链表指向发生变化），但是currentHashMap对链表迁移工作做了优化，对于链表最后几个元素位置相同（hash相同/index相同），就不用重新创建节点的工作，扩容后的位置就不用动直接用就行，链表前面的元素都必须创建新的节点对象来解决扩容并同时查询的问题（尾插法，后面元素插入头部，前面元素插入尾部）\r\n> - 迁移过程中put元素，非链表可以并发put，链表在迁移过程中会加锁，put操作只能阻塞住了；\r\n> - 当put的是forwardingNode这些已标记为迁移完成的索引，put不可能会到新数组去操作，只能等迁移完整个数组才能到新数组去操作，但是currentHashMap也做了一些优化，链表迁移工作也不是由一个线程一下子迁移完所有的链表，是划分了多个区间，每个线程可以一次迁移16个链表，如当前扩容线程可以迁移0-15的链表，这个时候来个一个put线程，没事干就进入空闲状态，但如果旧的数组容量为32时，扩容线程是处理16-31的链表，此时新加入的put线程发现16-31的数据已经处理完了，这种情况下就会帮忙扩容，处理0-15未标记的元素链表的迁移（并发分组迁移未迁移的元素），减少阻塞机会，让它也别闲着，让它也有活可干\r\n>\r\n> ![image-20230421183310345](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421183310345.png)\r\n\r\n\r\n\r\n## 8. ThreadLocal\r\n\r\n**要求**\r\n\r\n* 掌握 ThreadLocal 的作用与原理\r\n* 掌握 ThreadLocal 的内存释放时机\r\n\r\n### **作用**\r\n\r\n* ThreadLocal 可以实现【资源对象】的线程隔离，让每个线程各用各的【资源对象】，避免争用引发的线程安全问题；方法内的局部变量也是线程私有的，不牵扯到资源共享，虽然也不会引发线程安全问题，但有一个缺点就是不能跨越方法，如同一线程内要调用方法1、2、3、4，那局部变量的生命周期就局限在一个方法内，方法2就不能使用到方法1的局部变量\r\n* ThreadLocal 同时实现了【**线程内**】的资源共享\r\n\r\n![image-20230421192339867](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421192339867.png)\r\n\r\n### **原理**\r\n\r\n每个线程内有一个 ThreadLocalMap 类型的成员变量，用来存储资源对象\r\n\r\n* 调用 set 方法，就是以 ThreadLocal 自己作为 key，资源对象作为 value，放入当前线程的 ThreadLocalMap 集合中；解决索引冲突用的是开放寻值法方式\r\n\r\n* 调用 get 方法，就是以 ThreadLocal 自己作为 key，到当前线程中查找关联的资源值\r\n\r\n![image-20230421193232792](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421193232792.png)\r\n\r\n* 调用 remove 方法，就是以 ThreadLocal 自己作为 key，移除当前线程关联的资源值\r\n\r\nThreadLocalMap 的一些特点\r\n\r\n* key 的 hash 值统一分配\r\n* 初始容量 16，**扩容因子 2/3，扩容容量翻倍**\r\n* key 索引冲突后用开放寻址法解决冲突\r\n\r\n### **弱引用 key**\r\n\r\nThreadLocalMap 中的 key 被设计为弱引用，原因如下\r\n\r\n* Thread 可能需要长时间运行（如线程池中的线程），如果 key 不再使用，需要在内存不足（GC）时释放其占用的内存\r\n\r\n![image-20230421194454713](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421194454713.png)\r\n\r\n### **内存释放时机**\r\n\r\n* 被动 GC 释放 key\r\n  * 仅是让 key 的内存释放，关联 value 的内存并不会释放\r\n* 懒惰被动释放 value\r\n  * get key 时，发现是 null key，则释放其 value 内存\r\n  * set key 时，会使用启发式扫描，清除临近的 null key 的 value 内存，启发次数与元素个数，是否发现 null key 有关\r\n* 主动 remove 释放 key，value\r\n  * 会同时释放 key，value 的内存，也会清除临近的 null key 的 value 内存\r\n  * 推荐使用它，因为一般使用 ThreadLocal 时都把它作为静态变量（即强引用），因此无法被动依靠 GC 回收\r\n\r\n> - threadLocal是弱引用作为key来存储的，当下面线程1一直处于运行状态，不断的插入元素，这样键值就会越来越多，这时只能等GC垃圾回收了，如果threadLocal设计成强引用就不能被垃圾回收了（即使别的地方都没有引用threadLocal，只要threadLocalMap使用强引用引用资源，那被引用的资源就得不到释放），所以弱引用引用资源将来没人引用了就会被回收，但值是强引用的，GC仅是让key的内存释放，后续还要根据 key 是否为 null来进一步释放值的内存，\r\n> - GC垃圾回收时，把未被引用的threadLocal（a）清理掉，变为null，值还在；当新的threadLocal（c）去get这个key为Null的位置时，此时值就会被垃圾回收掉，变为Null；当get一个空闲位置时，map就会把当前新的threadLocal（d）作为key，但值为Null\r\n>\r\n> ![image-20230421195247137](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421195247137.png)\r\n>\r\n> - 当在被垃圾回收掉key的位置set（8）时，不光清理掉当前位置的值（清理并存储），还会把相邻位置也一起清理掉（9,10 的 k v），但离得比较远的位置就不会去清理（14）\r\n>\r\n> ![image-20230421195536553](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421195536553.png)\r\n>\r\n> - 一般情况是没有其他地方引用threadLocal就会被垃圾回收，key=Null，get，set发现Nullkey才会进一步清理value\r\n> - 实际情况是用静态变量来引用threadLocal对象，即静态变量跟这个对象为强引用，所以静态变量一直强引用使用对象，垃圾回收不了，即使threadLocal是弱引用，但是静态变量对threadLocal一直保持强引用状态，所以懒惰被动释放 value的两种方式是行不通的\r\n> - 使用remove主动清理直接将map的键值清理掉，前两种方式清理（get set）会产生内存泄露，需要用remove来及时清理；假设长时间运行的线程池资源（含threadLocal关联静态资源）没有即使清理的话，就会积累越来越多的键值资源，还有其他的静态变量强引用key，GC也没办法把它们回收，久而久之就会造成内存泄漏\r\n>\r\n> ![image-20230421200401064](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421200401064.png)\r\n"},{"title":"Java面试专题-框架篇","tags":["Spring Refresh","Spring Bean","Spring MVC","Spring Boot"],"categories":["Java","面试"],"author":"imklaus","excerpt":"\r\n参考视频：[满神Java面试专题](https://www.bilibili.com/video/BV15b4y117RJ)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Java_Interview_Topics-Framework","content":"\r\n参考视频：[满神Java面试专题](https://www.bilibili.com/video/BV15b4y117RJ)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n## 1. Spring refresh 流程\r\n\r\n### **Spring refresh 概述**\r\n\r\nrefresh 是 AbstractApplicationContext 中的一个方法，负责初始化 ApplicationContext 容器，容器必须调用 refresh 才能正常工作。它的内部主要会调用 12 个方法，我们把它们称为 refresh 的 12 个步骤：\r\n\r\n1. prepareRefresh\r\n\r\n2. obtainFreshBeanFactory\r\n\r\n3. prepareBeanFactory\r\n\r\n4. postProcessBeanFactory\r\n\r\n5. invokeBeanFactoryPostProcessors\r\n\r\n6. registerBeanPostProcessors\r\n\r\n7. initMessageSource\r\n\r\n8. initApplicationEventMulticaster\r\n\r\n9. onRefresh\r\n\r\n10. registerListeners\r\n\r\n11. finishBeanFactoryInitialization\r\n\r\n12. finishRefresh\r\n\r\n`org.springframework.context.support.AbstractApplicationContext#refresh`\r\n\r\n```java\r\n    @Override\r\n    public void refresh() throws BeansException, IllegalStateException {\r\n    \tsynchronized (this.startupShutdownMonitor) {\r\n\t\t\t// Prepare this context for refreshing.\r\n\t\t\tprepareRefresh();\r\n\r\n\t\t\t// Tell the subclass to refresh the internal bean factory.\r\n\t\t\tConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();\r\n\r\n\t\t\t// Prepare the bean factory for use in this context.\r\n\t\t\tprepareBeanFactory(beanFactory);\r\n\r\n\t\t\ttry {\r\n\t\t\t\t// Allows post-processing of the bean factory in context subclasses.\r\n\t\t\t\tpostProcessBeanFactory(beanFactory);\r\n\r\n\t\t\t\t// Invoke factory processors registered as beans in the context.\r\n\t\t\t\tinvokeBeanFactoryPostProcessors(beanFactory);\r\n\r\n\t\t\t\t// Register bean processors that intercept bean creation.\r\n\t\t\t\tregisterBeanPostProcessors(beanFactory);\r\n\r\n\t\t\t\t// Initialize message source for this context.\r\n\t\t\t\tinitMessageSource();\r\n\r\n\t\t\t\t// Initialize event multicaster for this context.\r\n\t\t\t\tinitApplicationEventMulticaster();\r\n\r\n\t\t\t\t// Initialize other special beans in specific context subclasses.\r\n\t\t\t\tonRefresh();\r\n\r\n\t\t\t\t// Check for listener beans and register them.\r\n\t\t\t\tregisterListeners();\r\n\r\n\t\t\t\t// Instantiate all remaining (non-lazy-init) singletons.\r\n\t\t\t\tfinishBeanFactoryInitialization(beanFactory);\r\n\r\n\t\t\t\t// Last step: publish corresponding event.\r\n\t\t\t\tfinishRefresh();\r\n\t\t\t}\r\n\r\n\t\t\tcatch (BeansException ex) {\r\n\t\t\t\tif (logger.isWarnEnabled()) {\r\n\t\t\t\t\tlogger.warn(\"Exception encountered during context initialization - \" +\r\n\t\t\t\t\t\t\t\"cancelling refresh attempt: \" + ex);\r\n\t\t\t\t}\r\n\r\n\t\t\t\t// Destroy already created singletons to avoid dangling resources.\r\n\t\t\t\tdestroyBeans();\r\n\r\n\t\t\t\t// Reset 'active' flag.\r\n\t\t\t\tcancelRefresh(ex);\r\n\r\n\t\t\t\t// Propagate exception to caller.\r\n\t\t\t\tthrow ex;\r\n\t\t\t}\r\n\r\n\t\t\tfinally {\r\n\t\t\t\t// Reset common introspection caches in Spring's core, since we\r\n\t\t\t\t// might not ever need metadata for singleton beans anymore...\r\n\t\t\t\tresetCommonCaches();\r\n\t\t\t}\r\n\t\t}\r\n    }\r\n```\r\n\r\n\r\n\r\n> ***功能分类***\r\n>\r\n> * 1 为准备环境\r\n>\r\n> * 2 3 4 5 6 为准备 BeanFactory\r\n>   * ApplicationContext只是一个外部的容器，它的一些核心功能还得另外交给这个叫BeanFactory容器来完成，即Bean的创建，Bean的依赖注入，Bean的初始化，ApplicationContext会借助其成员变量BeanFactory来完成Bean的创建，Bean的依赖注入，Bean的初始化等功能\r\n>\r\n> * 7 8 9 10 12 为准备 ApplicationContext\r\n>\r\n> * 11 为初始化 BeanFactory 中非延迟单例 bean\r\n\r\n\r\n\r\n### **1. prepareRefresh**\r\n\r\n* 这一步创建和准备了 Environment 对象，它作为 ApplicationContext 的一个成员变量\r\n\r\n* Environment 对象的作用之一是为后续 @Value，值注入时提供键值\r\n* Environment 分成三个主要部分\r\n  * systemProperties - 保存 java 环境键值\r\n  * systemEnvironment - 保存系统环境键值（操作系统的键值，如JAVA_HOME、PATH、CLASS_PATH等）\r\n  * 自定义 PropertySource - 保存自定义键值，例如来自于 *.properties 文件的键值\r\n\r\n![image-20210902181639048](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210902181639048.png)\r\n\r\n- 解析@Value、${}、#{}\r\n\r\n![image-20230421212541621](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421212541621.png)\r\n\r\n\r\n\r\n```java\r\n    /**\r\n     * Prepare this context for refreshing, setting its startup date and\r\n     * active flag as well as performing any initialization of property sources.\r\n     * 准备此上下文以进行刷新、设置其启动日期和活动标志以及执行属性源的任何初始化。\r\n     */\r\n    protected void prepareRefresh() {\r\n       ...\r\n\r\n       // Initialize any placeholder property sources in the context environment.\r\n       initPropertySources();\r\n\r\n       // Validate that all properties marked as required are resolvable:\r\n       // see ConfigurablePropertyResolver#setRequiredProperties\r\n       getEnvironment().validateRequiredProperties();\r\n\r\n       ...\r\n    }\r\n```\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n### **2. obtainFreshBeanFactory**\r\n\r\n* 这一步获取（或创建） BeanFactory，它也是作为 ApplicationContext 的一个成员变量\r\n* ApplicationContext+BeanFactory：ApplicationContext在Bean的管理上借助BeanFactory的功能\r\n* BeanFactory 的作用是负责 bean 的创建、依赖注入和初始化，bean 的各项特征由 BeanDefinition 定义\r\n  * BeanDefinition 作为 bean 的设计蓝图，规定了 bean 的特征，如单例多例、依赖关系、初始销毁方法等\r\n  * BeanDefinition 的来源有多种多样，可以是通过 xml 获得、配置类获得、组件扫描获得，也可以是编程添加\r\n* 所有的 BeanDefinition 会存入 BeanFactory 中的 beanDefinitionMap 集合；\r\n\r\n![image-20210902182004819](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210902182004819.png)\r\n\r\n![image-20230421223009256](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421223009256.png)\r\n\r\n> - BeanFactory中也有很多成员变量要初始化，其中有一个非常重要的beanDefinitionMap，BeanFactory并不是一上来就创建这些Bean，它必须先有些Bean的定义，它得知道这个Bean长什么样子，Bean是单例还是多例，它的初始化方法是什么，它有哪些属性需要依赖注入，这些信息在Spring中都是用beanDefinitionMap这个类来描述的，而这个beanDefinitionMap是用来存储所有的BeanDefinition\r\n> - BeanFactory不是一下子就把Bean创建出来，得借助BeanDefinition（Bean的设计蓝图），刚开始都是收集BeanDefinition的各种信息\r\n\r\n- 此方法仅在AbstractApplicationContext类内被调用且未被重写\r\n\r\n```java\r\n    protected ConfigurableListableBeanFactory obtainFreshBeanFactory() {\r\n       refreshBeanFactory();\r\n       return getBeanFactory();\r\n    }\r\n```\r\n\r\n- 以下两个方法由AbstractRefreshableApplicationContext和GenericApplicationContext两个类重写，且创建或获取的BeanFactory类型都为DefaultListableBeanFactory\r\n\r\n```java\r\n\r\n    protected abstract void refreshBeanFactory() throws BeansException, IllegalStateException;\r\n\r\n\r\n\r\n\t@Override\r\n\tpublic abstract ConfigurableListableBeanFactory getBeanFactory() throws IllegalStateException;\r\n```\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n### **3. prepareBeanFactory**\r\n\r\n```java\r\n/**\r\n * Configure the factory's standard context characteristics,\r\n * such as the context's ClassLoader and post-processors.\r\n * @param beanFactory the BeanFactory to configure\r\n */\r\nprotected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) {\r\n   ......\r\n}\r\n```\r\n\r\n* 这一步会进一步完善 BeanFactory，为它的各项成员变量赋值\r\n* beanExpressionResolver 用来解析 SpEL，常见实现为 StandardBeanExpressionResolver\r\n\r\n```java\r\nbeanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader()));\r\n```\r\n\r\n* propertyEditorRegistrar 会注册类型转换器\r\n  * 它在这里使用了 ResourceEditorRegistrar 实现类\r\n  * 并应用 ApplicationContext 提供的 Environment 完成 ${ } 解析\r\n\r\n  ```java\r\n  beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment()));\r\n  ```\r\n* registerResolvableDependency 来注册 beanFactory 以及 ApplicationContext，让它们也能用于依赖注入\r\n\r\n```java\r\n// BeanFactory interface not registered as resolvable type in a plain factory.\r\n// MessageSource registered (and found for autowiring) as a bean.\r\nbeanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);\r\nbeanFactory.registerResolvableDependency(ResourceLoader.class, this);\r\nbeanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this);\r\nbeanFactory.registerResolvableDependency(ApplicationContext.class, this);\r\n```\r\n\r\n* beanPostProcessors 是 bean 后处理器集合，会工作在 bean 的生命周期各个阶段，此处会添加两个：\r\n  * ApplicationContextAwareProcessor 用来解析 Aware 接口\r\n\r\n  ```java\r\n  // Configure the bean factory with context callbacks.\r\n  beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this));\r\n  ```\r\n\r\n  * ApplicationListenerDetector 用来识别容器中 ApplicationListener 类型的 bean\r\n\r\n  ```java\r\n  // Register early post-processor for detecting inner beans as ApplicationListeners.\r\n  beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this));\r\n  ```\r\n\r\n  * 粉红正方形代表内置的Bean后处理器\r\n\r\n![image-20210902182541925](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210902182541925.png)\r\n\r\n> - beanExpressionResolver是用来解析SpringEL表达式(SpEL)，即`#{}`\r\n> - propertyEditorRegistrar是注册一些类型转换器，因为Spring接下来尤其是做值注入，需要把字符串类型转换为一些其他类型，此时需要注册一些propertyEditor转换器来完成转换\r\n> - resolvableDependencies是管理一些特殊的对象用来进行依赖注入，因为将来大部分的Bean都是放在singletonObjects单例Bean工厂里去完成依赖注入，但是有些比较特殊的对象，如注入BeanFactory本身或者注入ApplicationContext本身，这些对象不是真正的Bean（特殊对象而已，还算不上Bean），它们没有在这个单例池里，没有在这个BeanDefinition里去定义，那么查询这些特殊Bean就是在这个resolvableDependencies里查\r\n> - beanPostProcessors是在我们Bean创建时，对这个Bean的各项功能做一些扩展，对里面的一些注解进行识别，Spring标准的功能里功能是非常有限的，它对Bean的创建过程做各种各样的扩展时必须借助于很多的beanPostProcessor\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n### **4. postProcessBeanFactory**\r\n\r\n* 这一步是空实现，留给子类扩展。（Bean工厂的一种扩展方式）\r\n\r\n  ```java\r\n  /**\r\n   * Modify the application context's internal bean factory after its standard\r\n   * initialization. All bean definitions will have been loaded, but no beans\r\n   * will have been instantiated yet. This allows for registering special\r\n   * BeanPostProcessors etc in certain ApplicationContext implementations.\r\n   * @param beanFactory the bean factory used by the application context\r\n   */\r\n  protected void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) {\r\n  }\r\n  ```\r\n  \r\n  * 一般 Web 环境的 ApplicationContext 都要利用它注册新的 Scope，完善 Web 下的 BeanFactory\r\n  \r\n* 这里体现的是模板方法设计模式\r\n\r\n> ApplicationContext将来可能有不同的子类，有一种是非web环境下的子类，还有一种是web环境下的子类，那web环境下的子类初始化beanFactory，就需要更多的信息，比如要注册一些新的scope，非web环境下的子类，只需要有singleton和prototype这两种scope,web环境下可能还需要request,session这样的scope，所以该方法就没有实现，留给子类扩展\r\n\r\n\r\n\r\n------\r\n\r\n### **5. invokeBeanFactoryPostProcessors**\r\n\r\n```java\r\n/**\r\n * Instantiate and invoke all registered BeanFactoryPostProcessor beans,\r\n * respecting explicit order if given.\r\n * <p>Must be called before singleton instantiation.\r\n * 实例化并调用所有已注册的 BeanFactoryPostProcessor bean，如果给定则遵循显式顺序。必须在单例化之前调用。\r\n */\r\nprotected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) {\r\n   PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors());\r\n\r\n   // Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime\r\n   // (e.g. through an @Bean method registered by ConfigurationClassPostProcessor)\r\n   if (beanFactory.getTempClassLoader() == null && beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) {\r\n      beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));\r\n      beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));\r\n   }\r\n}\r\n```\r\n\r\n* 这一步会调用 beanFactory 后处理器（Bean工厂的另一种扩展方式）\r\n  * 实际上将来真正工作的时候不可能为了扩展功能就去实现新的ApplicationContext子类，所以更好的扩展方式就是通过Bean工厂后处理器的方式来扩展BeanFactory的功能\r\n\r\n* **beanFactory 后处理器**，**充当 beanFactory 的扩展点**，可以用来补充或修改 BeanDefinition\r\n\r\n```java\r\npublic static void invokeBeanFactoryPostProcessors(\r\n      ConfigurableListableBeanFactory beanFactory, List<BeanFactoryPostProcessor> beanFactoryPostProcessors) {\r\n    ...\r\n\tSet<String> processedBeans = new HashSet<>();\r\n\r\n\tif (beanFactory instanceof BeanDefinitionRegistry) {    \r\n        BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;\r\n        ...\r\n        // Do not initialize FactoryBeans here: We need to leave all regular beans\r\n        // uninitialized to let the bean factory post-processors apply to them!\r\n        // Separate between BeanDefinitionRegistryPostProcessors that implement\r\n        // PriorityOrdered, Ordered, and the rest.\r\n        List<BeanDefinitionRegistryPostProcessor> currentRegistryProcessors = new ArrayList<>();\r\n        // First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered.\r\n        String[] postProcessorNames =\r\n                beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);\r\n        for (String ppName : postProcessorNames) {\r\n            if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {\r\n                currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));\r\n                processedBeans.add(ppName);\r\n            }\r\n        }\r\n    ...\r\n    }\r\n}\r\n```\r\n\r\n* 常见的 beanFactory 后处理器有\r\n  * ConfigurationClassPostProcessor – 解析 @Configuration、@Bean、@Import、@PropertySource 等\r\n\r\n  ```java\r\n  public class ConfigurationClassPostProcessor implements BeanDefinitionRegistryPostProcessor,\r\n        PriorityOrdered, ResourceLoaderAware, BeanClassLoaderAware, EnvironmentAware {...}\r\n  ```\r\n\r\n  * PropertySourcesPlaceHolderConfigurer – 替换 BeanDefinition 中的 `${}`（XML的ApplicationContext实现用的多）\r\n  * MapperScannerConfigurer – 补充 Mapper 接口对应的 BeanDefinition\r\n\r\n![image-20230421232304434](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421232304434.png)\r\n\r\n> beanFactory 后处理器在refresh方法调用之前就有一部分后处理器加入到容器了\r\n\r\n```java\r\npublic ConfigurableApplicationContext run(String... args) {\r\n    ...\r\n\tprepareContext(context, environment, listeners, applicationArguments, printedBanner);\r\n\trefreshContext(context);\r\n\tafterRefresh(context, applicationArguments);    \r\n    ...\r\n\r\n}\r\n```\r\n\r\n\r\n\r\n------\r\n\r\n### **6. registerBeanPostProcessors**\r\n\r\n```java\r\n/**\r\n * Instantiate and register all BeanPostProcessor beans,\r\n * respecting explicit order if given.\r\n * <p>Must be called before any instantiation of application beans.\r\n * 实例化并注册所有 BeanPostProcessor bean，如果给定则遵守显式顺序。必须在任何应用程序 bean 实例化之前调用。\r\n */\r\nprotected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) {\r\n   PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);\r\n}\r\n```\r\n\r\n* 这一步是继续从 beanFactory 中找出 bean 后处理器，添加至 beanPostProcessors 集合中\r\n\r\n```java\r\npublic static void registerBeanPostProcessors(\r\n      ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) {\r\n\r\n   String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);\r\n\r\n   // Register BeanPostProcessorChecker that logs an info message when\r\n   // a bean is created during BeanPostProcessor instantiation, i.e. when\r\n   // a bean is not eligible for getting processed by all BeanPostProcessors.\r\n   int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length;\r\n   beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount));\r\n\r\n   // Separate between BeanPostProcessors that implement PriorityOrdered,\r\n   // Ordered, and the rest.\r\n   List<BeanPostProcessor> priorityOrderedPostProcessors = new ArrayList<>();\r\n   List<BeanPostProcessor> internalPostProcessors = new ArrayList<>();\r\n   List<String> orderedPostProcessorNames = new ArrayList<>();\r\n   List<String> nonOrderedPostProcessorNames = new ArrayList<>();\r\n   for (String ppName : postProcessorNames) {\r\n      if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {\r\n         BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);\r\n         priorityOrderedPostProcessors.add(pp);\r\n         if (pp instanceof MergedBeanDefinitionPostProcessor) {\r\n            internalPostProcessors.add(pp);\r\n         }\r\n      }\r\n      else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {\r\n         orderedPostProcessorNames.add(ppName);\r\n      }\r\n      else {\r\n         nonOrderedPostProcessorNames.add(ppName);\r\n      }\r\n   }\r\n\r\n   // First, register the BeanPostProcessors that implement PriorityOrdered.\r\n   sortPostProcessors(priorityOrderedPostProcessors, beanFactory);\r\n   registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors);\r\n\r\n   // Next, register the BeanPostProcessors that implement Ordered.\r\n   List<BeanPostProcessor> orderedPostProcessors = new ArrayList<>(orderedPostProcessorNames.size());\r\n   for (String ppName : orderedPostProcessorNames) {\r\n      BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);\r\n      orderedPostProcessors.add(pp);\r\n      if (pp instanceof MergedBeanDefinitionPostProcessor) {\r\n         internalPostProcessors.add(pp);\r\n      }\r\n   }\r\n   sortPostProcessors(orderedPostProcessors, beanFactory);\r\n   registerBeanPostProcessors(beanFactory, orderedPostProcessors);\r\n\r\n   // Now, register all regular BeanPostProcessors.\r\n   List<BeanPostProcessor> nonOrderedPostProcessors = new ArrayList<>(nonOrderedPostProcessorNames.size());\r\n   for (String ppName : nonOrderedPostProcessorNames) {\r\n      BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);\r\n      nonOrderedPostProcessors.add(pp);\r\n      if (pp instanceof MergedBeanDefinitionPostProcessor) {\r\n         internalPostProcessors.add(pp);\r\n      }\r\n   }\r\n   registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors);\r\n\r\n   // Finally, re-register all internal BeanPostProcessors.\r\n   sortPostProcessors(internalPostProcessors, beanFactory);\r\n   registerBeanPostProcessors(beanFactory, internalPostProcessors);\r\n\r\n   // Re-register post-processor for detecting inner beans as ApplicationListeners,\r\n   // moving it to the end of the processor chain (for picking up proxies etc).\r\n   beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));\r\n}\r\n```\r\n\r\n* **bean 后处理器**，**充当 bean 的扩展点**，可以工作在 bean 的实例化、依赖注入、初始化阶段，常见的有：\r\n\r\n  * AutowiredAnnotationBeanPostProcessor 功能有：解析 @Autowired，@Value \r\n\r\n  ![image-20231128221603715](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20231128221603715.png)\r\n\r\n  * CommonAnnotationBeanPostProcessor 功能有：解析 @Resource，@PostConstruct，@PreDestroy\r\n\r\n  ![image-20231128222113889](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20231128222113889.png)\r\n\r\n  * AnnotationAwareAspectJAutoProxyCreator 功能有：为符合切点的目标 bean 自动创建代理\r\n\r\n  ![image-20231128221128903](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20231128221128903.png)\r\n\r\n  \r\n\r\n![image-20230421232557342](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421232557342.png)\r\n\r\n![image-20230421232957513](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230421232957513.png)\r\n\r\n> Bean的后处理器是对我们Bean创建的过程中做各种功能的增强，而Bean的后处理器其实都是从beanDefinitionMap中去搜索，看看里面这些BeanDefinition有没有实现BeanPostProcessor接口，如果实现了接口就会识别出来是个特殊的Bean，是个Bean的后处理器，那么就会把这样的Bean创建出来，创建出来以后，把这个Bean的后处理器对象加人到这个beanPostProcessors集合里，那在Ben真正创建的时候就会用到这些后处理器\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n### **7. initMessageSource**\r\n\r\n* 这一步是为 ApplicationContext 添加 messageSource 成员，实现国际化功能\r\n* 去 beanFactory 内找名为 messageSource 的 bean，如果没有，则提供空的 MessageSource 实现\r\n\r\n```java\r\n/**\r\n * Initialize the MessageSource.\r\n * Use parent's if none defined in this context.\r\n */\r\nprotected void initMessageSource() {\r\n   ConfigurableListableBeanFactory beanFactory = getBeanFactory();\r\n   if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) {\r\n      this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class);\r\n      // Make MessageSource aware of parent MessageSource.\r\n      if (this.parent != null && this.messageSource instanceof HierarchicalMessageSource) {\r\n         HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource;\r\n         if (hms.getParentMessageSource() == null) {\r\n            // Only set parent context as parent MessageSource if no parent MessageSource\r\n            // registered already.\r\n            hms.setParentMessageSource(getInternalParentMessageSource());\r\n         }\r\n      }\r\n      if (logger.isTraceEnabled()) {\r\n         logger.trace(\"Using MessageSource [\" + this.messageSource + \"]\");\r\n      }\r\n   }\r\n   else {\r\n      // Use empty MessageSource to be able to accept getMessage calls.\r\n      DelegatingMessageSource dms = new DelegatingMessageSource();\r\n      dms.setParentMessageSource(getInternalParentMessageSource());\r\n      this.messageSource = dms;\r\n      beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource);\r\n      if (logger.isTraceEnabled()) {\r\n         logger.trace(\"No '\" + MESSAGE_SOURCE_BEAN_NAME + \"' bean, using [\" + this.messageSource + \"]\");\r\n      }\r\n   }\r\n}\r\n```\r\n\r\n![image-20210902183819984](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210902183819984.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **8. initApplicationContextEventMulticaster**\r\n\r\n* 这一步为 ApplicationContext 添加事件广播器成员，即 applicationContextEventMulticaster\r\n* 它的作用是发布事件给监听器\r\n* 去 beanFactory 找名为 applicationEventMulticaster 的 bean 作为事件广播器，若没有，会创建默认的事件广播器\r\n* 之后就可以调用 ApplicationContext.publishEvent(事件对象) 来发布事件\r\n\r\n```java\r\n/**\r\n * Initialize the ApplicationEventMulticaster.\r\n * Uses SimpleApplicationEventMulticaster if none defined in the context.\r\n * @see org.springframework.context.event.SimpleApplicationEventMulticaster\r\n */\r\nprotected void initApplicationEventMulticaster() {\r\n   ConfigurableListableBeanFactory beanFactory = getBeanFactory();\r\n   if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) {\r\n      this.applicationEventMulticaster =\r\n            beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class);\r\n      if (logger.isTraceEnabled()) {\r\n         logger.trace(\"Using ApplicationEventMulticaster [\" + this.applicationEventMulticaster + \"]\");\r\n      }\r\n   }\r\n   else {\r\n      this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory);\r\n      beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster);\r\n      if (logger.isTraceEnabled()) {\r\n         logger.trace(\"No '\" + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + \"' bean, using \" +\r\n               \"[\" + this.applicationEventMulticaster.getClass().getSimpleName() + \"]\");\r\n      }\r\n   }\r\n}\r\n```\r\n\r\n![image-20210902183943469](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210902183943469.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **9. onRefresh**\r\n\r\n```java\r\n/**\r\n * Template method which can be overridden to add context-specific refresh work.\r\n * Called on initialization of special beans, before instantiation of singletons.\r\n * <p>This implementation is empty.\r\n * @throws BeansException in case of errors\r\n * @see #refresh()\r\n */\r\nprotected void onRefresh() throws BeansException {\r\n   // For subclasses: do nothing by default.\r\n}\r\n```\r\n\r\n* 这一步是空实现，留给子类扩展\r\n  * SpringBoot 中的子类在这里准备了 WebServer，即内嵌 web 容器\r\n* 体现的是模板方法设计模式\r\n\r\n\r\n\r\n------\r\n\r\n### **10. registerListeners**\r\n\r\n* 这一步会从多种途径找到事件监听器，并添加至 applicationEventMulticaster\r\n* 事件监听器顾名思义，用来接收事件广播器发布的事件，有如下来源\r\n  * 事先编程添加的\r\n  * 来自容器中的 bean\r\n  * 来自于 @EventListener 的解析\r\n* 要实现事件监听器，只需要实现 ApplicationListener 接口，重写其中 onApplicationEvent(E e) 方法即可\r\n\r\n```java\r\n/**\r\n * Add beans that implement ApplicationListener as listeners.\r\n * Doesn't affect other listeners, which can be added without being beans.\r\n */\r\nprotected void registerListeners() {\r\n   // Register statically specified listeners first.\r\n   for (ApplicationListener<?> listener : getApplicationListeners()) {\r\n      getApplicationEventMulticaster().addApplicationListener(listener);\r\n   }\r\n\r\n   // Do not initialize FactoryBeans here: We need to leave all regular beans\r\n   // uninitialized to let post-processors apply to them!\r\n   String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false);\r\n   for (String listenerBeanName : listenerBeanNames) {\r\n      getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName);\r\n   }\r\n\r\n   // Publish early application events now that we finally have a multicaster...\r\n   Set<ApplicationEvent> earlyEventsToProcess = this.earlyApplicationEvents;\r\n   this.earlyApplicationEvents = null;\r\n   if (earlyEventsToProcess != null) {\r\n      for (ApplicationEvent earlyEvent : earlyEventsToProcess) {\r\n         getApplicationEventMulticaster().multicastEvent(earlyEvent);\r\n      }\r\n   }\r\n}\r\n```\r\n\r\n- 微系统与第三方框架licationEventMulticaster 的实现类执行所有监听器的 onApplicationEvent 方法\r\n\r\n```java\r\npublic class SimpleApplicationEventMulticaster extends AbstractApplicationEventMulticaster {\r\n\r\n\t......\r\n\r\n\t@SuppressWarnings({\"rawtypes\", \"unchecked\"})\r\n\tprivate void doInvokeListener(ApplicationListener listener, ApplicationEvent event) {\r\n\t\ttry {\r\n\t\t\tlistener.onApplicationEvent(event);\r\n\t\t}\r\n\t\tcatch (ClassCastException ex) {\r\n\t\t\tString msg = ex.getMessage();\r\n\t\t\tif (msg == null || matchesClassCastMessage(msg, event.getClass())) {\r\n\t\t\t\t// Possibly a lambda-defined listener which we could not resolve the generic event type for\r\n\t\t\t\t// -> let's suppress the exception and just log a debug message.\r\n\t\t\t\tLog logger = LogFactory.getLog(getClass());\r\n\t\t\t\tif (logger.isTraceEnabled()) {\r\n\t\t\t\t\tlogger.trace(\"Non-matching event type for listener: \" + listener, ex);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\telse {\r\n\t\t\t\tthrow ex;\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\t......\r\n\r\n}\r\n\r\n```\r\n\r\n\r\n\r\n![image-20210902184343872](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210902184343872.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **11. finishBeanFactoryInitialization**\r\n\r\n* 这一步会将 beanFactory 的成员补充完毕，并初始化所有非延迟单例 bean\r\n* conversionService 也是一套转换机制，作为对 PropertyEditor 的补充\r\n* embeddedValueResolvers 即内嵌值解析器，用来解析 @Value 中的 `${}`，借用的是 Environment 的功能\r\n* singletonObjects 即单例池，缓存所有单例对象\r\n  * 对象的创建都分三个阶段，每一阶段都有不同的 bean 后处理器参与进来，扩展功能\r\n\r\n```java\r\n/**\r\n * Finish the initialization of this context's bean factory,\r\n * initializing all remaining singleton beans.\r\n */\r\nprotected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) {\r\n   // Initialize conversion service for this context.\r\n   if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &&\r\n         beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) {\r\n      beanFactory.setConversionService(\r\n            beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class));\r\n   }\r\n\r\n   // Register a default embedded value resolver if no bean post-processor\r\n   // (such as a PropertyPlaceholderConfigurer bean) registered any before:\r\n   // at this point, primarily for resolution in annotation attribute values.\r\n   if (!beanFactory.hasEmbeddedValueResolver()) {\r\n      beanFactory.addEmbeddedValueResolver(strVal -> getEnvironment().resolvePlaceholders(strVal));\r\n   }\r\n\r\n   // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early.\r\n   String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false);\r\n   for (String weaverAwareName : weaverAwareNames) {\r\n      getBean(weaverAwareName);\r\n   }\r\n\r\n   // Stop using the temporary ClassLoader for type matching.\r\n   beanFactory.setTempClassLoader(null);\r\n\r\n   // Allow for caching all bean definition metadata, not expecting further changes.\r\n   beanFactory.freezeConfiguration();\r\n\r\n   // Instantiate all remaining (non-lazy-init) singletons.\r\n   beanFactory.preInstantiateSingletons();\r\n}\r\n```\r\n\r\n![image-20210902184641623](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210902184641623.png)\r\n\r\n> - conversionService 也是做类型转换的，由于 Spring 的历史原因，最早是 propertyEditorRegistrars 来转换的，后来发现功能上、实现上有些欠考虑，因此设计了 conversionService 接口，这两个转换器是并存的\r\n> - embeddedValueResolvers 是做 `${}` 这种内嵌值的解析，间接地调用 Environment 的功能来完成 `${}` 的解析，只不过是从属于 BeanFactory 中的成员\r\n> - singletonObjects (单例池，用来缓存所有单例对象)是单例对象集合，它会找到 beanDefinitionMap 中所有使用到单例的对象，看有没有初始化方法，有没有依赖注入信息等，根据这些来创建Bean，前提是非延迟单例对象，如果是非延迟单例对象，这一步它就会把 Bean 的实例对象创建出来，如果是延迟单例对象，你第一次用到它的时候才会创建，在创建的过程中，之前的 beanPostProcessors 都可以派上用场，它们会工作在 Bean 创建的各个阶段，分为三个大的阶段，Bean 的创建、Bean 的依赖注入、Bean 的初始化，每个阶段都有不同的 Bean 后处理器参与进来，扩展功能\r\n\r\n\r\n\r\n------\r\n\r\n### **12. finishRefresh**\r\n\r\n* 这一步会为 ApplicationContext 添加 lifecycleProcessor 成员，用来控制容器内需要生命周期管理的 bean\r\n* 如果容器中有名称为 lifecycleProcessor 的 bean 就用它，否则创建默认的生命周期管理器\r\n* 准备好生命周期管理器，就可以实现\r\n  * 调用 context 的 start，即可触发所有实现 LifeCycle 接口 bean 的 start\r\n  * 调用 context 的 stop，即可触发所有实现 LifeCycle 接口 bean 的 stop\r\n* 发布 ContextRefreshed 事件，整个 refresh 执行完成\r\n\r\n```java\r\n/**\r\n * Finish the refresh of this context, invoking the LifecycleProcessor's\r\n * onRefresh() method and publishing the\r\n * {@link org.springframework.context.event.ContextRefreshedEvent}.\r\n */\r\nprotected void finishRefresh() {\r\n   // Clear context-level resource caches (such as ASM metadata from scanning).\r\n   clearResourceCaches();\r\n\r\n   // Initialize lifecycle processor for this context.\r\n   initLifecycleProcessor();\r\n\r\n   // Propagate refresh to lifecycle processor first.\r\n   getLifecycleProcessor().onRefresh();\r\n\r\n   // Publish the final event.\r\n   publishEvent(new ContextRefreshedEvent(this));\r\n\r\n   // Participate in LiveBeansView MBean, if active.\r\n   LiveBeansView.registerApplicationContext(this);\r\n}\r\n```\r\n\r\n![image-20210902185052433](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210902185052433.png)\r\n\r\n> lifecycleProcessor (生命周期处理器): 整个 Spring 容器中有很多的 Bean，它们都有自己独立的生命周期，都有一个停止，启动之类的生命周期处理，这里的生命周期并不是指初始化销毁，可以理解为一种服务，可以停止和启动，同样的从 beanDefinitionMap 中找到一个 lifecycleProcessor 的 Bean，如果有就直接用，没有它就用自己默认的生命周期处理器，这个 lifecycleProcessor 里面有 start 方法，可以调用 Bean 工厂中其他实现 lifecycleProcessor 接口的Bean的 start 方法，调用 stop 方法也一样，起到一个总控的作用，这个生命周期处理器创建好以后可以发布 ContextRefreshed 事件，表示整个 Spring 容器已经初始化( Refresh )完成\r\n\r\n\r\n\r\n------\r\n\r\n### **总结**\r\n\r\n![image-20230422003035699](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422003035699.png)\r\n\r\n\r\n\r\n------\r\n\r\n## 2. Spring bean 生命周期\r\n\r\n**bean 生命周期 概述**\r\n\r\n![image-20230422003651658](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422003651658.png)\r\n\r\n- 里面的这些Bean符合懒惰式初始化，开始并不会创建这些Bean，当你第一次获取时，才会创建这些Bean的实例，然后进行依赖注入初始化等操作，以doGetBean作为起点\r\n\r\nbean 的生命周期从调用 beanFactory 的 getBean 开始，到这个 bean 被销毁，可以总结为以下七个阶段：\r\n\r\n1. 处理名称，检查缓存\r\n2. 处理父子容器\r\n3. 处理 dependsOn\r\n4. 选择 scope 策略\r\n5. 创建 bean\r\n6. 类型转换处理\r\n7. 销毁 bean\r\n\r\n> ***注意***\r\n>\r\n> * 划分的阶段和名称并不重要，重要的是理解整个过程中做了哪些事情\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n### **1. 处理名称，检查缓存**\r\n\r\n* 这一步会处理别名，将别名解析为实际名称\r\n* 对 FactoryBean 也会特殊处理，如果以 & 开头表示要获取 FactoryBean 本身，否则表示要获取其产品\r\n* 这里针对单例对象会检查一级、二级、三级缓存\r\n  * singletonFactories 三级缓存，存放单例工厂对象\r\n  * earlySingletonObjects 二级缓存，存放单例工厂的产品对象\r\n    * 如果发生循环依赖，产品是代理；无循环依赖，产品是原始对象\r\n  * singletonObjects 一级缓存，存放单例成品对象\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractBeanFactory#doGetBean\r\n{\r\n    ...\r\n    final String beanName = transformedBeanName(name);\r\n    Object bean;\r\n\r\n    // Eagerly check singleton cache for manually registered singletons.\r\n    Object sharedInstance = getSingleton(beanName);\r\n    if (sharedInstance != null && args == null) {\r\n       if (logger.isTraceEnabled()) {\r\n          if (isSingletonCurrentlyInCreation(beanName)) {\r\n             logger.trace(\"Returning eagerly cached instance of singleton bean '\" + beanName +\r\n                   \"' that is not fully initialized yet - a consequence of a circular reference\");\r\n          }\r\n          else {\r\n             logger.trace(\"Returning cached instance of singleton bean '\" + beanName + \"'\");\r\n          }\r\n       }\r\n       bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);\r\n    }\r\n\t...\r\n}\r\n```\r\n\r\n![image-20230422005021610](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422005021610.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **2. 处理父子容器**\r\n\r\n* 如果当前容器根据名字找不到这个 bean，此时若父容器存在，则执行父容器的 getBean 流程\r\n* 优先找子容器的 bean，找到了直接返回，找不到继续到父容器找\r\n* 父子容器的 bean 名称可以重复\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractBeanFactory#doGetBean\r\n{\r\n    ...\r\n    // Check if bean definition exists in this factory.\r\n    BeanFactory parentBeanFactory = getParentBeanFactory();\r\n    if (parentBeanFactory != null && !containsBeanDefinition(beanName)) {\r\n       // Not found -> check parent.\r\n       String nameToLookup = originalBeanName(name);\r\n       if (parentBeanFactory instanceof AbstractBeanFactory) {\r\n          return ((AbstractBeanFactory) parentBeanFactory).doGetBean(\r\n                nameToLookup, requiredType, args, typeCheckOnly);\r\n       }\r\n       else if (args != null) {\r\n          // Delegation to parent with explicit args.\r\n          return (T) parentBeanFactory.getBean(nameToLookup, args);\r\n       }\r\n       else if (requiredType != null) {\r\n          // No args -> delegate to standard getBean method.\r\n          return parentBeanFactory.getBean(nameToLookup, requiredType);\r\n       }\r\n       else {\r\n          return (T) parentBeanFactory.getBean(nameToLookup);\r\n       }\r\n    }\r\n    ...\r\n}\r\n```\r\n\r\n> 首先查找缓存，缓存里有就直接返回，缓存里如果没有，也不会立刻去创建这个Bean，如果容器中又配置了父容器的话，缓存里没有它会到父容器里查找，看看里面有没有创建好的Bean，如果有就用父容器的Bean，就不用走创建流程，如果还没有才走后续流程\r\n\r\n\r\n\r\n------\r\n\r\n### **3. 处理 dependsOn**\r\n\r\n* 如果当前 bean 有通过 dependsOn 指定了非显式依赖的 bean，这一步会提前创建这些 dependsOn 的 bean \r\n* 所谓非显式依赖，就是指两个 bean 之间不存在直接依赖关系，但需要控制它们的创建先后顺序\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractBeanFactory#doGetBean\r\n{\r\n    ...\r\n    final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);\r\n    checkMergedBeanDefinition(mbd, beanName, args);\r\n\r\n    // Guarantee initialization of beans that the current bean depends on.\r\n    String[] dependsOn = mbd.getDependsOn();\r\n    if (dependsOn != null) {\r\n       for (String dep : dependsOn) {\r\n          if (isDependent(beanName, dep)) {\r\n             throw new BeanCreationException(mbd.getResourceDescription(), beanName,\r\n                   \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\");\r\n          }\r\n          registerDependentBean(dep, beanName);\r\n          try {\r\n             getBean(dep);\r\n          }\r\n          catch (NoSuchBeanDefinitionException ex) {\r\n             throw new BeanCreationException(mbd.getResourceDescription(), beanName,\r\n                   \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex);\r\n          }\r\n       }\r\n    }\r\n    ...\r\n}\r\n```\r\n\r\n![image-20230422005341839](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422005341839.png)\r\n\r\n> 大部分的Bean都有依赖关系，这些有依赖关系的Bean它们创建的次序是可以保障的，那些没有依赖关系的Bean可以使用dependsOn来控制次序\r\n\r\n\r\n\r\n------\r\n\r\n### **4. 选择 scope 策略**\r\n\r\n* 对于 singleton scope，首先到单例池去获取 bean，如果有则直接返回，没有再进入创建流程\r\n* 对于 prototype scope，每次都会进入创建流程\r\n* 对于自定义 scope，例如 request，首先到 request 域获取 bean，如果有则直接返回，如果没有，则创建并放入 request\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractBeanFactory#doGetBean\r\n{\r\n    ...\r\n    // Create bean instance.\r\n       if (mbd.isSingleton()) {\r\n          sharedInstance = getSingleton(beanName, () -> {\r\n             try {\r\n                return createBean(beanName, mbd, args);\r\n             }\r\n             catch (BeansException ex) {\r\n                // Explicitly remove instance from singleton cache: It might have been put there\r\n                // eagerly by the creation process, to allow for circular reference resolution.\r\n                // Also remove any beans that received a temporary reference to the bean.\r\n                destroySingleton(beanName);\r\n                throw ex;\r\n             }\r\n          });\r\n          bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);\r\n       }\r\n\r\n       else if (mbd.isPrototype()) {\r\n          // It's a prototype -> create a new instance.\r\n          Object prototypeInstance = null;\r\n          try {\r\n             beforePrototypeCreation(beanName);\r\n             prototypeInstance = createBean(beanName, mbd, args);\r\n          }\r\n          finally {\r\n             afterPrototypeCreation(beanName);\r\n          }\r\n          bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);\r\n       }\r\n\r\n       else {\r\n          String scopeName = mbd.getScope();\r\n          final Scope scope = this.scopes.get(scopeName);\r\n          if (scope == null) {\r\n             throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\");\r\n          }\r\n          try {\r\n             Object scopedInstance = scope.get(beanName, () -> {\r\n                beforePrototypeCreation(beanName);\r\n                try {\r\n                   return createBean(beanName, mbd, args);\r\n                }\r\n                finally {\r\n                   afterPrototypeCreation(beanName);\r\n                }\r\n             });\r\n             bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);\r\n          }\r\n          catch (IllegalStateException ex) {\r\n             throw new BeanCreationException(beanName,\r\n                   \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" +\r\n                   \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\",\r\n                   ex);\r\n          }\r\n       }\r\n    }\r\n    ...\r\n}\r\n```\r\n\r\n![image-20230422011157499](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422011157499.png)\r\n\r\n\r\n\r\n------\r\n\r\n### 5 创建 bean\r\n\r\n![image-20230422013329269](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422013329269.png)\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#createBean\r\n@Override\r\nprotected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args)\r\n      throws BeanCreationException {\r\n\t...\r\n      // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance.\r\n      Object bean = resolveBeforeInstantiation(beanName, mbdToUse);\r\n\t...\r\n      Object beanInstance = doCreateBean(beanName, mbdToUse, args);\r\n\t...\r\n}\r\n```\r\n\r\n\r\n\r\n------\r\n\r\n#### **5.1 创建 bean - 创建 bean 实例**\r\n\r\n| **要点**                             | **总结**                                                     |\r\n| ------------------------------------ | ------------------------------------------------------------ |\r\n| 有自定义 TargetSource 的情况         | 由 AnnotationAwareAspectJAutoProxyCreator 创建代理返回       |\r\n| Supplier 方式创建 bean 实例          | 为 Spring 5.0 新增功能，方便编程方式创建  bean  实例         |\r\n| FactoryMethod 方式  创建 bean  实例  | ① 分成静态工厂与实例工厂；② 工厂方法若有参数，需要对工厂方法参数进行解析，利用  resolveDependency；③ 如果有多个工厂方法候选者，还要进一步按权重筛选 |\r\n| AutowiredAnnotationBeanPostProcessor | ① 优先选择带  @Autowired  注解的构造；② 若有唯一的带参构造，也会入选 |\r\n| mbd.getPreferredConstructors         | 选择所有公共构造，这些构造之间按权重筛选                     |\r\n| 采用默认构造                         | 如果上面的后处理器和 BeanDefinition 都没找到构造，采用默认构造，即使是私有的 ( 私有构造方法也会用私有的构造创建 Bean 的实例，使用暴力反射并通过私有构造方法进行方法调用 ) |\r\n\r\n- **创建 bean 实例之前**，有自定义 TargetSource 的情况\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#\r\n@Nullable\r\nprotected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) {\r\n   \t...\r\n \tbean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName);\r\n\t...\r\n\tbean = applyBeanPostProcessorsAfterInitialization(bean, beanName);\r\n\t...\r\n}\r\n\r\n@Nullable\r\nprotected Object applyBeanPostProcessorsBeforeInstantiation(Class<?> beanClass, String beanName) {\r\n   ...\r\n         Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName);\r\n   ...\r\n}\r\n\r\n@Override\r\npublic Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName)\r\n\tthrows BeansException {\r\n \t...\r\n\tObject current = processor.postProcessAfterInitialization(result, beanName);\r\n\t...\r\n}\r\n```\r\n\r\n```java\r\n\t//org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator\r\n\t//创建 bean 实例之前\r\n\t@Override\r\n    public Object postProcessBeforeInstantiation(Class<?> beanClass, String beanName) {\r\n       Object cacheKey = getCacheKey(beanClass, beanName);\r\n\r\n       if (!StringUtils.hasLength(beanName) || !this.targetSourcedBeans.contains(beanName)) {\r\n          if (this.advisedBeans.containsKey(cacheKey)) {\r\n             return null;\r\n          }\r\n          if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) {\r\n             this.advisedBeans.put(cacheKey, Boolean.FALSE);\r\n             return null;\r\n          }\r\n       }\r\n\r\n       // Create proxy here if we have a custom TargetSource.\r\n       // Suppresses unnecessary default instantiation of the target bean:\r\n       // The TargetSource will handle target instances in a custom fashion.\r\n       TargetSource targetSource = getCustomTargetSource(beanClass, beanName);\r\n       if (targetSource != null) {\r\n          if (StringUtils.hasLength(beanName)) {\r\n             this.targetSourcedBeans.add(beanName);\r\n          }\r\n          Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource);\r\n          Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource);\r\n          this.proxyTypes.put(cacheKey, proxy.getClass());\r\n          return proxy;\r\n       }\r\n\r\n       return null;\r\n    }\r\n\t//bean 初始化完成之后\r\n\t@Override\r\n\tpublic Object postProcessAfterInitialization(@Nullable Object bean, String beanName) {\r\n\t\tif (bean != null) {\r\n\t\t\tObject cacheKey = getCacheKey(bean.getClass(), beanName);\r\n\t\t\tif (this.earlyProxyReferences.remove(cacheKey) != bean) {\r\n\t\t\t\treturn wrapIfNecessary(bean, beanName, cacheKey);\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn bean;\r\n\t}\r\n```\r\n\r\n- 默认情况\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean\r\nprotected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args)\r\n\t\t\tthrows BeanCreationException {\r\n\r\n\t\t// Instantiate the bean.\r\n\t\tBeanWrapper instanceWrapper = null;\r\n\t\tif (mbd.isSingleton()) {\r\n\t\t\tinstanceWrapper = this.factoryBeanInstanceCache.remove(beanName);\r\n\t\t}\r\n\t\tif (instanceWrapper == null) {\r\n\t\t\tinstanceWrapper = createBeanInstance(beanName, mbd, args);\r\n\t\t}\r\n\t\tfinal Object bean = instanceWrapper.getWrappedInstance();\r\n\t\tClass<?> beanType = instanceWrapper.getWrappedClass();\r\n\t\tif (beanType != NullBean.class) {\r\n\t\t\tmbd.resolvedTargetType = beanType;\r\n\t\t}\r\n    ...\r\n}\r\n```\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#createBeanInstance\r\nprotected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) {\r\n   ...\r\n\r\n   Supplier<?> instanceSupplier = mbd.getInstanceSupplier();\r\n   if (instanceSupplier != null) {\r\n      return obtainFromSupplier(instanceSupplier, beanName);\r\n   }\r\n\r\n   if (mbd.getFactoryMethodName() != null) {\r\n      return instantiateUsingFactoryMethod(beanName, mbd, args);\r\n   }\r\n\r\n   // Shortcut when re-creating the same bean...\r\n   boolean resolved = false;\r\n   boolean autowireNecessary = false;\r\n   if (args == null) {\r\n      synchronized (mbd.constructorArgumentLock) {\r\n         if (mbd.resolvedConstructorOrFactoryMethod != null) {\r\n            resolved = true;\r\n            autowireNecessary = mbd.constructorArgumentsResolved;\r\n         }\r\n      }\r\n   }\r\n   if (resolved) {\r\n      if (autowireNecessary) {\r\n         return autowireConstructor(beanName, mbd, null, null);\r\n      }\r\n      else {\r\n         return instantiateBean(beanName, mbd);\r\n      }\r\n   }\r\n\r\n   // Candidate constructors for autowiring?\r\n   Constructor<?>[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);\r\n   if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR ||\r\n         mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) {\r\n      return autowireConstructor(beanName, mbd, ctors, args);\r\n   }\r\n\r\n   // Preferred constructors for default construction?\r\n   ctors = mbd.getPreferredConstructors();\r\n   if (ctors != null) {\r\n      return autowireConstructor(beanName, mbd, ctors, null);\r\n   }\r\n\r\n   // No special handling: simply use no-arg constructor.\r\n   return instantiateBean(beanName, mbd);\r\n}\r\n```\r\n\r\n\r\n\r\n------\r\n\r\n#### **5.2 创建 bean - 依赖注入**\r\n\r\n![image-20230422013843155](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422013843155.png)\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean\r\n{\r\n        ...\r\n        // Allow post-processors to modify the merged bean definition.\r\n\t\tsynchronized (mbd.postProcessingLock) {\r\n\t\t\tif (!mbd.postProcessed) {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tapplyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);\r\n\t\t\t\t}\r\n\t\t\t\tcatch (Throwable ex) {\r\n\t\t\t\t\tthrow new BeanCreationException(mbd.getResourceDescription(), beanName,\r\n\t\t\t\t\t\t\t\"Post-processing of merged bean definition failed\", ex);\r\n\t\t\t\t}\r\n\t\t\t\tmbd.postProcessed = true;\r\n\t\t\t}\r\n\t\t}\r\n    \t// Eagerly cache singletons to be able to resolve circular references\r\n\t\t// even when triggered by lifecycle interfaces like BeanFactoryAware.\r\n\t\tboolean earlySingletonExposure = (mbd.isSingleton() && this.allowCircularReferences &&\r\n\t\t\t\tisSingletonCurrentlyInCreation(beanName));\r\n\t\tif (earlySingletonExposure) {\r\n\t\t\tif (logger.isTraceEnabled()) {\r\n\t\t\t\tlogger.trace(\"Eagerly caching bean '\" + beanName +\r\n\t\t\t\t\t\t\"' to allow for resolving potential circular references\");\r\n\t\t\t}\r\n             //添加单例工厂\r\n\t\t\taddSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean));\r\n\t\t}\r\n    \t...\r\n        \tpopulateBean(beanName, mbd, instanceWrapper);\r\n \t...\r\n}\r\n```\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#applyMergedBeanDefinitionPostProcessors\r\nprotected void applyMergedBeanDefinitionPostProcessors(RootBeanDefinition mbd, Class<?> beanType, String beanName) {\r\n   for (BeanPostProcessor bp : getBeanPostProcessors()) {\r\n      if (bp instanceof MergedBeanDefinitionPostProcessor) {\r\n         MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp;\r\n         bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName);\r\n      }\r\n   }\r\n}\r\n```\r\n\r\n- AutowiredAnnotationBeanPostProcessor\r\n\r\n```java\r\n//org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor#postProcessMergedBeanDefinition\r\n@Override\r\npublic void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class<?> beanType, String beanName) {\r\n   InjectionMetadata metadata = findAutowiringMetadata(beanName, beanType, null);\r\n   metadata.checkConfigMembers(beanDefinition);\r\n}\r\n```\r\n\r\n- CommonAnnotationBeanPostProcessor\r\n\r\n```java\r\n//org.springframework.context.annotation.CommonAnnotationBeanPostProcessor#postProcessMergedBeanDefinition\r\n@Override\r\npublic void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class<?> beanType, String beanName) {\r\n   super.postProcessMergedBeanDefinition(beanDefinition, beanType, beanName);\r\n   InjectionMetadata metadata = findResourceMetadata(beanName, beanType, null);\r\n   metadata.checkConfigMembers(beanDefinition);\r\n}\r\n```\r\n\r\n- `AUTOWIRE_BY_NAME;AUTOWIRE_BY_TYPE;resolveDependency;applyPropertyValues`\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#populateBean\r\nprotected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) {\r\n   ...\r\n\r\n   PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null);\r\n\r\n   int resolvedAutowireMode = mbd.getResolvedAutowireMode();\r\n   if (resolvedAutowireMode == AUTOWIRE_BY_NAME || resolvedAutowireMode == AUTOWIRE_BY_TYPE) {\r\n      ...\r\n   }\r\n\r\n   ...\r\n   if (needsDepCheck) {\r\n      if (filteredPds == null) {\r\n         filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);\r\n      }\r\n      checkDependencies(beanName, mbd, filteredPds, pvs);\r\n   }\r\n\r\n   if (pvs != null) {\r\n      applyPropertyValues(beanName, mbd, bw, pvs);\r\n   }\r\n}\r\n```\r\n\r\n| **要点**                             | **总结**                                                     |\r\n| ------------------------------------ | ------------------------------------------------------------ |\r\n| AutowiredAnnotationBeanPostProcessor | 识别   @Autowired  及 @Value  标注的成员，封装为  InjectionMetadata 进行依赖注入 |\r\n| CommonAnnotationBeanPostProcessor    | 识别   @Resource  标注的成员，封装为  InjectionMetadata 进行依赖注入 |\r\n| resolveDependency                    | 用来查找要装配的值，可以识别：① Optional；② ObjectFactory 及 ObjectProvider；③ @Lazy  注解；④ @Value  注解（`${}`, `#{}`, 类型转换）；⑤ 集合类型（Collection，Map，数组等）；⑥ 泛型和  @Qualifier（用来区分类型歧义）；⑦ primary  及名字匹配（用来区分类型歧义） |\r\n| AUTOWIRE_BY_NAME                     | 根据成员名字找 bean 对象，修改 mbd 的 propertyValues，不会考虑简单类型的成员 |\r\n| AUTOWIRE_BY_TYPE                     | 根据成员类型执行 resolveDependency 找到依赖注入的值，修改  mbd 的 propertyValues |\r\n| applyPropertyValues                  | 根据 mbd 的 propertyValues 进行依赖注入（即xml中 `<property name ref|value/>`） |\r\n\r\n- 相同成员依赖注入优先级：精准匹配>按类型/名字匹配>注解方式匹配\r\n\r\n![image-20230422014541831](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422014541831.png)\r\n\r\n> Bean的实例对象刚刚创建时里面是空空如也的，需要不断补充和完善它，接下来就对当前这个Bean的实例进行依赖注入，即建立当前这个Bean的实例跟容器中其他Bean之间的依赖关系，可以通过注解匹配和根据类型以及名字匹配\r\n>\r\n> - 在依赖注入阶段，有个条件是产生循环依赖，产生循环依赖以后，它会在单例工厂池中通过一个工厂对象来间接的调用到我们的自动代理后处理器类来创建代理\r\n>\r\n> ```java\r\n> //org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#getEarlyBeanReference\r\n>       ...\r\n>          exposedObject = bp.getEarlyBeanReference(exposedObject, beanName);\r\n>       ...\r\n> //org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#getEarlyBeanReference         \r\n> \t@Override\r\n> \tpublic Object getEarlyBeanReference(Object bean, String beanName) {\r\n> \t\tObject cacheKey = getCacheKey(bean.getClass(), beanName);\r\n> \t\tthis.earlyProxyReferences.put(cacheKey, bean);\r\n>          //创建代理方法\r\n> \t\treturn wrapIfNecessary(bean, beanName, cacheKey);\r\n> \t}\r\n> ```\r\n\r\n\r\n\r\n------\r\n\r\n#### **5.3 创建 bean - 初始化**\r\n\r\n![image-20230422014943738](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422014943738.png)\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean\r\n{    \r\n    ...\r\n    // Initialize the bean instance.\r\n    Object exposedObject = bean;\r\n    ...\r\n       exposedObject = initializeBean(beanName, exposedObject, mbd);\r\n    ...\r\n\r\n}\t\r\n```\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#initializeBean\r\nprotected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) {\r\n   if (System.getSecurityManager() != null) {\r\n      AccessController.doPrivileged((PrivilegedAction<Object>) () -> {\r\n         invokeAwareMethods(beanName, bean);\r\n         return null;\r\n      }, getAccessControlContext());\r\n   }\r\n   else {\r\n      invokeAwareMethods(beanName, bean);\r\n   }\r\n\r\n   Object wrappedBean = bean;\r\n   if (mbd == null || !mbd.isSynthetic()) {\r\n      wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);\r\n   }\r\n\r\n   ...\r\n      invokeInitMethods(beanName, wrappedBean, mbd);\r\n   ...\r\n   if (mbd == null || !mbd.isSynthetic()) {\r\n      //有自定义 TargetSource 的情况由 AnnotationAwareAspectJAutoProxyCreator 创建代理返回\r\n      wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);\r\n   }\r\n\r\n   return wrappedBean;\r\n}\r\n```\r\n\r\n| **要点**              | **总结**                                                     |\r\n| --------------------- | ------------------------------------------------------------ |\r\n| 内置 Aware 接口的装配 | 包括 BeanNameAware，BeanFactoryAware 等                      |\r\n| 扩展 Aware 接口的装配 | 由 ApplicationContextAwareProcessor 解析，执行时机在  postProcessBeforeInitialization |\r\n| @PostConstruct        | 由 CommonAnnotationBeanPostProcessor 解析，执行时机在  postProcessBeforeInitialization |\r\n| InitializingBean      | 通过接口回调执行初始化                                       |\r\n| initMethod            | 根据 BeanDefinition 得到的初始化方法执行初始化，即 `<bean init-method>` 或 @Bean(initMethod) |\r\n| 创建 aop 代理         | 由 AnnotationAwareAspectJAutoProxyCreator 创建，执行时机在  postProcessAfterInitialization |\r\n\r\n- 初始化顺序：\r\n  - 1.执行BeanFactoryAware接口的定义的初始化方法setBeanFactory\r\n  - 2.执行标注@PostConstruct的方法init\r\n  - 3.执行InitializingBean接口的重写方法初始化afterPorpertiesSet\r\n  - 4.执行用BeanDefinition指定的初始化方法\r\n\r\n![image-20230422015021268](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422015021268.png)\r\n\r\n> 初始化阶段：处理一些Aware接口、调用初始化方法、创建aop代理(如果你的Bean跟切面表达式匹配上，就帮你创建代理)，在初始化阶段，由Spring的BeanFactory容器来回调Aware接口中的方法，如你实现了BeanFactoryAware接口，就会相应地把BeanFactory对象通过回调此接口的方法给你传递进来\r\n> 初始化方法：@PostConstruct是通过一个Bean的后处理器来进行调用的\r\n\r\n\r\n\r\n------\r\n\r\n#### **5.4 创建 bean - 注册可销毁 bean**\r\n\r\n![image-20230422015302186](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422015302186.png)\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean\r\n...\r\n// Register bean as disposable.\r\ntry {\r\n   registerDisposableBeanIfNecessary(beanName, bean, mbd);\r\n}\r\ncatch (BeanDefinitionValidationException ex) {\r\n   throw new BeanCreationException(\r\n         mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex);\r\n}\r\n...\r\n```\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractBeanFactory#registerDisposableBeanIfNecessary\r\nprotected void registerDisposableBeanIfNecessary(String beanName, Object bean, RootBeanDefinition mbd) {\r\n   AccessControlContext acc = (System.getSecurityManager() != null ? getAccessControlContext() : null);\r\n   if (!mbd.isPrototype() && requiresDestruction(bean, mbd)) {\r\n      if (mbd.isSingleton()) {\r\n         // Register a DisposableBean implementation that performs all destruction\r\n         // work for the given bean: DestructionAwareBeanPostProcessors,\r\n         // DisposableBean interface, custom destroy method.\r\n         registerDisposableBean(beanName,\r\n               new DisposableBeanAdapter(bean, beanName, mbd, getBeanPostProcessors(), acc));\r\n      }\r\n      else {\r\n         // A bean with a custom scope...\r\n         Scope scope = this.scopes.get(mbd.getScope());\r\n         if (scope == null) {\r\n            throw new IllegalStateException(\"No Scope registered for scope name '\" + mbd.getScope() + \"'\");\r\n         }\r\n         scope.registerDestructionCallback(beanName,\r\n               new DisposableBeanAdapter(bean, beanName, mbd, getBeanPostProcessors(), acc));\r\n      }\r\n   }\r\n}\r\n```\r\n\r\n在这一步判断并登记可销毁 bean\r\n\r\n* 判断依据\r\n  * 如果实现了 DisposableBean 或 AutoCloseable 接口，则为可销毁 bean\r\n  * 如果自定义了 destroyMethod，则为可销毁 bean\r\n  * 如果采用 @Bean 没有指定 destroyMethod，则采用自动推断方式获取销毁方法名（close，shutdown）\r\n  * 如果有 @PreDestroy 标注的方法\r\n* 存储位置\r\n  * singleton scope 的可销毁 bean 会存储于 beanFactory 的成员当中\r\n  * 自定义 scope 的可销毁 bean 会存储于对应的域对象当中\r\n  * prototype scope 不会存储，需要自己找到此对象销毁\r\n* 存储时都会封装为 DisposableBeanAdapter 类型对销毁方法的调用进行适配\r\n\r\n\r\n\r\n------\r\n\r\n### **6. 类型转换处理**\r\n\r\n* 如果 getBean 的 requiredType 参数与实际得到的对象类型不同，会尝试进行类型转换\r\n* 这时Bean已经被创建并作为结果返回\r\n\r\n![image-20230422015511898](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422015511898.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **7. 销毁 bean**\r\n\r\n* 销毁时机\r\n  * singleton bean 的销毁在 ApplicationContext.close 时，此时会找到所有 DisposableBean 的名字，逐一销毁\r\n  * 自定义 scope bean 的销毁在作用域对象生命周期结束时（这类Bean的销毁时机在request域生命周期结束的时候，在它结束之前调用request scope bean的一个销毁）\r\n  * prototype bean 的销毁可以通过自己手动调用 AutowireCapableBeanFactory.destroyBean 方法执行销毁\r\n* 同一 bean 中不同形式销毁方法的调用次序\r\n  * 优先后处理器销毁，即 @PreDestroy\r\n  * 其次 DisposableBean 接口销毁\r\n  * 最后 destroyMethod 销毁（包括自定义名称，推断名称，AutoCloseable 接口 多选一）\r\n\r\n\r\n\r\n------\r\n\r\n### **总结**\r\n\r\n![image-20230422015825420](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422015825420.png)\r\n\r\n\r\n\r\n------\r\n\r\n## 3. Spring bean 循环依赖\r\n\r\n### 补充：创建代理\r\n\r\n**要点**\r\n\r\n- 要完全理解循环依赖，需要理解代理对象的创建时机\r\n- 掌握 ProxyFactory 创建代理的过程，理解 Advisor，Advice，Pointcut 与 Aspect\r\n- 掌握 AnnotationAwareAspectJAutoProxyCreator 筛选 Advisor 合格者，创建代理的过程\r\n  - bean 的后处理器，作用是为我们容器中的 bean，那些目标 bean 需不需要为之创建代理，它内部也会间接调用 ProxyFactory 来创建代理\r\n\r\n**代理工厂**\r\n\r\n- 只加了通知（环绕通知）来进行功能增强\r\n\r\n![image-20230423122730735](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423122730735.png)\r\n\r\n![image-20231202153033525](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20231202153033525.png)\r\n\r\n- 加入切点，观察CGLIB动态代理和JDK动态代理的区别\r\n\r\n![image-20230423123833981](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423123833981.png)\r\n\r\n> **说说 JDK 动态代理和 CGLIB 代理 ？**\r\n>\r\n> Spring 的 AOP 是通过[动态代理open in new window](https://mp.weixin.qq.com/s/aZtfwik0weJN5JzYc-JxYg)来实现的，动态代理主要有两种方式 JDK 动态代理和 Cglib 动态代理，这两种动态代理的使用和原理有些不同。\r\n>\r\n> **JDK 动态代理**\r\n>\r\n> 1. **Interface**：对于 JDK 动态代理，目标类需要实现一个 Interface。\r\n> 2. **InvocationHandler**：InvocationHandler 是一个接口，可以通过实现这个接口，定义横切逻辑，再通过反射机制（invoke）调用目标类的代码，在此过程，可能包装逻辑，对目标方法进行前置后置处理。\r\n> 3. **Proxy**：Proxy 利用 InvocationHandler 动态创建一个符合目标类实现的接口的实例，生成目标类的代理对象。\r\n>\r\n> **CgLib 动态代理**\r\n>\r\n> 1. 使用 JDK 创建代理有一大限制，它只能为接口创建代理实例，而 CgLib 动态代理就没有这个限制。\r\n> 2. CgLib 动态代理是使用字节码处理框架 **ASM**，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。\r\n> 3. **CgLib** 创建的动态代理对象性能比 JDK 创建的动态代理对象的性能高不少，但是 CGLib 在创建代理对象时所花费的时间却比 JDK 多得多，所以对于单例的对象，因为无需频繁创建对象，用 CGLib 合适，反之，使用 JDK 方式要更为合适一些。同时，由于 CGLib 是采用动态创建子类的方法，对于 final 方法，无法进行代理。\r\n>\r\n> 我们来看一个常见的小场景，客服中转，解决用户问题：\r\n>\r\n> ![用户向客服提问题](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/spring-c5c4b247-62dd-43a2-a043-da51c58f77c8.png)\r\n>\r\n> **JDK 动态代理实现：**\r\n>\r\n> ![JDK动态代理类图](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/spring-65b14a3f-2653-463e-af77-a8875d3d635c.png)\r\n>\r\n> - 接口\r\n>\r\n>   \r\n>\r\n>   ```java\r\n>   public interface ISolver {\r\n>       void solve();\r\n>   }\r\n>   ```\r\n>\r\n> - 目标类:需要实现对应接口\r\n>\r\n>   \r\n>\r\n>   ```java\r\n>   public class Solver implements ISolver {\r\n>       @Override\r\n>       public void solve() {\r\n>           System.out.println(\"疯狂掉头发解决问题……\");\r\n>       }\r\n>   }\r\n>   ```\r\n>\r\n> - 态代理工厂:ProxyFactory，直接用反射方式生成一个目标对象的代理对象，这里用了一个匿名内部类方式重写 InvocationHandler 方法，实现接口重写也差不多\r\n>\r\n>   \r\n>\r\n>   ```java\r\n>   public class ProxyFactory {\r\n>   \r\n>       // 维护一个目标对象\r\n>       private Object target;\r\n>   \r\n>       public ProxyFactory(Object target) {\r\n>           this.target = target;\r\n>       }\r\n>   \r\n>       // 为目标对象生成代理对象\r\n>       public Object getProxyInstance() {\r\n>           return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(),\r\n>                   new InvocationHandler() {\r\n>                       @Override\r\n>                       public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\r\n>                           System.out.println(\"请问有什么可以帮到您？\");\r\n>   \r\n>                           // 调用目标对象方法\r\n>                           Object returnValue = method.invoke(target, args);\r\n>   \r\n>                           System.out.println(\"问题已经解决啦！\");\r\n>                           return null;\r\n>                       }\r\n>                   });\r\n>       }\r\n>   }\r\n>   ```\r\n>\r\n> - 客户端：Client，生成一个代理对象实例，通过代理对象调用目标对象方法\r\n>\r\n>   \r\n>\r\n>   ```java\r\n>   public class Client {\r\n>       public static void main(String[] args) {\r\n>           //目标对象:程序员\r\n>           ISolver developer = new Solver();\r\n>           //代理：客服小姐姐\r\n>           ISolver csProxy = (ISolver) new ProxyFactory(developer).getProxyInstance();\r\n>           //目标方法：解决问题\r\n>           csProxy.solve();\r\n>       }\r\n>   }\r\n>   ```\r\n>\r\n> **Cglib 动态代理实现：**\r\n>\r\n> ![Cglib动态代理类图](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/spring-74da87af-20d1-4a5b-a212-3837a15f0bab.png)\r\n>\r\n> - 目标类：Solver，这里目标类不用再实现接口。\r\n>\r\n>   \r\n>\r\n>   ```java\r\n>   public class Solver {\r\n>   \r\n>       public void solve() {\r\n>           System.out.println(\"疯狂掉头发解决问题……\");\r\n>       }\r\n>   }\r\n>   ```\r\n>\r\n> - 动态代理工厂：\r\n>\r\n>   \r\n>\r\n>   ```java\r\n>   public class ProxyFactory implements MethodInterceptor {\r\n>   \r\n>      //维护一个目标对象\r\n>       private Object target;\r\n>   \r\n>       public ProxyFactory(Object target) {\r\n>           this.target = target;\r\n>       }\r\n>   \r\n>       //为目标对象生成代理对象\r\n>       public Object getProxyInstance() {\r\n>           //工具类\r\n>           Enhancer en = new Enhancer();\r\n>           //设置父类\r\n>           en.setSuperclass(target.getClass());\r\n>           //设置回调函数\r\n>           en.setCallback(this);\r\n>           //创建子类对象代理\r\n>           return en.create();\r\n>       }\r\n>   \r\n>       @Override\r\n>       public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {\r\n>           System.out.println(\"请问有什么可以帮到您？\");\r\n>           // 执行目标对象的方法\r\n>           Object returnValue = method.invoke(target, args);\r\n>           System.out.println(\"问题已经解决啦！\");\r\n>           return null;\r\n>       }\r\n>   \r\n>   }\r\n>   ```\r\n>\r\n> - 客户端：Client\r\n>\r\n>   \r\n>\r\n>   ```java\r\n>   public class Client {\r\n>       public static void main(String[] args) {\r\n>           //目标对象:程序员\r\n>           Solver developer = new Solver();\r\n>           //代理：客服小姐姐\r\n>           Solver csProxy = (Solver) new ProxyFactory(developer).getProxyInstance();\r\n>           //目标方法：解决问题\r\n>           csProxy.solve();\r\n>       }\r\n>   }\r\n>   ```\r\n\r\n**代理对象与advisor的关系**\r\n\r\n- 代理对象会间接去引用这些Advisor切面\r\n\r\n![image-20230423124430187](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423124430187.png)\r\n\r\n**@Aspect与advisor的关系**\r\n\r\n- 注解方式，整个类是一个切面，方法是通知，注解里的表达式是切点，这些注解的方式最终还是会转换成MethodInterceptor和Advisor这种方式的，而且转换的方式是以这种通知方法为单位来进行转换的，如有一个Aspect1的类它里面有一个环绕通知，最终会转换成一个advisor的切面，一个通知方法对应一个advisor切面，一个类中有多个通知方法就分别对应一个advisor切面，advisor切面相当于是一种更基本的或是Spring内置的这种切面形式，对于这些环绕通知，前置通知，后置通知也好，它们最终都会转换成Spring内置的MethodInterceptor的这种环绕通知的调用方式\r\n\r\n![image-20230423143827599](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423143827599.png)\r\n\r\n**AnnotationAwareAspectJAutoProxyCreator 自动代理后处理器**\r\n\r\n![image-20231202162832299](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20231202162832299.png)\r\n\r\n- wrapIfNecessary\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#initializeBean\r\n...\r\n      wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);//↓↓\r\n...\r\n//org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#postProcessAfterInitialization\r\n...\r\n    return wrapIfNecessary(bean, beanName, cacheKey);//↓↓\r\n...\r\n//AbstractAutoProxyCreator#wrapIfNecessary  \r\n    // Create proxy if we have advice.\r\n    ...\r\n        Object proxy = createProxy(\r\n                bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));\r\n    ...\r\n//AbstractAutoProxyCreator#createProxy\r\n...\r\n\treturn proxyFactory.getProxy(classLoader);\r\n...\r\n```\r\n\r\n\r\n\r\n![image-20230423144839058](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423144839058.png)\r\n\r\n- wrapIfNecessary-DEBUG\r\n\r\n![image-20230423150240536](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423150240536.png)\r\n\r\n- 代理创建时机\r\n  - 创建 bean 实例之前，如果你的bean自定义了 TargetSource，就会调用到自动代理后处理器来创建代理对象（用得较少，了解即可）；\r\n  - 在初始化阶段，会调用到这个自动代理后处理器，在初始化执行完以后，就要调用后处理器的 PostProcessAfterInitialization 方法，这时候就会用到这个自动代理后处理器来创建代理对象；\r\n  - 在依赖注入阶段，有个条件是产生循环依赖，产生循环依赖以后，它会在单例工厂池中通过一个工厂对象来间接的调用到我们的自动代理后处理器类来创建代理\r\n    - `org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#postProcessObjectFromFactoryBean`\r\n  \r\n  ```java\r\n  /**\r\n   * Applies the {@code postProcessAfterInitialization} callback of all\r\n   * registered BeanPostProcessors, giving them a chance to post-process the\r\n   * object obtained from FactoryBeans (for example, to auto-proxy them).\r\n   * @see #applyBeanPostProcessorsAfterInitialization\r\n   */\r\n  @Override\r\n  protected Object postProcessObjectFromFactoryBean(Object object, String beanName) {\r\n     return applyBeanPostProcessorsAfterInitialization(object, beanName);\r\n  }\r\n  ```\r\n\r\n![image-20230423150540283](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423150540283.png)\r\n\r\n![image-20230423150918284](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423150918284.png)\r\n\r\n**总结**\r\n\r\n- 最基本的切面是 Advisor，一个Aspect 切面对应一到多个 Advisor\r\n- 最基本的 Advice 是 Methodinterceptor，其它 Advice 最终都将适配为 Methodinterceptor\r\n- 创建代理的方式\r\n  - 实现了用户自定义接口，采用jdk 动态代理\r\n  - 没有实现用户自定义接口，采用 cglib 代理\r\n  - 设置了 setProxyTargetClass(true)，统一采用 cglib 代理\r\n- 切面、切点、通知等不会被代理\r\n- AnnotationAwareAspectJAutoProxyCreator 调用时机: 创建阶段、依赖注入阶段、**初始化阶段**\r\n\r\n\r\n\r\n------\r\n\r\n### **循环依赖的产生**\r\n\r\n* 首先要明白，bean 的创建要遵循一定的步骤，必须是创建、注入、初始化三步，这些顺序不能乱\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903085238916.png\" alt=\"image-20210903085238916\" style=\"zoom:50%;\" />\r\n\r\n* set 方法（包括成员变量）的循环依赖如图所示\r\n\r\n  * 可以在【a 创建】和【a set 注入 b】之间加入 b 的整个流程来解决\r\n  * 【b set 注入 a】 时可以成功，因为之前 a 的实例（未初始化）已经创建完毕\r\n\r\n  * a 的顺序，及 b 的顺序都能得到保障\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903085454603.png\" alt=\"image-20210903085454603\" style=\"zoom: 33%;\" />\r\n\r\n* 构造方法的循环依赖如图所示，显然无法用前面的方法解决\r\n\r\n![image-20230423164711640](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423164711640.png)\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n### **构造循环依赖的解决**\r\n\r\n* 思路1\r\n  * a 注入 b 的代理对象，这样能够保证 a 的流程走通\r\n  * 后续需要用到 b 的真实对象时，可以通过代理间接访问\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903091627659.png\" alt=\"image-20210903091627659\" style=\"zoom: 50%;\" />\r\n\r\n* 思路2\r\n  * a 注入 b 的工厂对象，让 b 的实例创建被推迟，这样能够保证 a 的流程先走通\r\n  * 后续需要用到 b 的真实对象时，再通过 ObjectFactory 工厂间接访问\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903091743366.png\" alt=\"image-20210903091743366\" style=\"zoom:50%;\" />\r\n\r\n![image-20230423164819587](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423164819587.png)\r\n\r\n* 示例1：用 @Lazy 为构造方法参数生成代理\r\n\r\n![image-20230423165237989](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423165237989.png)\r\n\r\n> @Lazy 可以加在成员变量上或方法参数上，也包括构造方法的参数上，加了之后 Spring 就去查找依赖注入的值时，就根据此注解进行解析，查找依赖注入的值会调用到 beanFactory 中的一个 resolveDependency 的方法判断是否该值加了 @Lazy 注解，加了就会进行代理对象的创建，否则返回原始对象\r\n\r\n* 示例2：用 ObjectFactory 或 ObjectProvider 延迟依赖对象的创建\r\n\r\n![image-20230423165816753](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423165816753.png)\r\n>\r\n> ObjectFactory 和 ObjectProvider 都是 Spring 提供的工厂接口\r\n\r\n* 示例3：用 @Scope 产生代理\r\n\r\n![image-20230423170840218](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423170840218.png)\r\n\r\n> 在 @Lazy 和 @Scope 这两种代理中选择创建代理的话，会选择 @Lazy，因为 @Scope 是一种比较 low 的解决方式，因为它是由代理工厂来生产代理对象的，所以这里就绕了一个弯，而且真正的目标也会在我们的单例池里存一份(scopeTarget.b)\r\n\r\n* 示例4：用 Provider 接口解决，原理上与 ObjectProvider 一样，Provider 接口是独立的 jar 包，需要加入依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>javax.inject</groupId>\r\n    <artifactId>javax.inject</artifactId>\r\n    <version>1</version>\r\n</dependency>\r\n```\r\n\r\n![image-20230423170300385](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423170300385.png)\r\n\r\n> Provider这个接口是java官方提供的一套工厂接口，在pom文件加入javax.inject的依赖，它的作用跟前面的两个工厂接口的作用是一样的，即可以推迟产品对象的获取\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n### 解决 set 循环依赖的原理\r\n\r\n**一级缓存 singletonObjects **\r\n\r\n![image-20230423152153455](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423152153455.png)\r\n\r\n作用是保证单例对象仅被创建一次\r\n\r\n* 第一次走 `getBean(\"a\")` 流程后，最后会将成品 a 放入 singletonObjects 一级缓存\r\n* 后续再走 `getBean(\"a\")` 流程时，先从一级缓存中找，这时已经有成品 a，就无需再次创建\r\n\r\n**一级缓存与循环依赖**\r\n\r\n![image-20230423152409029](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423152409029.png)\r\n\r\n一级缓存无法解决循环依赖问题，分析如下\r\n\r\n* 无论是获取 bean a 还是获取 bean b，走的方法都是同一个 getBean 方法，假设先走 `getBean(\"a\")`\r\n* 当 a 的实例对象创建，接下来执行 `a.setB()` 时，需要走 `getBean(\"b\")` 流程，红色箭头 1\r\n* 当 b 的实例对象创建，接下来执行 `b.setA()` 时，又回到了 `getBean(\"a\")` 的流程，红色箭头 2\r\n* 但此时 singletonObjects 一级缓存内没有成品的 a，陷入了死循环\r\n\r\n**二级缓存 singletonFactories（官方三级缓存） **\r\n\r\n![image-20230423152834032](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423152834032.png)\r\n\r\n解决思路如下：\r\n\r\n* 再增加一个 singletonFactories 缓存\r\n* 在依赖注入前，即 `a.setB()` 以及 `b.setA()` 将 a 及 b 的半成品对象（未完成依赖注入和初始化）放入此缓存\r\n* 执行依赖注入时，先看看 singletonFactories 缓存中是否有半成品的对象，如果有拿来注入，顺利走完流程\r\n\r\n对于上面的图\r\n\r\n* `a = new A()` 执行之后就会把这个半成品的 a 放入 singletonFactories 缓存，即 `factories.put(a)`\r\n* 接下来执行 `a.setB()`，走入 `getBean(\"b\")` 流程，红色箭头 3\r\n* 这回再执行到 `b.setA()` 时，需要一个 a 对象，有没有呢？有！\r\n* `factories.get()` 在 singletonFactories  缓存中就可以找到，红色箭头 4 和 5\r\n* b 的流程能够顺利走完，将 b 成品放入 singletonObject 一级缓存，返回到 a 的依赖注入流程，红色箭头 6\r\n\r\n**二级缓存与创建代理**\r\n\r\n![image-20230423153224037](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423153224037.png)\r\n\r\n二级缓存无法正确处理循环依赖并且包含有代理创建的场景，分析如下\r\n\r\n* spring 默认要求，在 `a.init` 完成之后才能创建代理 `pa = proxy(a)`\r\n* 由于 a 的代理创建时机靠后，在执行 `factories.put(a)` 向 singletonFactories 中放入的还是原始对象\r\n* 接下来箭头 3、4、5 这几步 b 对象拿到和注入的都是原始对象\r\n\r\n> 二级缓存的问题(singletonFactories)：依赖注入先发生，创建代理后发生，创建对象时代理对象还没有，即它只能注入那个原始的目标对象\r\n>\r\n> 解决办法：把代理对象提前创建，但Spring没有这么做，它还是想代理对象尽可能在最后来创建，即初始化后才创建，只有发生了循环依赖时它才提前创建代理\r\n\r\n**三级缓存 earlySingletonObjects（官方二级缓存） **\r\n\r\n![image-20230423154033542](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423154033542.png)\r\n\r\n简单分析的话，只需要将代理的创建时机放在依赖注入之前即可，但 spring 仍然希望代理的创建时机在 init 之后，只有出现循环依赖时，才会将代理的创建时机提前。所以解决思路稍显复杂：\r\n\r\n* 图中 `factories.put(fa)` 放入的既不是原始对象，也不是代理对象而是工厂对象 fa\r\n* 当检查出发生循环依赖时，fa 的产品就是代理 pa，没有发生循环依赖，fa 的产品是原始对象 a\r\n* 假设出现了循环依赖，拿到了 singletonFactories 中的工厂对象，通过在依赖注入前获得了 pa，红色箭头 5\r\n* 这回 `b.setA()` 注入的就是代理对象，保证了正确性，红色箭头 7\r\n* 还需要把 pa 存入新加的 earlySingletonObjects 缓存，红色箭头 6\r\n* `a.init` 完成后，无需二次创建代理，从哪儿找到 pa 呢？earlySingletonObjects 已经缓存，蓝色箭头 9\r\n* 当成品对象产生，放入 singletonObjects 后，singletonFactories 和 earlySingletonObjects 中的对象就没有用处，清除即可\r\n\r\n> 引入三级缓存(earlySingletonObjects)，并且还要引入一个工厂才能实现刚才的目的，这个工厂(理解为一个Lambda表达式fa-> pa || a)的作用是产生代理对象或原始对象，它会检查如果你将来发生了循环依赖，它就会提前创建生成代理对象并返回，如果没有发生循环依赖，它还是返回原始对象\r\n>\r\n\r\n\r\n\r\n**set循环依赖演示**\r\n\r\n![image-20230423154514318](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423154514318.png)\r\n\r\n- DEBUG - getSingleton\r\n\r\n![image-20230423160842182](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423160842182.png)\r\n\r\n![image-20230423160934610](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423160934610.png)\r\n\r\n![image-20230423160952450](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423160952450.png)\r\n\r\n> 起点由 refresh 第十一步（finishBeanFactoryInitialization）开始，初始化所有非延迟单例 bean\r\n>\r\n> ```java\r\n> protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) {\r\n>     ...\r\n> \tbeanFactory.preInstantiateSingletons();    \r\n> }\r\n> @Override\r\n> public void preInstantiateSingletons() throws BeansException {\r\n> \t...\r\n> \tList<String> beanNames = new ArrayList<>(this.beanDefinitionNames);\r\n> \t// Trigger initialization of all non-lazy singleton beans...\r\n> \tfor (String beanName : beanNames) {\r\n>          ...\r\n>          //非延迟单例 bean 获取   \r\n> \t\tgetBean(beanName);\r\n> \t\t...\r\n> \t}\r\n> }\r\n> //核心方法1\r\n> protected <T> T doGetBean(String name, @Nullable Class<T> requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException {\r\n>     //从1、2、3级缓存解决set循环依赖的核心方法，allowEarlyReference=true；debug核心点，设置面向all的beanName.equals(\"a\");哪个bean先注册就设置哪个\r\n>     //第一次getBean(\"a\")，sharedInstance=null，因为一级二级缓存都没有存储a或其代理对象，三级缓存还未添加\r\n> \tObject sharedInstance = getSingleton(beanName);\r\n>     //进入单例bean的创建步骤\r\n>     ...\r\n>     return createBean(beanName, mbd, args);\r\n>     ...\r\n> }\r\n> @Override\r\n> protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException {\r\n>     ...\r\n> \tObject beanInstance = doCreateBean(beanName, mbdToUse, args);\r\n>     ...\r\n> }\r\n> //bean的创建三阶段核心方法\r\n> protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException {\r\n>     ...\r\n>     //bean的实例化\r\n>     Object bean = instanceWrapper.getWrappedInstance();\r\n>     ...\r\n> \t//添加bean的三级缓存核心方法，存储Lambda表达式，后续调用getObject时会回调\r\n> \taddSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean));\r\n>     //记录原始bean，后续判断初始化阶段或之前有没有创建代理\r\n> \tObject exposedObject = bean;\r\n> \ttry {\r\n>          //依赖注入阶段\r\n> \t\tpopulateBean(beanName, mbd, instanceWrapper);\r\n> \t\t//初始化阶段\r\n>          exposedObject = initializeBean(beanName, exposedObject, mbd);\r\n> \t}\r\n>     ...\r\n> }\r\n> protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) {\r\n>     ...\r\n>     for (InstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().instantiationAware) {\r\n>         //遍历bean的后处理到AutowiredAnnotationBeanPostProcessor进行注解解析\r\n> \t\tPropertyValues pvsToUse = bp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName);\r\n>         ...\r\n>     }\r\n>     ...\r\n> }\r\n> ```\r\n>\r\n> - 循环依赖在依赖注入的关键点\r\n>   `postProcessProperties(...) -> inject(...):AutowiredMethodElement -> resolveMethodArguments(...) -> resolveDependency(...) -> doResolveDependency(...) -> resolveCandidate(...) -> getBean(\"b\")；`\r\n> - 进入 b 的创建过程，与 a 第一次 getBean 一样，然后依赖注入走到 `getBean(\"a\")`\r\n> - 第二次getBean(\"a\")，就会进入三级缓存获取 bean 的流程\r\n>\r\n> ```java\r\n> public Object getSingleton(String beanName) {\r\n> \treturn getSingleton(beanName, true);\r\n> }\r\n> //getSingleton三级缓存获取对象工厂的核心流程\r\n> ...\r\n> synchronized (this.singletonObjects) {\r\n> \t// Consistent creation of early reference within full singleton lock\r\n> \tsingletonObject = this.singletonObjects.get(beanName);\r\n> \tif (singletonObject == null) {\r\n> \t\tsingletonObject = this.earlySingletonObjects.get(beanName);\r\n> \t\tif (singletonObject == null) {\r\n> \t\t\tObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);\r\n> \t\t\tif (singletonFactory != null) {\r\n>                   //a第一次getBean时将自己到三级缓存里，singletonFactories=[{\"a\",()->{...}}]，所以当获取到a的工厂对象后调用getObject方法就会回调Lambda表达式里的代码块方法getEarlyBeanReference(beanName, mbd, bean)\r\n> \t\t\t\tsingletonObject = singletonFactory.getObject();\r\n> \t\t\t\tthis.earlySingletonObjects.put(beanName, singletonObject);\r\n> \t\t\t\tthis.singletonFactories.remove(beanName);\r\n> \t\t\t}\r\n> \t\t}\r\n> \t}\r\n> }\r\n> ...\r\n> ```\r\n>\r\n> ```java\r\n> protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {\r\n>    Object exposedObject = bean;\r\n>    ...\r\n>          exposedObject = bp.getEarlyBeanReference(exposedObject, beanName);\r\n>    ...\r\n>    return exposedObject;\r\n> }\r\n> //org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator#getEarlyBeanReference\r\n> @Override\r\n> public Object getEarlyBeanReference(Object bean, String beanName) {\r\n>  \tObject cacheKey = getCacheKey(bean.getClass(), beanName);\r\n>     //将准备进入代理的对象引入存入二级缓存，后续在初始化完成后进行代理增强的判断，无需再次创建代理\r\n>  \tthis.earlyProxyReferences.put(cacheKey, bean);\r\n>     //将返回代理后的对象：包名.$类名$$EnhancerBySpringCGLIB$$引用地址\r\n>  \treturn wrapIfNecessary(bean, beanName, cacheKey);\r\n> }\r\n> ```\r\n>\r\n> ```java\r\n> //#doGetBean\r\n> ...\r\n> if (sharedInstance != null && args == null) {\r\n>    ...\r\n>    beanInstance = getObjectForBeanInstance(sharedInstance, name, beanName, null);\r\n> }\r\n> ...\r\n> return adaptBeanInstance(name, beanInstance, requiredType);\r\n> //方法跳出 -> resolveCandidate(...) -> resolveDependency -> resolveMethodArguments(...) -> inject(...)\r\n> //#doResolveDependency\r\n>     ...\r\n>     instanceCandidate = descriptor.resolveCandidate(autowiredBeanName, type, this);\r\n>     ...\r\n>     return result;\r\n> \t}\r\n> \tfinally {\r\n>         //方法返回前执行\r\n> \t    ConstructorResolver.setCurrentInjectionPoint(previousInjectionPoint);\r\n> \t}\r\n> }\r\n> //#resolveDependency\r\n> ...\r\n>     if (result == null) {\r\n>       //result为a的代理对象\r\n> \t  result = doResolveDependency(descriptor, requestingBeanName, autowiredBeanNames, typeConverter);\r\n> \t}\r\n> \treturn result;\r\n> ...\r\n>     \r\n> //#inject\r\n>     else {\r\n>         arguments = resolveMethodArguments(method, bean, beanName);\r\n>     }\r\n>     if (arguments != null) {\r\n>         try {\r\n>             ReflectionUtils.makeAccessible(method);\r\n>             //反射执行setA注入给B\r\n>             method.invoke(bean, arguments);\r\n>             //输出：- setA(class 包名.$A$$EnhancerBySpringCGLIB$$5fbc14f4) \r\n>         }\r\n>         catch (...) {...}\r\n>     }\r\n> ...\r\n> ```\r\n>\r\n> - b依赖注入完后跳出 populateBean 进入b的初始化过程\r\n> - b整个创建流程走完最后也是方法跳出到resolveCandidate方法，进行a的依赖注入流程，反射执行setB注入给a\r\n> - a的初始化走完，进入第二次缓存检查，防止代理对象的遗漏\r\n>\r\n> ```java\r\n> //doCreateBean\r\n> ...\r\n> //原始对象\r\n> Object exposedObject = bean;\r\n> \ttry {\r\n> \t\tpopulateBean(beanName, mbd, instanceWrapper);\r\n>          //初始化后对象，因为在初始化阶段a没有进行代理创建，但是b注入a时提前把a的代理对象创建并进行值注入，所以后面进行第二次缓存检查获取代理对象，防止遗漏\r\n> \t\texposedObject = initializeBean(beanName, exposedObject, mbd);\r\n> \t}\r\n> ...\r\n> if (earlySingletonExposure) {\r\n>     //从二级缓存获取a的代理对象\r\n>    Object earlySingletonReference = getSingleton(beanName, false);\r\n>    if (earlySingletonReference != null) {\r\n>       if (exposedObject == bean) {\r\n>           //将a的原始引用指向代理对象引用\r\n>          exposedObject = earlySingletonReference;\r\n>       }\r\n>       ...\r\n>    }\r\n> }\r\n> ...\r\n> ```\r\n\r\n\r\n\r\n- set循环依赖 - 二级缓存作用1\r\n\r\n![image-20230423162034164](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423162034164.png)\r\n\r\n```java\r\n//org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#doCreateBean\r\n...\r\n    \t//bean为原始对象\r\n    \tObject bean = instanceWrapper.getWrappedInstance();\r\n\t\t...\r\n             //发生循环依赖，将对象加入三级缓存singletonFactories\r\n\t\t\taddSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean));\r\n\t\t...\r\n\t\t// Initialize the bean instance.\r\n\t\tObject exposedObject = bean;\r\n\t\ttry {\r\n             //依赖注入\r\n\t\t\tpopulateBean(beanName, mbd, instanceWrapper);\r\n\t\t\t//初始化后的bean\r\n             exposedObject = initializeBean(beanName, exposedObject, mbd);\r\n\t\t}\r\n\t\tcatch (Throwable ex) {...}\r\n\r\n\t\tif (earlySingletonExposure) {\r\n             //获取一级和二级缓存是否有该目前的bean，但不会到三级缓存中获取，目的是防止bean提前创建代理后在二级缓存中的遗漏\r\n\t\t\tObject earlySingletonReference = getSingleton(beanName, false);\r\n\t\t\tif (earlySingletonReference != null) {\r\n\t\t\t\tif (exposedObject == bean) {\r\n                      //防止二级缓存遗漏，若提前创建了代理直接改变引用即可，否则就是原始对象了（提前创建代理发生在doGetBean一开始调用的getSingleton(beanName)，此方法就会在三级缓存singletonFactories对要注入的bean进行提前创建代理，或者说B要注入A时，）\r\n\t\t\t\t\texposedObject = earlySingletonReference;\r\n\t\t\t\t}\r\n                 //初始化阶段就创建代理了，直接返回代理对象\r\n\t\t\t\telse if (!this.allowRawInjectionDespiteWrapping && hasDependentBean(beanName)) {\r\n\t\t\t\t\t...\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n...\r\n```\r\n\r\n\r\n\r\n- set循环依赖 - 二级缓存作用2\r\n\r\n![image-20230423163506278](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423163506278.png)\r\n\r\n- set循环依赖 - 如何避免重复创建代理\r\n\r\n![image-20230423163952262](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423163952262.png)\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n### 总结\r\n\r\n- 单例 set 方法(包括成员变量)循环依赖，Spring 会利用三级缓存解决，无需额外配置\r\n  - 一级缓存存放成品对象\r\n  - 二级缓存存放发生了循环依赖时的产品对象 (可能是原始 bean，也可能是代理 bean)\r\n  - 三级缓存存放工厂对象，发生循环依赖时，会调用工厂获取产品\r\n  - Spring 期望在初始化时创建代理，但如果发生了循环依赖，会由工厂提前创建代理，后续初始化时就不必重复创建代理\r\n  - 二级缓存的意义在于，如果提前创建了代理对象，在最后的阶段需要从二级缓存中获取此代理对象，作为最终结果\r\n- 构造方法及多例循环依赖解决办法\r\n  - @Lazy\r\n  - @Scope\r\n  - ObjectFactory & ObjectProvider\r\n  - Provider\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n## 4. Spring 事务失效\r\n\r\n### **1. 抛出检查异常导致事务不能正确回滚**\r\n\r\n* 问题：出现了数据不一致情况（总金额2000=>1500，被系统吃了500）\r\n\r\n* 原因：Spring 默认只会回滚非检查异常\r\n\r\n* 解法：配置 rollbackFor 属性\r\n  * `@Transactional(rollbackFor = Exception.class)`\r\n\r\n![image-20230422140026927](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422140026927.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **2. 业务方法内自己 try-catch 异常导致事务不能正确回滚**\r\n\r\n* 问题：出现了数据不一致情况（总金额2000=>1500，被系统吃了500）\r\n\r\n* 原因：事务通知只有捉到了目标抛出的异常，才能进行后续的回滚处理，如果目标自己处理掉异常，事务通知无法知悉\r\n\r\n* 解法1：异常原样抛出\r\n  * 在 catch 块添加 `throw new RuntimeException(e);`\r\n\r\n* 解法2：手动设置 `TransactionStatus.setRollbackOnly()`\r\n  * 在 catch 块添加 `TransactionInterceptor.currentTransactionStatus().setRollbackOnly();`\r\n\r\n![image-20230422140710210](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422140710210.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **3. aop 切面顺序导致导致事务不能正确回滚**\r\n\r\n* 原因：事务切面优先级最低，但如果自定义的切面优先级和他一样，则还是自定义切面在内层，这时若自定义切面没有正确抛出异常，事务也不会回滚\r\n\r\n* 解法1、2：同情况2 中的解法:1、2\r\n* 解法3：调整切面顺序，在 MyAspect 上添加 `@Order(Ordered.LOWEST_PRECEDENCE - 1)` （不推荐）\r\n\r\n![image-20230422141539702](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422141539702.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **4. 非 public 方法导致的事务失效**\r\n\r\n* 原因：Spring 为方法创建代理、添加事务通知、前提条件都是该方法是 public 的；因为Spring中有个检查，它发现你的方法不是public，去读取事务的属性时就会返回null，即不会返回事务的属性，从而不会加这些事务的相关配置\r\n\r\n* 解法1：改为 public 方法\r\n* 解法2：添加 bean 配置如下（不推荐）\r\n\r\n```java\r\n@Bean\r\npublic TransactionAttributeSource transactionAttributeSource() {\r\n    return new AnnotationTransactionAttributeSource(false);\r\n}\r\n```\r\n\r\n![image-20230422141914663](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422141914663.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **5. 父子容器导致的事务失效**\r\n\r\n现在配置了父子容器，WebConfig 对应子容器，AppConfig 对应父容器，发现事务依然失效\r\n\r\n* 原因：子容器扫描范围过大，本来只需扫描controller，但是把service也扫了进来，service虽然有事务注解，但是子容器配置类并没有开启事务配置，因此事务失效\r\n\r\n![image-20231205214825213](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20231205214825213.png)\r\n\r\n* 解法1：各扫描各的，不要图简便\r\n\r\n* 解法2：不要用父子容器，所有 bean 放在同一容器\r\n\r\n![image-20230422143148085](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422143148085.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **6. ★调用本类方法导致传播行为失效★**\r\n\r\n```java\r\n@Transactional\r\npublic void foo(){\r\n    bar();\r\n}\r\n@Transactional\r\npublic void bar(){\r\n}\r\n```\r\n\r\n* 原因：本类方法调用不经过代理，因此无法增强\r\n\r\n* 解法1：依赖注入自己（代理）来调用\r\n\r\n* 解法2：通过 AopContext 拿到代理对象，来调用（代理模式是在运行期间生成一些代理的新的字节码来实现功能的增强）\r\n\r\n* 解法3：通过 CTW（编译时织入），LTW （加载时织入）实现功能增强（原理都是修改类的字节码来实现功能增强）\r\n\r\n解法1\r\n\r\n```java\r\n@Service\r\npublic class Service6 {\r\n\t@Autowired\r\n\tprivate Service6 proxy; // 本质上是一种循环依赖\r\n    @Transactional\r\n    public void foo()  {\r\n\t\tproxy.bar();\r\n    }\r\n    @Transactional\r\n    public void bar() {\r\n    }\r\n}\r\n```\r\n\r\n解法2，还需要在 AppConfig 上添加 `@EnableAspectJAutoProxy(exposeProxy = true)`\r\n\r\n```java\r\n@Service\r\npublic class Service6 {\r\n    @Transactional\r\n    public void foo(){\r\n\t\t((Service6) AopContext.currentProxy()).bar();\r\n    }\r\n    @Transactional\r\n    public void bar(){\r\n    }\r\n}\r\n```\r\n\r\n![image-20230422143959797](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422143959797.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **7. @Transactional 没有保证原子行为**\r\n\r\n```java\r\n@Transactional(rollbackFor = Exception.class)\r\npublic void transfer(int from, int to, int amount) {\r\n    int fromBalance = accountMapper.findBalanceBy(from);\r\n    logger.debug(\"更新前查询余额为: {}\", fromBalance);\r\n    if (fromBalance - amount >= 0) {\r\n        accountMapper.update(from, -1 * amount);\r\n        accountMapper.update(to, amount);\r\n    }\r\n}\r\n```\r\n\r\n上面的代码实际上是有 bug 的，假设 from 余额为 1000，两个线程都来转账 1000，可能会出现扣减为负数的情况\r\n\r\n* 原因：事务的原子性仅涵盖 insert、update、delete、select … for update 语句，select 方法并不阻塞\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903120436365.png\" alt=\"image-20210903120436365\" style=\"zoom: 50%;\" />\r\n\r\n* 如上图所示，红色线程和蓝色线程的查询都发生在扣减之前，都以为自己有足够的余额做扣减\r\n\r\n![image-20230422144457753](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422144457753.png)\r\n\r\n\r\n\r\n------\r\n\r\n### **8. ★@Transactional 方法导致的 synchronized 失效★**\r\n\r\n针对上面的问题，能否在方法上加 synchronized 锁来解决呢？\r\n\r\n答案是不行，原因如下：\r\n\r\n* synchronized 保证的仅是目标方法的原子性，环绕目标方法的还有 commit 等操作，它们并未处于 sync 块内\r\n* 可以参考下图发现，蓝色线程的查询只要在红色线程提交之前执行，那么依然会查询到有 1000 足够余额来转账（实际已经扣过1000了，那么最终结果就是 -1000）\r\n\r\n![image-20210903120800185](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903120800185.png)\r\n\r\n* 解法1：synchronized 范围应扩大至代理方法调用（DEBUG来Commit）\r\n\r\n![image-20230422145400664](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422145400664.png)\r\n\r\n* 解法2：使用 select … for update 替换 select（推荐使用数据库层面来解决）\r\n\r\n![image-20230422145452610](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422145452610.png)\r\n\r\n\r\n\r\n------\r\n\r\n## 5. Spring MVC 执行流程\r\n\r\n**概要**\r\n\r\n我把整个流程分成三个阶段\r\n\r\n- 初始化阶段\r\n- 匹配阶段\r\n- 执行阶段\r\n\r\n### **初始化阶段**\r\n\r\n![image-20231206162537789](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20231206162537789.png)\r\n\r\n1. 在 Web 容器第一次用到 DispatcherServlet 的时候，会创建其对象并执行 init 方法\r\n\r\n2. init 方法内会创建 Spring Web 容器，并调用容器 refresh 方法\r\n\r\n3. refresh 过程中会创建并初始化 SpringMVC 中的重要组件， 例如 MultipartResolver，HandlerMapping，HandlerAdapter，HandlerExceptionResolver、ViewResolver 等\r\n\r\n4. 容器初始化后，会将上一步初始化好的重要组件，赋值给 DispatcherServlet 的成员变量，供后续使用\r\n\r\n![](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903140657163.png)\r\n\r\n![image-20230422150617027](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422150617027.png)\r\n\r\n> - **DispatcherServlet** 是 SpringMVC 中的一个非常核心的类，由 web 容器(tomcat)创建和初始化，传统的 SpringMVC 跟 Spring 整合的时候还是由 Tomcat 来创建它的，当然，到了 SpringBoot 里，这个 DispatcherServlet 就有可能由 Spring 容器自身来创建和初始化\r\n> - 除 MultipartResovler 可能只有一个实例以外，其他的重要组件同一个类型可能有多个实例对象存在这个 Spring 容器中\r\n> - **HandlerMapping** 是做请求映射的，就是根据你的请求路径找到一个对应的控制器和它相关的方法来处理这个请求，就是把浏览器的请求映射到我们 Spring 中一个控制器的方法调用上\r\n> - **HandlerAdapter** 就是负责真正去调用这个控制器的控制方法来处理请求，如果在调用这个控制器的控制方法的过程中出现了异常时由**HandlerExceptionResovler**来处理异常，最终这个控制方法执行完毕后，就会封装成一个 ModelAndView 对象，但这个对象中的视图可能只包含一个字符串的名字，那我们需要把这个字符串的名字去解析成一个视图对象由 **ViewResovler** 负责把名字解析成视图对象，视图对象内部就可以根据不同的实现去选择是跳转到JSP还是跳转到一些模板引擎，去执行这个视图的渲染工作\r\n> - 最后的这个 **MultipartResovler** 并不是必须的，它是用在文件的上传时处理这种 Multipart 格式的表单数据\r\n>\r\n> **Spring MVC 的核心组件**？\r\n>\r\n> 1. **DispatcherServlet**：前置控制器，是整个流程控制的**核心**，控制其他组件的执行，进行统一调度，降低组件之间的耦合性，相当于总指挥。\r\n> 2. **Handler**：处理器，完成具体的业务逻辑，相当于 Servlet 或 Action。\r\n> 3. **HandlerMapping**：DispatcherServlet 接收到请求之后，通过 HandlerMapping 将不同的请求映射到不同的 Handler。\r\n> 4. **HandlerInterceptor**：处理器拦截器，是一个接口，如果需要完成一些拦截处理，可以实现该接口。\r\n> 5. **HandlerExecutionChain**：处理器执行链，包括两部分内容：Handler 和 HandlerInterceptor（系统会有一个默认的 HandlerInterceptor，如果需要额外设置拦截，可以添加拦截器）。\r\n> 6. **HandlerAdapter**：处理器适配器，Handler 执行业务方法之前，需要进行一系列的操作，包括表单数据的验证、数据类型的转换、将表单数据封装到 JavaBean 等，这些操作都是由 HandlerApater 来完成，开发者只需将注意力集中业务逻辑的处理上，DispatcherServlet 通过 HandlerAdapter 执行不同的 Handler。\r\n> 7. **ModelAndView**：装载了模型数据和视图信息，作为 Handler 的处理结果，返回给 DispatcherServlet。\r\n> 8. **ViewResolver**：视图解析器，DispatcheServlet 通过它将逻辑视图解析为物理视图，最终将渲染结果响应给客户端。\r\n\r\n\r\n\r\n------\r\n\r\n### **匹配阶段**\r\n\r\n1. 用户发送的请求统一到达前端控制器 DispatcherServlet\r\n\r\n2. DispatcherServlet 遍历所有 HandlerMapping ，找到与路径匹配的处理器\r\n\r\n   ① HandlerMapping 有多个，每个 HandlerMapping 会返回不同的处理器对象，谁先匹配，返回谁的处理器。其中能识别 @RequestMapping 的优先级最高\r\n\r\n   ② 对应 @RequestMapping 的处理器是 HandlerMethod，它包含了控制器对象和控制器方法信息\r\n\r\n   ③ 其中路径与处理器的映射关系在 HandlerMapping 初始化时就会建立好\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903141017502.png\" alt=\"image-20210903141017502\" style=\"zoom:80%;\" />\r\n\r\n3. 将 HandlerMethod 连同匹配到的拦截器，生成调用链对象 HandlerExecutionChain 返回\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903141124911.png\" alt=\"image-20210903141124911\" style=\"zoom:80%;\" />\r\n\r\n4. 遍历HandlerAdapter 处理器适配器，找到能处理 HandlerMethod 的适配器对象，开始调用\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903141204799.png\" alt=\"image-20210903141204799\" style=\"zoom:80%;\" />\r\n\r\n![image-20230422151134584](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422151134584.png)\r\n\r\n> - DispatcherServlet主要职责是作为一个左请求的入口，但是接下来处理请求是交给其他一些处理器对象来完成，它并不负责处理具体的请求，因此接下来会遍历所有的HandlerMapping，借助这个HandlerMapping找到与当前路径能够匹配的处理器，由处理器对象来处理请求，并不是一个请求返回多个处理器，最终只能一个请求由一个处理器对象进行处理，即谁先与当前路径匹配上，就返回谁的处理\r\n> - @RequestMapping对应的处理器对象HandlerMethod，它包含了它属于哪个controller对象以及对应的controller方法的这些信息，通过HandlerMethod可以得到它将来要调用哪个controller对象和调用哪个controller方法，即反射调用\r\n\r\n\r\n\r\n------\r\n\r\n### **调用阶段**\r\n\r\n1. 执行拦截器 preHandle\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903141445870.png\" alt=\"image-20210903141445870\" style=\"zoom: 67%;\" />\r\n\r\n2. 由 HandlerAdapter 调用 HandlerMethod\r\n\r\n   ① 调用前处理不同类型的参数\r\n\r\n   ② 调用后处理不同类型的返回值\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903141658199.png\" alt=\"image-20210903141658199\" style=\"zoom:67%;\" />\r\n\r\n3. 第 2 步没有异常\r\n\r\n   ① 返回 ModelAndView\r\n\r\n   ② 执行拦截器 postHandle 方法\r\n\r\n   ③ 解析视图，得到 View 对象，进行视图渲染\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903141749830.png\" alt=\"image-20210903141749830\" style=\"zoom:67%;\" />\r\n\r\n4. 第 2 步有异常，进入 HandlerExceptionResolver 异常处理流程\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210903141844185.png\" alt=\"image-20210903141844185\" style=\"zoom:67%;\" />\r\n\r\n5. 最后都会执行拦截器的 afterCompletion 方法\r\n\r\n6. 如果控制器方法标注了 @ResponseBody 注解，则在第 2 步，就会生成 json 结果，并标记 ModelAndView 已处理，这样就不会执行第 3 步的视图渲染\r\n\r\n![image-20230426024421958](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426024421958.png)\r\n\r\n> - 执行阶段首先会调用执行链中的拦截器的 preHandle 方法，**由外到内依次调用**，调用这个 preHandle 方法的时候，这个方法会有一个返回值，返回值为真表示放行，会进行后续的调用，为假表示被拦截器拦截下来了，就不会往后走了\r\n> - HandlerAdapter 调用 HandlerMethod，虽然知道哪个bean的哪个方法，但是方法调用之前得给方法准备所有的参数，因为控制器方法的参数是十分复杂的，多种多样，既可以是 Request、Respone、Session之类，也可能是一些模型，model 对象，还有可能是方法的参数来自于请求参数，路径参数，各种情况都有，你得把这些参数进行一个解析，把参数都准备好了，就可以反射调用这个 HandlerMethod 中的 method 方法，通过 method 的反射调用执行 invoke 方法，然后把 bean 传进去，把刚才准备好的参数传入 invoke 方法并执行，这样就完成了控制器方法的一个调用，等调用结束后还要处理返回值，这个控制器方法的返回值也是多种多样，有可能返回的是一个字符串类型，Map 集合，List 集合，或者 JavaBean，都有可能，因此还要对这个返回值进行一个处理，那返回值处理完了，这个调用就暂时结束了\r\n> - 结束之后分成两种情况，一种是没有异常，一种是有异常\r\n>   - 没有异常\r\n>     1. 把上一步结果返回统一封装成 ModelAndView，不管之前是什么类型(字符串..)，最终都会封装成 ModelAndView 对象，此对象里面就包含模型数据，视图相关的信息\r\n>     2. 返回了 ModelAndView 对象之后又回到拦截器，这回是调用拦截器的 postHandle 方法，这个 postHandle 方法调用的次序正好和 preHandle 方法调用的次序相反，即由内至外，把所有的 postHandle 也调用一遍后，最终才处理这个 ModelAndView\r\n>     3. ModelAndView 处理的时候，第一个要处理的是这个视图，因为前面的调用仅仅返回的是一个字符串的视图名称，而不是一个视图对象，因此要借助一个叫做 ViewResovler 视图解析器，把这种字符串名字解析成一个真正的视图对象，当然，如果返回的直接是视图对象，它就直接用了\r\n>     4. 解析好视图之后，它就可以进入这个视图的渲染，它会把模型数据根据视图的实现不同先存储到不同的位置，如 JSP 的实现，它就把模型数据取出来放入到 Request 作用域，接下来转发到 JSP 的视图，JSP 视图里就可以从作用域中取出模型数据，最后渲染生成一个 html 并返回\r\n>     5. 等这个视图处理完后，还有一个收尾工作，它最终还会回到我们的拦截器，由内到外的顺序调用 afterCompletion 方法，等所有的 afterCompletion 调用完后，整个的执行流程就结束了\r\n>   - 出现了异常\r\n>     1. 出现异常之后，ModelAndView 就没有了，而是拿到一个 Exception 的异常对象，它有一个 catch 块可以捕捉到异常对象\r\n>     2. 捉住到异常对象以后，DispatcherServlet 里还有一个 HandlerExceptionResolver 成员，它们就是用来处理异常的，按照优先级次序，谁先匹配到这个异常对象谁就来处理，挑出一个 HandlerExceptionResolver 来处理异常\r\n>     3. 当然，处理完异常，它也会走到最后的 afterCompletion 方法方法由内向外去逐一调用，这个时候就不会调用 postHandle 方法，因为出现异常了，它就没机会执行这个 postHandle\r\n> - 无论以后有没有异常都会执行到拦截器的 afterCompletion 方法\r\n> - 还有一点，就是如果我们的控制器方法标注了 @ResponseBody 注解，这个时候就不是跳转到视图了，它是要返回这种 Json 数据，即在 HandlerAdapter 调用 HandlerMethod 时，有一个阶段是处理返回值，即在处理返回值的阶段去检查是不是这个方法上标注了 @ResponseBody 注解，如果是的话，它就会标记 ModelAndView 已处理，后续就不会去执行视图渲染了，即在处理返回值阶段的时候生成一个叫 MessageConverter 的消息转换器，生成 Json 作为最终结果返回，就不会走视图渲染的流程，当然，这里的 postHandle 和 afterCompletion 这些拦截器的处理操作还是会执行\r\n\r\n\r\n\r\n------\r\n\r\n### **总结**\r\n\r\n![Spring MVC的工作流程](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/spring-e29a122b-db07-48b8-8289-7251032e87a1.png)\r\n\r\n1. 客户端向服务端发送一次请求，这个请求会先到前端控制器 DispatcherServlet(也叫中央控制器)。\r\n2. DispatcherServlet 接收到请求后会调用 HandlerMapping 处理器映射器。由此得知，该请求该由哪个 Controller 来处理（并未调用 Controller，只是得知）\r\n3. DispatcherServlet 调用 HandlerAdapter 处理器适配器，告诉处理器适配器应该要去执行哪个 Controller\r\n4. HandlerAdapter 处理器适配器去执行 Controller 并得到 ModelAndView(数据和视图)，并层层返回给 DispatcherServlet\r\n5. DispatcherServlet 将 ModelAndView 交给 ViewReslover 视图解析器解析，然后返回真正的视图。\r\n6. DispatcherServlet 将模型数据填充到视图中\r\n7. DispatcherServlet 将结果响应给客户端\r\n\r\n**Spring MVC** 虽然整体流程复杂，但是实际开发中很简单，大部分的组件不需要开发人员创建和管理，只需要通过配置文件的方式完成配置即可，真正需要开发人员进行处理的只有 **Handler（Controller）** 、**View** 、**Model**。\r\n\r\n当然我们现在大部分的开发都是前后端分离，Restful 风格接口，后端只需要返回 Json 数据就行了。\r\n\r\n\r\n\r\n------\r\n\r\n\r\n\r\n## 5.1 SpringMVC Restful 执行流程\r\n\r\nPS:这是一道全新的八股，毕竟 ModelAndView 这种方式应该没人用了吧？现在都是前后端分离接口，八股也该更新换代了。\r\n\r\n我们都知道 Restful 接口，响应格式是 json，这就用到了一个常用注解：**@ResponseBody**\r\n\r\n\r\n\r\n```java\r\n    @GetMapping(\"/user\")\r\n    @ResponseBody\r\n    public User user(){\r\n        return new User(1,\"张三\");\r\n    }\r\n```\r\n\r\n加入了这个注解后，整体的流程上和使用 ModelAndView 大体上相同，但是细节上有一些不同：\r\n\r\n![image-20231206192404673](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20231206192404673.png)\r\n\r\n1. 客户端向服务端发送一次请求，这个请求会先到前端控制器 DispatcherServlet\r\n\r\n2. DispatcherServlet 接收到请求后会调用 HandlerMapping 处理器映射器。由此得知，该请求该由哪个 Controller 来处理\r\n\r\n3. DispatcherServlet 调用 HandlerAdapter 处理器适配器，告诉处理器适配器应该要去执行哪个 Controller\r\n\r\n4. Controller 被封装成了 ServletInvocableHandlerMethod，HandlerAdapter 处理器适配器去执行 invokeAndHandle 方法，完成对 Controller 的请求处理\r\n\r\n5. HandlerAdapter 执行完对 Controller 的请求，会调用 HandlerMethodReturnValueHandler 去处理返回值，主要的过程：\r\n\r\n   5.1. 调用 RequestResponseBodyMethodProcessor，创建 ServletServerHttpResponse（Spring 对原生 ServerHttpResponse 的封装）实例\r\n\r\n   5.2.使用 HttpMessageConverter 的 write 方法，将返回值写入 ServletServerHttpResponse 的 OutputStream 输出流中\r\n\r\n   5.3.在写入的过程中，会使用 JsonGenerator（默认使用 Jackson 框架）对返回值进行 Json 序列化\r\n\r\n6. 执行完请求后，返回的 ModealAndView 为 null，ServletServerHttpResponse 里也已经写入了响应，所以不用关心 View 的处理\r\n\r\n\r\n\r\n------\r\n\r\n## 6. Spring 注解\r\n\r\n**lang**\r\n\r\nlang 中的注解是 Spring 框架内部自己使用的一些注解\r\n\r\n- @NonNull\r\n- @NonNullApi\r\n- @NonNullFields\r\n- @Nullable\r\n- @UsesSunMisc\r\n\r\n\r\n\r\n------\r\n\r\n### **事务注解**\r\n\r\n* **@EnableTransactionManagement**，会额外加载 4 个 bean\r\n  * BeanFactoryTransactionAttributeSourceAdvisor 事务切面类\r\n  * TransactionAttributeSource 用来解析事务属性\r\n  * TransactionInterceptor 事务拦截器\r\n  * TransactionalEventListenerFactory 事务监听器工厂\r\n  \r\n  ![image-20230422152841010](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422152841010.png)\r\n* **@Transactional**\r\n\r\n\r\n\r\n------\r\n\r\n**监控**\r\n\r\n- @EnableMBeanExport\r\n- @ManagedAttribute\r\n- @ManagedMetric\r\n- @ManagedNotification\r\n- @ManagedNotifications\r\n- @ManagedOperation\r\n- @ManagedOperationParameter\r\n- @ManagedOperationParameters\r\n- @ManagedResource\r\n\r\n**核心**\r\n\r\n- @AliasFor是给注解起别名(了解)\r\n\r\n* **@Order**是用来控制一些bean它们的一些执行顺序，最低优先级=整数最大值\r\n\r\n**事件、调度、异步**\r\n\r\n- @EventListener\r\n- @TransactionalEventListener\r\n- @EnableAsync\r\n- @Async\r\n- @EnableScheduling\r\n- @Scheduled\r\n- @Schedules\r\n\r\n------\r\n\r\n### **切面**\r\n\r\n* **@EnableAspectJAutoProxy**\r\n  * 会加载 AnnotationAwareAspectJAutoProxyCreator，它是一个 bean 后处理器，用来创建代理\r\n  * 如果没有配置 @EnableAspectJAutoProxy，又需要用到代理（如事务）则会使用 InfrastructureAdvisorAutoProxyCreator 这个 bean 后处理器\r\n\r\n![image-20230422154010262](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422154010262.png)\r\n\r\n> - @EnableAspectJAutoProxy是启用我们的AOP这种自动代理，看看它@Import的实现，后面的类型加入 AnnotationAwareAspectJAutoProxyCreator 的 bean 后处理器，这个后处理会在 bean 的初始化后期帮助我们检查看看需不需添加一个代理，如果你的 bean 跟某个切点表达式匹配上了，它就会为你的 bean 生成一个代理对象，最终将代理对象放入单例池去代替掉目标的 target 对象，说白了，它就是帮助我们产生这个代理来协助 AOP 增强的，当然，这个代理的执行时机绝大多数情况都是在初始化之后生成代理的，如果遇到了循环依赖又需要代理的情况，它会让代理的生成提前，在这个依赖注入之前就生成代理\r\n> - @Around、@Before、@After 这些与切面通知相关注解实际上是属于第三方库 AspectJ 提供的，Spring 只是借用了人家第三方的注解，并不是 Spring 自己的\r\n\r\n### **组件扫描与配置类**\r\n\r\n* @Component\r\n\r\n* @Controller\r\n\r\n* @Service\r\n\r\n* @Repository\r\n\r\n> @Component、@Controller、@Service、@Repository 这四个是配合做组件扫描的，标注了这些注解的类将来一旦组件扫描到它了，就会把它纳入到 Spring 的容器管理，跟它们配合使用的还有 @ComponentScan，它可以指定一个起始包名，它就会以这个起始包名开始去扫描这个包以及这个包的所有子孙后代包，扫描这些注解，扫描到就把它们加入到 Spring 的容器管理中\r\n\r\n* @ComponentScan\r\n\r\n* @Conditional（Spring 自身就有的功能，并不是只有 SpringBoot）是在这个组件扫描时做一些条件装配，符合条件的就加入到 Spring 容器中，如果判断条件不成立，即使扫描到了，它也不会加入的，它除了和我们组件扫描时候配合以外，还可以跟这个配置类解析 @Bean时配合使用，也会判断是否满足条件\r\n\r\n* **@Configuration**\r\n\r\n  * 配置类其实相当于一个工厂，标注 @Bean 注解的方法相当于工厂方法\r\n\r\n  ![image-20230422190940503](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422190940503.png)\r\n\r\n  * @Bean 不支持方法重载，如果有多个重载方法，仅有一个能入选为工厂方法\r\n\r\n  ![image-20230422191323803](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422191323803.png)\r\n\r\n  * @Configuration 默认会为标注的类生成代理，其目的是保证 @Bean 方法相互调用时，仍然能保证其单例特性\r\n\r\n  ![image-20230422191956615](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422191956615.png)\r\n\r\n  * @Configuration 中如果含有 BeanFactory 后处理器的 bean 要创建，则实例工厂方法会导致 MyConfig 提前创建，造成其依赖注入失败，解决方法是改用静态工厂方法或直接为 @Bean 的方法参数依赖注入，针对 Mapper 扫描可以改用注解方式\r\n\r\n  ![image-20230422192558594](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422192558594.png)\r\n\r\n* @Bean 是标注在配置类里的那些方法（工厂方法），标注 @Configuration 的配置类（工厂类）来定义 @Bean 方法返回的 bean \r\n\r\n* @Import \r\n\r\n  * 四种用法\r\n\r\n    ① 引入单个 bean\r\n\r\n    ② 引入一个配置类\r\n\r\n    ③ 通过 Selector 引入多个类\r\n\r\n    ④ 通过 beanDefinition 注册器引入多个类\r\n\r\n  ![image-20230422193333726](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422193333726.png)\r\n\r\n  * 解析规则\r\n\r\n    * 同一配置类中，@Import 先解析  @Bean 后解析\r\n    * 同名定义，默认后面解析的会覆盖前面解析的\r\n    * 不允许覆盖的情况下，如何能够让 MyConfig(主配置类) 的配置优先? (虽然覆盖方式能解决)\r\n    * 采用 DeferredImportSelector，因为它最后工作，可以简单认为先解析 @Bean，再 Import\r\n\r\n  ![image-20230422215656267](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422215656267.png)\r\n\r\n  > @Import是导入其他的配置类或普通类；导入其他的一些Selector根据它们返回的bean的名字把它们加入到当前的Spring容器中\r\n\r\n* @Lazy\r\n\r\n  * 加在类上，表示此类延迟实例化、初始化\r\n  * 加在方法参数上，此参数会以代理方式注入\r\n\r\n  > 有两个用途，一个用途是标注在类上，表示这个类是延迟初始化和实例化的，即一开始你没有用到的时候，它是不会创建这个标注了 @Lazy 的 bean 的实例，当你第一次用到的时候，才会去创建这个标注了 @Lazy 的 bean；还有一个更重要的用法是用在方法参数上和成员变量上，它可以解决循环依赖问题，即让你的这个依赖注入包括参数的注入，它是推迟执行，会注入一个代理对象，代理对象注入以后就解决了循环依赖，将来等循环依赖这个过程走完，你将来真正用到这个 bean 时，它才会真正创建这个 bean，它是用代理解决了循环依赖，这是它更重要的一个用途\r\n\r\n* @PropertySource 是用来读取一些自定义的 properties 文件，把它们作为键值信息加入到我们 environment 对象里来， environment 就是包含了整个应用程序在运行期间需要的所有键值信息\r\n\r\n**依赖注入**\r\n\r\n* **@Autowired** 加在方法参数上或成员变量上都可以完成依赖注入\r\n* **@Qualifier** 是在依赖注入时，如果同一类型有多个 bean，就会根据名字进行区分\r\n* **@Value** 是做值注入的，可以对`${}`，`#{}`这种内嵌式的符号实现内嵌式的注入\r\n\r\n**缓存**\r\n\r\n- @EnableCaching\r\n- @CacheConfig\r\n- @CacheEvict\r\n- @CachePut\r\n- @Cacheable\r\n- @Caching\r\n\r\n------\r\n\r\n### **mvc mapping**\r\n\r\n* @RequestMapping 作用是建立我们请求路径跟控制器方法之间的映射关系，将来有一个请求过来的时候它就会根据这个请求路径与我们 @RequestMapping 中的路径进行一个匹配，匹配上了它就知道，接下来应该由匹配成功的标注了 @RequestMapping 注解的方法来处理这个请求，这是它的一个最重要的用途，当然这个注解也可以加在类上，加在类上时当你的这个类有多个控制器方法它们有一个相同的路径前缀时，那么可以把这个相同的路径前缀给它提取出来，放在类上的 @RequestMapping \r\n  * 可以派生多个注解如  @GetMapping  等，@GetMapping 功能跟 @RequestMapping 相同，只不过 method 只能是GET请求，它不会去处理其他的 POST，PUT，DELETE 之类的请求，只认 GET 请求\r\n\r\n\r\n**mvc rest**\r\n\r\n* @RequestBody 是处理请求体中的 Json 数据的，把 Json 数据转换为 Java 对象\r\n* @ResponseBody 是把控制器上返回的 Java 对象转换成 Json 数据，然后写入到响应体，组合 @ResponseBody + @Controller =  @RestController\r\n* @ResponseStatus 是可以控制响应的状态码\r\n\r\n**mvc 统一处理**\r\n\r\n* **@ControllerAdvice** ：如果你做一些统一处理的异常方法，或这个转换器方法，还有这个标注了 @ModelAttribute 的方法 ，都可以放在那种标注了 @ControllerAdvice 的类来达到一个统一处理的目的，当然，我们最常用的是把一些处理异常的方法放在标注了 @ControllerAdvice 的方法中来实现一个异常的统一处理，可以让一个标注了 @ExceptionHandler 的方法来处理异常，它是专门来处理异常方法的，当然，这两个注解结合使用的比较多\r\n* 标注了 **@ExceptionHandler** 的方法不一定是放在标注了 @ControllerAdvice 的方法中，也可以放在一个普通的控制器中，放在一个单独的控制器中就相当于是一个局部的异常处理，如果方法在一个标注 @ControllerAdvice 的类中，就表示是一个全局的异常处理\r\n*  @RestControllerAdvice 是一个组合注解，即 @ControllerAdvice + @ResponseBody，将来标注了 @ControllerAdvice 的**方法**做了异常处理，也会转换为 Json 数据写到响应体里\r\n\r\n**mvc 参数**\r\n\r\n* @RequestHeader 是获取请求头中的参数信息\r\n* @CookieValue 是获取Cookie的值\r\n* **@PathVariable** 是获取请求路径的参数值\r\n* **@RequestParam** 是获取真正的请求参数值，就是之后的键值信息，也可以是表单中的请求参数，只要你的请求参数跟方法名称对应上，就可以省略这个@RequestParam，其主要作用是可以设置默认值，即defaultValue属性，如果没有传这个请求参数，可以给它设置一个默认值\r\n\r\n**转换与格式化**\r\n\r\n- @DateTimeFormat是转换日期和时间格式\r\n- @NumberFormat是转换数字格式的\r\n- @InitBinder是注册一些自定义的类型转换器的\r\n\r\n**validation**是做这个bean的校验的\r\n\r\n- @Validated 加在 Javabean 上，表示这个 Javabean 将来要做数据校验，至于这个校验规则也是加在 Javabean 的属性上，它是借助一个第三方的注解，比如 @NotEmpty，@NotBlank，@NotNull等，这些注解才真正完成校验规则的，而 @Validated 只是作为一个校验的入口\r\n\r\n**scope**\r\n\r\n- 标注了@ApplicationScop，@RequestScope，@SessionScope这类的注解的类，就可以在Spring容器中里面控制它们的作用域\r\n\r\n**mvc ajax**\r\n\r\n* @CrossOrigin是解决ajax请求的一个跨域问题，原理是在响应头上加一些特殊的头，允许你的这个ajax跨域的这种请求，当然，如果你用的HttpClient的这种客户端就没有这种跨域问题，它只适合用于javaScrip里面使用ajax访问时才会存在跨域问题\r\n\r\n------\r\n\r\n### **boot**\r\n\r\n **auto**\r\n\r\n* @SpringBootApplication（每个SpringBoot程序都要加的注解)是一个组合注解，即@EnableAutoConfiguration，@SpringBootConfiguration 和@ ComponentScan）\r\n* @EnableAutoConfiguration 是去找到一些自动配置类，把这些自动配置类关联的 Bean 都要注册到 Spring 容器当中，这个也是一个组合注解，@AutoConfigurationPackage 和 @Import，@AutoConfigurationPackage 的作用是它所标注的类的包名会被记录下来，放到容器中，将来你要用到这个包名的时候，那么就可以通过一个工具类到容器中找到这个包名\r\n* @SpringBootConfiguration 是表示一个针对 SpringBoot 的配置类，跟原生的 @Configuration 几乎等价，它跟 @Configuration 区别在哪呢，其实用 @Configuration 标注的，将来一个应用程序可以有多个的配置类，但是 @SpringBootConfiguration 它对应的配置类呢，整个应用程序只可以有这么一个配置类（应用程序类），因为它要根据它断定你的主配置，根据你的主配置类找到我们的应用程序，算是一个入口\r\n\r\n![image-20230422190402081](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422190402081.png)\r\n\r\n**condition**（对@Conditional的一个扩展）\r\n\r\n* @ConditionalOnClass是当你的类路径下包含某个类时，这个条件才算成立，比如说我要配置数据源，可能希望类路径下有具体的数据源实现类，如有一个driuid的DataSource，这个条件才成立，否则不成立，即检查类路径下如果有某个类存在条件才成立，才会执行后续的装配；**classpath 下存在某个 class 时，条件才成立**\r\n\r\n![image-20230422190325299](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230422190325299.png)\r\n\r\n* @ConditionalOnMissingBean 是当你的容器中缺失某个 bean 时，条件才成立，它经常作为一些后补的操作，如你没有提供某个 bean，即当你缺失配置某个 bean 时条件就会成立，把一个默认的后补的 bean 添加到 Spring 容器中，这个缺失的条件是根据 bean 的名字来匹配的，如果容器中没有这个 bean 时条件就成立，如果这个 bean 的名字已经存在了，条件就不成立；**beanFactory 内不存在某个 bean 时，条件才成立**\r\n* @ConditionalOnProperty 是根据 properties 文件的键值信息，看看是不是做了某些键值的配置，如果这些键值配置了，并且条件相符，条件才算成立，比如你的某个键或值跟这个 @ConditionalOnProperty 中值也一致了，条件才算成立，如果你没有这个相应的键值，条件就不成立；**配置文件中存在某个 property（键、值）时，条件才成立**\r\n\r\n**properties**\r\n\r\n* @ConfigurationProperties，会将当前 bean 的属性与配置文件中的键值进行绑定\r\n  * @ConfigurationProperties 是把我们 properties 文件中的键值信息跟 JavaBean 的属性进行绑定，属性名称与这个配置文件中键的名称相同，对应的值就会赋值给我们标注了 @ConfigurationProperties 的 Javabean 的属性，相当于简化了一些 bean 的初始化，如果用 @Value 虽然也可以对这个值进行初始化，但是比较复杂，@ConfigurationProperties 在一定程度上可以去简化 @Value 的一些赋值操作\r\n\r\n* @EnableConfigurationProperties 就是启用 @ConfigurationProperties 功能，它也是在 bean 工厂加了一些后处理器，这些后处理器能够识别 @ConfigurationProperties ，一旦识别到它就会执行这个绑定操作，**会添加以下两个较为重要的 bean**\r\n  * ConfigurationPropertiesBindingPostProcessor，bean 后处理器，在 bean 初始化前调用下面的 binder\r\n  * ConfigurationPropertiesBinder，真正执行绑定操作\r\n\r\n\r\n\r\n------\r\n\r\n## 7. SpringBoot 自动配置原理\r\n\r\n**自动配置原理**\r\n\r\n![image-20230423003501071](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423003501071.png)\r\n\r\n@SpringBootApplication 是一个组合注解，由 @ComponentScan、@EnableAutoConfiguration 和 @SpringBootConfiguration 组成\r\n\r\n1. @SpringBootConfiguration 与普通 @Configuration 相比，唯一区别是前者要求整个 app 中只出现一次\r\n2. @ComponentScan\r\n   * excludeFilters - 用来在组件扫描时进行排除，也会排除自动配置类\r\n\r\n   ![image-20230423003533333](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423003533333.png)\r\n   \r\n3. @EnableAutoConfiguration 也是一个组合注解，由下面注解组成\r\n   * @AutoConfigurationPackage – 用来记住扫描的起始包，放到容器中，将来要用到包名时可以用一个工具类到容器中找到\r\n   * @Import(AutoConfigurationImportSelector.class) 用来加载 `META-INF/spring.factories` 中的自动配置类\r\n   \r\n   ![image-20230423004955603](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230423004955603.png)\r\n\r\n**为什么不使用 @Import 直接引入自动配置类**\r\n\r\n有两个原因：\r\n\r\n1. 让主配置类和自动配置类变成了强耦合，主配置类不应该知道有哪些从属配置\r\n2. 直接用 `@Import(自动配置类.class)`，引入的配置解析优先级较高，自动配置类的解析应该在主配置没提供时作为默认配置\r\n\r\n因此，采用了 `@Import(AutoConfigurationImportSelector.class)`\r\n\r\n* 由 `AutoConfigurationImportSelector.class` 去读取 `META-INF/spring.factories` 中的自动配置类，实现了弱耦合。\r\n* 另外 `AutoConfigurationImportSelector.class` 实现了 DeferredImportSelector 接口，让自动配置的解析晚于主配置的解析\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n## 8. Spring 中的设计模式\r\n\r\n### **1. Spring 中的 Singleton**\r\n\r\n**请大家区分 singleton pattern 与 Spring 中的 singleton bean**\r\n\r\n* 根据单例模式的目的 *Ensure a class only has one instance, and provide a global point of access to it* \r\n* 显然 Spring 中的 singleton bean 并非实现了单例模式，singleton bean 只能保证每个容器内，相同 id 的 bean 单实例\r\n* 当然 Spring 中也用到了单例模式，例如\r\n  * `org.springframework.transaction.TransactionDefinition#withDefaults`\r\n  * `org.springframework.aop.TruePointcut#INSTANCE`\r\n  * `org.springframework.aop.interceptor.ExposeInvocationInterceptor#ADVISOR`\r\n  * `org.springframework.core.annotation.AnnotationAwareOrderComparator#INSTANCE`\r\n  * `org.springframework.core.OrderComparator#INSTANCE`\r\n\r\n> 单例模式的原始定义是确保一个类只有一个实例，并且提到一个全局的访问点，则Spring中的 Singleton bean 是不符合的，因为你一个 Spring 容器中可以一个类型定义多个实例，只要多个 bean 它们的 id 和名字有可能不一样，则可能有多个实例，而且 Spring 可以有多个容器的，多个容器同一个类也可能有不同的实例，同样的 propertype bean 也不是原型模式\r\n\r\n\r\n\r\n------\r\n\r\n### **2. Spring 中的 Builder**\r\n\r\n定义： *Separate the construction of a complex object from its representation so that the same construction process can create different representations* \r\n\r\n它主要的亮点有三处：\r\n\r\n1. 较为灵活的构建产品对象\r\n\r\n2. 在不执行最后 build 方法前，产品对象都不可用\r\n\r\n3. 构建过程采用链式调用，看起来比较爽\r\n\r\nSpring 中体现 Builder 模式的地方：（这种以Builder结尾的命名的，一般来讲都可以看作它是实现了这种构建器对象，可以对照着它的定义看一下）\r\n\r\n* org.springframework.beans.factory.support.BeanDefinitionBuilder\r\n\r\n* org.springframework.web.util.UriComponentsBuilder\r\n\r\n* org.springframework.http.ResponseEntity.HeadersBuilder\r\n\r\n* org.springframework.http.ResponseEntity.BodyBuilder\r\n\r\n> Builder 建造器模式，它用在一个对象建造过程比较复杂，可以用这个构建器跟对象把它俩分离开来，这个构建器负责对象创建前的准备，最终调用它的Builder方法创建最终的产品对象\r\n\r\n\r\n\r\n------\r\n\r\n### **3. Spring 中的 Factory Method**\r\n\r\n定义： *Define an interface for creating an object, but let subclasses decide which class to instantiate. Factory Method lets a class defer instantiation to subclasses* \r\n\r\n根据上面的定义，Spring 中的 ApplicationContext 与 BeanFactory 中的 getBean 都可以视为工厂方法，它隐藏了 bean （产品）的创建过程和具体实现；\r\n\r\n> 因为你 getBean 出来有可能是一个接口，但是具体实现你也不知道，它都是在 Spring 的配置文件或配置类 bean (产品)的创建过程和具体实现已经定义好了，并且你怎么构建也不知道，也不用去关心，甚至你不用接口去 getBean 它有可能给你返回的是一个**代理**，即隐藏了 bean 创建过程和具体实现\r\n\r\nSpring 中其它工厂：\r\n\r\n* org.springframework.beans.factory.FactoryBean\r\n\r\n* @Bean 标注的静态方法及实例方法\r\n\r\n* ObjectFactory 及 ObjectProvider\r\n\r\n前两种工厂主要封装第三方的 bean 的创建过程，后两种工厂可以推迟 bean 创建，解决循环依赖及单例注入多例等问题\r\n\r\n> Factory Method工厂方法模式，抛开它的定义，它的核心就是去让我们的接口和实现相分离，去降低耦合，这是它最重要的目的\r\n\r\n\r\n\r\n------\r\n\r\n### **4. Spring 中的 Adapter**\r\n\r\n定义： *Convert the interface of a class into another interface clients expect. Adapter lets classes work together that couldn't otherwise because of incompatible interfaces* \r\n\r\n典型的实现有两处：\r\n\r\n* `org.springframework.web.servlet.HandlerAdapter` – 因为控制器实现有各种各样，比如有\r\n  * 大家熟悉的 @RequestMapping 标注的控制器实现\r\n  * 传统的基于 Controller 接口（不是 @Controller 注解啊）的实现\r\n  * 较新的基于 RouterFunction 接口的实现\r\n  * 它们的处理方法都不一样，为了统一调用，必须适配为 HandlerAdapter 接口\r\n* `org.springframework.beans.factory.support.DisposableBeanAdapter` – 因为销毁方法多种多样，因此都要适配为 DisposableBean 来统一调用销毁方法 \r\n\r\n> Adapter适配器模式，适配器模式的定义是把一个或一套接口转换成另一套调用者所期望的接口\r\n\r\n\r\n\r\n------\r\n\r\n### **5. Spring 中的 Composite**\r\n\r\n定义： *Compose objects into tree structures to represent part-whole hierarchies. Composite lets clients treat individual objects and compositions of objects uniformly* \r\n\r\n典型实现有：\r\n\r\n* org.springframework.web.method.support.HandlerMethodArgumentResolverComposite\r\n* org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite\r\n* org.springframework.web.servlet.handler.HandlerExceptionResolverComposite\r\n* org.springframework.web.servlet.view.ViewResolverComposite\r\n\r\ncomposite 对象的作用是，将分散的调用集中起来，统一调用入口，它的特征是，与具体干活的实现实现的是同一个接口，当调用 composite 对象的接口方法时，其实是委托具体干活的实现来完成\r\n\r\n> Composite 组合模式，它的作用是将分散的调用集中起来，统一调用入口，如在 SpringMVC 中，在调用某个控制器方法前都要给它准备各种各样的参数，不同的参数它的来源是不一样的，获取方式也不一样，如有的是从路径中获取参数，有的是从请求参数获取信息，有的是要生成一个 Model 模型对象作为参数，有的是从传统的 request，response 中获取参数，所以这种不同的参数的解析也是不一样的，这么多参数的解析器，我们要把它们的调用统一起来，我们就提供一个 HandlerMethodArgumentResloverComposite，即参数解析器的组合器，将来只需要调用组合器就行，组合器里有个集合，这个集合里有各种各样的参数解析器，这样就把分散的调用集中起来，统一调用入口，它的特征是与具体干活的实现实现的是同一个 HandlerMethodArgumentReslover 接口，当调用 composite 组合器对象的接口方法时，其实是委托具体干活的实现来完成的\r\n\r\n\r\n\r\n------\r\n\r\n### **6. Spring 中的 Decorator**\r\n\r\n定义： *Attach additional responsibilities to an object dynamically. Decorators provide a flexible alternative to subclassing for extending functionality* \r\n\r\n典型实现：\r\n\r\n* org.springframework.web.util.ContentCachingRequestWrapper\r\n\r\n> Decorator 装饰器模式，它的定义是对一个对象动态地去增加一些职责和功能，它主要解决这种用子类扩展方式来实现这种功能增强的问题，因为子类去实现功能增强最大的问题是子类不管用不用的到，它都得把父类的方法继承过来，即继承了很多它用不上的父类方法，装饰器就可以避免这个问题，它跟代理模式的定义很像，也是做功能增强，但做功能增强的实际上不是代理对象，是那些通知(环绕通知之类的)，代理其实只起到一个入口的作用，代理只起到对目标对象和目标方法提供一个统一入口的作用，把它们结合起来\r\n\r\n\r\n\r\n------\r\n\r\n### **7. Spring 中的 Proxy**\r\n\r\n定义： *Provide a surrogate or placeholder for another object to control access to it* \r\n\r\n装饰器模式注重的是功能增强，避免子类继承方式进行功能扩展，而代理模式更注重控制目标的访问\r\n\r\n典型实现：\r\n\r\n* org.springframework.aop.framework.JdkDynamicAopProxy\r\n  * 用jdk动态代理的方式生成最终的代理对象，它的限制是要求你的目标对象必须实现一个接口，那生成的代理也是针对这个接口代理\r\n\r\n* org.springframework.aop.framework.ObjenesisCglibAopProxy\r\n  * 既可以针对接口代理，也可以生成一个子类作为代理，**Objenesis是做补充的（提供一个无参构造）**，这种如果你的目标它没有无参构造，那它在创建这个目标对象时就创建不了，它必须让目标提供一个无参构造\r\n  * Objenesis相当于一个小工具，即使你的目标只有一些带参构造，没有无参构造，它也可以生成一个空空如也的对象，让这个代理能够创建成功\r\n\r\n> Proxy代理模式，它原本的定义是对另外的对象提供一个代理或者占位用来控制对这个对象的访问，即侧重于对这个目标对象的控制和访问，而不是侧重于对目标对象做功能增强的\r\n\r\n\r\n\r\n------\r\n\r\n### **8. Spring 中的 Chain of Responsibility**\r\n\r\n定义： *Avoid coupling the sender of a request to its receiver by giving more than one object a chance to handle the request. Chain the receiving objects and pass the request along the chain until an object handles it* \r\n\r\n典型实现：\r\n\r\n* org.springframework.web.servlet.HandlerInterceptor\r\n\r\n> Chain of Responsibility责任链模式，它的定义是将来可以有多个请求的处理对象，把这多个请求的处理对象串成一个链，每个对象都有机会处理这个请求，这个请求就会沿着这个处理链依次向后传递，直到遇到一个能够处理它的对象为止，根据这个定义，SpringMVC的HandlerInterceptor拦截器是符合这个定义的，我们使用拦截器的时候都知道，多个拦截器都会和最终的这个控制器方法形成一个调用链，这个调用链其实就是我们这里的责任链，请求会沿着这个调用链，先给调用链里第一个拦截器，第一个拦截器处理完后放行了就交给第二个拦截器，以此类推，最终到达我们的这个控制器方法来调用它，这就是拦截器的一个典型体现\r\n\r\n\r\n\r\n------\r\n\r\n### **9. Spring 中的 Observer**\r\n\r\n定义： *Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically* \r\n\r\n典型实现：\r\n\r\n* org.springframework.context.ApplicationListener\r\n* org.springframework.context.event.ApplicationEventMulticaster\r\n* org.springframework.context.ApplicationEvent\r\n\r\n> Observer观察者模式，作用就是用来解耦的，它主要体现在Spring它实现了这种ApplicationListener监听器(接收事件)，ApplicationEventMulticaster事件广播器(发生事件)，想当于把发送者和接收者进行一个解耦，还有一个ApplicationEvent对象\r\n\r\n\r\n\r\n------\r\n\r\n### **10. Spring 中的 Strategy**\r\n\r\n定义： *Define a family of algorithms, encapsulate each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it* \r\n\r\n典型实现：\r\n\r\n* org.springframework.beans.factory.support.InstantiationStrategy\r\n* org.springframework.core.annotation.MergedAnnotations.SearchStrategy\r\n  * 查找注解的时候,它是要到当前类查找还是要考虑它的父类呢，就用到多种策略方式\r\n\r\n* org.springframework.boot.autoconfigure.condition.SearchStrategy\r\n  * 做条件判断的时候，同样的条件判断是看看你的这个bean是当前容器里还是在这个父容器里呢，还是在所有容器里都去找呢，也是有一个搜索的策略\r\n\r\n\r\n\r\n------\r\n\r\n\r\n### **11. Spring 中的 Template Method**\r\n\r\n定义： *Define the skeleton of an algorithm in an operation, deferring some steps to subclasses. Template Method lets subclasses redefine certain steps of an algorithm without changing the algorithm's structure* \r\n\r\n典型实现：\r\n\r\n* 大部分以 Template 命名的类，如 JdbcTemplate，TransactionTemplate\r\n* 很多以 Abstract 命名的类，如 AbstractApplicationContext"},{"title":"Java面试专题-虚拟机篇","tags":["JVM 内存结构","JVM 内存参数","JVM 垃圾回收","内存溢出","类加载","引用","finalize"],"categories":["Java","面试"],"author":"imklaus","excerpt":"\r\n参考视频：[满神Java面试专题](https://www.bilibili.com/video/BV15b4y117RJ)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Java_Interview_Topics-JVM","content":"\r\n参考视频：[满神Java面试专题](https://www.bilibili.com/video/BV15b4y117RJ)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n## 1. JVM 内存结构\r\n\r\n**要求**\r\n\r\n* 掌握 JVM 内存结构划分\r\n* 尤其要知道方法区、永久代、元空间的关系\r\n\r\n**结合一段 java 代码的执行理解内存划分**\r\n\r\n![image-20210831165728217](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831165728217.png)\r\n\r\n* 执行 javac 命令编译源代码为字节码\r\n* 执行 java 命令\r\n  1. 创建 JVM，调用类加载子系统加载 class，将类的信息存入**方法区**\r\n  2. 创建 main 线程，使用的内存区域是 **JVM 虚拟机栈**，开始执行 main 方法代码\r\n  3. 如果遇到了未见过的类，会继续触发类加载过程，同样会存入**方法区**\r\n  4. 需要创建对象，会使用**堆**内存来存储对象\r\n  5. 不再使用的对象，会由**垃圾回收器**在内存不足时回收其内存\r\n  6. 调用方法时，方法内的局部变量、方法参数所使用的是  **JVM 虚拟机栈**中的栈帧内存\r\n  7. 调用方法时，先要到**方法区**获得到该方法的字节码指令，由**解释器**将字节码指令解释为机器码执行\r\n  8. 调用方法时，会将要执行的指令行号读到**程序计数器**，这样当发生了线程切换，恢复时就可以从中断的位置继续\r\n  9. 对于非 java 实现的方法调用，使用内存称为**本地方法栈**（见说明）\r\n  10. 对于热点方法调用，或者频繁的循环代码，由 **JIT 即时编译器**将这些代码编译成机器码缓存，提高执行性能\r\n\r\n说明\r\n\r\n* 加粗字体代表了 JVM 虚拟机组件\r\n* 对于 Oracle 的 Hotspot 虚拟机实现，不区分虚拟机栈和本地方法栈\r\n\r\n**会发生内存溢出的区域**\r\n\r\n* 不会出现内存溢出的区域 – 程序计数器\r\n* 出现 OutOfMemoryError 的情况\r\n  * 堆内存耗尽 – 对象越来越多，又一直在使用，不能被垃圾回收\r\n  * 方法区内存耗尽 – 加载的类越来越多，很多框架都会在运行期间动态产生新的类\r\n  * 虚拟机栈累积 – 每个线程最多会占用 1 M 内存，线程个数越来越多，而又长时间运行不销毁时\r\n* 出现 StackOverflowError 的区域\r\n  * JVM 虚拟机栈，原因有方法递归调用未正确结束、反序列化 json 时循环引用\r\n\r\n**方法区、永久代、元空间**\r\n\r\n* **方法区**是 JVM 规范中定义的一块内存区域，用来存储类元数据、方法字节码、即时编译器需要的信息等\r\n* **永久代**是 Hotspot 虚拟机对 JVM 规范的实现（1.8 之前）\r\n* **元空间**是 Hotspot 虚拟机对 JVM 规范的另一种实现（1.8 以后），使用本地内存作为这些信息的存储空间\r\n\r\n![image-20210831170457337](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831170457337.png)\r\n\r\n从这张图学到三点\r\n\r\n* 当第一次用到某个类是，由类加载器将 class 文件的类元信息读入，并存储于元空间\r\n* X，Y 的类元信息是存储于元空间中，无法直接访问\r\n* 可以用 X.class，Y.class 间接访问类元信息，它们俩属于 java 对象，我们的代码中可以使用\r\n\r\n![image-20210831170512418](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831170512418.png)\r\n\r\n从这张图可以学到\r\n\r\n* 堆内存中：当一个**类加载器对象**，这个类加载器对象加载的所有**类对象**，这些类对象对应的所有**实例对象**都没人引用时，GC 时就会对它们占用的对内存进行释放\r\n* 元空间中：内存释放**以类加载器为单位**，当堆中类加载器内存释放时，对应的元空间中的类元信息也会释放\r\n\r\n\r\n\r\n## 2. JVM 内存参数\r\n\r\n**要求** \r\n\r\n* 熟悉常见的 JVM 参数，尤其和大小相关的\r\n\r\n**堆内存，按大小设置**\r\n\r\n![image-20210831173130717](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831173130717.png)\r\n\r\n解释：\r\n\r\n* -Xms 最小堆内存（包括新生代和老年代）\r\n* -Xmx 最大对内存（包括新生代和老年代）\r\n* 通常建议将 -Xms 与 -Xmx 设置为大小相等，即不需要保留内存，不需要从小到大增长，这样性能较好\r\n* -XX:NewSize 与 -XX:MaxNewSize 设置新生代的最小与最大值，但一般不建议设置，由 JVM 自己控制\r\n* -Xmn 设置新生代大小，相当于同时设置了 -XX:NewSize 与 -XX:MaxNewSize 并且取值相等\r\n* 保留是指，一开始不会占用那么多内存，随着使用内存越来越多，会逐步使用这部分保留内存。下同\r\n\r\n\r\n\r\n**堆内存，按比例设置**\r\n\r\n![image-20210831173045700](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831173045700.png)\r\n\r\n解释：\r\n\r\n* -XX:NewRatio=2:1 表示老年代占两份，新生代占一份\r\n* -XX:SurvivorRatio=4:1 表示新生代分成六份，伊甸园占四份，from 和 to 各占一份\r\n\r\n\r\n\r\n**元空间内存设置**\r\n\r\n![image-20210831173118634](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831173118634.png)\r\n\r\n解释：\r\n\r\n* class space 存储类的基本信息，最大值受 -XX:CompressedClassSpaceSize 控制\r\n* non-class space 存储除类的基本信息以外的其它信息（如方法字节码、注解等）\r\n* class space 和 non-class space 总大小受 -XX:MaxMetaspaceSize 控制\r\n\r\n注意：\r\n\r\n* 这里 -XX:CompressedClassSpaceSize 这段空间还与是否开启了指针压缩有关，这里暂不深入展开，可以简单认为指针压缩默认开启\r\n\r\n\r\n\r\n**代码缓存内存设置**\r\n\r\n![image-20210831173148816](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831173148816.png)\r\n\r\n解释：\r\n\r\n* 如果 -XX:ReservedCodeCacheSize < 240m，所有优化机器代码不加区分存在一起\r\n* 否则，分成三个区域（图中笔误 mthod 拼写错误，少一个 e）\r\n  * non-nmethods - JVM 自己用的代码\r\n  * profiled nmethods - 部分优化的机器码\r\n  * non-profiled nmethods - 完全优化的机器码\r\n\r\n\r\n\r\n**线程内存设置**\r\n\r\n![image-20210831173155481](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831173155481.png)\r\n\r\n> ***官方参考文档***\r\n>\r\n> * https://docs.oracle.com/en/java/javase/11/tools/java.html#GUID-3B1CE181-CD30-4178-9602-230B800D4FAE\r\n\r\n\r\n\r\n## 3. JVM 垃圾回收\r\n\r\n**要求**\r\n\r\n* 掌握垃圾回收算法\r\n* 掌握分代回收思想\r\n* 理解三色标记及漏标处理\r\n* 了解常见垃圾回收器\r\n\r\n**三种垃圾回收算法**\r\n\r\n标记清除法\r\n\r\n![image-20210831211008162](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831211008162.png)\r\n\r\n解释：\r\n\r\n1. 找到 GC Root 对象，即那些一定不会被回收的对象，如正执行方法内局部变量引用的对象、静态变量引用的对象\r\n2. 标记阶段：沿着 GC Root 对象的引用链找，直接或间接引用到的对象加上标记\r\n3. 清除阶段：释放未加标记的对象占用的内存\r\n\r\n要点：\r\n\r\n* 标记速度与存活对象线性关系\r\n* 清除速度与内存大小线性关系\r\n* 缺点是会产生内存碎片\r\n\r\n\r\n\r\n标记整理法\r\n\r\n![image-20210831211641241](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831211641241.png)\r\n\r\n解释：\r\n\r\n1. 前面的标记阶段、清理阶段与标记清除法类似\r\n2. 多了一步整理的动作，将存活对象向一端移动，可以避免内存碎片产生\r\n\r\n特点：\r\n\r\n* 标记速度与存活对象线性关系\r\n\r\n* 清除与整理速度与内存大小成线性关系\r\n* 缺点是性能上较慢\r\n\r\n\r\n\r\n标记复制法\r\n\r\n![image-20210831212125813](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831212125813.png)\r\n\r\n解释：\r\n\r\n1. 将整个内存分成两个大小相等的区域，from 和 to，其中 to 总是处于空闲，from 存储新创建的对象\r\n2. 标记阶段与前面的算法类似\r\n3. 在找出存活对象后，会将它们从 from 复制到 to 区域，复制的过程中自然完成了碎片整理\r\n4. 复制完成后，交换 from 和 to 的位置即可\r\n\r\n特点：\r\n\r\n* 标记与复制速度与存活对象成线性关系\r\n* 缺点是会占用成倍的空间\r\n\r\n\r\n\r\n**GC 与分代回收算法**\r\n\r\nGC 的目的在于实现无用对象内存自动释放，减少内存碎片、加快分配速度\r\n\r\nGC 要点：\r\n\r\n* 回收区域是**堆内存**，不包括虚拟机栈\r\n* 判断无用对象，使用**可达性分析算法**，**三色标记法**标记存活对象，回收未标记对象\r\n* GC 具体的实现称为**垃圾回收器**\r\n* GC 大都采用了**分代回收思想**\r\n  * 理论依据是大部分对象朝生夕灭，用完立刻就可以回收，另有少部分对象会长时间存活，每次很难回收\r\n  * 根据这两类对象的特性将回收区域分为**新生代**和**老年代**，新生代采用标记复制法、老年代一般采用标记整理法\r\n* 根据 GC 的规模可以分成 **Minor GC**，**Mixed GC**，**Full GC**\r\n\r\n\r\n\r\n**分代回收**\r\n\r\n1. 伊甸园 eden，最初对象都分配到这里，与幸存区 survivor（分成 from 和 to）合称新生代，\r\n\r\n![image-20210831213622704](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831213622704.png)\r\n\r\n2. 当伊甸园内存不足，标记伊甸园与 from（现阶段没有）的存活对象\r\n\r\n![image-20210831213640110](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831213640110.png)\r\n\r\n3. 将存活对象采用复制算法复制到 to 中，复制完毕后，伊甸园和 from 内存都得到释放\r\n\r\n![image-20210831213657861](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831213657861.png)\r\n\r\n4. 将 from 和 to 交换位置\r\n\r\n![image-20210831213708776](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831213708776.png)\r\n\r\n5. 经过一段时间后伊甸园的内存又出现不足\r\n\r\n![image-20210831213724858](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831213724858.png)\r\n\r\n6. 标记伊甸园与 from（现阶段没有）的存活对象\r\n\r\n![image-20210831213737669](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831213737669.png)\r\n\r\n7. 将存活对象采用复制算法复制到 to 中\r\n\r\n![image-20210831213804315](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831213804315.png)\r\n\r\n8. 复制完毕后，伊甸园和 from 内存都得到释放\r\n\r\n![image-20210831213815371](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831213815371.png)\r\n\r\n9. 将 from 和 to 交换位置\r\n\r\n![image-20210831213826017](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831213826017.png)\r\n\r\n10. 老年代 old，当幸存区对象熬过几次回收（最多15次），晋升到老年代（幸存区内存不足或大对象会导致提前晋升）\r\n\r\n\r\n\r\n**GC 规模**\r\n\r\n* Minor GC 发生在新生代的垃圾回收，暂停时间短\r\n\r\n* Mixed GC 新生代 + 老年代部分区域的垃圾回收，G1 收集器特有\r\n\r\n* Full GC 新生代 + 老年代完整垃圾回收，暂停时间长，**应尽力避免**\r\n\r\n\r\n\r\n**三色标记**\r\n\r\n即用三种颜色记录对象的标记状态\r\n\r\n* 黑色 – 已标记\r\n* 灰色 – 标记中\r\n* 白色 – 还未标记\r\n\r\n\r\n\r\n1. 起始的三个对象还未处理完成，用灰色表示\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831215016566.png\" alt=\"image-20210831215016566\" style=\"zoom:50%;\" />\r\n\r\n2. 该对象的引用已经处理完成，用黑色表示，黑色引用的对象变为灰色\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831215033510.png\" alt=\"image-20210831215033510\" style=\"zoom:50%;\" />\r\n\r\n3. 依次类推\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831215105280.png\" alt=\"image-20210831215105280\" style=\"zoom:50%;\" />\r\n\r\n4. 沿着引用链都标记了一遍\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831215146276.png\" alt=\"image-20210831215146276\" style=\"zoom:50%;\" />\r\n\r\n5. 最后为标记的白色对象，即为垃圾\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831215158311.png\" alt=\"image-20210831215158311\" style=\"zoom:50%;\" />\r\n\r\n**并发漏标问题**\r\n\r\n比较先进的垃圾回收器都支持**并发标记**，即在标记过程中，用户线程仍然能工作。但这样带来一个新的问题，如果用户线程修改了对象引用，那么就存在漏标问题。例如：\r\n\r\n1. 如图所示标记工作尚未完成\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831215846876.png\" alt=\"image-20210831215846876\" style=\"zoom:50%;\" />\r\n\r\n2. 用户线程同时在工作，断开了第一层 3、4 两个对象之间的引用，这时对于正在处理 3 号对象的垃圾回收线程来讲，它会将 4 号对象当做是白色垃圾\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831215904073.png\" alt=\"image-20210831215904073\" style=\"zoom:50%;\" />\r\n\r\n3. 但如果其他用户线程又建立了 2、4 两个对象的引用，这时因为 2 号对象是黑色已处理对象了，因此垃圾回收线程不会察觉到这个引用关系的变化，从而产生了漏标\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831215919493.png\" alt=\"image-20210831215919493\" style=\"zoom:50%;\" />\r\n\r\n4. 如果用户线程让黑色对象引用了一个新增对象，一样会存在漏标问题\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831220004062.png\" alt=\"image-20210831220004062\" style=\"zoom:50%;\" />\r\n\r\n因此对于**并发标记**而言，必须解决漏标问题，也就是要记录标记过程中的变化。有两种解决方法：\r\n\r\n1. Incremental Update 增量更新法，CMS 垃圾回收器采用\r\n   * 思路是拦截每次赋值动作，只要赋值发生，被赋值的对象就会被记录下来，在重新标记阶段再确认一遍\r\n2. Snapshot At The Beginning，SATB 原始快照法，G1 垃圾回收器采用\r\n   * 思路也是拦截每次赋值动作，不过记录的对象不同，也需要在重新标记阶段对这些对象二次处理\r\n   * 新加对象会被记录\r\n   * 被删除引用关系的对象也被记录\r\n\r\n\r\n\r\n**垃圾回收器 - Parallel GC**\r\n\r\n* eden 内存不足发生 Minor GC，采用标记复制算法，需要暂停用户线程\r\n* old 内存不足发生 Full GC，采用标记整理算法，需要暂停用户线程\r\n\r\n* **注重吞吐量**\r\n\r\n**垃圾回收器 - ConcurrentMarkSweep GC**\r\n\r\n* 它是工作在 old 老年代，支持**并发标记**的一款回收器，采用**并发清除**算法\r\n  * 并发标记时不需暂停用户线程\r\n  * 重新标记时仍需暂停用户线程\r\n\r\n* 如果并发失败（即回收速度赶不上创建新对象速度），会触发 Full GC\r\n\r\n* **注重响应时间**\r\n\r\n**垃圾回收器 - G1 GC**\r\n\r\n* **响应时间与吞吐量兼顾**\r\n* 划分成多个区域，每个区域都可以充当 eden，survivor，old， humongous，其中 humongous 专为大对象准备\r\n* 分成三个阶段：新生代回收、并发标记、混合收集\r\n* 如果并发失败（即回收速度赶不上创建新对象速度），会触发 Full GC\r\n\r\n\r\n\r\n**G1 回收阶段 - 新生代回收**\r\n\r\n1. 初始时，所有区域都处于空闲状态\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222639754.png\" alt=\"image-20210831222639754\" style=\"zoom:50%;\" />\r\n\r\n2. 创建了一些对象，挑出一些空闲区域作为伊甸园区存储这些对象\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222653802.png\" alt=\"image-20210831222653802\" style=\"zoom:50%;\" />\r\n\r\n3. 当伊甸园需要垃圾回收时，挑出一个空闲区域作为幸存区，用复制算法复制存活对象，需要暂停用户线程\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222705814.png\" alt=\"image-20210831222705814\" style=\"zoom:50%;\" />\r\n\r\n4. 复制完成，将之前的伊甸园内存释放\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222724999.png\" alt=\"image-20210831222724999\" style=\"zoom:50%;\" />\r\n\r\n5. 随着时间流逝，伊甸园的内存又有不足\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222737928.png\" alt=\"image-20210831222737928\" style=\"zoom:50%;\" />\r\n\r\n6. 将伊甸园以及之前幸存区中的存活对象，采用复制算法，复制到新的幸存区，其中较老对象晋升至老年代\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222752787.png\" alt=\"image-20210831222752787\" style=\"zoom:50%;\" />\r\n\r\n7. 释放伊甸园以及之前幸存区的内存\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222803281.png\" alt=\"image-20210831222803281\" style=\"zoom:50%;\" />\r\n\r\n**G1 回收阶段 - 并发标记与混合收集**\r\n\r\n1. 当老年代占用内存超过阈值后，触发并发标记，这时无需暂停用户线程\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222813959.png\" alt=\"image-20210831222813959\" style=\"zoom:50%;\" />\r\n\r\n2. 并发标记之后，会有重新标记阶段解决漏标问题，此时需要暂停用户线程。这些都完成后就知道了老年代有哪些存活对象，随后进入混合收集阶段。此时不会对所有老年代区域进行回收，而是根据**暂停时间目标**优先回收价值高（存活对象少）的区域（这也是 Gabage First 名称的由来）。\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222828104.png\" alt=\"image-20210831222828104\" style=\"zoom:50%;\" />\r\n\r\n3. 混合收集阶段中，参与复制的有 eden、survivor、old，下图显示了伊甸园和幸存区的存活对象复制\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222841096.png\" alt=\"image-20210831222841096\" style=\"zoom:50%;\" />\r\n\r\n4. 下图显示了老年代和幸存区晋升的存活对象的复制\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222859760.png\" alt=\"image-20210831222859760\" style=\"zoom:50%;\" />\r\n\r\n5. 复制完成，内存得到释放。进入下一轮的新生代回收、并发标记、混合收集\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210831222919182.png\" alt=\"image-20210831222919182\" style=\"zoom:50%;\" />\r\n\r\n## 4. 内存溢出\r\n\r\n**要求**\r\n\r\n* 能够说出几种典型的导致内存溢出的情况\r\n\r\n\r\n\r\n**典型情况**\r\n\r\n* 误用线程池导致的内存溢出\r\n  * 参考 day03.TestOomThreadPool\r\n* 查询数据量太大导致的内存溢出\r\n  * 参考 day03.TestOomTooManyObject\r\n* 动态生成类导致的内存溢出\r\n  * 参考 day03.TestOomTooManyClass\r\n\r\n\r\n\r\n## 5. 类加载\r\n\r\n**要求**\r\n\r\n* 掌握类加载阶段\r\n* 掌握类加载器\r\n* 理解双亲委派机制\r\n\r\n\r\n\r\n**类加载过程的三个阶段**\r\n\r\n1. 加载\r\n\r\n   1. 将类的字节码载入方法区，并创建类.class 对象\r\n\r\n   2. 如果此类的父类没有加载，先加载父类\r\n   3. 加载是懒惰执行\r\n\r\n2. 链接\r\n   1. 验证 – 验证类是否符合 Class 规范，合法性、安全性检查\r\n   2. 准备 – 为 static 变量分配空间，设置默认值\r\n   3. 解析 – 将常量池的符号引用解析为直接引用\r\n\r\n3. 初始化\r\n   1. 静态代码块、static 修饰的变量赋值、static final 修饰的引用类型变量赋值，会被合并成一个 `<cinit>` 方法，在初始化时被调用\r\n   2. static final 修饰的基本类型变量赋值，在链接阶段就已完成\r\n   3. 初始化是懒惰执行\r\n\r\n> ***验证手段***\r\n>\r\n> * 使用 jps 查看进程号\r\n> * 使用 jhsdb 调试，执行命令 `jhsdb.exe hsdb` 打开它的图形界面\r\n>   * Class Browser 可以查看当前 jvm 中加载了哪些类\r\n>   * 控制台的 universe 命令查看堆内存范围\r\n>   * 控制台的 g1regiondetails 命令查看 region 详情\r\n>   * `scanoops 起始地址 结束地址 对象类型` 可以根据类型查找某个区间内的对象地址\r\n>   * 控制台的 `inspect 地址` 指令能够查看这个地址对应的对象详情\r\n> * 使用 javap 命令可以查看 class 字节码\r\n\r\n\r\n\r\n>***代码说明***\r\n>\r\n>* day03.loader.TestLazy - 验证类的加载是懒惰的，用到时才触发类加载\r\n>* day03.loader.TestFinal - 验证使用 final 修饰的变量不会触发类加载\r\n\r\n\r\n\r\n**jdk 8 的类加载器**\r\n\r\n| **名称**                | **加载哪的类**        | **说明**                       |\r\n| ----------------------- | --------------------- | ------------------------------ |\r\n| Bootstrap ClassLoader   | JAVA_HOME/jre/lib     | 无法直接访问                   |\r\n| Extension ClassLoader   | JAVA_HOME/jre/lib/ext | 上级为 Bootstrap，显示为  null |\r\n| Application ClassLoader | classpath             | 上级为 Extension               |\r\n| 自定义类加载器          | 自定义                | 上级为 Application             |\r\n\r\n\r\n\r\n**双亲委派机制**\r\n\r\n所谓的双亲委派，就是指优先委派上级类加载器进行加载，如果上级类加载器\r\n\r\n* 能找到这个类，由上级加载，加载后该类也对下级加载器可见\r\n* 找不到这个类，则下级类加载器才有资格执行加载\r\n\r\n双亲委派的目的有两点\r\n\r\n1. 让上级类加载器中的类对下级共享（反之不行），即能让你的类能依赖到 jdk 提供的核心类\r\n\r\n2. 让类的加载有优先次序，保证核心类优先加载\r\n\r\n\r\n\r\n**对双亲委派的误解**\r\n\r\n下面面试题的回答是错误的\r\n\r\n![image-20210901110910016](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210901110910016.png)\r\n\r\n错在哪了？\r\n\r\n* 自己编写类加载器就能加载一个假冒的 java.lang.System 吗? 答案是不行。\r\n\r\n* 假设你自己的类加载器用双亲委派，那么优先由启动类加载器加载真正的 java.lang.System，自然不会加载假冒的\r\n\r\n* 假设你自己的类加载器不用双亲委派，那么你的类加载器加载假冒的 java.lang.System 时，它需要先加载父类 java.lang.Object，而你没有用委派，找不到 java.lang.Object 所以加载会失败\r\n\r\n* **以上也仅仅是假设**。事实上操作你就会发现，自定义类加载器加载以 java. 打头的类时，会抛安全异常，在 jdk9 以上版本这些特殊包名都与模块进行了绑定，更连编译都过不了\r\n\r\n\r\n\r\n>***代码说明***\r\n>\r\n>* day03.loader.TestJdk9ClassLoader - 演示类加载器与模块的绑定关系\r\n\r\n\r\n\r\n## 6. 四种引用\r\n\r\n**要求**\r\n\r\n* 掌握四种引用\r\n\r\n\r\n\r\n**强引用**\r\n\r\n1. 普通变量赋值即为强引用，如 A a = new A();\r\n\r\n2. 通过 GC Root 的引用链，如果强引用不到该对象，该对象才能被回收\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210901111903574.png\" alt=\"image-20210901111903574\" style=\"zoom:80%;\" />\r\n\r\n**软引用（SoftReference）**\r\n\r\n1. 例如：SoftReference a = new SoftReference(new A());\r\n\r\n2. 如果仅有软引用该对象时，首次垃圾回收不会回收该对象，如果内存仍不足，再次回收时才会释放对象\r\n\r\n3. 软引用自身需要配合引用队列来释放\r\n\r\n4. 典型例子是反射数据\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210901111957328.png\" alt=\"image-20210901111957328\" style=\"zoom:80%;\" />\r\n\r\n\r\n\r\n**弱引用（WeakReference）**\r\n\r\n1. 例如：WeakReference a = new WeakReference(new A());\r\n\r\n2. 如果仅有弱引用引用该对象时，只要发生垃圾回收，就会释放该对象\r\n\r\n3. 弱引用自身需要配合引用队列来释放\r\n\r\n4. 典型例子是 ThreadLocalMap 中的 Entry 对象\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210901112107707.png\" alt=\"image-20210901112107707\" style=\"zoom:80%;\" />\r\n\r\n\r\n\r\n**虚引用（PhantomReference）**\r\n\r\n1. 例如： PhantomReference a = new PhantomReference(new A(), referenceQueue);\r\n\r\n2. 必须配合引用队列一起使用，当虚引用所引用的对象被回收时，由 Reference Handler 线程将虚引用对象入队，这样就可以知道哪些对象被回收，从而对它们关联的资源做进一步处理\r\n\r\n3. 典型例子是 Cleaner 释放 DirectByteBuffer 关联的直接内存\r\n\r\n<img src=\"https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210901112157901.png\" alt=\"image-20210901112157901\" style=\"zoom:80%;\" />\r\n\r\n\r\n\r\n\r\n\r\n>***代码说明***\r\n>\r\n>* day03.reference.TestPhantomReference - 演示虚引用的基本用法\r\n>* day03.reference.TestWeakReference - 模拟 ThreadLocalMap, 采用引用队列释放 entry 内存\r\n\r\n\r\n\r\n## 7. finalize\r\n\r\n**要求**\r\n\r\n* 掌握 finalize 的工作原理与缺点\r\n\r\n\r\n\r\n**finalize**\r\n\r\n* 它是 Object 中的一个方法，如果子类重写它，垃圾回收时此方法会被调用，可以在其中进行资源释放和清理工作\r\n* 将资源释放和清理放在 finalize 方法中非常不好，非常影响性能，严重时甚至会引起 OOM，从 Java9 开始就被标注为 @Deprecated，不建议被使用了\r\n\r\n\r\n\r\n**finalize 原理**\r\n\r\n1. 对 finalize 方法进行处理的核心逻辑位于 java.lang.ref.Finalizer 类中，它包含了名为 unfinalized 的静态变量（双向链表结构），Finalizer 也可被视为另一种引用对象（地位与软、弱、虚相当，只是不对外，无法直接使用）\r\n2. 当重写了 finalize 方法的对象，在构造方法调用之时，JVM 都会将其包装成一个 Finalizer 对象，并加入 unfinalized 链表中\r\n\r\n![image-20210901121032813](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210901121032813.png)\r\n\r\n3. Finalizer 类中还有另一个重要的静态变量，即 ReferenceQueue 引用队列，刚开始它是空的。当狗对象可以被当作垃圾回收时，就会把这些狗对象对应的 Finalizer 对象加入此引用队列\r\n4. 但此时 Dog 对象还没法被立刻回收，因为 unfinalized -> Finalizer 这一引用链还在引用它嘛，为的是【先别着急回收啊，等我调完 finalize 方法，再回收】\r\n5. FinalizerThread 线程会从 ReferenceQueue 中逐一取出每个 Finalizer 对象，把它们从链表断开并真正调用 finallize 方法\r\n\r\n![image-20210901122228916](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20210901122228916.png)\r\n\r\n6. 由于整个 Finalizer 对象已经从 unfinalized 链表中断开，这样没谁能引用到它和狗对象，所以下次 gc 时就被回收了\r\n\r\n\r\n\r\n**finalize 缺点**\r\n\r\n* 无法保证资源释放：FinalizerThread 是守护线程，代码很有可能没来得及执行完，线程就结束了\r\n* 无法判断是否发生错误：执行 finalize 方法时，会吞掉任意异常（Throwable）\r\n* 内存释放不及时：重写了 finalize 方法的对象在第一次被 gc 时，并不能及时释放它占用的内存，因为要等着 FinalizerThread 调用完 finalize，把它从 unfinalized 队列移除后，第二次 gc 时才能真正释放内存\r\n* 有的文章提到【Finalizer 线程会和我们的主线程进行竞争，不过由于它的优先级较低，获取到的CPU时间较少，因此它永远也赶不上主线程的步伐】这个显然是错误的，FinalizerThread 的优先级较普通线程更高，原因应该是 finalize 串行执行慢等原因综合导致\r\n\r\n\r\n\r\n> ***代码说明***\r\n>\r\n> * day03.reference.TestFinalize - finalize 的测试代码"},{"title":"mall项目总结","tags":["Spring Boot","Spring Cloud","Spring Cloud Alibaba","MySQL","MyBatis-Plus","Redis","RabbitMQ"],"categories":["Java","项目"],"author":"imklaus","excerpt":"\n\n参考视频：[雷神谷粒商城项目](https://www.bilibili.com/video/BV1np4y1C7Yf/)\n\n\n\n\n ![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230315150052611.png)\n\n![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230315145952769.png)\n\n## 项目名称\n\n- 书阁”图书商城管理系统、微盟电子商城网络交易系统、高校闲置资源交易系统\n- 购物在“e”零售商城平台、惠农通—智慧农资商城 、农产品轻量级微商城系统\n- 精美鞋业贸易系统\n\n## 项目简介\n\n- 本系统采用微服务架构设计，在分布式环境下利用Spring Cloud框架，通过业务划分，设计独立模块的微服务，拆分为订单服务、购物车服务、支付服务、用户管理服务、商品管理服务、文件上传服务等模块，结合了当前比较流行的互联网电商模式，为消费者提供商品贸易平台。\n","link":"/posts/mall","content":"\n\n参考视频：[雷神谷粒商城项目](https://www.bilibili.com/video/BV1np4y1C7Yf/)\n\n\n\n\n ![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230315150052611.png)\n\n![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230315145952769.png)\n\n## 项目名称\n\n- 书阁”图书商城管理系统、微盟电子商城网络交易系统、高校闲置资源交易系统\n- 购物在“e”零售商城平台、惠农通—智慧农资商城 、农产品轻量级微商城系统\n- 精美鞋业贸易系统\n\n## 项目简介\n\n- 本系统采用微服务架构设计，在分布式环境下利用Spring Cloud框架，通过业务划分，设计独立模块的微服务，拆分为订单服务、购物车服务、支付服务、用户管理服务、商品管理服务、文件上传服务等模块，结合了当前比较流行的互联网电商模式，为消费者提供商品贸易平台。\n<!-- more -->\n\n## 系统架构\n\n- 该系用采用SpringCloud架构，利用SpringBoot构建应用，Nacos作为服务的注册、配置中心，OpenFeign实现与其他模块进行交互，Sentinel实现熔断降级和错误处理，Seata分布式事务解决方案，Gateway作为服务网关，Sleuth链路追踪，RabbitMQ实现延迟队列，Redis作为缓存解决读多写少的场景，MySQL进行持久化，MyBatisPlus作为持久化框架。\n\n## 我的职责\n\n- 完成平台**商品、购物车、订单、库存、优惠券、支付、文件上传**等服务模块的接口开发；\n- 使用**RabbitMQ延时队列**实现未付款订单，超过一定时间后，**系统自动取消订单并解锁库存；**\n- 使用**redis+lua脚本**防止重复提交攻击，**解决了用户利用浏览器刷新和回退重复提交订单的问题；**\n- 基于**Redisson分布式限流：Semaphore信号量**实现**秒杀和一人一单功能**，通过逐步**改进分布式锁**的方案，**解决在多线程情况下用户重复提交订单的幂等性问题；**\n- 基于 **Token** 的认证授权机制：**JWT**，通过对登录用户颁发登录凭证，**实现登录模块认证授权功能；**\n- 使用**ElasticSearch分布式全文搜索引擎**，对冷数据，商品信息数据**建立索引**，**保证冷数据，商品数据的查询性能；**\n- 利用**Jmeter工具**进行压测，找到在**多线程**情况下造成的**内存泄漏，并发与同步**等问题，**保证了系统在线上的处理能力和稳定性维持在一个标准范围内；**\n- 使用**Redis**进行**热点信息缓存**，比如附近购物车信息和登录信息,**提高服务器的性能**；\n- 使用**Spring Schedule定时任务**提前上架抢购商品信息到Redis缓存中实现**库存预热功能**\n- 使用**Redisson分布式锁**解决分布式系统下商品重复上架的**幂等性问题**；\n- 使用**Spring Cache方法级别缓存技术**，实现已经被调用过的指定的目标方法，直接从缓存中获取方法调用后的结果返回，**提高系统的响应速度；**\n- 使用**CompletableFuture 异步编排**解决查询商品详情⻚**响应速度慢的问题**；\n- 使用**Nacos作为注册中心与配置中心**，将服务名称及其对应地址进行存储，实现服务地址的**注册与发现**以及**配置动态加载**等功能\n- 使用**Seata中的TCC事务模式**，把一个完整的业务逻辑拆分成三个阶段,通过事务管理器进行管理，**保证分布式系统数据一致性问题；**\n- 整合**第三方文件上传服务**，如阿里云对象存储，基于服务端签名后直传，**保证文件传输的安全性**；\n- 整合**OAuth2.0协议授权**，使用AccessToken调用开发API获取用户信息，**支持微信、QQ、微博、Gitee、Github等第三方登陆；**\n- 使用**RSA算法保证数据加密安全**，成功对接第三方支付功能，订单付款支持**支付宝、微信支付**等第三方支付服务。\n\n1、梳理自己项目的难点或亮点是什么？\n2、项目中，为什么用 xx 技术点，用 yy 的可以吗？或者为什么这么设计？\n\n关于第一点，这个内容即使面试官没问，我们也可以在自我介绍时候表述出来。\n\n如果你觉得自己的项目的确没什么厉害的东西，都是业务的 curd。那就挑一个值得说过的优化，或者设计方案也行。\n\n毕竟高大上的东西的确只有少数人接触到，都是理解的。\n\n接下来关于第二点，目的是考察你对自己项目的理解是不是真的知其所以然，还是说自己只是一个无情的 curd 机器。\n\n项目切入点:分布式锁的实现、分布式Session、分布式缓存、缓存一致性、跨域、异步编排等，重点把握秒杀模块和\n订单模块的设计及流程\n\n\n\n## 项目概述\n\n​    本系统是专门为精美鞋业有限公司制定的对外贸易系统，大部分商品出售给越南地区，供那边的厂商进行二次加工。\n​    本系统采用微服务架构设计，在分布式环境下利用Spring Cloud框架，通过业务划分，设计独立模块的微服务，拆分为订单服务、购物车服务、支付服务、用户管理服务、商品管理服务、文件上传服务等模块，为客户提供半成品商品贸易平台。\n\n### 核心业务一：购物车\n\n- 购物车Redis数据结构选型：\n\n  - 双层 Map：Map<String,Map<String,String>>\n\n    - 第一层 Map，Key 是用户 id\n\n    - 第二层 Map，Key 是购物车中商品 id，值是购物项数据\n\n- 购物车两个核心功能：新增商品到购物车、查询购物车\n\n  - 新增商品：判断是否登录\n\n    - 是：则添加商品到后台 Redis 中，把 user 的唯一标识符作为 key。\n    - 否：则添加商品到后台 Redis 中，使用随机生成的 user-key 作为 key。\n\n- 查询购物车列表：判断是否登录\n\n  - 否：直接根据 user-key 查询 Redis 中数据并展示\n  - 是：已登录，则需要先根据 user-key 查询 Redis 是否有数据。\n  - 有：需要提交到后台添加到 Redis ，合并数据，而后查询。\n  - 否：直接去后台查询 Redis ，而后返回\n\n\n### 核心业务二：订单\n\n#### 订单中心\n\n- 电商系统涉及到 3 流，分别时信息流，资金流，物流，而订单系统作为中枢将三者有机的集\n  合起来。\n- 订单模块是电商系统的枢纽，在订单这个环节上需求获取多个模块的数据和信息，同时对这\n  些信息进行加工处理后流向下个环节，这一系列就构成了订单的信息流通。\n\n#### 订单构成\n\n![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410153419456.png)\n\n#### 订单状态\n\n1. 待付款\n   - 用户提交订单后，订单进行预下单，目前主流电商网站都会唤起支付，便于用户快速完成支\n     付，需要注意的是待付款状态下可以对库存进行锁定，锁定库存需要配置支付超时时间，超\n     时后将自动取消订单，订单变更关闭状态。\n2. 已付款/ 待发货\n   - 用户完成订单支付，订单系统需要记录支付时间，支付流水单号便于对账，订单下放到 WMS\n     系统，仓库进行调拨，配货，分拣，出库等操作。\n3. 待收货/ 已发货\n   - 仓储将商品出库后，订单进入物流环节，订单系统需要同步物流信息，便于用户实时知悉物\n     品物流状态\n4. 已完成\n   - 用户确认收货后，订单交易完成。后续支付侧进行结算，如果订单存在问题进入售后状态\n5. 已取消\n   - 付款之前取消订单。包括超时未付款或用户商户取消订单都会产生这种订单状态。\n\n#### 订单流程\n\n- 正常的网购步骤：订单生成–>支付订单–>卖家发货–>确认收货–>交易成功\n\n##### 1.订单创建与支付\n\nhttp://order.gulimall.com/toTrade\n\n![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403130800413.png)\n\nhttp://order.gulimall.com/submitOrder\n\n- `com.klaus.gulimall.order.web.OrderWebController#submitOrder`\n\n```java\n\n     /**\n     * \n     * @param vo 上一个页面携带的数据\n     * @param model\n     * @param redirectAttributes\n     * @return\n     */\n@PostMapping(\"/submitOrder\")\npublic String submitOrder(OrderSubmitVo vo, Model model, RedirectAttributes redirectAttributes){\n    //捕获异常\n    try {\n        SubmitOrderResponseVo responseVo = orderService.submitOrder(vo);\n        //下单：去创建订单，验令牌，验价格，锁库存....\n        System.out.println(\"订单提交的数据...\" + vo);\n        if (responseVo.getCode() == 0){\n            //下单成功来到支付选择页\n            model.addAttribute(\"submitOrderResponse\", responseVo);\n            return \"pay\";\n        }else {\n            //下单失败重定向到订单确认页\n            String msg = \"下单失败：\";\n            switch (responseVo.getCode()){\n                case 1: msg+= \"订单信息过期，请刷新再次提交\"; break;\n                case 2: msg+= \"订单商品价格发生了变化，请刷新再次提交\"; break;\n                case 3: msg+= \"库存锁定失败，商品库存不足\"; break;\n            }\n            redirectAttributes.addFlashAttribute(\"msg\", msg);\n            return \"redirect:http://order.gulimall.com/toTrade\";\n        }\n    }catch (Exception e) {\n        if (e instanceof NoStockException) {\n            String message = ((NoStockException) e).getMessage();\n            //抛出无库存异常后页面显示此异常信息NO_STOCK_EXCEPTION(21000, \"商品库存不足\");\n            redirectAttributes.addFlashAttribute(\"msg\", message);\n        }\n        //抛出任何异常后重定向会订单确认页\n        return \"redirect:http://order.gulimall.com/toTrade\";\n    }\n}\n\n```\n\n- `com.klaus.gulimall.order.service.impl.OrderServiceImpl#submitOrder`\n\n```java\n /**\n     * 下单\n     * 加入统一事务\n     * @param vo\n     * @return\n     * @Transactional 本地事务，在分布式系统下，只能控制自己的回滚，控制不了其他服务的回滚\n     * (isolation = Isolation.REPEATABLE_READ)默认隔离级别\n     * ->分布式事务: 最大原因是网络问题+分布式机器\n     *\n     */\n//@GlobalTransactional 高并发 此注解会加很多全局锁，导致下单只能等别人先下完单才能下，高并发环境不可取\n    @Transactional\n    @Override\n    public SubmitOrderResponseVo submitOrder(OrderSubmitVo vo) {\n        submitVoThreadLocal.set(vo);\n        SubmitOrderResponseVo responseVo = new SubmitOrderResponseVo();\n        //从拦截器里获取用户信息\n        MemberRespVo memberRespVo = LoginUserInterceptor.loginUser.get();\n        responseVo.setCode(0);\n        //1、验证令牌【令牌的对比和删除必须保证原子性】\n        //0令牌失败 - 1删除成功(校验成功)\n        String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\";\n        String orderToken = vo.getOrderToken();\n        //原子验证令牌和删除令牌\n        Long result = redisTemplate.execute(\n                //脚本返回类型->0,1\n                new DefaultRedisScript<Long>(script, Long.class),\n                //将缓存中将要比对的key转为集合\n                Arrays.asList(OrderConstant.USER_ORDER_TOKEN_PREFIX + memberRespVo.getId()),\n                //传入要校验的值\n                orderToken);\n        if (result == 0L) {\n            //验证失败，设置错误状态码为1，key过期等情况\n            responseVo.setCode(1);\n            return responseVo;\n        } else {\n            //验证成功\n            //下单：去创建订单，验令牌，验价格，锁库存....\n            //1、创建订单，订单项等信息\n            OrderCreateTo order = createOrder();\n            // todo 观察者模式: 发布商品下单事件\n            ApplicationContextHolder.getInstance().publishEvent(new OrderCreateEvent(this, order));\n            //2、验价，拿到应付金额与页面提交的金额进行校验\n            BigDecimal payAmount = order.getOrder().getPayAmount();\n            BigDecimal payPrice = vo.getPayPrice();\n            //两者相减的绝对值小于0.01就算校验通过\n            if (Math.abs(payAmount.subtract(payPrice).doubleValue()) < 0.01){\n                //校验通过\n                //TODO 3、保存订单\n                saveOrder(order);\n                //4、库存锁定，这样能避免库存不足等现象发生\n                //只要有异常就回滚订单数据(订单号，所有订单项（skuId，skuName，num）)\n                WareSkuLockVo lockVo = new WareSkuLockVo();\n                //设置指定库存的订单号\n                lockVo.setOrderSn(order.getOrder().getOrderSn());\n                List<OrderItemVo> locks = order.getOrderItems().stream().map(item -> {\n                    OrderItemVo orderItemVo = new OrderItemVo();\n                    //订单已经保存了，可以直接设置\n                    orderItemVo.setSkuId(item.getSkuId());\n                    orderItemVo.setCount(item.getSkuQuantity());\n                    orderItemVo.setTitle(item.getSkuName());\n                    return orderItemVo;\n                }).collect(Collectors.toList());\n                //锁定订单项数据\n                lockVo.setLocks(locks);\n                //todo 4、远程锁库存\n                //库存锁定成功了，但是网络原因超时了，订单回滚，库存不回滚\n                //为了保证高并发，库存服务自己回滚，可以发消息给库存服务\n                //库存服务本身也可以使用自动解锁模式->消息队列\n                R r = wmsFeignService.orderLockStock(lockVo);\n                //判断远程调用是否成功\n                if (r.getCode() == 0){\n                    //远程调用成功，锁成功了\n                    responseVo.setOrder(order.getOrder());\n //todo 5、远程扣减积分  出异常 引入seata后业务标注@GlobalTransactional订单回滚，库存回滚\n\t\t\t\t\t// int i = 10/0;//不标注@GlobalTransactional 订单回滚，库存不回滚\n                    //todo 订单创建成功发送消息给MQ\n                    rabbitTemplate.convertAndSend(\"order-event-exchange\", \"order.create.order\", order.getOrder());\n                    return responseVo;\n                }else {\n                    //远程调用失败，锁定失败\n                    //锁定失败\n                    String msg = (String) r.get(\"msg\");\n                    //抛出异常就不能设置错误状态码了\n                    throw new NoStockException(msg);\n//                    responseVo.setCode(3);\n//                    return responseVo;\n                }\n            }else {\n                //校验失败\n                responseVo.setCode(2);\n                return responseVo;\n            }\n        }\n    }\n```\n\n- `com.klaus.gulimall.order.service.impl.OrderServiceImpl#createOrder`\n\n```java\n/**\n     * 创建订单聚合方法，含构建订单和所有订单项\n     * @return\n     */\n    private OrderCreateTo createOrder() {\n        //获取当前登录的用户信息\n        MemberRespVo memberRespVo = LoginUserInterceptor.loginUser.get();\n        OrderCreateTo createTo = new OrderCreateTo();\n        //1、todo 生成订单号(使用雪花算法根据用户id创建订单号)\n//        String orderSn = IdWorker.getTimeId();\n        String orderSn = SnowflakeIdUtil.nextIdStrByService(memberRespVo.getId().toString());\n        //创建订单\n        OrderEntity orderEntity = buildOrder(orderSn);\n        //2、获取到所有的订单项\n        List<OrderItemEntity> itemEntities = buildOrderItems(orderSn);\n        //3、验价，计算价格、积分等相关\n        computePrice(orderEntity, itemEntities);\n//        createTo.setOrderItems(itemEntities);\n//        createTo.setOrder(orderEntity);\n        // 构建订单聚合根\n        OrderCreateTo order = createTo.builder()\n                .order(orderEntity)\n                .orderItems(itemEntities)\n                .fare(orderEntity.getFreightAmount())\n                .payPrice(orderEntity.getPayAmount())\n                .build();\n\n        return order;\n    }\n```\n\n![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403131446123.png)\n\n- 支付服务，提供支付宝、微信、银行卡等支付方式，支持支付查询以及退款等功能。\n\n\n- ###### **配置项修改**\n\n详情见 **支付宝沙箱对接** 中需要修改配置项。\n\n> - ###### **核心流程**\n>\n> **核心流程(刚果商城项目参考)：**\n>\n> 1）通过策略模式封装支付渠道和支付场景，用户支付时动态选择对应的支付组件。\n>\n> - 代码地址：`org.opengoofy.congomall.biz.pay.application.service.impl.PayServiceImpl#commonPay`\n>\n> 2）通过策略模式封装支付回调场景，三方支付平台回调时动态选择对应的支付回调组件。\n>\n> - 代码地址：`org.opengoofy.congomall.biz.pay.application.service.impl.PayServiceImpl#callback`\n\n- ###### 支付宝沙箱对接\n\n项目中已对接支付宝沙箱环境，以下介绍如何对接支付宝沙箱。\n\n- 1. **注册账号**\n\n注册支付宝开发者账户，进入开发者控制台。\n\n[https://openhome.alipay.com/platform/developerIndex.htmopen in new window](https://openhome.alipay.com/platform/developerIndex.htm)\n\n直接进入沙箱环境地址。\n\n[https://open.alipay.com/develop/sandbox/appopen in new window](https://open.alipay.com/develop/sandbox/app)\n\n沙箱应用页面如下：\n\n![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1674111619522-82229cf7-482d-4a4e-81bd-637c55c3d6a9.png)\n\n- 2. **获取支付参数**\n\n拿到 APPID 替换 `application.properties` 文件中 `alipay.app-id`。\n\n![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1674111838001-9ff075ce-e324-43a6-a6b6-e3d860970e6a.png)\n\n为了图方便，这里直接使用支付宝自定义公钥和私钥。\n\n我这里是已经开启过的，所以启用按钮是置灰的。第一次使用应该是蓝色可点击的状态。\n\n![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1674112006561-4be2d9d4-ef90-4c49-aee6-1f6f6a988f2d.png)\n\n复制支付宝公钥替换 `application.properties` 文件中 `alipay.alipay_public_key`。\n\n复制应用私钥替换 `application.properties` 文件中 `alipay.private_key`。\n\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1674112099708-2d1a70a2-6af5-4502-8192-f6bb587b302f.png)\n\n至此，就可以调用支付接口进行支付宝支付功能了。\n\n- 3. **调用支付宝接口**\n\n访问支付服务 API，调用支付宝支付接口。\n\n调用支付接口http://order.gulimall.com/payOrder?orderSn=202304031500558581642784227126714369后，新创建 `pay.html` 空文件，复制控制台日志中前端文件代码到 `pay.html`。\n\n- `com.klaus.gulimall.order.service.impl.OrderServiceImpl#getOrderPay`\n\n```java\n/**\n * 获取当前订单的支付信息\n * @param orderSn\n * @return\n */\n@Override\npublic PayVo getOrderPay(String orderSn) {\n    PayVo payVo = new PayVo();\n    OrderEntity entity = this.getOrderByOrderSn(orderSn);\n\n    //保留2位小数，有小数就想上取值\n    BigDecimal bigDecimal = entity.getTotalAmount().setScale(2, BigDecimal.ROUND_UP);\n    payVo.setTotal_amount(bigDecimal.toString());\n    payVo.setOut_trade_no(entity.getOrderSn());\n\n    List<OrderItemEntity> itemEntities = orderItemService.list(new QueryWrapper<OrderItemEntity>().eq(\"order_sn\", orderSn));\n    OrderItemEntity item = itemEntities.get(0);\n    payVo.setSubject(item.getSkuName());\n    payVo.setBody(item.getSkuAttrsVals());\n\n    return payVo;\n}\n```\n\n- `com.klaus.gulimall.order.web.PayWebController#payOrder`\n\n```java\n /**\n     * 1、将支付页让浏览器展示\n     * 2、支付成功以后，我们要跳到用户的订单列表页\n     * @param orderSn\n     * @return\n     * @throws AlipayApiException\n     */\n    @ResponseBody\n    @GetMapping(value = \"/payOrder\", produces = \"text/html\")\n    public String payOrder(@RequestParam(\"orderSn\") String orderSn) throws AlipayApiException {\n\n\n        PayVo payVo = orderService.getOrderPay(orderSn);\n        //返回的是一个页面，将此页面直接交给浏览器就行\n        String pay = alipayTemplate.pay(payVo);\n//        System.out.println(pay);\n        return pay;\n    }\n```\n\n- `com.klaus.gulimall.order.config.AlipayTemplate#pay`\n\n```java\npublic  String pay(PayVo vo) throws AlipayApiException {\n\n    //AlipayClient alipayClient = new DefaultAlipayClient(AlipayTemplate.gatewayUrl, AlipayTemplate.app_id, AlipayTemplate.merchant_private_key, \"json\", AlipayTemplate.charset, AlipayTemplate.alipay_public_key, AlipayTemplate.sign_type);\n    //1、根据支付宝的配置生成一个支付客户端\n    AlipayClient alipayClient = new DefaultAlipayClient(gatewayUrl,\n            app_id, merchant_private_key, \"json\",\n            charset, alipay_public_key, sign_type);\n\n    //2、创建一个支付请求 //设置请求参数\n    AlipayTradePagePayRequest alipayRequest = new AlipayTradePagePayRequest();\n    alipayRequest.setReturnUrl(return_url);\n    alipayRequest.setNotifyUrl(notify_url);\n\n    //商户订单号，商户网站订单系统中唯一订单号，必填\n    String out_trade_no = vo.getOut_trade_no();\n    //付款金额，必填\n    String total_amount = vo.getTotal_amount();\n    //订单名称，必填\n    String subject = vo.getSubject();\n    //商品描述，可空\n    String body = vo.getBody();\n\n    alipayRequest.setBizContent(\"{\\\"out_trade_no\\\":\\\"\"+ out_trade_no +\"\\\",\"\n            + \"\\\"total_amount\\\":\\\"\"+ total_amount +\"\\\",\"\n            + \"\\\"subject\\\":\\\"\"+ subject +\"\\\",\"\n            + \"\\\"body\\\":\\\"\"+ body +\"\\\",\"\n            + \"\\\"timeout_express\\\":\\\"\"+timeout+\"\\\",\"\n            + \"\\\"product_code\\\":\\\"FAST_INSTANT_TRADE_PAY\\\"}\");\n\n    String result = alipayClient.pageExecute(alipayRequest).getBody();\n\n    //会收到支付宝的响应，响应的是一个页面，只要浏览器显示这个页面，就会自动来到支付宝的收银台页面\n    System.out.println(\"支付宝的响应：\"+result);\n\n    return result;\n\n}\n```\n\n![image](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403152134343.png)\n\n通过谷歌浏览器打开 `pay.html`即可，看到以下页面即为正常现象。\n\n![image-20230403131612455](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403131612455.png)\n\n账户名和支付密码从沙箱账号处复制买方信息。如果买方账户余额为 0，可随意充值金额。\n\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/1674195718913-2cf0d08a-1bc0-4303-aef5-df51a662fadf.png)\n\n使用账户余额支付即可。\n\n![image-20230403131639507](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403131639507.png)\n\n支付结果显示成功。\n\n![image-20230403131649890](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403131649890.png)\n\n- 4. **支付结果回调**\n\n如果希望在沙箱环境中得知具体支付结果，我们需要通过 Natapp 开通内网穿透，开通教程详细查看下述官方文档：\n\n[https://natapp.cn/article/natapp_newbieopen in new window](https://natapp.cn/article/natapp_newbie)\n\n开通后，将内网穿透端口为 80，本地地址改为虚拟机映射本地host的地址(192.168.10.103=>order.gulimall.com)即支付服务项目端口。\n\n![image-20230403152749004](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403152749004.png)\n\n将 Natapp 内网穿透地址替换 `application.properties` 文件下 `alipay.notify_url` 属性。\n\n再重复调用下支付宝支付接口流程，即可看到回调效果。\n\n- 配置以上内网穿透配置才能完成订单支付，否则订单支付失败，订单自动取消，库存自动解锁\n\n```properties\n#异步通知：支付宝会悄悄的给我们发送一个请求，告诉我们支付成功的信息\nalipay.notify_url=http://mqbb4a.natappfree.cc/paid/notify\n```\n\n![image-20230403131656175](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403131656175.png)\n\n- `com.klaus.gulimall.order.service.impl.OrderServiceImpl#handlePayResult`\n\n\n```java\n/**\n     * 处理支付宝的支付结果\n     * @param vo\n     * @return\n     */\n    @Override\n    public String handlePayResult(PayAsyncVo vo) {\n        //1、保存交易流水\n        PaymentInfoEntity infoEntity = new PaymentInfoEntity();\n        infoEntity.setAlipayTradeNo(vo.getTrade_no());\n        infoEntity.setOrderSn(vo.getOut_trade_no());\n        infoEntity.setPaymentStatus(vo.getTrade_status());\n        infoEntity.setCallbackTime(vo.getNotify_time());\n\n        paymentInfoService.save(infoEntity);\n\n        //2、修改订单的状态信息\n        if (vo.getTrade_status().equals(\"TRADE_SUCCESS\") || vo.getTrade_status().equals(\"TRADE_FINISHED\")){\n            //支付成功状态\n            String outTradeNo = vo.getOut_trade_no();\n            this.baseMapper.updateOrderStatus(outTradeNo, OrderStatusEnum.PAYED.getCode());\n        }\n\n        return \"success\";\n    }\n```\n\n- `com.klaus.gulimall.order.listener.OrderPaidListener#handleAlipaid`\n\n```java\n /**\n     * 支付成功异步通知\n     * @param vo\n     * @param request\n     * @return\n     */\n    @PostMapping(\"/paid/notify\")\n    public String handleAlipaid(PayAsyncVo vo, HttpServletRequest request) throws Exception {\n\n        //只要我们收到了支付宝给我们异步的通知，告诉我们订单支付成功，返回success，支付宝就再也不通知\n//        Map<String, String[]> map = request.getParameterMap();\n//        for (String key : map.keySet()) {\n//            String value = request.getParameter(key);\n//            System.out.println(\"参数名：\"+key+\"==>参数值：\"+ value);\n//        }\n//        System.out.println(\"支付宝通知到位了...数据：\"+map);\n        //验签\n        Map<String,String> params = new HashMap<String,String>();\n        Map<String,String[]> requestParams = request.getParameterMap();\n        for (Iterator<String> iter = requestParams.keySet().iterator(); iter.hasNext();) {\n            String name = (String) iter.next();\n            String[] values = (String[]) requestParams.get(name);\n            String valueStr = \"\";\n            for (int i = 0; i < values.length; i++) {\n                valueStr = (i == values.length - 1) ? valueStr + values[i]\n                        : valueStr + values[i] + \",\";\n            }\n            //乱码解决，这段代码在出现乱码时使用\n//            valueStr = new String(valueStr.getBytes(\"ISO-8859-1\"), \"utf-8\");\n            params.put(name, valueStr);\n        }\n\n        boolean signVerified = AlipaySignature.rsaCheckV1(params, alipayTemplate.getAlipay_public_key(), alipayTemplate.getCharset(), alipayTemplate.getSign_type()); //\n        if (signVerified){\n            //验签成功\n            System.out.println(\"签名验证成功.....\");\n            String result = orderService.handlePayResult(vo);\n            return result;\n        }else {\n            System.out.println(\"签名验证失败.....\");\n            return \"error\";\n        }\n    }\n```\n\n页面跳转同步通知页面路径 需http://格式的完整路径，不能加?id=123这类自定义参数，必须外网可以正常访问；订单支付完成成功返回以下页面(同步通知，支付成功，一般跳转到成功页)：\n\n```java\nprivate  String return_url = \"http://member.gulimall.com/memberOrder.html\";\n```\n\n- `com.klaus.gulimall.member.Web.MemberWebController#memberOrderPage`\n\n```java\n@GetMapping(\"/memberOrder.html\")\npublic String memberOrderPage(@RequestParam(value = \"pageNum\", defaultValue = \"1\") Integer pageNum,\n                              Model model) {\n\n    //查出当前登录的用户的所有订单列表数据\n    Map<String, Object> page = new HashMap<>();\n    page.put(\"page\", pageNum.toString());\n    R r = orderFeignService.listWithItem(page);\n    System.out.println(JSON.toJSONString(r));\n    model.addAttribute(\"orders\", r);\n\n    return \"orderList\";\n}\n```\n\n- 远程调用订单服务查出当前登录的用户的所有订单列表数据\n- `com.klaus.gulimall.order.controller.OrderController#listWithItem`\n\n```java\n/**\n * todo 远程调用都要全用@POSTMapping+@RequestBody(请求体只支持post)\n * 分页查询当前登录用户的所有订单\n * @param params\n * @return\n */\n@PostMapping(\"/listWithItem\")\n//@RequiresPermissions(\"order:order:list\")\npublic R listWithItem(@RequestBody Map<String, Object> params){\n    PageUtils page = orderService.queryPageWithItem(params);\n\n    return R.ok().put(\"page\", page);\n}\n```\n\n- `com.klaus.gulimall.order.service.impl.OrderServiceImpl#queryPageWithItem`\n\n```java\n@Override\npublic PageUtils queryPageWithItem(Map<String, Object> params) {\n    //获取当前登录的用户信息\n    MemberRespVo memberRespVo = LoginUserInterceptor.loginUser.get();\n\n    IPage<OrderEntity> page = this.page(\n            new Query<OrderEntity>().getPage(params),                                            //根据id降序\n            new QueryWrapper<OrderEntity>().eq(\"member_id\", memberRespVo.getId()).orderByDesc(\"id\")\n    );\n\n    List<OrderEntity> orderEntities = page.getRecords().stream().map(order -> {\n        //封装订单项到订单\n        List<OrderItemEntity> itemEntities = orderItemService.list(new QueryWrapper<OrderItemEntity>().eq(\"order_sn\", order.getOrderSn()));\n        order.setItemEntities(itemEntities);\n        return order;\n    }).collect(Collectors.toList());\n\n    page.setRecords(orderEntities);\n\n    return new PageUtils(page);\n}\n```\n\n![image-20230403131702203](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403131702203.png)\n\n\n\n\n\n\n\n##### 2.订单创建前需要预览订单，选择收货信息等\n\nhttp://cart.gulimall.com/cart.html\n\n![image-20230403130248691](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403130248691.png)\n\nhttp://order.gulimall.com/toTrade\n\n- `com.klaus.gulimall.order.web.OrderWebController#toTrade`\n\n```java\n/**\n     * OrderConfirmVo = [List<MemberAddressVo> address, //收货地址， \n     *                  List<OrderItemVo> items,      //所有选中的购物项\n     *                 Integer integration,         //积分...\n     *                 Map<Long, Boolean> stocks, //库存信息\n     *                 String orderToken        //防重令牌]\n*/\n@GetMapping(\"/toTrade\")\npublic String toTrade(Model model, HttpServletRequest request) throws ExecutionException, InterruptedException {\n    OrderConfirmVo confirmVo = orderService.confirmOrder();\n    model.addAttribute(\"orderConfirmData\", confirmVo);\n    //展示订单确认的数据(页面跳转)\n    return \"confirm\";\n}\n```\n\n- `com.klaus.gulimall.order.service.impl.OrderServiceImpl#confirmOrder`\n\n- > **注**：使用异步编排时用到远程调用，如果不进行请求上下文共享将造成Feign异步情况丢失上下文问题\n\n```java\n/**\n * 订单确认页返回需要用到的数据\n * @return\n */\n@Override\npublic OrderConfirmVo confirmOrder() throws ExecutionException, InterruptedException {\n    OrderConfirmVo confirmVo = new OrderConfirmVo();\n    //从拦截器里获取用户信息\n    MemberRespVo memberRespVo = LoginUserInterceptor.loginUser.get();\n    System.out.println(\"主线程....\" + Thread.currentThread().getId());\n\n    //获取原来请求上下文请求属性\n    RequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();\n    //进行异步编排\n    CompletableFuture<Void> getAddressFuture = CompletableFuture.runAsync(() -> {\n        //1、远程查询所有的收货地址列表\n        System.out.println(\"member线程....\" + Thread.currentThread().getId());\n        //在Feign异步调用前将请求上下文进行共享操作(之前的请求数据都来共享每一个线程)\n        RequestContextHolder.setRequestAttributes(requestAttributes);\n        List<MemberAddressVo> address = memberFeignService.getAddress(memberRespVo.getId());\n        confirmVo.setAddress(address);\n    }, executor);\n\n    CompletableFuture<Void> cartFuture = CompletableFuture.runAsync(() -> {\n        //2、远程查询购物车所有选中的购物项\n        System.out.println(\"cart线程....\" + Thread.currentThread().getId());\n        //在Feign异步调用前将请求上下文进行共享操作\n        RequestContextHolder.setRequestAttributes(requestAttributes);\n        List<OrderItemVo> items = cartFeignService.currentUserCartItems();\n        confirmVo.setItems(items);\n        //feign在远程调用之前要构造请求，调用很多的拦截器\n        //for(RequestInterceptor interceptor:requestInterceptors)\n    }, executor).thenRunAsync(() -> {\n        List<OrderItemVo> items = confirmVo.getItems();\n        List<Long> skuIds = items.stream().map(item -> item.getSkuId()).collect(Collectors.toList());\n        //远程查询库存\n        R r = wmsFeignService.getSkusHasStock(skuIds);\n        List<SkuStockVo> data = r.getData(new TypeReference<List<SkuStockVo>>() {\n        });\n        if (data != null) {\n            // Map<SkuId, hasStock> map\n            Map<Long, Boolean> map = data.stream().collect(Collectors.toMap(SkuStockVo::getSkuId, SkuStockVo::getHasStock));\n            // Map<Long, Boolean> stocks;\n            confirmVo.setStocks(map);\n        }\n    }, executor);\n\n    //3、查询用户积分\n    Integer integration = memberRespVo.getIntegration();\n    confirmVo.setIntegration(integration);\n\n    //4、其他数据自动计算\n\n    //todo 5、防重令牌\n    String token = UUID.randomUUID().toString().replace(\"-\", \"\");\n    //给服务器一个令牌\n    redisTemplate.opsForValue().set(OrderConstant.USER_ORDER_TOKEN_PREFIX + memberRespVo.getId(), token, 30, TimeUnit.MINUTES);\n    //给页面一个令牌\n    confirmVo.setOrderToken(token);\n    CompletableFuture.allOf(getAddressFuture, cartFuture).get();\n    return confirmVo;\n}\n```\n\n![image-20230403130554589](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403130554589.png)\n\n![image-20230416234636426](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230416234636426.png)\n\n\n\n##### 3.订单创建需要锁定库存，库存有才可创建，否则不能创建\n\n- 查询sku是否有库存\n- `com.klaus.gulimall.ware.controller.WareSkuController#getSkusHasStock`\n\n```java\n//查询sku是否有库存\n    @PostMapping(\"/hasstock\")\n    public R getSkusHasStock(@RequestBody List<Long> skuIds) {\n        //sku_id stock\n        List<SkuHasStockVo> vos = wareSkuService.getSkusHasStock(skuIds);\n        return R.ok().setData(vos);\n    }\n```\n\n- `com.klaus.gulimall.ware.service.impl.WareSkuServiceImpl#getSkusHasStock`\n\n```java\n@Override\npublic List<SkuHasStockVo> getSkusHasStock(List<Long> skuIds) {\n\n    List<SkuHasStockVo> collect = skuIds.stream().map(skuId -> {\n        SkuHasStockVo vo = new SkuHasStockVo();\n        //查询当前sku的总库存量\n        //SELECT SUM(stock-stock_locked) FROM `wms_ware_sku` WHERE sku_id=1\n        //获取查询到的库存记录数\n        Long count = baseMapper.getSkuStock(skuId);\n        vo.setSkuId(skuId);\n        //记录数大于0表示有库存\n        vo.setHasStock(count == null ? false : count > 0);\n        return vo;\n    }).collect(Collectors.toList());\n    return collect;\n}\n```\n\n- SQL\n\n```xml\n<select id=\"getSkuStock\" resultType=\"java.lang.Long\">\n    SELECT SUM(stock-stock_locked) FROM `wms_ware_sku` WHERE sku_id=#{skuId}\n</select>\n```\n\n![image-20230404010335539](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404010335539.png)\n\n- 创建订单进行库存锁定\n- `com.klaus.gulimall.ware.controller.WareSkuController#orderLockStock`\n\n```java\n@RequestMapping(\"/lock/order\")\npublic R orderLockStock(@RequestBody WareSkuLockVo vo){\n    Boolean lockStock = null;\n    try {\n        lockStock = wareSkuService.orderLockStock(vo);\n        return R.ok();\n    } catch (NoStockException e) {\n        //通过测试发现商品库存不足将会在页面显示以下错误信息(http://order.gulimall.com/toTrade)\n        return R.error(BizCodeEnum.NO_STOCK_EXCEPTION.getCode(), BizCodeEnum.NO_STOCK_EXCEPTION.getMsg());\n    }\n}\n```\n\n- `com.klaus.gulimall.ware.service.impl.WareSkuServiceImpl#orderLockStock`\n\n```java\n/**\n * 为某个订单锁定库存\n * 加入统一事务\n * (rollbackFor = NoStockException.class )\n * 默认只要是运行时异常都会回滚\n * 库存解锁的场景\n * 1）、下订单成功，订单过期没有支付被系统自动取消、被用户手动取消，都要解锁库存\n * 2）、下订单成功，库存锁定成功，接下来的业务调用失败，导致订单回滚\n * 之前锁定的库存就要自动解锁\n * @param vo\n * @return\n */\n@Transactional\n@Override\npublic Boolean orderLockStock(WareSkuLockVo vo) {\n    /**\n     * 保存库存工作单的详情的两张表\n     * 追溯\n     */\n    WareOrderTaskEntity taskEntity = new WareOrderTaskEntity();\n    taskEntity.setOrderSn(vo.getOrderSn());\n    wareOrderTaskService.save(taskEntity);\n    //按照下单的收货地址，找到一个就近仓库，锁定库存\n    //1、找到每个商品在哪个仓库都有库存\n    List<OrderItemVo> locks = vo.getLocks();\n    List<SkuWareHasStock> collect = locks.stream().map(item -> {\n        SkuWareHasStock stock = new SkuWareHasStock();\n        Long skuId = item.getSkuId();\n        stock.setSkuId(skuId);\n        stock.setNum(item.getCount());\n        //查询这个商品在哪里有库存\n        List<Long> wareIds = wareSkuDao.listWareIdHasSkuStock(skuId);\n        stock.setWareIds(wareIds);\n        return stock;\n    }).collect(Collectors.toList());\n    //2、锁定库存\n    for (SkuWareHasStock hasStock : collect) {\n        Boolean skuStocked = false;//lock_status=0\n        Long skuId = hasStock.getSkuId();\n        List<Long> wareIds = hasStock.getWareIds();\n        if (wareIds == null || wareIds.size() == 0) {\n            //没有任何仓库有这个商品的库存\n            throw new NoStockException(skuId);\n        }\n        //1、如果每一个商品都锁定成功，将当前商品锁定了几件的工作单记录发给MQ\n        //2、锁定失败。前面保存的工作单信息就回滚了，即使要解锁记录，由于去数据库查不到id，所以就不用解锁\n        //  log:skuId-num-ware: 1:1-2-1(v) 2:2-1-3(v) 3:3-1-1(x)\n        //  既然锁成功了就应该扣减，之后就应该解锁，因为3记录锁失败，1,2记录就回滚了，相当于工作单回滚了，库存没回滚库存扣减\n        // 只传id工作单是不知道当时库存锁了多少个\n        for (Long wareId : wareIds) {\n            //成功就返回1，否则就是0\n            Long count = wareSkuDao.lockSkuStock(skuId, wareId, hasStock.getNum());\n            if (count == 1) {\n                //锁成功了==>lock_status=1\n                skuStocked = true;\n                //退出当前循环\n                //todo 告诉MQ库存锁定成功\n                WareOrderTaskDetailEntity detailEntity = new WareOrderTaskDetailEntity(null, skuId, \"\", hasStock.getNum(), taskEntity.getId(), wareId, 1);\n                //保存工作单详情\n                wareOrderTaskDetailService.save(detailEntity);\n                StockLockedTo lockedTo = new StockLockedTo();\n                //属性拷贝到to\n                StockDetailTo stockDetailTo = new StockDetailTo();\n                BeanUtils.copyProperties(detailEntity, stockDetailTo);\n                //只传工作单id还不够，防止回滚以后找不到数据\n                lockedTo.setId(taskEntity.getId());\n                lockedTo.setDetailTo(stockDetailTo);\n                //发送锁定库存消息；提交订单后，出现异常，订单回滚，库存不回滚，延时队列有2个任务等待死信时间结束后发送消息\n                rabbitTemplate.convertAndSend(\"stock-event-exchange\", \"stock.locked\", lockedTo);\n                break;\n            } else {\n                //当前仓库锁失败了，重试下一个仓库\n            }\n        }\n        if (skuStocked == false) {\n            //当前商品所有仓库都没有锁住\n            throw new NoStockException(skuId);\n        }\n    }\n    //3、肯定全部都是锁定成功过的\n    return true;\n}\n```\n\n- 库存工作单表`wms_ware_order_task`\n\n![image-20230404012221654](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404012221654.png)\n\n- 库存工作单详情`wms_ware_order_task_detail`\n- ![image-20230404012535232](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404012535232.png)\n\n![image-20230404012359140](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404012359140.png)\n\n```java\n//查询这个商品在哪里有库存\n//com.klaus.gulimall.ware.dao.WareSkuDao#listWareIdHasSkuStock\nList<Long> wareIds = wareSkuDao.listWareIdHasSkuStock(skuId);\n```\n\n - SQL\n\n```xml\n<select id=\"listWareIdHasSkuStock\" resultType=\"java.lang.Long\">\n    SELECT ware_id FROM `wms_ware_sku` WHERE sku_id=#{skuId} AND stock-stock_locked >0\n</select>\n```\n\n![image-20230404013003956](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404013003956.png)\n\n```java\n//库存锁定成功就返回1，否则就是0\n//com.klaus.gulimall.ware.dao.WareSkuDao#lockSkuStock\nLong count = wareSkuDao.lockSkuStock(skuId, wareId, hasStock.getNum());\n```\n\n- SQL\n\n```xml\n<update id=\"lockSkuStock\">\n    UPDATE `wms_ware_sku` SET stock_locked = stock_locked + #{num}\n    WHERE sku_id =#{skuId} AND ware_id=#{wareId} AND stock-stock_locked>=#{num}\n</update>\n```\n\n![image-20230404014111150](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404014111150.png)\n\n\n\n\n\n\n\n\n\n##### 4.订单创建后超时未支付需要解锁库存\n\n- 库存解锁分两种情况，一种是订单正常支付超时库存自动解锁；一种是订单服务异常/宕机库存自动解锁\n\n- `com.klaus.gulimall.ware.service.impl.WareSkuServiceImpl#unlockStock(com.klaus.common.to.mq.StockLockedTo)`\n\n```java\n/**\n * 1、库存自动解锁\n *      下订单成功，库存锁定成功，接下来的业务调用失败，导致订单回滚。之前锁定的库存就要自动解锁\n * 2、下订单失败\n * 锁库存失败\n * 只要解锁库存的消息失败，一定要告诉服务器解锁失败\n * @param to\n * @param message\n */\n@Override\npublic void unlockStock(StockLockedTo to) {\n    StockDetailTo detail = to.getDetailTo();\n    Long detailId = detail.getId();\n    //1、查询数据库关于这个订单的锁定库存信息\n    // 有： 证明库存锁定成功了\n    //     解锁：订单情况\n    //          1、没有这个订单，必须解锁\n    //          2、有这个订单，就不是解锁库存\n    //                  订单状态： 已取消：解锁库存\n    //                           没取消：不能接受\n    // 没有：库存锁定失败了，库存回滚了。这种情况无需解锁\n    WareOrderTaskDetailEntity taskDetailEntity = wareOrderTaskDetailService.getById(detailId);\n    if (taskDetailEntity != null) {\n        //有工作详情单，但只能证明库存服务在锁库存的时候锁成功后返回出去的，\n        // 要看整个订单有没有下单成功，如果订单远程调用的其他服务崩了导致订单回滚，这跟库存服务没有关系，直接解锁是有问题的，因为订单都没有\n        //解锁\n        Long id = to.getId();//库存工作单的id\n        //获取订单状态\n        WareOrderTaskEntity taskEntity = wareOrderTaskService.getById(id);\n        String orderSn = taskEntity.getOrderSn();\n        //根据订单号查询订单的状态\n        R r = orderFeignService.getOrderStatus(orderSn);\n        if (r.getCode() == 0) {\n            //远程调用成功，订单数据返回成功\n            OrderVo data = r.getData(new TypeReference<OrderVo>() {\n            });\n            if (data == null || data.getStatus() == 4) {\n                //订单已经被取消或订单不存在，才能解锁库存\n                //问题：订单服务由于网络等原因迟迟没有将订单解锁(data.getStatus()==0)导致库存永远释放不了锁\n                if (taskDetailEntity.getLockStatus() == 1){\n                    //当前库存工作单详情，状态为1 已锁定但是未解锁才可以解锁\n                    unLockStock(detail.getSkuId(), detail.getWareId(), detail.getSkuNum(), detailId);\n                }\n            }\n        } else {\n            //远程调用失败直接抛异常\n            throw new RuntimeException(\"远程服务失败\");\n        }\n    } else {\n        //无需解锁\n    }\n}\n```\n\n- 远程调用订单服务获取订单状态\n\n- `com.klaus.gulimall.order.controller.OrderController#getOrderStatus`\n\n```java\n@GetMapping(\"/status/{orderSn}\")\npublic R getOrderStatus(@PathVariable(\"orderSn\") String orderSn){\n    OrderEntity orderEntity = orderService.getOrderByOrderSn(orderSn);\n    return R.ok().setData(orderEntity);\n}\n```\n\n```java\n@Override\npublic OrderEntity getOrderByOrderSn(String orderSn) {\n    OrderEntity orderEntity = this.getOne(new QueryWrapper<OrderEntity>().eq(\"order_sn\", orderSn));\n    return orderEntity;\n}\n```\n\n- `com.klaus.gulimall.ware.service.impl.WareSkuServiceImpl#unlockStock(com.klaus.common.to.mq.OrderTo)`\n\n```java\n/**\n* 防止订单服务卡顿，导致更改订单状态的操作无法完成以及更改的mq消息没有得到执行，解锁库存的消息优先到期，扫描订单状态是新建状态，就会什么都不做\n * 导致卡顿的订单永远不能解锁库存\n * @param orderTo\n * 加入统一事务\n */\n@Transactional\n@Override\npublic void unlockStock(OrderTo orderTo) {\n    String orderSn = orderTo.getOrderSn();\n    //查一下最新库存的状态，防止重复解锁库存\n    WareOrderTaskEntity task = wareOrderTaskService.getOrderTaskByOrderSn(orderSn);\n    Long id = task.getId();\n    //按照工作单找到所有 没有解锁的库存，进行解锁\n    List<WareOrderTaskDetailEntity> detailEntities = wareOrderTaskDetailService.list(new QueryWrapper<WareOrderTaskDetailEntity>().\n            eq(\"task_id\", id).\n            //新建的还没被解锁的库存\n            eq(\"lock_status\", 1));\n    for (WareOrderTaskDetailEntity entity : detailEntities) {\n        //此解锁方式可以解决高并发问题和整个系统的异构(两个服务开发语言不同。如java，php)\n        unLockStock(entity.getSkuId(), entity.getWareId(), entity.getSkuNum(), entity.getId());\n    }\n}\n```\n\n- 库存解锁方法`com.klaus.gulimall.ware.service.impl.WareSkuServiceImpl#unLockStock`\n\n```java\nprivate void unLockStock(Long skuId, Long wareId, Integer num, Long taskDetailId) {\n    //库存解锁\n    wareSkuDao.unLockStock(skuId, wareId, num);\n    //更新库存工作单的状态\n    WareOrderTaskDetailEntity entity = new WareOrderTaskDetailEntity();\n    entity.setId(taskDetailId);\n    entity.setLockStatus(2);//变为已解锁\n    wareOrderTaskDetailService.updateById(entity);\n}\n```\n\n- SQL\n\n```xml\n<update id=\"unLockStock\">\n    UPDATE `wms_ware_sku` SET stock_locked=stock_locked-#{num}\n    WHERE sku_id=#{skuId} AND ware_id=#{wareId}\n</update>\n```\n\n![image-20230404015601068](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404015601068.png)\n\n\n\n\n\n\n\n##### 5.支付成功后，需要进行拆单，根据商品打包方式，所在仓库，物流等进行拆单(待开发)\n\n##### 6.支付的每笔流水都需要记录，以待查账\n\n![image-20230403161913669](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230403161913669.png)\n\n- `com.klaus.gulimall.order.service.impl.OrderServiceImpl#handlePayResult`\n\n```java\n/**\n * 处理支付宝的支付结果\n * @param vo\n * @return\n */\n@Override\npublic String handlePayResult(PayAsyncVo vo) {\n    //1、保存交易流水\n    PaymentInfoEntity infoEntity = new PaymentInfoEntity();\n    infoEntity.setAlipayTradeNo(vo.getTrade_no());\n    infoEntity.setOrderSn(vo.getOut_trade_no());\n    infoEntity.setPaymentStatus(vo.getTrade_status());\n    infoEntity.setCallbackTime(vo.getNotify_time());\n\n    paymentInfoService.save(infoEntity);\n\n    //2、修改订单的状态信息\n    if (vo.getTrade_status().equals(\"TRADE_SUCCESS\") || vo.getTrade_status().equals(\"TRADE_FINISHED\")){\n        //支付成功状态\n        String outTradeNo = vo.getOut_trade_no();\n        this.baseMapper.updateOrderStatus(outTradeNo, OrderStatusEnum.PAYED.getCode());\n    }\n\n    return \"success\";\n}\n```\n\n\n\n\n\n##### 7.订单创建，支付成功(待开发)等状态都需要给 MQ 发送消息，方便其他系统感知订阅\n\n- 添加依赖\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-amqp</artifactId>\n</dependency>\n```\n\n- **订单创建**：(MQ)\n- 订单创建采用延迟队列\n- `com.klaus.gulimall.order.config.MyMQConfig`\n\n```java\n@Bean\npublic Queue orderDelayQueue(){\n\n    Map<String, Object> arguments = new HashMap<>();\n    /**\n     * x-dead-letter-exchange: order-event-exchange\n     * x-dead-letter-routing-key: order.release.order\n     * x-message-ttl: 60000\n     */\n    arguments.put(\"x-dead-letter-exchange\", \"order-event-exchange\");\n    arguments.put(\"x-dead-letter-routing-key\", \"order.release.order\");\n    arguments.put(\"x-message-ttl\", 60000);\n\n    //String name, boolean durable, boolean exclusive, boolean autoDelete, Map<String, Object> arguments\n    Queue queue = new Queue(\"order.delay.queue\", true, false, false, arguments);\n    return queue;\n}\n@Bean\npublic Exchange orderEventExchange(){\n    //String name, boolean durable, boolean autoDelete, Map<String, Object> arguments\n    return new TopicExchange(\"order-event-exchange\", true, false);\n}\n@Bean\npublic Binding orderCreateOrderBinding(){\n   //String destination, Binding.DestinationType destinationType, String exchange, String routingKey, Map<String, Object> arguments\n   return new Binding(\"order.delay.queue\",\n                Binding.DestinationType.QUEUE,\n                \"order-event-exchange\",\n                \"order.create.order\", null);\n}\n```\n\n> - 创建订单 进入路由键-order.create.order- 进入交换机order-event-exchange， 根据路由键会转发到延时队列order.delay.queue 30min(60s)过期时间，过期时间到了之后，根据**死信**路由键-order.release.order-到达释放订单队列order.release.order.queue，监听这个队列的方法判断订单是不是已支付。\n\n![image-20230404121815115](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404121815115.png)\n\n- `com.klaus.gulimall.order.service.impl.OrderServiceImpl#submitOrder`\n\n```java\n@Transactional\n@Override\npublic SubmitOrderResponseVo submitOrder(OrderSubmitVo vo) {\n    ...\n    //todo 订单创建成功发送消息给MQ\n    rabbitTemplate.convertAndSend(\"order-event-exchange\", \"order.create.order\", order.getOrder());\n\t...\n}\n```\n\n\n\n**库存锁定**：(MQ)\n\n- 库存锁定采用延迟队列\n\n- `com.klaus.gulimall.ware.config.MyRabbitConfig`\n\n```java\n@Bean\npublic Exchange stockEventExchange(){\n    return new TopicExchange(\"stock-event-exchange\", true, false);\n}\n@Bean\npublic Queue stockDelayQueue(){\n    Map<String, Object> arguments = new HashMap<>();\n    arguments.put(\"x-dead-letter-exchange\", \"stock-event-exchange\");\n    arguments.put(\"x-dead-letter-routing-key\", \"stock.release\");\n    arguments.put(\"x-message-ttl\", 120000);\n\n    //String name, boolean durable, boolean exclusive, boolean autoDelete, Map<String, Object> arguments\n    return new Queue(\"stock.delay.queue\", true, false, false, arguments);\n}\n\n@Bean\npublic Binding stockLockedBinding(){\n    //String destination, Binding.DestinationType destinationType, String exchange, String routingKey, Map<String, Object> arguments\n    return new Binding(\"stock.delay.queue\",\n            Binding.DestinationType.QUEUE,\n            \"stock-event-exchange\",\n            \"stock.locked\", null);\n}\n```\n\n> - 库存锁定成功 进入路由键-stock.locked- 进入交换机stock-event-exchange， 根据路由键会转发到延时队列stock.delay.queue 50min(120s)过期时间，延迟时间到，根据**死信**路由键-stock.release-到达释放订单队列stock.release.stock.queue，检查订单状态，确认是否需要解锁。\n\n![image-20230404122316210](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404122316210.png)\n\n- 订单创建成功后库存锁定也成功就发送消息给MQ\n\n- `com.klaus.gulimall.ware.service.impl.WareSkuServiceImpl#orderLockStock`\n\n```java\n@Transactional\n@Override\npublic Boolean orderLockStock(WareSkuLockVo vo) {\n    ...\n //发送锁定库存消息；提交订单后，出现异常，订单回滚，库存不回滚，延时队列有2个任务等待死信时间结束后发送消息\n  rabbitTemplate.convertAndSend(\"stock-event-exchange\", \"stock.locked\", lockedTo);\n  ...\n}\n```\n\n\n\n\n\n**防止超卖**：数据库 unsigned int 做最后的保证。 (范围0~65535)\n\n- 在mysql数据库中，unsigned表面含义是 '无符号'的意思，unsigned既为非负数，用此类型可以增加数据长度。\n\n\n\n**自动关单**：订单超时未支付，需要取消订单 (MQ)\n\n- `com.klaus.gulimall.order.config.MyMQConfig`\n\n```java\n\t@Bean\n    public Queue orderReleaseOrderQueue(){\n        Queue queue = new Queue(\"order.release.order.queue\", true, false, false);\n        return queue;\n    }\n \t@Bean\n    public Exchange orderEventExchange(){\n        //String name, boolean durable, boolean autoDelete, Map<String, Object> arguments\n        return new TopicExchange(\"order-event-exchange\", true, false);\n    }\n\t@Bean\n    public Binding orderReleaseOrderBinding(){\n        return new Binding(\"order.release.order.queue\",\n                Binding.DestinationType.QUEUE,\n                \"order-event-exchange\",\n                \"order.release.order\", null);\n    }\n```\n\n> - 订单创建延迟时间到了之后，根据路由键-order.release.order-到达释放订单队列order.release.order.queue， 监听这个队列的方法 先是判断订单是不是已支付，如果不是就关闭订单，`关闭订单之后，根据路由键order.release.other 发送关闭的订单数据消息到交换机order-event-exchange，交换机再转发到order.release.coupon.queue优惠券队列，返回优惠券，与之通过 也是根据路由键order.release.other(待开发)`\n\n![image-20230404124500812](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404124500812.png)\n\n- `com.klaus.gulimall.order.listener.OrderCloseListener`\n- 添加配置文件`application.properties`中的RabbitMQ配置项\n\n```properties\nspring.rabbitmq.host=192.168.10.103\nspring.rabbitmq.port=5672\nspring.rabbitmq.virtual-host=/\n# 开启发送端确认\nspring.rabbitmq.publisher-confirms=true\n# 开启发送端消息抵达队列的确认\nspring.rabbitmq.publisher-returns=true\n# 只要抵达队列，以异步发送优先回调我们这个returnConfirm\nspring.rabbitmq.template.mandatory=true\n# 手动ack消息\nspring.rabbitmq.listener.simple.acknowledge-mode=MANUAL\n```\n\n```java\n/**\n * 订单释放(关单)监听器\n */\n@Service\n@RabbitListener(queues = \"order.release.order.queue\")\npublic class OrderCloseListener {\n\n    @Autowired\n    OrderService orderService;\n\n    @RabbitHandler\n    public void listener(OrderEntity entity, Channel channel, Message message) throws IOException {\n        //等待死信时间到后收到订单消息\n        System.out.println(\"收到过期的订单信息，准备关闭订单\"+entity.getOrderSn());\n        try {\n            orderService.closeOrder(entity);\n            //手动调用支付宝收单\n\n            //签收订单\n            channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);\n        } catch (Exception e) {\n\n            channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);\n        }\n    }\n}\n```\n\n- `com.klaus.gulimall.order.service.impl.OrderServiceImpl#closeOrder`\n\n```java\n/**\n   * 关单方法，将订单新建(待付款)状态设置为已取消状态并发送消息给MQ确认关单完成\n   * @param entity\n*/\n@Override\npublic void closeOrder(OrderEntity entity) {\n    //查询当前这个订单的最新状态\n    //将要发送的消息队列实体(释放订单服务前)\n    OrderEntity orderEntity = this.getById(entity.getId());\n    //status=0\n    if (orderEntity.getStatus() == OrderStatusEnum.CREATE_NEW.getCode()){\n        //在待付款状态下才关单(消息队列的实体有可能过期了，所以创建新实体)\n        OrderEntity update = new OrderEntity();\n        update.setId(entity.getId());\n        // status=4\n        update.setStatus(OrderStatusEnum.CANCLED.getCode());\n        this.updateById(update);\n        OrderTo orderTo = new OrderTo();\n        BeanUtils.copyProperties(orderEntity, orderTo);\n        try {\n            //todo 保证消息一定会发送出去，每一个消息都可以做好日志记录（给数据库保存每一个消息的详细信息）\n            //todo 定期扫描数据库将失败的消息再发送一遍；\n            //只要解锁成功了就【立即】发消息给MQ\n            rabbitTemplate.convertAndSend(\"order-event-exchange\", \"order.release.other\", orderTo);\n        } catch (Exception e) {\n            //todo 将没发送成功的消息进行重试发送 （while）\n        }\n    }\n}\n```\n\n**解锁库存**： (MQ)\n\n- `com.klaus.gulimall.ware.config.MyRabbitConfig`\n\n```java\n@Bean\npublic Exchange stockEventExchange(){\n    return new TopicExchange(\"stock-event-exchange\", true, false);\n}\n@Bean\npublic Queue stockReleaseStockQueue(){\n    return new Queue(\"stock.release.stock.queue\", true, false, false);\n}\n@Bean\npublic Binding stockReleaseBinding(){\n    return new Binding(\"stock.release.stock.queue\",\n                Binding.DestinationType.QUEUE,\n                \"stock-event-exchange\",\n                \"stock.release.#\", null);\n}\n```\n\n> - `关闭订单之后，根据路由键order.release.other 发送关闭的订单数据到交换机order-event-exchange，交换机再转发到order.release.coupon.queue优惠券队列，返回优惠券，与之通过 也是根据路由键order.release.other，和数据一起转发到解锁库存队列stock.release.stock.queue 解锁库存(待开发)。`\n\n![image-20230404134206092](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404134206092.png)\n\n- 订单关闭，需要解锁已经占用的库存\n\n- `com.klaus.gulimall.ware.listener.StockReleaseListener`\n\n```java\n/**\n * 监听库存解锁队列\n */\n@RabbitListener(queues = \"stock.release.stock.queue\")\n@Service\npublic class StockReleaseListener {\n\n    @Autowired\n    WareSkuService wareSkuService;\n\n\t/**\n     * 订单正常关闭(订单服务正常运行)，需要解锁已经占用的库存\n     * @param to 库存工作单(含工作单详情)\n     */\n    @RabbitHandler\n    public void handleStockLockedRelease(StockLockedTo to, Message message, Channel channel) throws IOException {\n        System.out.println(\"收到解锁库存的消息...\");\n        try {\n            //当前消息是否被第二次及以后(重新)派发过来了\n//            Boolean redelivered = message.getMessageProperties().getRedelivered();\n            wareSkuService.unlockStock(to);\n            //只要解锁成功了，就签收消息\n            channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);\n        } catch (Exception e) {\n            //有任何异常直接拒绝签收;消息拒绝以后重新放到队列里面，让别人继续消费解锁\n            channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);\n        }\n    }\n}\n```\n\n- `com.klaus.gulimall.ware.service.impl.WareSkuServiceImpl#unlockStock(com.klaus.common.to.mq.StockLockedTo)`\n\n```java\n@Override\npublic void unlockStock(StockLockedTo to) {\n    ...\n    //问题：订单服务由于网络等原因迟迟没有将订单解锁(data.getStatus()==0)导致库存永远释放不了锁\n    if (taskDetailEntity.getLockStatus() == 1){\n    //当前库存工作单详情，状态为1 已锁定但是未解锁才可以解锁\n    unLockStock(detail.getSkuId(), detail.getWareId(), detail.getSkuNum(), detailId);\n\t...\n}    \n```\n\n- 库存锁定成功，订单回滚，保证最终一致性，也需要库存自动解锁；库存锁定成功，订单服务全部炸了，订单都没有创建好，就必须有自动解锁功能\n- `com.klaus.gulimall.ware.listener.StockReleaseListener`\n\n```java\n/**\n * 监听库存解锁队列\n */\n@RabbitListener(queues = \"stock.release.stock.queue\")\n@Service\npublic class StockReleaseListener {\n\n    @Autowired\n    WareSkuService wareSkuService;\n\n    /**\n     * 订单异常关闭(订单服务发送运行时异常或宕机)，需要解锁已经占用的库存\n     * 如果库存锁定成功，订单服务全部炸了，订单都没有创建好，就必须有自动解锁功能\n     * @param orderTo 完整订单信息\n     * @param message\n     * @param channel\n     * @throws IOException\n     */\n    @RabbitHandler\n    public void handleOrderCloseRelease(OrderTo orderTo, Message message, Channel channel) throws IOException {\n        System.out.println(\"订单关闭准备解锁库存....\");\n        try {\n            wareSkuService.unlockStock(orderTo);\n            //只要解锁成功了，就签收消息\n            channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);\n        } catch (Exception e) {\n            //有任何异常直接拒绝签收;消息拒绝以后重新放到队列里面，让别人继续消费解锁\n            channel.basicReject(message.getMessageProperties().getDeliveryTag(), true);\n        }\n    }\n}\n```\n\n- `com.klaus.gulimall.ware.service.impl.WareSkuServiceImpl#unlockStock(com.klaus.common.to.mq.OrderTo)+#unLockStock`\n\n```java\n/**\n * 防止订单服务卡顿，导致更改订单状态的操作无法完成以及更改的mq消息没有得到执行，解锁库存的消息优先到期，扫描订单状态是新建状态，就会什么都不做\n * 导致卡顿的订单永远不能解锁库存\n * @param orderTo\n * 加入统一事务\n */\n@Transactional\n@Override\npublic void unlockStock(OrderTo orderTo) {\n    String orderSn = orderTo.getOrderSn();\n    //查一下最新库存的状态，防止重复解锁库存\n    WareOrderTaskEntity task = wareOrderTaskService.getOrderTaskByOrderSn(orderSn);\n    Long id = task.getId();\n    //按照工作单找到所有 没有解锁的库存，进行解锁\n    List<WareOrderTaskDetailEntity> detailEntities = wareOrderTaskDetailService.list(new QueryWrapper<WareOrderTaskDetailEntity>().\n            eq(\"task_id\", id).\n            //新建的还没被解锁的库存\n            eq(\"lock_status\", 1));\n    for (WareOrderTaskDetailEntity entity : detailEntities) {\n        //此解锁方式可以解决高并发问题和整个系统的异构(两个服务开发语言不同。如java，php)\n        unLockStock(entity.getSkuId(), entity.getWareId(), entity.getSkuNum(), entity.getId());\n    }\n}\nprivate void unLockStock(Long skuId, Long wareId, Integer num, Long taskDetailId) {\n    //库存解锁\n    wareSkuDao.unLockStock(skuId, wareId, num);\n    //更新库存工作单的状态\n    WareOrderTaskDetailEntity entity = new WareOrderTaskDetailEntity();\n    entity.setId(taskDetailId);\n    entity.setLockStatus(2);//变为已解锁\n    wareOrderTaskDetailService.updateById(entity);\n}\n```\n\n\n\n##### 订单确认页流程\n\n![image-20230322151416874](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322151416874.png)\n\n##### 电商订单流程图\n\n![image-20230322151557139](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322151557139.png)\n\n##### 消息队列流程图\n\n![image-20230416235749443](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230416235749443.png)\n\n##### 支付宝支付流程图\n\n![image-20230404162856264](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230404162856264.png)\n\n\n\n### 项目难点\n\n- 订单服务与库存的联动(延时队列的使用)\n\n- 订单释放&库存解锁\n\n  ![image-20230322190959538](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322190959538.png)\n\n### 解决问题\n\n- 使用**CompletableFuture 异步编排**解决查询商品详情⻚**响应速度慢的问题**；\n\n  - 假如商品详情页的每个查询，需要如下标注的时间才能完成\n    那么，用户需要 5.5s 后才能看到商品详情页的内容。很显然是不能接受的。\n    如果有多个线程同时完成这 6 步操作，也许只需要 1.5s 即可完成响应。\n\n- 使用**Spring Cache方法级别缓存技术**，实现已经被调用过的指定的目标方法，直接从缓存中获取方法调用后的结果返回，**提高系统的响应速度；**\n\n- 幂等解决方案\n\n  - token 机制\n\n    - 1、服务端提供了发送 token 的接口。我们在分析业务的时候，哪些业务是存在幂等问题的，就必须在执行业务前，先去获取 token，服务器会把token 保存到 redis 中。\n\n    - 2、然后调用业务接口请求时，把 token 携带过去，一般放在请求头部。\n\n    - 3、服务器判断 token 是否存在 redis 中，存在表示第一次请求，然后删除 token,继续执行业务。\n\n    - 4、如果判断 token 不存在 redis 中，就表示是重复操作，直接返回重复标记给 client，这样就保证了业务代码，不被重复执行。\n\n    - 危险性：\n\n      - 1、先删除 token 还是后删除 token；\n\n      - (1) 先删除可能导致，业务确实没有执行，重试还带上之前 token，由于防重设计导致，请求还是不能执行。\n\n      - (2) 后删除可能导致，业务处理成功，但是服务闪断，出现超时，没有删除 token，别人继续重试，导致业务被执行两遍\n\n      - (3) 我们最好设计为先删除 token，如果业务调用失败，就重新获取 token 再次请求。\n\n      - 2、Token 获取、比较和删除必须是原子性\n\n      - (1) redis.get(token) 、token.equals、redis.del(token)如果这两个操作不是原子，可能导致，高并发下，都 get 到同样的数据，判断都成功，继续业务并发执行\n\n      - (2) 可以在 redis 使用 lua 脚本完成这个操作\n\n   ```shell\n   if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\n   ```\n\n- Session共享问题解决-不同服务，子域session共享\n\n  - jsessionid这个cookie默认是当前系统域名的。当我们分拆服务，不同域名部署的时候，我们可以使用如下解决方案；\n\n  ![image-20230323001610876](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230323001610876.png)\n\n\n  ```java\n  @Configuration\n  public class GulimallSessionConfig {\n  \n      @Bean\n      public CookieSerializer cookieSerializer(){\n          DefaultCookieSerializer cookieSerializer = new DefaultCookieSerializer();\n  \n          cookieSerializer.setDomainName(\"gulimall.com\");\n          cookieSerializer.setCookieName(\"KLAUSSESSION\");\n          return cookieSerializer;\n      }\n  \n      @Bean\n      public RedisSerializer<Object> springSessionDefaultRedisSerializer() {\n          return new GenericJackson2JsonRedisSerializer();\n      }\n  }\n  ```\n\n  - SpringSession核心原理\n\n  ```java\n  /**\n   * 加入依赖\n   *          <dependency>\n   *             <groupId>org.springframework.boot</groupId>\n   *             <artifactId>spring-boot-starter-data-redis</artifactId>\n   *         </dependency>\n   *\n   *         <!--整合Springsession完成session共享问题-->\n   *         <dependency>\n   *             <groupId>org.springframework.session</groupId>\n   *             <artifactId>spring-session-data-redis</artifactId>\n   *         </dependency>\n   * 核心原理\n   * 1、@EnableRedisHttpSession导入RedisHttpSessionConfiguration配置\n   *      1）、给容器中添加了一个组件\n   *          传入SessionRepository==》【RedisOperationsSessionRepository】===》redis操作session，session的增删改查封装类\n   *      2）、SessionRepositoryFilter==》Filter(web)：session存储过滤器；每个请求过来都必须经过Filter\n   *         I）、创建的时候，就自动从容器中获取了SessionRepository\n   *         II）、原始的HttpServletRequest request, HttpServletResponse response都被分别包装成了SessionRepositoryRequestWrapper，SessionRepositoryResponseWrapper\n   *         III）、以后获取session-》request.getSession();（原始的）\n   *         //SessionRepositoryRequestWrapper重写getSession方法\n   *         IV）、wrapperRequest.getSession();==> SessionRepository中获取的到\n   *  装饰者模式；\n   *\n   *  自动延期；redis中的数据也是有过期时间的\n   */\n  @EnableRedisHttpSession //整合redis作为session存储\n  @SpringBootApplication\n  public class GulimallAuthServerApplication {\n  \n      public static void main(String[] args) {\n          SpringApplication.run(GulimallAuthServerApplication.class, args);\n      }\n  \n  }\n  ```\n\n  ![image-20230323001706985](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230323001706985.png)\n\n- ThreadLocal-同一个线程共享数据\n\n![image-20230323001857265](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230323001857265.png)\n\n- Feign远程调用丢失请求头问题\n\n  ![image-20230323001742038](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230323001742038.png)\n\n  - `com.klaus.gulimall.member.config`\n\n\n```java\n@Configuration\npublic class GulimallFeignConfig {\n\n    @Bean(\"requestInterceptor\")\n    public RequestInterceptor requestInterceptor() {\n        // RequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();\n        //RequestContextHolder.setRequestAttributes(requestAttributes);\n        // 进行共享操作，拦截器才会有请求上下文的所有数据\n        return new RequestInterceptor() {\n\n            @Override\n            public void apply(RequestTemplate template) {\n                //1、RequestContextHolder拿到刚进来的这个请求\n                ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();\n                if (attributes != null){\n                    System.out.println(\"RequestInterceptor线程....\"+Thread.currentThread().getId());\n                    HttpServletRequest request = attributes.getRequest();//老请求\n                    if (request != null){\n                        //请求不为空\n                        //同步请求头数据，Cookie\n                        String cookie = request.getHeader(\"Cookie\");\n//                System.out.println(\"feign远程之前先进行RequestInterceptor.apply\");\n                        //给新请求同步了老请求的Cookie\n                        template.header(\"Cookie\", cookie);\n                    }\n                }\n            }\n        };\n    }\n}\n```\n\n- Feign异步情况丢失上下文问题\n\n  ![image-20230323001802654](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230323001802654.png)\n\n  - `com.klaus.gulimall.order.service.impl.OrderServiceImpl#confirmOrder`\n\n\n```java\n//获取原来请求上下文请求属性\nRequestAttributes requestAttributes = RequestContextHolder.getRequestAttributes();\n//进行异步编排\nCompletableFuture<Void> getAddressFuture = CompletableFuture.runAsync(() -> {\n    //1、远程查询所有的收货地址列表\n    System.out.println(\"member线程....\" + Thread.currentThread().getId());\n    //在Feign异步调用前将请求上下文进行共享操作(之前的请求数据都来共享每一个线程)\n    RequestContextHolder.setRequestAttributes(requestAttributes);\n    List<MemberAddressVo> address = memberFeignService.getAddress(memberRespVo.getId());\n    confirmVo.setAddress(address);\n}, executor);\n\nCompletableFuture<Void> cartFuture = CompletableFuture.runAsync(() -> {\n    //2、远程查询购物车所有选中的购物项\n    System.out.println(\"cart线程....\" + Thread.currentThread().getId());\n    //在Feign异步调用前将请求上下文进行共享操作\n    RequestContextHolder.setRequestAttributes(requestAttributes);\n    List<OrderItemVo> items = cartFeignService.currentUserCartItems();\n    confirmVo.setItems(items);\n    //feign在远程调用之前要构造请求，调用很多的拦截器\n    //for(RequestInterceptor interceptor:requestInterceptors)\n}, executor).thenRunAsync(() -> {\n    List<OrderItemVo> items = confirmVo.getItems();\n    List<Long> skuIds = items.stream().map(item -> item.getSkuId()).collect(Collectors.toList());\n    //远程查询库存\n    R r = wmsFeignService.getSkusHasStock(skuIds);\n    List<SkuStockVo> data = r.getData(new TypeReference<List<SkuStockVo>>() {\n    });\n    if (data != null) {\n        // Map<SkuId, hasStock> map\n        Map<Long, Boolean> map = data.stream().collect(Collectors.toMap(SkuStockVo::getSkuId, SkuStockVo::getHasStock));\n        // Map<Long, Boolean> stocks;\n        confirmVo.setStocks(map);\n    }\n}, executor);\n```\n\n### 项目优化\n\n- 使用动态线程池管理和监控，定时获取线程池的运行数据\n\nHippo4j 提供了应用线程池运行时变更核心参数的功能。而且，如果应用是集群部署，可以选择修改线程池某一实例，或者修改集群全部实例，运行时生效，不需要再重启服务。\n\n压测时可以使用 Hippo4j 动态调整线程池参数，判断线程池核心参数设置是否合理。对于开发测试来说，如果不满足可以随时调整。\n\n\n\n## CompletableFuture异步编排\n\n### 概念\n\n- CompletableFuture是JDK1.8里面引入的一个异步回调类，就是说当前使用异步线程去执行一个任务时候，我们希望在这个任务结束以后，触发一个后续的动作，而CompletableFuture就可以实现这样的功能。\n\n### 业务场景\n\n- 查询商品详情页的逻辑比较复杂，有些数据还需要远程调用，必然需要花费更多的时间。\n\n![image-20230322152108985](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322152108985.png)\n\n- 假如商品详情页的每个查询，需要如下标注的时间才能完成\n  那么，用户需要 5.5s 后才能看到商品详情页的内容。很显然是不能接受的。\n  如果有多个线程同时完成这 6 步操作，也许只需要 1.5s 即可完成响应。\n- 在 Java 8 中, 新增加了一个包含 50 个方法左右的类: CompletableFuture，提供了非常强大的\n  Future 的扩展功能，可以帮助我们简化异步编程的复杂性，提供了函数式编程的能力，可以\n  通过回调的方式处理计算结果，并且提供了转换和组合 CompletableFuture 的方法。\n\n### 项目代码\n\n- `com.klaus.gulimall.product.service.impl.SkuInfoServiceImpl#item`\n\n\n```java\n    //四、线程串行化方法\n    /*\n    thenApply 方法：当一个线程依赖另一个线程时，获取上一个任务返回的结果，并返回当前\n    任务的返回值。\n    thenAccept 方法：消费处理结果。接收任务的处理结果，并消费处理，无返回结果。\n    thenRun 方法：只要上面的任务执行完成，就开始执行 thenRun，只是处理完任务后，执行\n    thenRun 的后续操作\n    带有 Async 默认是异步执行的。同之前。\n    以上都要前置任务成功完成。\n     */\n\t@Override\n    public SkuItemVo item(Long skuId) throws ExecutionException, InterruptedException {\n        SkuItemVo skuItemVo = new SkuItemVo();\n        //一、创建异步对象\n        /*\n         runAsync和supplyAsync  runXxxx 都是没有返回结果的，supplyXxx 都是可以获取返回结果的\n         可以传入自定义的线程池，否则就用默认的线程池；\n         */\n        CompletableFuture<SkuInfoEntity> infoFuture = CompletableFuture.supplyAsync(() -> {\n            //1.sku基本信息获取 pms_sku_info\n            SkuInfoEntity info = this.getById(skuId);\n            skuItemVo.setInfo(info);\n            return info;\n        }, executor);\n    CompletableFuture<Void> saleAttrFuture = infoFuture.thenAcceptAsync((res) -> {\n        //3、 获取spu的销售属性组合\n        List<SkuItemSaleAttrVo> saleAttrVos = skuSaleAttrValueService.getSaleAttrBySpuId(res.getSpuId());\n        skuItemVo.setSaleAttr(saleAttrVos);\n    }, executor);\n\n    CompletableFuture<Void> descFuture = infoFuture.thenAcceptAsync((res) -> {\n        //4.获取spu的介绍 pms_spu_info_desc\n        SpuInfoDescEntity spuInfoDescEntity = spuInfoDescService.getById(res.getSpuId());\n        skuItemVo.setDesc(spuInfoDescEntity);\n    }, executor);\n\n    CompletableFuture<Void> baseAttrFuture = infoFuture.thenAcceptAsync((res) -> {\n        //5.获取spu的规格参数信息\n        List<SpuItemAttrGroupVo> attrGroupVos = attrGroupService.getAttrGroupWithAttrsBySpuId(res.getSpuId(), res.getCatalogId());\n        skuItemVo.setGroupAttrs(attrGroupVos);\n    }, executor);\n\n    //一、创建异步对象\n    /*\n     runAsync和supplyAsync  runXxxx 都是没有返回结果的，supplyXxx 都是可以获取返回结果的\n     可以传入自定义的线程池，否则就用默认的线程池；\n     */\n    //2.sku图片信息  pms_spu_images\n    CompletableFuture<Void> imageFuture = CompletableFuture.runAsync(() -> {\n        List<SkuImagesEntity> imagesEntities = skuImagesService.getImagesBySkuId(skuId);\n        skuItemVo.setImages(imagesEntities);\n    }, executor);\n\n    //TODO //3、远程调用查询当前sku是否参与秒杀优惠活动\n    CompletableFuture<Void> seckillFuture = CompletableFuture.runAsync(() -> {\n        //3.远程调用查询当前sku是否参与秒杀优惠活动\n        R skuSeckilInfo = seckillFeignService.getSkuSeckilInfo(skuId);\n        if (skuSeckilInfo.getCode() == 0) {\n            //查询成功\n            SeckillSkuVo skuSeckilInfoData = skuSeckilInfo.getData(\"data\", new TypeReference<SeckillSkuVo>() {\n            });\n            skuItemVo.setSeckillSkuVo(skuSeckilInfoData);\n\n            if (skuSeckilInfoData != null) {\n                long currentTime = System.currentTimeMillis();\n                if (currentTime > skuSeckilInfoData.getEndTime()) {\n                    skuItemVo.setSeckillSkuVo(null);\n                }\n            }\n        }\n    }, executor);\n\n    //七、多任务组合\n    /*\n    allOf：等待所有任务完成\n    anyOf：只要有一个任务完成\n     */\n    //等到所有任务完成  //TODO 秒杀优惠活动Future\n    CompletableFuture.allOf(saleAttrFuture,descFuture,baseAttrFuture,imageFuture,seckillFuture).get();\n    return skuItemVo;\n}\n```\n\n## RabbitMQ延时队列（实现定时任务）\n\n### 场景：\n\n![image-20230322165119843](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322165119843.png)\n\n- 比如未付款订单，超过一定时间后，系统自动取消订单并释放占有物品。\n\n- 常用解决方案：spring的 schedule 定时任务轮询数据库\n\n  - 缺点：消耗系统内存、增加了数据库的压力、存在较大的时间误差\n\n  - 定时任务的时效性问题\n\n    定时任务开启的第一次扫描，订单未创建，1min后创建完成，30min第二次扫描订单未过期，无事发生，31min订单过期，直到60min第三次扫描才扫到过期订单\n\n    ![image-20230322165931065](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322165931065.png)\n\n- 解决：rabbitmq的消息TTL和死信Exchange结合\n\n- 订单释放&库存解锁\n\n![image-20230410190115962](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410190115962.png)\n\n\n\n### 消息的TTL（Time To Live）\n\n- 消息的TTL就是消息的存活时间。\n- RabbitMQ可以对队列和消息分别设置TTL。\n- 对队列设置就是队列没有消费者连着的保留时间，**也可以对每一个单独的消息做单独的**\n  **设置。超过了这个时间，我们认为这个消息就死了，称之为死信**。\n- 如果队列设置了，消息也设置了，那么会**取小的**。所以一个消息如果被路由到不同的队\n  列中，这个消息死亡的时间有可能不一样（不同的队列设置）。这里单讲单个消息的\n  TTL，因为它才是实现延迟任务的关键。可以通过**设置消息的expiration字段或者x-**\n  **message-ttl属性来设置时间**，两者是一样的效果。\n\n### Dead Letter Exchanges（DLX）\n\n- 一个消息在满足如下条件下，会进\n\n  死信路由\n\n  ，记住这里是路由而不是队列，\n\n  一个路由可以对应很多队列。（什么是死信）\n\n  - 一个消息被Consumer拒收了，并且reject方法的参数里requeue是false。也就是说不\n    会被再次放在队列里，被其他消费者使用。 （ basic.reject/ basic.nack ） requeue=false\n  - 上面的消息的TTL到了，消息过期了。\n  - 队列的长度限制满了。排在前面的消息会被丢弃或者扔到死信路由上\n\n- Dead Letter Exchange其实就是一种普通的exchange，和创建其他\n  exchange没有两样。只是在某一个设置Dead Letter Exchange的队列中有\n  消息过期了，会自动触发消息的转发，发送到Dead Letter Exchange中去。\n\n- 我们既可以控制消息在一段时间后变成死信，又可以控制变成死信的消息\n  被路由到某一个指定的交换机，结合二者，其实就可以实现一个延时队列\n\n- 手动ack&异常消息统一放在一个队列处理建议的两种方式\n\n- catch异常后，手动发送到指定队列，然后使用channel给rabbitmq确认消息已消费\n\n- 给Queue绑定死信队列，使用nack（requque为false）确认消息消费失败\n\n### 延时队列实现\n\n- 给队列设置过期时间\n\n![image-20230322152334742](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322152334742.png)\n\n- 给消息设置过期时间\n\n![image-20230322152358754](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322152358754.png)\n\n- 推荐：给队列设置过期时间，因为给消息设置过期时间的话，RabbitMQ采用的是惰性检查机制，假设队列里面的消息过期时间不同，后面的消息必须等前面的消息过期，最终导致消息不能按照规定的过期时间过期。\n\n### SpringBoot中使用延时队列\n\n- 1、Queue、Exchange、Binding可以@Bean进去\n- 2、监听消息的方法可以有三种参数（不分数量，顺序）\n  - Object content, Message message, Channel channel\n- 3、channel可以用来拒绝消息，否则自动ack；\n\n### 消息队列流程\n\n- 使用RabbitMQ延时队列实现未付款订单，超过一定时间后，系统自动取消订单并解锁库存。\n- PS:创建订单 进入路由键-order.create.order- 进入交换机order-event-exchange， 根据路由键会转发到延时队列order.delay.queue 1min过期时间，过期时间到了之后，根据路由键order.release.order-到达释放订单队列order.release.order.queue， 监听这个队列的方法 先是判断订单是不是已支付，如果不是 就关闭订单，关闭订单之后，根据路由键order.release.other 发送关闭的订单数据到交换机order-event-exchange，交换机再转发到order.release.coupon.queue优惠券队列，返回优惠券，与之通过 也是根据路由键order.release.other，和数据一起转发到解锁库存队列stock.release.stock.queue 解锁库存。\n\n![image-20230416235749443](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230416235749443.png)\n\n## Redis缓存中的数据结构\n\n### 分类菜单\n\n- 类型：String\n- value: 菜单信息\n\n### 登陆信息-SpringSession\n\n### 购物车\n\n- 类型：Hash\n- key: gulimall:cart:2 // 2为用户ID\n- field: 商品 id\n- value: 购物项数据\n- 综上所述，我们的购物车结构是一个双层 Map：Map<String,Map<String,String>>\n  - 第一层 Map，Key 是用户 id\n  - 第二层 Map，Key 是购物车中商品 id，值是购物项数据\n\n### 秒杀上架 (幂等性处理)\n\n- 缓存秒杀活动信息 (seckill:session:)\n  - 类型: List\n  - key: seckill:session:start_endtime // 开始时间的时间戳_结束时间的时间戳\n  - value: 场次ID_商品ID\n- 缓存秒杀活动所关联的商品信息 (seckill:skus)\n  - 类型：Hash\n  - key: seckill:skus\n  - field: 场次ID_商品ID\n  - value: 秒杀商品信息\n- 秒杀库存信号量\n  - 类型： String\n  - key: seckIll:stock:UUID\n  - value: 库存数量\n\n### 幂等性保证\n\n- 缓存商品信息前，先判断有没有这个key\n\n```java\n    String redisKey = seckillSkuVo.getPromotionSessionId().toString() + \"-\" + seckillSkuVo.getSkuId().toString();\n            if (!operations.hasKey(redisKey)) {\n              //判断Redis中是否有该信息，如果没有才进行添加\n                Boolean hasKey = redisTemplate.hasKey(key);\n                //缓存活动信息\n                if (!hasKey) {\n```\n\n### Redission分布式锁\n\n- 设置分布式锁以及信号量-关键代码\n\n```java\n    //秒杀商品上架功能的锁\n    private final String upload_lock = \"seckill:upload:lock\";\n    \n  //分布式锁 .可重入锁（Reentrant Lock）\n        RLock lock = redissonClient.getLock(upload_lock);\n        try {\n            //加锁\n            lock.lock(10, TimeUnit.SECONDS);\n            seckillService.uploadSeckillSkuLatest3Days();\n        }catch (Exception e){\n            e.printStackTrace();\n        }finally {\n            lock.unlock();\n        }\n          //如果当前这个场次的商品库存信息已经上架就不需要上架\n                        //5、使用库存作为分布式Redisson信号量（限流）\n                        // 使用库存作为分布式信号量\n                        RSemaphore semaphore = redissonClient.getSemaphore(SKU_STOCK_SEMAPHORE + token);\n                        // 商品可以秒杀的数量作为信号量\n                        semaphore.trySetPermits(seckillSkuVo.getSeckillCount());\n```\n\n## 分布式事务\n\n![image-20230322165148070](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322165148070.png)\n\n- **事务保证：**\n\n1. 订单服务异常，库存锁定不运行，全部回滚，撤销操作\n2. 库存服务事务自治，锁定失败全部回滚，订单感受到，继续回滚\n3. 库存服务锁定成功了，但是网络原因返回数据途中问题？\n4. 库存服务锁定成功了，库存服务下面的逻辑发生故障，订单回滚了，怎么处理？\n\n- **利用消息队列实现最终一致**\n\n库存服务锁定成功后发给消息队列消息（当前库存工作单），过段时间自动解锁，解锁时先查询订单的支付状态。解锁成功修改库存工作单详情项状态为已解锁\n\n- 1、远程服务假失败：\n  - 远程服务其实成功了，由于网络故障等没有返回\n  - 导致：订单回滚，库存却扣减\n- 2、远程服务执行完成，下面的其他方法出现问题\n  - 导致：已执行的远程请求，肯定不能回滚\n\n### 事务的坑\n\n- 在同一个类里面，编写两个方法，内部调用的时候，会导致事务设置失效。原因是没有用到代理对象的缘故。\n- 解决：\n  - 0）、导入 spring-boot-starter-aop\n  - 1）、@EnableTransactionManagement(proxyTargetClass = true)\n  - 2）、@EnableAspectJAutoProxy(exposeProxy=true)\n  - 3）、AopContext.currentProxy() 调用方法\n\n### CAP理论\n\n- C是**一致性**，分布式系统的**数据要保持一致**\n- A是**可用性**，分布式系统能进行**故障转移**\n- P是**分区容错性**，分布式系统**出现网络问题能正常运行**\n- CAP理论是指分布式系统中不能保证三者同时存在，只能两两组合\n\n### BASE 理论\n\n- 是对 CAP 理论的延伸，思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但可 以采用适当的采取弱一致性，即**最终一致性。**\n\n### 分布式事务几种方案\n\n- 2PC 模式\n  - 数据库支持的 2PC【2 phase commit 二阶提交】，又叫做 XA Transactions。\n    - 第一阶段：事务协调器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是 否可以提交.\n    - 第二阶段：事务协调器要求每个数据库提交数据。\n  - **性能不理想**\n- 柔性事务-TCC 事务补偿型方案\n  - 一阶段 prepare 行为：调用 自定义 的 prepare 逻辑。\n  - 二阶段 commit 行为：调用 自定义 的 commit 逻辑。\n  - 二阶段 rollback 行为：调用 自定义 的 rollback 逻辑。\n  - 所谓 TCC 模式，是指支持把 自定义 的分支事务纳入到全局事务的管理中\n- 柔性事务-最大努力通知型方案\n  - 按规律进行通知，**不保证数据一定能通知成功，但会提供可查询操作接口进行核对**。\n  - 这种 方案主要用在与第三方系统通讯时，比如：调用微信或支付宝支付后的支付结果通知。\n  - 这种 方案也是结合 MQ 进行实现，例如：通过 MQ 发送 http 请求，设置最大通知次数。达到通知次数后即不再通知。\n- 柔性事务-**可靠消息**+最终一致性方案（异步确保型）\n  - 实现：业务处理服务在业务事务提交之前，向实时消息服务请求发送消息，实时消息服务只 记录消息数据，而不是真正的发送。业务处理服务在业务事务提交之后，向实时消息服务确 认发送。只有在得到确认发送指令后，实时消息服务才会真正发送。\n  - 防止消息丢失：\n    - 1、做好消息确认机制（pulisher，consumer【手动 ack】）\n    - 2、每一个发送的消息都在数据库做好记录。定期将失败的消息再次发送一 遍\n\n> 刚性事务：遵循 ACID 原则，强一致性。\n>\n> 柔性事务：遵循 BASE 理论，最终一致性；\n>\n> 与刚性事务不同，柔性事务允许一定时间内，不同节点的数据不一致，但要求最终一致。\n\n## Seata\n\n[Seata 是什么](https://seata.io/zh-cn/docs/overview/what-is-seata.html)\n\n### Seata的理解\n\n- Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。\n  - AT模式。是一种基于**本地事务+二阶段协议**来实现的**最终数据一致性方案**，也是Seata默认的解决方案。\n  - TCC模式，TCC事务是Try,Confirm,Cancel 三个词语的缩写，简单理解就是把**一个完整的业务逻辑拆分成三个阶段**，然后通过事务管理器在业务逻辑层面，根据每个分支事务的执行情况分别调用该业务的Confirm 或者Cacel方法。\n  - Saga模式，Saga模式是SEATA提供**长事务解决方案**，在Saga模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者。\n  - XA模式，XA可以认为是一种**强一致性的事务解决方法**，它利用事务资源（数据库，消息服务等）对XA协议的支持，以XA协议的机制来管理分支事务的一种事务模式。\n\n> [Seata 是什么](https://seata.io/zh-cn/docs/overview/what-is-seata.html)\n>\n> - #### TC (Transaction Coordinator) - 事务协调者\n>\n>   - 维护全局和分支事务的状态，驱动全局事务提交或回滚。\n>\n> - #### TM (Transaction Manager) - 事务管理器\n>\n>   - 定义全局事务的范围：开始全局事务、提交或回滚全局事务。\n>\n> - #### RM (Resource Manager) - 资源管理器\n>\n>   - 管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。\n>\n> ![image-20230322152804762](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322152804762.png)\n\n### Seata项目整合\n\n- Seata控制分布式事务\n- 1）、每一个微服务先必须创建 undo_log；\n- 2）、安装事务协调器；seata-server： https://github.com/seata/seata/releases\n- 3）、整合\n  - 1、导入依赖 spring-cloud-starter-alibaba-seata seata-all-0.7.1\n  - 2、解压并启动seata-server；\n    - registry.conf: 注册中心配置； 修改registry type=nacos\n    - file.conf：\n  - 3、所有想要用到分布式事务的微服务使用seata DataSourceProxy代理自己的数据源\n  - 4、每个微服务，都必须导入\n    - registry.conf\n    - file.conf vgroup_mapping.{application.name}-fescar-service-group = “default”\n  - 5、启动测试分布式事务\n  - 6、给分布式大事务的入口标注@GlobalTransactional\n  - 7、每一个远程的小事务用 @Transactional\n\n应用场景：\n\n- 订单服务提交订单，库存服务扣减库存\n  - seta-提交订单接口 OrderServiceImpl 类submitOrder（）方法 加 @GlobalTransactional\n  - （下单是高并发场景，不推荐seata分布式事务。推荐用消息队列 最终一致性）\n- 商品服务保持商品信息，远程调用优惠服务保持商品优惠券信息\n- - 开启seta全局事务-SpuInfoServiceImpl类saveSpuInfo()方法 （推荐）\n\n\n\n## Sentinel\n\n[介绍 · alibaba/Sentinel Wiki · GitHub](https://github.com/alibaba/Sentinel/wiki/介绍)\n\n### Sentinel理解\n\n- 随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从**流量控制、熔断降级**、系统负载保护等多个维度保护服务的稳定性。\n- 我们说的资源，可以是任何东西，服务，服务里的方法，甚至是一段代码。使用 Sentinel 来进行资源保护，主要分为几个步骤:\n  1. 定义资源\n  2. 定义规则\n  3. 检验规则是否生效\n- Sentinel 分为两个部分:\n  - 核心库（Java 客户端）不依赖任何框架/库，能够运行于所有 Java 运行时环境，同时 对 Dubbo / Spring Cloud 等框架也有较好的支持。\n  - 控制台（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器\n\n### 熔断降级限流\n\n- 熔断\n  - A 服务调用 B 服务的某个功能，B服务卡死，功能时间超长，我们就将B断路，返回降级数据。\n- 降级\n  - 流量高峰期，服务器压力剧增，对一些页面和服务做策略的降级（停止服务，调用直接返回降级数据）\n- 熔断、降级区别\n  - 相同点\n    - 保证服务的可用性\n  - 不同点\n    - 1、熔断是被调用方故障，触发的系统主动规则\n    - 2、降级是基于全局考虑，停止一些正常服务，释放资源\n- 限流\n  - 对打入服务的请求流量进行控制，使服务能够承担不超过自己能力的流量压力\n\n### 项目整合步骤\n\n```java\n/**\n\n * 1、整合Sentinel\n * 1）、导入依赖 spring-cloud-starter-alibaba-sentinel\n * 2）、下载sentinel的控制台\n * 3）、配置sentinel控制台地址信息\n * 4) 、在控制台调整参数。【默认所有的流控设置保存在内存中，重启失效】\n      *\n       *\n * 2、每一个微服务都导入 actuator ()；并配合management.endpoints.web.exposure.include=*\n * 3、自定义sentinel流控返回数据\n   *\n * 4、使用Sentinel来保护feign远程调用：熔断；\n * 1）、调用方的熔断保护：feign.sentinel.enabled=true\n * 2）、调用方手动指定远程服务的降级策略。远程服务被降级处理。触发我们的熔断回调方法\n * 3）、超大浏览的时候，必须牺牲一些远程服务。在服务的提供方（远程服务）指定降级策略；\n * 提供方是在运行。但是不运行自己的业务逻辑，返回的是默认的降级数据（限流的数据），\n    *\n * 5、自定义受保护的资源\n * 1）、代码\n * try(Entry entry = SphU.entry(\"seckillSkus\")){\n * //业务逻辑\n * }\n * catch(Execption e){}\n    *\n * 2）、基于注解。\n * @SentinelResource(value = \"getCurrentSeckillSkusResource\",blockHandler = \"blockHandler\")\n    *\n * 无论是1,2方式一定要配置被限流以后的默认返回.\n * url请求可以设置统一返回:WebCallbackManager\n    *\n    *\n    */\n```\n\n### 整合 Feign+Sentinel 测试熔断降级\n\n- 引入依赖：>spring-cloud-starter-openfeign、spring-cloud-starter-alibaba-sentinel<\n\n- 2、使用 Nacos 注册中心 spring-cloud-starter-alibaba-nacos-discovery\n\n- 定义 fallbackfactory 并放在容器中\n\n  ```java\n     /**\n     \n      * @Author zly\n     \n      * @Date 2022/7/26 16:22\n        */\n        @Slf4j\n        @Component\n        public class SeckillFeignServiceFallBack implements SeckillFeignService {\n     \n        @Override\n        public R getSkuSeckilInfo(Long skuId) {\n            log.info(\"熔断方法调用..\");\n            return R.error(BizCodeEnum.TO_MANY_REQUEST.getCode(),BizCodeEnum.TO_MANY_REQUEST.getMessage());\n        }\n    }\n  ```\n\n- 远程接口配置 feign 客户端容错\n\n  ```java\n    /**\n     * @Author zly\n     * @Date 2022/7/26 16:21\n     */\n    @FeignClient(value = \"gulimall-seckill\",fallback = SeckillFeignServiceFallBack.class)\n    public interface SeckillFeignService {\n    \n        /**\n         * 根据skuId查询商品是否参加秒杀活动\n         * @param skuId\n         * @return\n         */\n        @GetMapping(value = \"/sku/seckill/{skuId}\")\n        R getSkuSeckilInfo(@PathVariable(\"skuId\") Long skuId);\n    \n    }\n  ```\n\n- 开启 sentinel 代理 feign 功能；在 application.properties 中配置\n\n  - feign.sentinel.enabled=true\n\n  > [注解支持 · alibaba/Sentinel Wiki · GitHub](https://github.com/alibaba/Sentinel/wiki/注解支持)\n  >\n  > 1、使用@SentinelResource，并定义 fallback\n  >\n  > ```java\n  > com.atguigu.gulimall.seckill.service.impl.SeckillServiceImpl\n  > @SentinelResource(value = \"getCurrentSeckillSkusResource\",blockHandler = \"blockHandler\")\n  > @Override\n  > public List<SeckillSkuRedisTo> getCurrentSeckillSkus() {\n  > \n  > }\n  > ```\n  >\n  > \n\n  \n\n## Nacos\n\n> [Nacos Spring Cloud](https://nacos.io/zh-cn/docs/use-nacos-with-springcloud.html)\n\n### 项目整合\n\n```java\n/**\n * 1、如何使用Nacos作为配置中心统一管理配置\n *\n * 1）、引入依赖，\n *         <dependency>\n *             <groupId>com.alibaba.cloud</groupId>\n *             <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>\n *         </dependency>\n * 2）、创建一个bootstrap.properties。\n *      spring.application.name=gulimall-coupon\n *      spring.cloud.nacos.config.server-addr=127.0.0.1:8848\n * 3）、需要给配置中心默认添加一个叫 数据集（Data Id）gulimall-coupon.properties。默认规则，应用名.properties\n * 4）、给 应用名.properties 添加任何配置\n * 5）、动态获取配置。\n *      @RefreshScope：动态获取并刷新配置\n *      @Value(\"${配置项的名}\")：获取到配置。\n *      如果配置中心和当前应用的配置文件中都配置了相同的项，优先使用配置中心的配置。\n *\n * 2、细节\n *  1）、命名空间：配置隔离；\n *      默认：public(保留空间)；默认新增的所有配置都在public空间。\n *      1、开发，测试，生产：利用命名空间来做环境隔离。\n *         注意：在bootstrap.properties；配置上，需要使用哪个命名空间下的配置，\n *         spring.cloud.nacos.config.namespace=9de62e44-cd2a-4a82-bf5c-95878bd5e871\n *      2、每一个微服务之间互相隔离配置，每一个微服务都创建自己的命名空间，只加载自己命名空间下的所有配置\n *\n *  2）、配置集：所有的配置的集合\n *\n *  3）、配置集ID：类似文件名。\n *      Data ID：类似文件名\n *\n *  4）、配置分组：\n *      默认所有的配置集都属于：DEFAULT_GROUP；\n *      1111，618，1212\n *\n * 项目中的使用：每个微服务创建自己的命名空间，使用配置分组区分环境，dev，test，prod\n *\n * 3、同时加载多个配置集\n * 1)、微服务任何配置信息，任何配置文件都可以放在配置中心中\n * 2）、只需要在bootstrap.properties说明加载配置中心中哪些配置文件即可\n * 3）、@Value，@ConfigurationProperties。。。\n * 以前SpringBoot任何方法从配置文件中获取值，都能使用。\n * 配置中心有的优先使用配置中心中的，\n *\n /**\n * 1、开启服务注册发现\n *  (配置nacos的注册中心地址)\n * 2、编写网关配置文件\n */\n```\n\n### Nacos作为注册中心：\n\n- 将微服务注册到 nacos 中\n\n- 1、首先，修改 pom.xml 文件，引入 Nacos Discovery Starter。\n\n- 2、在应用的 /src/main/resources/application.properties 配置文 件中配置 Nacos Server 地址\n\n   ```properties\n    spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848\n   ```\n\n- 3、使用@EnableDiscoveryClient 开启服务注册发现功能\n\n- 4、启动应用，观察 nacos 服务列表是否已经注册上服务\n\n  - > 注意：每一个应用都应该有名字，这样才能注册上去。修改 application.properties 文件\n    >\n    > spring.application.name=service-provider\n    >\n    > server.port=8000\n\n- 5、注册更多的服务上去，测试使用 feign 远程调用\n\n  - > Nacos 使用三步\n    >\n    > 1、导包 nacos-discovery\n    >\n    > 2、写配置，指定 nacos 地址，指定应用的名字\n    >\n    > 3、开启服务注册发现功能@EnableDiscoveryClient\n    >\n    > Feign 使用三步\n    >\n    > 1、导包 openfeign\n    >\n    > 2、开启@EnableFeignClients 功能\n    >\n    > 3、编写接口，进行远程调用\n\n### Nacos作为配置中心\n\n- 1、pom.xml 引入 Nacos Config Starter。\n\n- 2、在应用的 /src/main/resources/bootstrap.properties 配 置文件中配置 Nacos Config 元数据\n\n  ```properties\n    spring.application.name=nacos-config-example\n    spring.cloud.nacos.config.server-addr=127.0.0.1:8848\n    #指定命名空间\n    spring.cloud.nacos.config.namespace=af7b6638-68dd-43a0-8bef-19dbaf2ae5c3 \n    #指定分组  默认DEFAULT_GROUP\n    spring.cloud.nacos.config.group=dev\n    #主要配置应用名和配置中心地址\n  ```\n\n- 3、在 nacos 中添加配置\n\n  - 在 nacos 中创建一个 **应用名.properties** 配置文件并编写配置\n\n  - > **Nacos Config** **数据结构**\n    >\n    > Nacos Config 主要通过 dataId 和 group 来唯一确定一条配置。\n    >\n    > Nacos Client 从 Nacos Server 端获取数据时，调用的是此接口 ConfigService.getConfig(String dataId, String group, long timeoutMs)。\n    >\n    > **Spring Cloud** **应用获取数据**\n    >\n    > **dataID**:\n    >\n    > 在 Nacos Config Starter 中，dataId 的拼接格式如下\n    >\n    > - ${prefix} - ${spring.profiles.active} . ${file-extension} prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix 来配置。\n    > - spring.profiles.active 即为当前环境对应的 profile\n    >\n    > 注意，当 activeprofile 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 prefix . {prefix}.*p**re**f**i**x*.{file-extension}\n    >\n    > file-extension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。 目前只支持 properties 类型。\n    >\n    > **Group**：\n    >\n    > Group 默认为 DEFAULT_GROUP，可以通过 spring.cloud.nacos.config.group 配置。\n\n- 4、在应用中使用@Value 和@RefreshScope\n\n  - > 完成上述两步后，应用会从 Nacos Config 中获取相应的配置，并添加在 Spring Environment\n    >\n    > 的 PropertySources 中 。 这 里 我 们 使 用 @Value 注 解 来 将 对 应 的 配 置 注 入 到\n    >\n    > SampleController 的 userName 和 age 字段，并添加 @RefreshScope 打开动态刷新功能\n    >\n    > **@RefreshScope**\n    >\n    > class SampleController {\n    >\n    > **@Value(“${user.name}”)**\n    >\n    > String userName;\n    >\n    > **@Value(“${user.age}”)**\n    >\n    > int age;\n    >\n    > }\n\n### Nacos进阶\n\n- **核心概念**\n\n  - **命名空间：配置隔离**\n\n    - 用于进行租户粒度的配置隔离。不同的命名空间下，可以存在相同的 **Group** 或 **Data ID** 的\n\n      配置。**Namespace** 的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生\n\n      产环境的资源（如配置、服务）隔离等\n\n  - **配置集：所有配置的集合**\n\n    - 一组相关或者不相关的配置项的集合称为配置集。在系统中，一个配置文件通常就是一个配\n\n      置集，包含了系统各个方面的配置。例如，一个配置集可能包含了数据源、线程池、日志级\n\n      别等配置项。\n\n  - **配置集ID：类似文件名。**\n\n    - Nacos 中的某个配置集的 ID。配置集 ID 是组织划分配置的维度之一。**Data ID** 通常用于组\n\n      织划分系统的配置集。一个系统或者应用可以包含多个配置集，每个配置集都可以被一个有\n\n      意义的名称标识。Data ID 通常采用类 Java 包（如 com.taobao.tc.refund.log.level）的命名\n\n      规则保证全局唯一性。此命名规则非强制。\n\n  - **配置分组：默认所有的配置集都属于：DEFAULT_GROUP；**\n\n    - Nacos 中的一组配置集，是组织配置的维度之一。通过一个有意义的字符串（如 Buy 或\n\n      Trade ）对配置集进行分组，从而区分 Data ID 相同的配置集。当您在 Nacos 上创建一个\n\n      配置时，如果未填写配置分组的名称，则配置分组的名称默认采用 DEFAULT_GROUP 。配置\n\n      分组的常见场景：不同的应用或组件使用了相同的配置类型，如 database_url 配置和\n\n      MQ_topic 配置。\n\n- **原理**\n\n  - 自动注入：\n    - NacosConfigStarter 实现了 org.springframework.cloud.bootstrap.config.PropertySourceLocator 接口，并将优先级设置成了最高。 在 Spring Cloud 应用启动阶段，会主动从 Nacos Server 端获取对应的数据，并将获取到的 数据转换成 PropertySource 且注入到 Environment 的 PropertySources 属性中，所以使用 @Value 注解也能直接获取 Nacos Server 端配置的内容。\n  - 动态刷新：\n    - Nacos Config Starter 默认为所有获取数据成功的 Nacos 的配置项添加了监听功能，在监听 到服务端配置发生变化时会实时触发 org.springframework.cloud.context.refresh.ContextRefresher 的 refresh 方法 。\n    - 如果需要对 Bean 进行动态刷新，请参照 Spring 和 Spring Cloud 规范。推荐给类添加**@RefreshScope** **或** **@ConfigurationProperties** 注解，\n\n- **3、加载多配置文件**\n\n   ```properties\n    spring.cloud.nacos.config.server-addr=127.0.0.1:8848\n    spring.cloud.nacos.config.namespace=31098de9-fa28-41c9-b0bd-c754ce319ed4 \n    spring.cloud.nacos.config.ext-config[0].data-id=gulimall-datasource.yml \n    #动态刷新\n    spring.cloud.nacos.config.ext-config[0].refresh=false\n    spring.cloud.nacos.config.ext-config[0].group=dev\n   ```\n\n- **4、namespace 与 group 最佳实践**\n\n  - 每个微服务创建自己的 namespace 进行隔离，group 来区分 dev，beta，prod 等环境\n\n## Gateway\n\n> [Spring Cloud Gateway](https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.1.3.RELEASE/single/spring-cloud-gateway.html)\n\n- 简介\n  - 网关作为流量的入口，常用功能包括路由转发、权限校验、限流控制等。\n- 特点\n  - 基于 Spring5，支持响应式编程和 SpringBoot2.0\n  - 支持使用任何请求属性进行路由匹配\n  - 特定于路由的断言和过滤器\n  - 集成 Hystrix 进行断路保护\n  - 集成服务发现功能\n  - 易于编写 Predicates 和 Filters\n  - 支持请求速率限制\n  - 支持路径重写\n- API网关优点\n  - 易于监控。可以在网关收集监控数据并将其推送到外部系统进行分析。\n  - 易于认证。可以在网关上进行认证，然后再将请求转发到后端的微服务，而无须在 每个微服务中进行认证。\n  - 减少了客户端与各个微服务之间的交互次数。\n- 核心概率\n  - 路由\n    - 路由是网关最基础的部分，路由信息有一个 ID、一个目的 URL、一组断言和一组 Filter 组成。如果断言路由为真，则说明请求的 URL 和配置匹配\n  - 断言\n    - Java8 中的断言函数。Spring Cloud Gateway 中的断言函数输入类型是 Spring5.0 框 架中的 ServerWebExchange。Spring Cloud Gateway 中的断言函数允许开发者去定义匹配 来自于 http request 中的任何信息，比如请求头和参数等。\n  - 过滤器\n    - 一个标准的 Spring webFilter。Spring cloud gateway 中的 filter 分为两种类型的 Filter，分别是 Gateway Filter 和 Global Filter。过滤器 Filter 将会对请求和响应进行修改 处理\n  - **满足某些断言（predicates）就路由到指定的地址（uri），使用指定的过滤器（filter）**\n\n> ```yaml\n> spring:\n> cloud:\n>  gateway:\n>    routes:\n>         - id: test_route\n>           uri: https://www.baidu.com\n>           predicates:\n>             - Query=url,baidu\n> \n>        - id: product_route\n>           uri: lb://gulimall-product\n>           predicates:\n>             - Path=/api/product/**\n>           filters:\n>             - RewritePath=/api/?(?<segment>.*),/$\\{segment}\n> \n>        - id: gulimall_host_route\n>           uri: lb://gulimall-product\n>           predicates:\n>             - Host=gulimall.com,item.gulimall.com\n> ```\n\n## Feign\n\n**Feign** **声明式远程调用**\n\n- 简介\n\n  - Feign 是一个声明式的 HTTP 客户端，它的目的就是让远程调用更加简单。\n  - Feign 整合了 **Ribbon（负载均衡）和 Hystrix(服务熔断)，**\n\n- **使用**\n\n  - 1、引入依赖 spring-cloud-starter-openfeign\n\n  - 2、开启 feign 功能 @EnableFeignClients(basePackages = “com.atguigu.gulimall.member.feign”)\n\n  - 3、声明远程接口\n\n    ```java\n    /**\n    * @Author zly\n    * @Date 2022/7/25 12:04\n    */\n    @FeignClient(\"gulimall-order\")\n    public interface OrderFeignService {\n    /**\n     * 分页查询当前登录用户的所有订单信息\n     * @param params\n     * @return\n     */\n    @PostMapping(\"/order/order/listWithItem\")\n    R listWithItem(@RequestBody Map<String, Object> params);\n    \n    }\n    ```\n\n### Feign远程调用丢失请求头问题\n\n![image-20230410205425533](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410205425533.png)\n\n\n\n\n\n### Feign异步情况丢失上下文问题\n\n![image-20230410205453081](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410205453081.png)\n\n\n\n\n\n\n\n## SpringCloud Alibaba 常用组件端口号总结\n\n- Nacos 默认端口号：8848\n\n  ```properties\n  #*************** Spring Boot Related Configurations ***************#\n  ### Default web context path:\n  server.servlet.contextPath=/nacos\n  ### Default web server port:\n  server.port=8848\n  ```\n\n- Seata默认端口号：8091\n\n- Sentinel控制台默认运行在8080端口上\n\n> Elasticsearch 默认端口 9200 搜索引擎 不属于SpringCloud Alibaba\n\n## 支付\n\n### 加密-对称加密\n\n![image-20230410190257408](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410190257408.png)\n\n### 加密-非对称加密\n\n![image-20230410190307734](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410190307734.png)\n\n### 支付宝验签\n\n![image-20230410201313818](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410201313818.png)\n\n### 收单\n\n- 1、订单在支付页，不支付，一直刷新，订单过期了才支付，订单状态改为已支付了，但是库存解锁了。\n  - 使用支付宝自动收单功能解决。只要一段时间不支付，就不能支付了。\n- 2、由于时延等问题。订单解锁完成，正在解锁库存的时候，异步通知才到\n  - 订单解锁，手动调用收单\n- 3、网络阻塞问题，订单支付成功的异步通知一直不到达\n  - 查询订单列表时，ajax获取当前未支付的订单状态，查询订单状态时，再获取一下支付宝此订单的状态\n- 4、其他各种问题\n  - 每天晚上闲时下载支付宝对账单，一一进行对账\n\n\n\n\n\n\n\n## MD5&MD5盐值加密\n\n- MD5\n  - Message Digest algorithm 5，信息摘要算法\n    - 压缩性：任意长度的数据，算出的MD5值长度都是固定的。\n    - 容易计算：从原数据计算出MD5值很容易。\n    - 抗修改性：对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。\n    - 强抗碰撞：想找到两个不同的数据，使它们具有相同的MD5值，是非常困难的。\n    - 不可逆\n- 加盐：\n  - 通过生成随机数与MD5生成字符串进行组合\n  - 数据库同时存储MD5值与salt值。验证正确性时使用salt进行MD5即可\n\n\n\n## 项目微服务\n\n![image-20230410191352836](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191352836.png)\n\n## Nginx+Windows搭建域名访问环境\n\n![image-20230410191454442](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191454442.png)\n\n### 域名映射效果\n\n- 请求接口 gulimall.com\n- 请求页面 gulimall.com\n- nginx直接代理给网关，网关判断\n- 如果/api/****，转交给对应的服务器\n- 如果是 满足域名，转交给对应的服务\n\n### 正向代理与反向代理\n\n- 正向代理：如科学上网，隐藏客户端信息\n\n![image-20230410191634342](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191634342.png)\n\n- 反向代理：屏蔽内网服务器信息，负载均衡访问\n\n![image-20230410191643706](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191643706.png)\n\n### Nginx配置文件\n\n![image-20230410191710095](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191710095.png)\n\n### Nginx动静分离\n\n![image-20230410191732131](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191732131.png)\n\n### Nginx转发效果\n\n![image-20230410191756149](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191756149.png)\n\n\n\n\n\n\n\n## 内网穿透\n\n![image-20230410190339367](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410190339367.png)\n\n![image-20230410190351905](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410190351905.png)\n\n### 内网穿透联调\n\n![image-20230410190422986](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410190422986.png)\n\n### 配置\n\n- Nginx配置\n\n...\n\nlisten 80;\nserver_name gulimall.com *.gulimall.com 497n86m7k7.52http.net;\n#charset koi8-r;\n#access_log /var/log/nginx/log/host.access.log main;\nlocation /static/ {\nroot /usr/share/nginx/html;\n}\nlocation /payed/ {\nproxy_set_header Host order.gulimall.com;\nproxy_pass http://gulimall;\n}\n\n...\n\n## 缓存\n\n### 本地缓存\n\n\n\n![image-20230410191857648](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191857648.png)\n\n### 分布式缓存-本地模式在分布式下的问题\n\n![image-20230410191940056](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410191940056.png)\n\n### 分布式缓存\n\n![image-20230410192021777](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410192021777.png)\n\n#### 高并发下缓存失效问题-缓存穿透\n\n![image-20230410192133778](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410192133778.png)\n\n- **缓存穿透**：\n  - 指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查询的null写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义\n- **风险**：\n  - 利用不存在的数据进行攻击，数据库瞬时压力增大，最终导致崩溃\n- **解决**：\n  - null结果缓存，并加入短暂过期时间\n\n#### 高并发下缓存失效问题-缓存雪崩\n\n![image-20230410192133778](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410192133778.png)\n\n- **缓存雪崩**：\n  - 缓存雪崩是指在我们设置缓存时key采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。\n\n- **解决**：\n  - 原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\n\n#### 高并发下缓存失效问题-缓存击穿\n\n![image-20230410192628947](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410192628947.png)\n\n- **缓存穿透**：\n  - 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常\"**热点**\"的数据。如果这个key在大量请求同时进来前正好失效，那么所有对这个key的数据查询都落到db，我们称为缓存击穿。\n\n- **解决**：\n  - 加锁\n    - 大量并发只让一个去查，其他人等待，查到以后释放锁，其他人获取到锁，先查缓存，就会有数据，不用去db\n\n### 分布式下如何加锁？\n\n![image-20230410192940277](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410192940277.png)\n\n- 本地锁，只能锁住当前进程，所以我们需要分布式锁\n\n### 锁-时序问题\n\n![image-20230410193041285](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193041285.png)\n\n### 分布式锁演进-基本原理\n\n![image-20230410193221079](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193221079.png)\n\n> 我们可以同时去一个地方“占坑”，如果占到，就执行逻辑。否则就必须等待，直到释放锁。\n> “占坑”可以去redis，可以去数据库，可以去任何大家都能访问的地方。\n> 等待可以自旋的方式。\n\n#### 分布式锁演进-阶段一\n\n![image-20230410193430589](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193430589.png)\n\n\n\n\n\n#### 分布式锁演进-阶段二\n\n![image-20230410193552631](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193552631.png)\n\n\n\n\n\n#### 分布式锁演进-阶段三\n\n![image-20230410193625611](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193625611.png)\n\n\n\n\n\n#### 分布式锁演进-阶段四\n\n![image-20230410193648301](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193648301.png)\n\n\n\n\n\n#### 分布式锁演进-阶段五-最终形态\n\n![image-20230410193719776](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193719776.png)\n\n\n\n\n\n### 缓存数据一致性-双写模式\n\n![image-20230410193831064](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193831064.png)\n\n\n\n### 缓存数据一致性-失效模式\n\n![image-20230410193909090](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410193909090.png)\n\n\n\n### 缓存数据一致性-解决方案\n\n-  无论是双写模式还是失效模式，都会导致缓存的不一致问题。即多个实例同时更新会出事。怎么办？\n   - 1、如果是用户纬度数据（订单数据、用户数据），这种并发几率非常小，不用考虑这个问题，缓存数据加上过期时间，每隔一段时间触发读的主动更新即可\n   - 2、如果是菜单，商品介绍等基础数据，也可以去使用canal订阅binlog的方式。\n   - 3、缓存数据+过期时间也足够解决大部分业务对于缓存的要求。\n   - 4、通过加锁保证并发读写，写写的时候按顺序排好队。读读无所谓。所以适合使用读写锁。（业务不关心脏数据，允许临时脏数据可忽略）；\n-  总结：\n   - 我们能放入缓存的数据本就不应该是实时性、一致性要求超高的。所以缓存数据的时候加上过期时间，保证每天拿到当前最新数据即可。\n   - 我们不应该过度设计，增加系统的复杂性\n   - 遇到实时性、一致性要求高的数据，就应该查数据库，即使慢点。\n\n\n\n### 缓存数据一致性-解决-Canal\n\n![image-20230410194458435](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410194458435.png)\n\n\n\n\n\n## Session共享问题\n\n### session原理\n\n![image-20230410195022298](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195022298.png)\n\n\n\n### 分布式下session共享问题\n\n![image-20230410195051946](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195051946.png)\n\n\n\n### 解决-session复制\n\n![image-20230410195126743](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195126743.png)\n\n\n\n- 优点\n  - web-server（Tomcat）原生支持，只需要修改配置文件\n- 缺点\n  - session同步需要数据传输，占用大量网络带宽，降低了服务器群的业务处理能力\n  - 任意一台web-server保存的数据都是所有web-server的session总和，受到内存限制无法水平扩展更多的web-server\n  - 大型分布式集群情况下，由于所有web-server都全量保存数据，所以此方案不可取。\n\n\n\n### 解决-客户端存储\n\n![image-20230410195314820](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195314820.png)\n\n\n\n- 优点\n  - 服务器不需存储session，用户保存自己的session信息到cookie中。节省服务端资源\n\n- 缺点\n  - 都是缺点，这只是一种思路。\n  - 具体如下：\n    - 每次http请求，携带用户在cookie中的完整信息，浪费网络带宽\n    - session数据放在cookie中，cookie有长度限制4K，不能保存大量信息\n    - session数据放在cookie中，存在泄漏、篡改、窃取等安全隐患\n- 这种方式不会使用。\n\n\n\n### 解决-hash一致性\n\n![image-20230410195638892](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195638892.png)\n\n\n\n- 优点：\n  - 只需要改nginx配置，不需要修改应用代码\n  - 负载均衡，只要hash属性的值分布是均匀的，多台web-server的负载是均衡的\n  - 可以支持web-server水平扩展（session同步法是不行的，受内存限制）\n- 缺点\n  - session还是存在web-server中的，所以web-server重启可能导致部分session丢失，影响业务，如部分用户需要重新登录\n  - 如果web-server水平扩展，rehash后session重新分布，也会有一部分用户路由不到正确的session\n- 但是以上缺点问题也不是很大，因为session本来都是有有效期的。所以这两种反向代理的方式可以使用\n\n\n\n### 解决-统一存储\n\n![image-20230410195856602](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410195856602.png)\n\n\n\n- 优点：\n  - 没有安全隐患\n  - 可以水平扩展，数据库/缓存水平切分即可\n  - web-server重启或者扩容都不会有session丢失\n- 不足\n  - 增加了一次网络调用，并且需要修改应用代码；如将所有的getSession方法替换为从Redis查数据的方式。redis获取数据比内存慢很多\n  - 上面缺点可以用SpringSession完美解决\n\n\n\n\n\n### 解决-不同服务，子域session共享\n\n> jsessionid这个cookie默认是当前系统域名的。当我们分拆服务，不同域名部署的时候，我们可以使用\n> 如下解决方案；\n\n![image-20230410200123345](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410200123345.png)\n\n\n\n\n\n### SpringSession核心原理\n\n![image-20230410200156413](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410200156413.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 购物车\n\n### 购物车数据结构\n\n![image-20230410200320343](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410200320343.png)\n\n> - Map<String k1,Map<String k2,CartItemInfo>> \t\t\t在redis中\n> - k1：标识每一个用户的购物车\t\t\t\t\t\t\t\t\t\t\tkey:用户标识\n> - k2：购物项的商品id  \t\t\t\t\t\t\t\t\t\t\t\t\t\tvalue:Hash（k：商品id，v：购物项详情）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 消息队列RabbitMQ\n\n### RabbitMQ概念\n\n![image-20230410200724866](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230410200724866.png)\n\n> rabbitmq 是一个开源的消息代理和队列服务器，通过普通的协议（Amqp 协议）来完成不同应用之间的数据共享，rabbitMq 是通过 erlang 语言来开发的基于 amqp 协议。\n\n### 什么AMQP协议\n\n1. 是一个二进制协议\n2. amqp 是一个应用层协议的规范（定义了很多规范），可以有很多不同的消息中间件产品（需要遵循该规范）\n\n- server： 是消息队列节点\n\n- virtual host： 虚拟主机\n\n- exchange： 交换机（消息投递到交换机上）\n\n- message  queue： 被消费者监听消息\n\n  `交换机和队列是有一个绑定的关系`\n\n![image-20230310210242731](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230310210242731.png)\n\n### AMQP的核心概念\n\n1.  server ： 又称为broker，接受客户端连接，实现amqp实体服务\n2.  connection： 连接，应用程序与broker建立网络连接\n3.  channel： 网络通道，几乎所有的操作都是在 channel 中进行的，是进行消息对象的通道，客户端可以建立多个通道，每一个 channnel 表示一个会话任务。\n4.  Message： 服务器和应用程序之间传递数据的载体，有 properties（消息属性，用来修饰消息，比如消息的优先级，延时投递）和 Body （消息体）\n5.  virtual host（虚拟主机）：是一个逻辑概念，最上层的消息路由，一个虚拟主机中可以包含多个 exchange 和 queue 但是一个虚拟主机中不能有名称相同的 exchange 和 queue\n6.  exchange （交换机）： 消息直接投递到交换机上，然后交换机根据消息的路由 key 来路由到对应绑定的队列上。\n7.  binding  （绑定）： 绑定 exchange 与 queue 的虚拟连接， binding 中可以包含route_key\n8.  route_key（路由key）：它的作用是在交换机上通过 route_key 来把消息路由到那个队列上。\n9.  queue 队列（队列）： 用来保存消息的载体，有消费者监听，然后消费消息。\n\n### RabbitMq的消息是如何流转的？\n\n![image-20230310210409545](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230310210409545.png)\n\n### RabbitMq 交换机详解\n\n#### **作用**： \n\n- 接受生产者的消息，然后根据路由键把消息投递到跟交换机绑定的对应的队列上。\n\n\n![image-20230310210717895](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230310210717895.png)\n\n#### **交换机属性**\n\n- Name： 交换机名称\n- Type： 交换机类型，Direct、topic、fanout、headers\n- Durablity：是否需要持久化\n- autodelete： 假如没有队列绑定到该交换机，那么交换机会自动删除。\n- internal： 当前交换机交换机是否用户 RabbitMq 内部使用不常用，默认为false \n- Argurements： 扩展参数，用户扩展AMQP定制化协议。\n\n \n\n#### 交换机类型\n\n- **直连交换机（Direct exchange）** \n\n> 所有发送的 Direct exchange 的消息都会被投递到与 Routekey名称（与队列名称）相同的queue上\n>\n> direct 模式下，可以使用 RabbitMq 自定exchange ---> default exchange 所以不需要交换机和任何队列绑定，消息将会投递到route_key名称和队列名称相同的队列上。\n\n![image-20230310211903967](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230310211903967.png)\n\n- **主题交换机 TopicExchange**\n\n> 就是在队列上绑到 top 交换机上的路由key 可以是通过通配符来匹配的通配符的规则是\n>\n> 比如：log.#: 可以是匹配一个单词 也可以匹配多个单词  比如 log.# 可以匹配log.a log.a.b \n> log.* ： 可以匹配一个单词，比如log.* ，可以匹配log.a 但是不可以匹配log.a.b。\n\n![image-20230310211944528](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230310211944528.png)\n\n- **扇形交换机（fanout exchange）**\n\n> 就是消息通过丛交换机到队列上不会通过路由key  所以该模式的速度是最快的  只要和交换机绑定的那么消息就会被分发到与之绑定的队列上。\n\n![mall](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230310212034909.png)\n\n\n\n### **队列、绑定主机、消息**\n\n- 绑定： exchange 与 之间的连接关系（通过路由规则）\n- 队列： 用来存储消息的实体\n- 队列的属性： durablility 是否被持久化\n- AutoDelete： 表示最后一个监听被移除那么该队列就会删除。\n\n- 消息： 用来生产者 和 消费者之间传递数据的\n\n- 消息属性： 包括 消息体Body 和 属性 properties\n\n- 常用属性： delivery mode,headers,content_type(消息类型) content_encoding（消息编码），priporty（消息优先级） correntlation_id( 最终消息唯一的ID)、reply_to(消息失败重回队列)，expiretion(消息的过期时 间),message_id(消息id);timestamp,type,user_id ，app_id,cluster_id等 \n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"分布式文件系统-minio","tags":["Spring Cloud","Spring Boot","minio"],"categories":["Java","微系统与第三方框架"],"author":"imklaus","excerpt":"\r\n\r\n参考视频：[黑马学成在线项目](https://www.bilibili.com/video/BV1j8411N7Bm/)\r\n\r\n","link":"/posts/minio","content":"\r\n\r\n参考视频：[黑马学成在线项目](https://www.bilibili.com/video/BV1j8411N7Bm/)\r\n\r\n<!-- more -->\r\n\r\n## **一 分布式文件系统**\r\n\r\n### **1.1 什么是分布式文件系统**\r\n\r\n要理解分布式文件系统首先了解什么是文件系统。\r\n\r\n查阅百度百科：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps49.jpg) \r\n\r\n​    文件系统是负责管理和存储文件的系统软件，操作系统通过文件系统提供的接口去存取文件，用户通过操作系统访问磁盘上的文件。\r\n\r\n下图指示了文件系统所处的位置：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps50.jpg) \r\n\r\n常见的文件系统：FAT16/FAT32、NTFS、HFS、UFS、APFS、XFS、Ext4等 。\r\n\r\n现在有个问题，一此短视频平台拥有大量的视频、图片，这些视频文件、图片文件该如何存储呢？如何存储可以满足互联网上海量用户的浏览。\r\n\r\n今天讲的分布式文件系统就是海量用户查阅海量文件的方案。\r\n\r\n我们阅读百度百科去理解分布式文件系统的定义：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps51.jpg) \r\n\r\n通过概念可以简单理解为：一个计算机无法存储海量的文件，通过网络将若干计算机组织起来共同去存储海量的文件，去接收海量用户的请求，这些组织起来的计算机通过网络进行通信，如下图：\r\n\r\n![image-20230704215201202](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704215201202.png)\r\n\r\n 好处：\r\n\r\n> 1、一台计算机的文件系统处理能力扩充到多台计算机同时处理。\r\n>\r\n> 2、一台计算机挂了还有另外副本计算机提供数据。\r\n>\r\n> 3、每台计算机可以放在不同的地域，这样用户就可以就近访问，提高访问速度。\r\n\r\n市面上有哪些分布式文件系统的产品呢？\r\n\r\n1、NFS\r\n\r\n阅读百度百科：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps53.jpg) \r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps54.jpg) \r\n\r\n特点：\r\n\r\n1）在客户端上映射NFS服务器的驱动器。\r\n\r\n2）客户端通过网络访问NFS服务器的硬盘完全透明。\r\n\r\n \r\n\r\n \r\n\r\n2、GFS\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps55.jpg) \r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps56.jpg) \r\n\r\n1）GFS采用主从结构，一个GFS集群由一个master和大量的chunkserver组成。\r\n\r\n2）master存储了数据文件的元数据，一个文件被分成了若干块存储在多个chunkserver中。\r\n\r\n3）用户从master中获取数据元信息，向chunkserver存储数据。\r\n\r\n \r\n\r\n3、HDFS\r\n\r\nHDFS，是Hadoop Distributed File System的简称，是Hadoop抽象文件系统的一种实现。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。 HDFS的文件分布在集群机器上，同时提供副本进行容错及可靠性保证。例如客户端写入读取文件的直接操作都是分布在集群各个机器上的，没有单点性能压力。\r\n\r\n下图是HDFS的架构图：\r\n\r\n![image-20230704215636100](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704215636100.png) \r\n\r\n1）HDFS采用主从结构，一个HDFS集群由一个名称结点和若干数据结点组成。\r\n\r\n2）名称结点存储数据的元信息，一个完整的数据文件分成若干块存储在数据结点。\r\n\r\n3）客户端从名称结点获取数据的元信息及数据分块的信息，得到信息客户端即可从数据块来存取数据。\r\n\r\n \r\n\r\n**4、云计算厂家**\r\n\r\n阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。其数据设计持久性不低于 99.9999999999%（12 个 9），服务设计可用性（或业务连续性）不低于 99.995%。\r\n\r\n*官方网站：*[*https://www.aliyun.com/product/oss*](https://www.aliyun.com/product/oss) \r\n\r\n百度对象存储BOS提供稳定、安全、高效、高可扩展的云存储服务。您可以将任意数量和形式的非结构化数据存入BOS，并对数据进行管理和处理。BOS支持标准、低频、冷和归档存储等多种存储类型，满足多场景的存储需求。 \r\n\r\n*官方网站：*[*https://cloud.baidu.com/product/bos.html*](https://cloud.baidu.com/product/bos.html) \r\n\r\n### **1.2 MinIO**\r\n\r\n#### **1.2.1 介绍**\r\n\r\n本项目采用MinIO构建分布式文件系统，MinIO 是一个非常轻量的服务,可以很简单的和其他应用的结合使用，它兼容亚马逊 S3 云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等。\r\n\r\n它一大特点就是轻量，使用简单，功能强大，支持各种平台，单个文件最大5TB，兼容 Amazon S3接口，提供了 Java、Python、GO等多版本SDK支持。\r\n\r\n官网：https://min.io\r\n\r\n中文：https://www.minio.org.cn/，http://docs.minio.org.cn/docs/\r\n\r\n \r\n\r\nMinIO集群采用去中心化共享架构，每个结点是对等关系，通过Nginx可对MinIO进行负载均衡访问。\r\n\r\n去中心化有什么好处？\r\n\r\n在大数据领域，通常的设计理念都是无中心和分布式。Minio分布式模式可以帮助你搭建一个高可用的对象存储服务，你可以使用这些存储设备，而不用考虑其真实物理位置。\r\n\r\n它将分布在不同服务器上的多块硬盘组成一个对象存储服务。由于硬盘分布在不同的节点上，分布式Minio避免了单点故障。如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps58.jpg) \r\n\r\nMinio使用纠删码技术来保护数据，它是一种恢复丢失和损坏数据的数学算法，它将数据分块冗余的分散存储在各各节点的磁盘上，所有的可用磁盘组成一个集合，上图由8块硬盘组成一个集合，当上传一个文件时会通过纠删码算法计算对文件进行分块存储，除了将文件本身分成4个数据块，还会生成4个校验块，数据块和校验块会分散的存储在这8块硬盘上。\r\n\r\n使用纠删码的好处是即便丢失一半数量（N/2）的硬盘，仍然可以恢复数据。 比如上边集合中有4个以内的硬盘损害仍可保证数据恢复，不影响上传和下载，如果多于一半的硬盘坏了则无法恢复。\r\n\r\n \r\n\r\n#### **1.2.2 数据恢复演示**\r\n\r\n下边在本机演示MinIO恢复数据的过程，在本地创建4个目录表示4个硬盘。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps59.jpg) \r\n\r\n下载minio，下载地址在https://dl.min.io/server/minio/release/，可从课程资料找到MinIO的安装文件minio.zip解压即可使用，CMD进入有minio.exe的目录，运行下边的命令：\r\n\r\n```shell\r\nminio.exe server D:\\develop\\minio_data\\data1  D:\\develop\\minio_data\\data2  D:\\develop\\minio_data\\data3  D:\\develop\\minio_data\\data4\r\n```\r\n\r\n启动结果如下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps60.jpg) \r\n\r\n说明如下：\r\n\r\n`WARNING: MINIO_ACCESS_KEY and MINIO_SECRET_KEY are deprecated.      Please use MINIO_ROOT_USER and MINIO_ROOT_PASSWORD Formatting 1st pool, 1 set(s), 4 drives per set. WARNING: Host local has more than 2 drives of set. A host failure will result in data becoming unavailable. WARNING: Detected default credentials 'minioadmin:minioadmin', we recommend that you change these values with 'MINIO_ROOT_USER' and 'MINIO_ROOT_PASSWORD' environment variables`\r\n\r\n1）老版本使用的MINIO_ACCESS_KEY 和 MINIO_SECRET_KEY不推荐使用，推荐使用MINIO_ROOT_USER 和MINIO_ROOT_PASSWORD设置账号和密码。\r\n\r\n2）pool即minio节点组成的池子，当前有一个pool和4个硬盘组成的set集合\r\n\r\n3）因为集合是4个硬盘，大于2的硬盘损坏数据将无法恢复。\r\n\r\n4）账号和密码默认为minioadmin、minioadmin，可以在环境变量中设置通过'MINIO_ROOT_USER' and 'MINIO_ROOT_PASSWORD' 进行设置。\r\n\r\n下边输入http://localhost:9000进行登录，账号和密码为：minioadmin/minioadmin\r\n\r\n \r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps61.jpg) \r\n\r\n \r\n\r\n登录成功：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps62.jpg) \r\n\r\n下一步创建bucket，桶，它相当于存储文件的目录，可以创建若干的桶。\r\n\r\n![image-20230704220604232](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704220604232.png) \r\n\r\n输入bucket的名称，点击“CreateBucket”，创建成功\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps64.jpg) \r\n\r\n点击“upload”上传文件。\r\n\r\n下边上传几个文件 \r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps65.jpg) \r\n\r\n \r\n\r\n下边去四个目录观察文件的存储情况\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps66.jpg) \r\n\r\n我们发现上传的1.mp4文件存储在了四个目录，即四个硬盘上。\r\n\r\n下边测试minio的数据恢复过程：\r\n\r\n1、首先删除一个目录。\r\n\r\n删除目录后仍然可以在web控制台上传文件和下载文件。\r\n\r\n稍等片刻删除的目录自动恢复。\r\n\r\n2、删除两个目录。\r\n\r\n删除两个目录也会自动恢复。\r\n\r\n3、删除三个目录 。\r\n\r\n由于 集合中共有4块硬盘，有大于一半的硬盘损坏数据无法恢复。\r\n\r\n此时报错：`We encountered an internal error, please try again.  (Read failed.  Insufficient number of drives online)`在线驱动器数量不足。\r\n\r\n \r\n\r\n#### **1.2.3 测试Docker环境**\r\n\r\n开发阶段和生产阶段统一使用Docker下的MINIO。\r\n\r\n在下发的虚拟机中已安装了MinIO的镜像和容器，执行sh /data/soft /restart.sh启动Docker下的MinIO\r\n\r\n启动完成登录MinIO查看是否正常。\r\n\r\n访问http://192.168.2.203:9000\r\n\r\n![image-20230704221009748](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704221009748.png)\r\n\r\n本项目创建两个buckets：\r\n\r\nmediafiles： 普通文件\r\n\r\nvideo：视频文件\r\n\r\n \r\n\r\n#### **1.2.4 SDK**\r\n\r\n##### **1.2.4.1上传文件**\r\n\r\nMinIO提供多个语言版本SDK的支持，下边找到java版本的文档：\r\n\r\n地址：https://docs.min.io/docs/java-client-quickstart-guide.html\r\n\r\n最低需求Java 1.8或更高版本:\r\n\r\nmaven依赖如下：\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>io.minio</groupId>\r\n    <artifactId>minio</artifactId>\r\n    <version>8.4.3</version>\r\n</dependency>\r\n<dependency>\r\n    <groupId>com.squareup.okhttp3</groupId>\r\n    <artifactId>okhttp</artifactId>\r\n    <version>4.8.1</version>\r\n</dependency>\r\n```\r\n\r\n在media-service工程添加此依赖。\r\n\r\n参数说明：\r\n\r\n需要三个参数才能连接到minio服务。\r\n\r\n| 参数       | 说明                                         |\r\n| ---------- | -------------------------------------------- |\r\n| Endpoint   | 对象存储服务的URL                            |\r\n| Access Key | Access key就像用户ID，可以唯一标识你的账户。 |\r\n| Secret Key | Secret key是你账户的密码。                   |\r\n\r\n \r\n\r\n官方的示例代码如下：\r\n\r\n```java\r\nimport io.minio.BucketExistsArgs;\r\nimport io.minio.MakeBucketArgs;\r\nimport io.minio.MinioClient;\r\nimport io.minio.UploadObjectArgs;\r\nimport io.minio.errors.MinioException;\r\nimport java.io.IOException;\r\nimport java.security.InvalidKeyException;\r\nimport java.security.NoSuchAlgorithmException;\r\npublic class FileUploader {\r\n  public static void main(String[] args)throws IOException, NoSuchAlgorithmException, InvalidKeyException {\r\n    try {\r\n      // Create a minioClient with the MinIO server playground, its access key and secret key.\r\n      MinioClient minioClient =\r\n          MinioClient.builder()\r\n              .endpoint(\"https://play.min.io\")\r\n              .credentials(\"Q3AM3UQ867SPQQA43P2F\", \"zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG\")\r\n              .build();\r\n      // Make 'asiatrip' bucket if not exist.\r\n      boolean found =\r\n          minioClient.bucketExists(BucketExistsArgs.builder().bucket(\"asiatrip\").build());\r\n      if (!found) {\r\n        // Make a new bucket called 'asiatrip'.\r\n        minioClient.makeBucket(MakeBucketArgs.builder().bucket(\"asiatrip\").build());\r\n      } else {\r\n        System.out.println(\"Bucket 'asiatrip' already exists.\");\r\n      }\r\n      // Upload '/home/user/Photos/asiaphotos.zip' as object name 'asiaphotos-2015.zip' to bucket\r\n      // 'asiatrip'.\r\n      minioClient.uploadObject(\r\n          UploadObjectArgs.builder()\r\n              .bucket(\"asiatrip\")\r\n              .object(\"asiaphotos-2015.zip\")\r\n              .filename(\"/home/user/Photos/asiaphotos.zip\")\r\n              .build());\r\n      System.out.println(\r\n          \"'/home/user/Photos/asiaphotos.zip' is successfully uploaded as \"\r\n              + \"object 'asiaphotos-2015.zip' to bucket 'asiatrip'.\");\r\n    } catch (MinioException e) {\r\n      System.out.println(\"Error occurred: \" + e);\r\n      System.out.println(\"HTTP trace: \" + e.httpTrace());\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n参考示例在media-service工程中 测试上传文件功能，首先创建一个用于测试的bucket\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps68.jpg) \r\n\r\n点击“Manage”修改bucket的访问权限\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps69.jpg) \r\n\r\n选择public权限\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps70.jpg) \r\n\r\n在xuecheng-plus-media-service工程 的test下编写测试代码如下：\r\n\r\n```java\r\nimport io.minio.BucketExistsArgs;\r\nimport io.minio.MakeBucketArgs;\r\nimport io.minio.MinioClient;\r\nimport io.minio.UploadObjectArgs;\r\nimport io.minio.errors.MinioException;\r\n\r\nimport java.io.IOException;\r\nimport java.security.InvalidKeyException;\r\nimport java.security.NoSuchAlgorithmException;\r\npublic class MinioTest {\r\n    MinioClient minioClient =\r\n            MinioClient.builder()\r\n                    .endpoint(\"http://192.168.2.203:9000\")\r\n                    .credentials(\"minioadmin\", \"minioadmin\")\r\n                    .build();\r\n    @Test\r\n    public void test_upload() throws Exception {\r\n        try {\r\n            UploadObjectArgs testbucket = UploadObjectArgs.builder()\r\n                    .bucket(\"testbucket\")//桶\r\n                    .filename(\"D:\\\\Learning\\\\upload\\\\1.mp4\") //指定本地文件路径\r\n    //                .object(\"1.mp4\")//对象名 在桶下存储该文件\r\n                    .object(\"test/01/1.mp4\")//对象名 放在子目录下\r\n                    .contentType(\"video/mp4\")//默认根据扩展名确定文件内容类型，也可以指定\r\n                    .build();\r\n            minioClient.uploadObject(testbucket);\r\n            System.out.println(\"上传成功\");\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n            System.out.println(\"上传失败\");\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n执行upload方法，分别测试向桶的根目录上传文件以及子目录上传文件。\r\n\r\n上传成功，通过web控制台查看文件，并预览文件。\r\n\r\n说明：\r\n\r\n设置contentType可以通过com.j256.simplemagic.ContentType枚举类查看常用的mimeType（媒体类型）\r\n\r\n通过扩展名得到mimeType，代码如下：\r\n\r\n```java\r\n\t//根据扩展名取出mimeType\r\n    ContentInfo extensionMatch = ContentInfoUtil.findExtensionMatch(\".mp4\");\r\n    String mimeType = MediaType.APPLICATION_OCTET_STREAM_VALUE;//通用mimeType，字节流\r\n```\r\n\r\n完善上边的代码 如下：\r\n\r\n```java\r\n\t@Test\r\n    public void test_upload() throws Exception {\r\n        //通过扩展名得到媒体资源类型 mimeType\r\n        //根据扩展名取出mimeType\r\n        ContentInfo extensionMatch = ContentInfoUtil.findExtensionMatch(\".mp4\");\r\n        String mimeType = MediaType.APPLICATION_OCTET_STREAM_VALUE;//通用mimeType，字节流\r\n        if(extensionMatch!=null){\r\n            mimeType = extensionMatch.getMimeType();\r\n        }\r\n        //上传文件的参数信息\r\n        UploadObjectArgs uploadObjectArgs = UploadObjectArgs.builder()\r\n                .bucket(\"testbucket\")//桶\r\n                .filename(\"D:\\\\Learning\\\\upload\\\\1.mp4\") //指定本地文件路径\r\n//                .object(\"1.mp4\")//对象名 在桶下存储该文件\r\n                .object(\"test/01/1.mp4\")//对象名 放在子目录下\r\n                .contentType(mimeType)//设置媒体文件类型\r\n                .build();\r\n        //上传文件\r\n        minioClient.uploadObject(uploadObjectArgs);\r\n    }\r\n```\r\n\r\n \r\n\r\n##### **1.2.4.2 删除文件**\r\n\r\n下边测试删除文件\r\n\r\n参考：https://docs.min.io/docs/java-client-api-reference#removeObject\r\n\r\n```java\r\n@Test\r\npublic void delete(){\r\n    try {\r\n        minioClient.removeObject(\r\n               RemoveObjectArgs.builder().bucket(\"testbucket\").object(\"001/test001.mp4\").build());\r\n        System.out.println(\"删除成功\");\r\n    } catch (Exception e) {\r\n       e.printStackTrace();\r\n        System.out.println(\"删除失败\");\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n##### **1.2.4.3 查询文件**\r\n\r\n通过查询文件查看文件是否存在minio中。\r\n\r\n参考：https://docs.min.io/docs/java-client-api-reference#getObject\r\n\r\n校验文件的完整性，对文件计算出md5值，比较原始文件的md5和目标文件的md5，一致则说明完整\r\n\r\n```java\r\n//查询文件 从minio中下载\r\n@Test\r\npublic void test_getFile() throws Exception {\r\n\r\n    GetObjectArgs getObjectArgs = GetObjectArgs.builder().bucket(\"testbucket\").object(\"test/01/1.mp4\").build();\r\n    //查询远程服务获取到一个流对象\r\n    FilterInputStream inputStream = minioClient.getObject(getObjectArgs);\r\n    //指定输出流\r\n    FileOutputStream outputStream = new FileOutputStream(new File(\"D:\\\\Learning\\\\upload\\\\1a.mp4\"));\r\n    IOUtils.copy(inputStream,outputStream);\r\n\r\n    //校验文件的完整性对文件的内容进行md5\r\n    FileInputStream fileInputStream1 = new FileInputStream(new File(\"D:\\\\Learning\\\\upload\\\\1.mp4\"));\r\n    String source_md5 = DigestUtils.md5Hex(fileInputStream1);\r\n    FileInputStream fileInputStream = new FileInputStream(new File(\"D:\\\\Learning\\\\upload\\\\1a.mp4\"));\r\n    String local_md5 = DigestUtils.md5Hex(fileInputStream);\r\n    if(source_md5.equals(local_md5)){\r\n        System.out.println(\"下载成功\");\r\n    }\r\n\r\n\r\n}\r\n```\r\n\r\n\r\n\r\n## **二 上传图片**\r\n\r\n### **2.1 需求分析**\r\n\r\n#### **2.1.1 业务流程**\r\n\r\n课程图片是宣传课程非常重要的信息，在新增课程界面上传课程图片，也可以修改课程图片。\r\n\r\n如下图：\r\n\r\n![image-20230704224229162](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704224229162.png)\r\n\r\n上传课程图片总体上包括两部分：\r\n\r\n1、上传课程图片前端请求媒资管理服务将文件上传至分布式文件系统，并且在媒资管理数据库保存文件信息。\r\n\r\n2、上传图片成功保存图片地址到课程基本信息表中。\r\n\r\n详细流程如下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps72.jpg) \r\n\r\n1、前端进入上传图片界面\r\n\r\n2、上传图片，请求媒资管理服务。\r\n\r\n3、媒资管理服务将图片文件存储在MinIO。\r\n\r\n4、媒资管理记录文件信息到数据库。\r\n\r\n5、前端请求内容管理服务保存课程信息，在内容管理数据库保存图片地址。\r\n\r\n \r\n\r\n#### **2.1.2 数据模型**\r\n\r\n涉及到的数据表有：课程信息表中的图片字段、媒资数据库的文件表，下边主要看媒资数据库的文件表。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps73.jpg) \r\n\r\n各字段描述如下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps74.jpg) \r\n\r\n \r\n\r\n### **2.2 准备环境**\r\n\r\n首先在minio配置bucket，bucket名称为：mediafiles，并设置bucket的权限为公开。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps75.jpg) \r\n\r\n在nacos配置中minio的相关信息，进入`media-service-dev.yaml`:\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps76.jpg) \r\n\r\n配置信息如下：\r\n\r\n```yaml\r\nminio:\r\n  endpoint: http://192.168.2.203:9000\r\n  accessKey: minioadmin\r\n  secretKey: minioadmin\r\n  bucket:\r\n    files: mediafiles\r\n    videofiles: video\r\n\r\n \r\n```\r\n\r\n在media-service工程编写minio的配置类：\r\n\r\n```java\r\n@Configuration\r\npublic class MinioConfig {\r\n\r\n\r\n @Value(\"${minio.endpoint}\")\r\n private String endpoint;\r\n @Value(\"${minio.accessKey}\")\r\n private String accessKey;\r\n @Value(\"${minio.secretKey}\")\r\n private String secretKey;\r\n\r\n @Bean\r\n public MinioClient minioClient() {\r\n\r\n  MinioClient minioClient =\r\n          MinioClient.builder()\r\n                  .endpoint(endpoint)\r\n                  .credentials(accessKey, secretKey)\r\n                  .build();\r\n  return minioClient;\r\n }\r\n}\r\n```\r\n\r\n \r\n\r\n### **2.3 接口定义**\r\n\r\n根据需求分析，下边进行接口定义，此接口定义为一个通用的上传文件接口，可以上传图片或其它文件。\r\n\r\n首先分析接口：\r\n\r\n> 请求地址：/media/upload/coursefile\r\n>\r\n> 请求内容：**Content-Type:** multipart/form-data;\r\n>\r\n> form-data; name=\"filedata\"; filename=\"具体的文件名称\"\r\n\r\n \r\n\r\n响应参数：文件信息，如下\r\n\r\n```json\r\n{\r\n  \"id\": \"a16da7a132559daf9e1193166b3e7f52\",\r\n  \"companyId\": 1232141425,\r\n  \"companyName\": null,\r\n  \"filename\": \"1.jpg\",\r\n  \"fileType\": \"001001\",\r\n  \"tags\": \"\",\r\n  \"bucket\": \"/testbucket/2022/09/12/a16da7a132559daf9e1193166b3e7f52.jpg\",\r\n  \"fileId\": \"a16da7a132559daf9e1193166b3e7f52\",\r\n  \"url\": \"/testbucket/2022/09/12/a16da7a132559daf9e1193166b3e7f52.jpg\",\r\n  \"timelength\": null,\r\n  \"username\": null,\r\n  \"createDate\": \"2022-09-12T21:57:18\",\r\n  \"changeDate\": null,\r\n  \"status\": \"1\",\r\n  \"remark\": \"\",\r\n  \"auditStatus\": null,\r\n  \"auditMind\": null,\r\n  \"fileSize\": 248329\r\n}\r\n```\r\n\r\n定义上传响应模型类：\r\n\r\n```java\r\n/**\r\n * @description 上传普通文件成功响应结果\r\n */\r\n@Data\r\npublic class UploadFileResultDto extends MediaFiles {\r\n}\r\n```\r\n\r\n \r\n\r\n定义接口如下：\r\n\r\n```java\r\n@ApiOperation(\"上传文件\")\r\n@RequestMapping(value = \"/upload/coursefile\", consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\r\npublic UploadFileResultDto upload(@RequestPart(\"filedata\") MultipartFile upload) throws IOException {\r\n\r\n    return null;\r\n}\r\n```\r\n\r\n接口定义好后可以用httpclient工具测试一下\r\n\r\n使用httpclient测试\r\n\r\n```http\r\n### 上传文件\r\nPOST {{media_host}}/media/upload/coursefile\r\nContent-Type: multipart/form-data; boundary=WebAppBoundary\r\n\r\n--WebAppBoundary\r\nContent-Disposition: form-data; name=\"filedata\"; filename=\"1.jpg\"\r\nContent-Type: application/octet-stream\r\n\r\n< d:/develop/upload/1.jpg\r\n```\r\n\r\n \r\n\r\n### **2.4 接口开发**\r\n\r\n#### **2.4.1 DAO开发**\r\n\r\n根据需求分析DAO层实现向`media_files`表插入一条记录，使用`media_files`表生成的mapper即可。\r\n\r\n#### **2.4.2 Service开发**\r\n\r\nService方法需要提供一个更加通用的保存文件的方法。\r\n\r\n定义请求参数类：\r\n\r\n```java\r\n/**\r\n * @description 上传普通文件请求参数\r\n */\r\n @Data\r\npublic class UploadFileParamsDto {\r\n\r\n /**\r\n  * 文件名称\r\n  */\r\n private String filename;\r\n\r\n\r\n /**\r\n  * 文件类型（文档，音频，视频）\r\n  */\r\n private String fileType;\r\n /**\r\n  * 文件大小\r\n  */\r\n private Long fileSize;\r\n\r\n /**\r\n  * 标签\r\n  */\r\n private String tags;\r\n\r\n /**\r\n  * 上传人\r\n  */\r\n private String username;\r\n\r\n /**\r\n  * 备注\r\n  */\r\n private String remark;\r\n\r\n\r\n\r\n}\r\n```\r\n\r\n定义service方法：\r\n\r\n```java\r\n/**\r\n * 上传文件\r\n * @param companyId 机构id\r\n * @param uploadFileParamsDto 上传文件信息\r\n * @param localFilePath 文件磁盘路径\r\n * @return 文件信息\r\n */\r\npublic UploadFileResultDto uploadFile(Long companyId, UploadFileParamsDto uploadFileParamsDto, String localFilePath);\r\n//修改版\r\npublic UploadFileResultDto uploadFile(Long companyId, UploadFileParamsDto uploadFileParamsDto, String localFilePath, String objectName);\r\n```\r\n\r\n实现方法如下：\r\n\r\n```java\r\n@Autowired\r\nMinioClient minioClient;\r\n\r\n@Autowired\r\nMediaFilesMapper mediaFilesMapper;\r\n\r\n//普通文件桶\r\n@Value(\"${minio.bucket.files}\")\r\nprivate String bucket_Files;\r\n\r\n\r\n//获取文件默认存储目录路径 年/月/日\r\nprivate String getDefaultFolderPath() {\r\n    SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd\");\r\n    String folder = sdf.format(new Date()).replace(\"-\", \"/\")+\"/\";\r\n    return folder;\r\n}\r\n\r\n//获取文件的md5\r\nprivate String getFileMd5(File file) {\r\n    try (FileInputStream fileInputStream = new FileInputStream(file)) {\r\n        String fileMd5 = DigestUtils.md5Hex(fileInputStream);\r\n        return fileMd5;\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n        return null;\r\n    }\r\n}\r\n\r\n\r\nprivate String getMimeType(String extension){\r\n    if(extension==null)\r\n        extension = \"\";\r\n    //根据扩展名取出mimeType\r\n    ContentInfo extensionMatch = ContentInfoUtil.findExtensionMatch(extension);\r\n    //通用mimeType，字节流\r\n    String mimeType = MediaType.APPLICATION_OCTET_STREAM_VALUE;\r\n    if(extensionMatch!=null){\r\n        mimeType = extensionMatch.getMimeType();\r\n    }\r\n    return mimeType;\r\n}\r\n/**\r\n * @description 将文件写入minIO\r\n * @param localFilePath  文件地址\r\n * @param bucket  桶\r\n * @param objectName 对象名称\r\n * @return void\r\n */\r\npublic boolean addMediaFilesToMinIO(String localFilePath,String mimeType,String bucket, String objectName) {\r\n    try {\r\n        UploadObjectArgs testbucket = UploadObjectArgs.builder()\r\n                .bucket(bucket)\r\n                .object(objectName)\r\n                .filename(localFilePath)\r\n                .contentType(mimeType)\r\n                .build();\r\n        minioClient.uploadObject(testbucket);\r\n        log.debug(\"上传文件到minio成功,bucket:{},objectName:{}\",bucket,objectName);\r\n        System.out.println(\"上传成功\");\r\n        return true;\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n        log.error(\"上传文件到minio出错,bucket:{},objectName:{},错误原因:{}\",bucket,objectName,e.getMessage(),e);\r\n        XueChengPlusException.cast(\"上传文件到文件系统失败\");\r\n    }\r\n    return false;\r\n}\r\n\r\n/**\r\n * @description 将文件信息添加到文件表\r\n * @param companyId  机构id\r\n * @param fileMd5  文件md5值\r\n * @param uploadFileParamsDto  上传文件的信息\r\n * @param bucket  桶\r\n * @param objectName 对象名称\r\n * @return com.xuecheng.media.model.po.MediaFiles\r\n */\r\n@Transactional\r\npublic MediaFiles addMediaFilesToDb(Long companyId,String fileMd5,UploadFileParamsDto uploadFileParamsDto,String bucket,String objectName){\r\n    //从数据库查询文件\r\n    MediaFiles mediaFiles = mediaFilesMapper.selectById(fileMd5);\r\n    if (mediaFiles == null) {\r\n        mediaFiles = new MediaFiles();\r\n        //拷贝基本信息\r\n        BeanUtils.copyProperties(uploadFileParamsDto, mediaFiles);\r\n        mediaFiles.setId(fileMd5);\r\n        mediaFiles.setFileId(fileMd5);\r\n        mediaFiles.setCompanyId(companyId);\r\n        mediaFiles.setUrl(\"/\" + bucket + \"/\" + objectName);\r\n        mediaFiles.setBucket(bucket);\r\n        mediaFiles.setFilePath(objectName);\r\n        mediaFiles.setCreateDate(LocalDateTime.now());\r\n        mediaFiles.setAuditStatus(\"002003\");\r\n        mediaFiles.setStatus(\"1\");\r\n        //保存文件信息到文件表\r\n        int insert = mediaFilesMapper.insert(mediaFiles);\r\n        if (insert < 0) {\r\n            log.error(\"保存文件信息到数据库失败,{}\",mediaFiles.toString());\r\n            XueChengPlusException.cast(\"保存文件信息失败\");\r\n        }\r\n        log.debug(\"保存文件信息到数据库成功,{}\",mediaFiles.toString());\r\n\r\n    }\r\n    return mediaFiles;\r\n\r\n}\r\n@Transactional\r\n@Override\r\npublic UploadFileResultDto uploadFile(Long companyId, UploadFileParamsDto uploadFileParamsDto, String localFilePath) {\r\n    File file = new File(localFilePath);\r\n    if (!file.exists()) {\r\n        XueChengPlusException.cast(\"文件不存在\");\r\n    }\r\n    //文件名称\r\n    String filename = uploadFileParamsDto.getFilename();\r\n    //文件扩展名\r\n    String extension = filename.substring(filename.lastIndexOf(\".\"));\r\n    //文件mimeType\r\n    String mimeType = getMimeType(extension);\r\n    //文件的md5值\r\n    String fileMd5 = getFileMd5(file);\r\n    //文件的默认目录\r\n    String defaultFolderPath = getDefaultFolderPath();\r\n    //存储到minio中的对象名(带目录)\r\n    String  objectName = defaultFolderPath + fileMd5 + exension;\r\n    //将文件上传到minio\r\n    boolean b = addMediaFilesToMinIO(localFilePath, mimeType, bucket_files, objectName);\r\n    //文件大小\r\n    uploadFileParamsDto.setFileSize(file.length());\r\n    //将文件信息存储到数据库\r\n    MediaFiles mediaFiles = addMediaFilesToDb(companyId, fileMd5, uploadFileParamsDto, bucket_files, objectName);\r\n    //准备返回数据\r\n    UploadFileResultDto uploadFileResultDto = new UploadFileResultDto();\r\n    BeanUtils.copyProperties(mediaFiles, uploadFileResultDto);\r\n    return uploadFileResultDto;\r\n\r\n}\r\n```\r\n\r\n 修改版\r\n\r\n```java\r\n//将文件信息添加到文件表添加到service接口\r\nMediaFiles addMediaFilesToDb(Long companyId,String fileMd5,UploadFileParamsDto uploadFileParamsDto,String bucket,String objectName);\r\n/*-----------------------------------------------------------------------------------------------------------------------*/\r\n//注入自身\r\n@Autowired\r\nMediaFileService currentProxy;\r\n\r\n/**\r\n     * @description 将文件信息添加到文件表\r\n     * @param companyId  机构id\r\n     * @param fileMd5  文件md5值\r\n     * @param uploadFileParamsDto  上传文件的信息\r\n     * @param bucket  桶\r\n     * @param objectName 对象名称\r\n     * @return com.xuecheng.media.model.po.MediaFiles\r\n     */\r\n    @Override\r\n    @Transactional\r\n    public MediaFiles addMediaFilesToDb(Long companyId,String fileMd5,UploadFileParamsDto uploadFileParamsDto,String bucket,String objectName){\r\n        //将文件信息保存到数据库\r\n        MediaFiles mediaFiles = mediaFilesMapper.selectById(fileMd5);\r\n        if(mediaFiles == null){\r\n            mediaFiles = new MediaFiles();\r\n            BeanUtils.copyProperties(uploadFileParamsDto,mediaFiles);\r\n            //文件id\r\n            mediaFiles.setId(fileMd5);\r\n            //机构id\r\n            mediaFiles.setCompanyId(companyId);\r\n            //桶\r\n            mediaFiles.setBucket(bucket);\r\n            //file_path\r\n            mediaFiles.setFilePath(objectName);\r\n            //file_id\r\n            mediaFiles.setFileId(fileMd5);\r\n            //url\r\n            mediaFiles.setUrl(\"/\"+bucket+\"/\"+objectName);\r\n            //上传时间\r\n            mediaFiles.setCreateDate(LocalDateTime.now());\r\n            //状态\r\n            mediaFiles.setStatus(\"1\");\r\n            //审核状态\r\n            mediaFiles.setAuditStatus(\"002003\");\r\n            //插入数据库\r\n            int insert = mediaFilesMapper.insert(mediaFiles);\r\n            if(insert<=0){\r\n                log.debug(\"向数据库保存文件失败,bucket:{},objectName:{}\",bucket,objectName);\r\n                return null;\r\n            }\r\n            //添加到待处理任务表\r\n            addWaitingTask(mediaFiles);\r\n            log.debug(\"保存文件信息到数据库成功,{}\", mediaFiles.toString());\r\n\r\n        }\r\n        return mediaFiles;\r\n\r\n    }\r\n\r\n@Override\r\npublic UploadFileResultDto uploadFile(Long companyId, UploadFileParamsDto uploadFileParamsDto, String localFilePath, String objectName) {\r\n\r\n    //文件名\r\n    String filename = uploadFileParamsDto.getFilename();\r\n    //先得到扩展名\r\n    String extension = filename.substring(filename.lastIndexOf(\".\"));\r\n\r\n    //得到mimeType\r\n    String mimeType = getMimeType(extension);\r\n\r\n    //子目录\r\n    String defaultFolderPath = getDefaultFolderPath();\r\n    //文件的md5值\r\n    String fileMd5 = getFileMd5(new File(localFilePath));\r\n    if (StringUtil.isEmpty(objectName)){\r\n        //                      2023/6/23/  adgfgetgwg24f4gr.jpg\r\n        objectName = defaultFolderPath+fileMd5+extension;\r\n    }\r\n    //上传文件到minio\r\n    boolean result = addMediaFilesToMinIO(localFilePath, mimeType, bucket_mediafiles, objectName);\r\n    if(!result){\r\n        XueChengPlusException.cast(\"上传文件失败\");\r\n    }\r\n    //入库文件信息\r\n    MediaFiles mediaFiles = currentProxy.addMediaFilesToDb(companyId, fileMd5, uploadFileParamsDto, bucket_mediafiles, objectName);\r\n    if(mediaFiles==null){\r\n        XueChengPlusException.cast(\"文件上传后保存信息失败\");\r\n    }\r\n    //准备返回的对象\r\n    UploadFileResultDto uploadFileResultDto = new UploadFileResultDto();\r\n    BeanUtils.copyProperties(mediaFiles,uploadFileResultDto);\r\n\r\n    return uploadFileResultDto;\r\n}\r\n```\r\n\r\n#### **2.4.3 完善接口层**\r\n\r\n完善接口层代码 ：\r\n\r\n```java\r\n@ApiOperation(\"上传文件\")\r\n@RequestMapping(value = \"/upload/coursefile\",consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\r\n@ResponseBody\r\npublic UploadFileResultDto upload(@RequestPart(\"filedata\") MultipartFile upload,@RequestParam(value = \"folder\",required=false) String folder,@RequestParam(value = \"objectName\",required=false) String objectName) throws IOException {\r\n\r\n        Long companyId = 1232141425L;\r\n    UploadFileParamsDto uploadFileParamsDto = new UploadFileParamsDto();\r\n    //文件大小\r\n    uploadFileParamsDto.setFileSize(filedata.getSize());\r\n    //图片\r\n    uploadFileParamsDto.setFileType(\"001001\");\r\n    //文件名称\r\n    uploadFileParamsDto.setFilename(filedata.getOriginalFilename());//文件名称\r\n    //文件大小\r\n    long fileSize = filedata.getSize();\r\n    uploadFileParamsDto.setFileSize(fileSize);\r\n    //创建临时文件\r\n    File tempFile = File.createTempFile(\"minio\", \"temp\");\r\n    //上传的文件拷贝到临时文件\r\n    filedata.transferTo(tempFile);\r\n    //文件路径\r\n    String absolutePath = tempFile.getAbsolutePath();\r\n    //上传文件\r\n    UploadFileResultDto uploadFileResultDto = mediaFileService.uploadFile(companyId, uploadFileParamsDto, absolutePath);\r\n    \r\n    return uploadFileResultDto;\r\n}\r\n\r\n\t//修改版\r\n \t@ApiOperation(\"上传图片\")\r\n    @RequestMapping(value = \"/upload/coursefile\",consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\r\n    public UploadFileResultDto upload(@RequestPart(\"filedata\") MultipartFile filedata,\r\n                                      @RequestParam(value= \"objectName\",required=false) String objectName) throws IOException {\r\n\r\n        //准备上传文件的信息\r\n        UploadFileParamsDto uploadFileParamsDto = new UploadFileParamsDto();\r\n        //原始文件名称\r\n        uploadFileParamsDto.setFilename(filedata.getOriginalFilename());\r\n        //文件大小\r\n        uploadFileParamsDto.setFileSize(filedata.getSize());\r\n        //文件类型\r\n        uploadFileParamsDto.setFileType(\"001001\");\r\n        //创建一个临时文件\r\n        File tempFile = File.createTempFile(\"minio\", \".temp\");\r\n        //将本地要上传的文件拷贝到临时文件，拿到本地路径\r\n        filedata.transferTo(tempFile);\r\n        Long companyId = 1232141425L;\r\n        //文件路径\r\n        String localFilePath = tempFile.getAbsolutePath();\r\n\r\n        //调用service上传图片\r\n        UploadFileResultDto uploadFileResultDto = mediaFileService.uploadFile(companyId, uploadFileParamsDto, localFilePath, objectName);\r\n\r\n        return uploadFileResultDto;\r\n    }\r\n```\r\n\r\n \r\n\r\n#### **2.4.4 接口测试**\r\n\r\n1、首先使用httpclient测试\r\n\r\n```http\r\n### 上传文件\r\nPOST {{media_host}}/media/upload/coursefile\r\nContent-Type: multipart/form-data; boundary=WebAppBoundary\r\n\r\n--WebAppBoundary\r\nContent-Disposition: form-data; name=\"filedata\"; filename=\"1.jpg\"\r\nContent-Type: application/octet-stream\r\n\r\n< d:/develop/upload/1.jpg\r\n```\r\n\r\n2、再进行前后端联调测试\r\n\r\n在新增课程、编辑课程界面上传图，保存课程信息后再次进入编辑课程界面，查看是否可以正常保存课程图片信息。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps77.jpg) \r\n\r\n上图图片完成后，进入媒资管理，查看文件列表中是否有刚刚上传的图片信息。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps78.jpg) \r\n\r\n \r\n\r\n#### **2.4.5 Service事务优化**\r\n\r\n上边的service方法优化后并测试通过，现在思考关于uploadFile方法的是否应该开启事务。\r\n\r\n目前是在uploadFile方法上添加`@Transactional`，当调用uploadFile方法前会开启数据库事务，如果上传文件过程时间较长那么数据库的事务持续时间就会变长，这样数据库链接释放就慢，最终导致数据库链接不够用。\r\n\r\n我们只将addMediaFilesToDb方法添加事务控制即可,uploadFile方法上的`@Transactional`注解去掉。\r\n\r\n优化后如下：\r\n\r\n```java\r\n/**\r\n * @description 将文件信息添加到文件表\r\n * @param companyId  机构id\r\n * @param fileMd5  文件md5值\r\n * @param uploadFileParamsDto  上传文件的信息\r\n * @param bucket  桶\r\n * @param objectName 对象名称\r\n * @return com.xuecheng.media.model.po.MediaFiles\r\n */\r\n@Override\r\n@Transactional\r\npublic MediaFiles addMediaFilesToDb(Long companyId,String fileMd5,UploadFileParamsDto uploadFileParamsDto,String bucket,String objectName){\r\n    //将文件信息保存到数据库\r\n    MediaFiles mediaFiles = mediaFilesMapper.selectById(fileMd5);\r\n    if(mediaFiles == null){\r\n        mediaFiles = new MediaFiles();\r\n        BeanUtils.copyProperties(uploadFileParamsDto,mediaFiles);\r\n        //文件id\r\n        mediaFiles.setId(fileMd5);\r\n        //机构id\r\n        mediaFiles.setCompanyId(companyId);\r\n        //桶\r\n        mediaFiles.setBucket(bucket);\r\n        //file_path\r\n        mediaFiles.setFilePath(objectName);\r\n        //file_id\r\n        mediaFiles.setFileId(fileMd5);\r\n        //url\r\n        mediaFiles.setUrl(\"/\"+bucket+\"/\"+objectName);\r\n        //上传时间\r\n        mediaFiles.setCreateDate(LocalDateTime.now());\r\n        //状态\r\n        mediaFiles.setStatus(\"1\");\r\n        //审核状态\r\n        mediaFiles.setAuditStatus(\"002003\");\r\n        //插入数据库\r\n        int insert = mediaFilesMapper.insert(mediaFiles);\r\n        if(insert<=0){\r\n            log.debug(\"向数据库保存文件失败,bucket:{},objectName:{}\",bucket,objectName);\r\n            return null;\r\n        }\r\n        //添加到待处理任务表\r\n        addWaitingTask(mediaFiles);\r\n        log.debug(\"保存文件信息到数据库成功,{}\", mediaFiles.toString());\r\n\r\n    }\r\n    return mediaFiles;\r\n\r\n}\r\n```\r\n\r\n我们人为在`int insert = mediaFilesMapper.insert(mediaFiles);`下边添加一个异常代码`int a=1/0;`\r\n\r\n测试是否事务控制。很遗憾，事务控制失败。\r\n\r\n方法上已经添加了`@Transactional`注解为什么该方法不能被事务控制呢？\r\n\r\n如果是在uploadFile方法上添加`@Transactional`注解就可以控制事务，去掉则不行。\r\n\r\n现在的问题其实是一个非事务方法调同类一个事务方法，事务无法控制，这是为什么？\r\n\r\n下边分析原因：\r\n\r\n如果在uploadFile方法上添加`@Transactional`注解，代理对象执行此方法前会开启事务，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps79.jpg) \r\n\r\n如果在uploadFile方法上没有`@Transactional`注解，代理对象执行此方法前不进行事务控制，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps80.jpg) \r\n\r\n所以判断该方法是否可以事务控制必须保证是通过代理对象调用此方法，且此方法上添加了`@Transactional`注解。\r\n\r\n现在在addMediaFilesToDb方法上添加`@Transactional`注解，也不会进行事务控制是因为并不是通过代理对象执行的addMediaFilesToDb方法。为了判断在uploadFile方法中去调用addMediaFilesToDb方法是否是通过代理对象去调用，我们可以打断点跟踪。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps81.jpg) \r\n\r\n我们发现在uploadFile方法中去调用addMediaFilesToDb方法不是通过代理对象去调用。\r\n\r\n \r\n\r\n如何解决呢？通过代理对象去调用addMediaFilesToDb方法即可解决。\r\n\r\n在MediaFileService的实现类中注入MediaFileService的代理对象，如下：\r\n\r\n```java\r\n@Autowired\r\nMediaFileService currentProxy;\r\n```\r\n\r\n将addMediaFilesToDb方法提成接口。\r\n\r\n```java\r\n/**\r\n * @description 将文件信息添加到文件表\r\n * @param companyId  机构id\r\n * @param fileMd5  文件md5值\r\n * @param uploadFileParamsDto  上传文件的信息\r\n * @param bucket  桶\r\n * @param objectName 对象名称\r\n * @return com.xuecheng.media.model.po.MediaFiles\r\n */\r\npublic MediaFiles addMediaFilesToDb(Long companyId,String fileMd5,UploadFileParamsDto uploadFileParamsDto,String bucket,String objectName);\r\n```\r\n\r\n \r\n\r\n调用addMediaFilesToDb方法的代码处改为如下：\r\n\r\n```java\r\n..... \r\n    //写入文件表 \r\n    MediaFiles mediaFiles = currentProxy.addMediaFilesToDb(companyId, fileMd5, uploadFileParamsDto, bucket_files, objectName);  \r\n....\r\n```\r\n\r\n再次测试事务是否可以正常控制。\r\n\r\n\r\n\r\n## **三 上传视频**\r\n\r\n### **3.1 需求分析**\r\n\r\n1、教学机构人员进入媒资管理列表查询自己上传的媒资文件。\r\n\r\n点击“媒资管理”\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps82.jpg) \r\n\r\n进入媒资管理列表页面查询本机构上传的媒资文件。\r\n\r\n![image-20230704231746909](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704231746909.png)\r\n\r\n \r\n\r\n2、教育机构用户在\"媒资管理\"页面中点击 \"上传视频\" 按钮。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps84.jpg) \r\n\r\n点击“上传视频”打开上传页面\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps85.jpg) \r\n\r\n3、选择要上传的文件，自动执行文件上传。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps86.jpg) \r\n\r\n4、视频上传成功会自动处理，处理完成可以预览视频。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps87.jpg) \r\n\r\n \r\n\r\n### **3.2 断点续传技术**\r\n\r\n#### **3.2.1 什么是断点续传**\r\n\r\n通常视频文件都比较大，所以对于媒资系统上传文件的需求要满足大文件的上传要求。http协议本身对上传文件大小没有限制，但是客户的网络环境质量、电脑硬件环境等参差不齐，如果一个大文件快上传完了网断了没有上传完成，需要客户重新上传，用户体验非常差，所以对于大文件上传的要求最基本的是断点续传。\r\n\r\n什么是断点续传：\r\n\r\n​    引用百度百科：断点续传指的是在下载或上传时，将下载或上传任务（一个文件或一个压缩包）人为的划分为几个部分，每一个部分采用一个线程进行上传或下载，如果碰到网络故障，可以从已经上传或下载的部分开始继续上传下载未完成的部分，而没有必要从头开始上传下载，断点续传可以提高节省操作时间，提高用户体验性。\r\n\r\n断点续传流程如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps88.jpg) \r\n\r\n流程如下：\r\n\r\n1、前端上传前先把文件分成块\r\n\r\n2、一块一块的上传，上传中断后重新上传，已上传的分块则不用再上传\r\n\r\n3、各分块上传完成最后在服务端合并文件\r\n\r\n#### **3.2.2 分块与合并测试**\r\n\r\n为了更好的理解文件分块上传的原理，下边用java代码测试文件的分块与合并。\r\n\r\n文件分块的流程如下：\r\n\r\n1、获取源文件长度\r\n\r\n2、根据设定的分块文件的大小计算出块数\r\n\r\n3、从源文件读数据依次向每一个块文件写数据。\r\n\r\n测试代码如下：\r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2023/06/23 19:43\r\n * @description 测试大文件上传方法\r\n */\r\npublic class BigFileTest {\r\n    //分块测试\r\n    @Test\r\n    public void testChunk() throws IOException {\r\n        //源文件\r\n        File sourceFile = new File(\"D:\\\\Learning\\\\upload\\\\1.mkv\");\r\n        //分块文件存储路径\r\n        String chunkFilePath = \"D:\\\\Learning\\\\upload\\\\chunk\\\\\";\r\n        //分块文件大小\r\n        //long chunkSize = 1024 * 1024 * 1;\r\n        int chunkSize = 1024 * 1024 * 5;\r\n        //分块文件个数\r\n        int chunkNum = (int) Math.ceil(sourceFile.length() * 1.0 / chunkSize);\r\n        //使用流从源文件读数据，向分块文件中写数据\r\n        RandomAccessFile raf_r = new RandomAccessFile(sourceFile, \"r\");\r\n        //缓存区\r\n        byte[] bytes = new byte[1024];\r\n        for (int i = 0; i < chunkNum; i++) {\r\n            File chunkFile = new File(chunkFilePath + i);\r\n            //分块文件写入流\r\n            RandomAccessFile raf_rw = new RandomAccessFile(chunkFile, \"rw\");\r\n            int len = -1;\r\n            while ((len=raf_r.read(bytes))!=-1){\r\n                raf_rw.write(bytes,0,len);\r\n                if(chunkFile.length()>=chunkSize){\r\n                    break;\r\n                }\r\n            }\r\n            raf_rw.close();\r\n        }\r\n        raf_r.close();\r\n\r\n    }\r\n}\r\n```\r\n\r\n文件合并流程：\r\n\r\n1、找到要合并的文件并按文件合并的先后进行排序。\r\n\r\n2、创建合并文件\r\n\r\n3、依次从合并的文件中读取数据向合并文件写入数\r\n\r\n文件合并的测试代码 ：\r\n\r\n```java\r\n//将分块进行合并\r\n@Test\r\npublic void testMerge() throws IOException {\r\n    //块文件目录\r\n    File chunkFolder = new File(\"D:\\\\Learning\\\\upload\\\\chunk\");\r\n    //源文件\r\n    File sourceFile = new File(\"D:\\\\Learning\\\\upload\\\\1.mkv\");\r\n    //合并后的文件\r\n    File mergeFile = new File(\"D:\\\\Learning\\\\upload\\\\1_1.mkv\");\r\n\r\n    //取出所有分块文件\r\n    File[] files = chunkFolder.listFiles();\r\n    //将数组转成list\r\n    List<File> filesList = Arrays.asList(files);\r\n    //对分块文件排序\r\n    Collections.sort(filesList, new Comparator<File>() {\r\n        @Override\r\n        public int compare(File o1, File o2) {\r\n            return Integer.parseInt(o1.getName())-Integer.parseInt(o2.getName());\r\n        }\r\n    });\r\n    //向合并文件写的流\r\n    RandomAccessFile raf_rw = new RandomAccessFile(mergeFile, \"rw\");\r\n    //缓存区\r\n    byte[] bytes = new byte[1024];\r\n    //遍历分块文件，向合并 的文件写\r\n    for (File file : filesList) {\r\n        //读分块的流\r\n        RandomAccessFile raf_r = new RandomAccessFile(file, \"r\");\r\n        int len = -1;\r\n        while ((len=raf_r.read(bytes))!=-1){\r\n            raf_rw.write(bytes,0,len);\r\n        }\r\n        raf_r.close();\r\n\r\n    }\r\n    raf_rw.close();\r\n    //合并文件完成后对合并的文件md5校验\r\n    FileInputStream fileInputStream_merge = new FileInputStream(mergeFile);\r\n    FileInputStream fileInputStream_source = new FileInputStream(sourceFile);\r\n    String md5_merge = DigestUtils.md5Hex(fileInputStream_merge);\r\n    String md5_source = DigestUtils.md5Hex(fileInputStream_source);\r\n    if(md5_merge.equals(md5_source)){\r\n        System.out.println(\"文件合并成功\");\r\n    }\r\n\r\n}\r\n```\r\n\r\n#### **3.2.3 视频上传流程**\r\n\r\n下图是上传视频的整体流程：\r\n\r\n![image-20230704232249335](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704232249335.png)\r\n\r\n1、前端对文件进行分块。\r\n\r\n2、前端上传分块文件前请求媒资服务检查文件是否存在，如果已经存在则不再上传。\r\n\r\n3、如果分块文件不存在则前端开始上传\r\n\r\n4、前端请求媒资服务上传分块。\r\n\r\n5、媒资服务将分块上传至MinIO。\r\n\r\n6、前端将分块上传完毕请求媒资服务合并分块。\r\n\r\n7、媒资服务判断分块上传完成则请求MinIO合并文件。\r\n\r\n8、合并完成校验合并后的文件是否完整，如果完整则上传完成，否则删除文件。\r\n\r\n \r\n\r\n#### **3.2.4 minio合并文件测试**\r\n\r\n1、将分块文件上传至minio\r\n\r\n```java\r\n//将分块文件上传到minio\r\n@Test\r\npublic void uploadChunk() throws IOException,  InsufficientDataException, ErrorResponseException, NoSuchAlgorithmException,  InvalidResponseException, XmlParserException, InternalException, ServerException, InvalidKeyException {\r\n\r\n    for (int i = 0; i < 3; i++) {\r\n        //上传文件的参数信息\r\n        UploadObjectArgs uploadObjectArgs = UploadObjectArgs.builder()\r\n                .bucket(\"testbucket\")//桶\r\n                .filename(\"D:\\\\Learning\\\\upload\\\\chunk\\\\\"+i) //指定本地文件路径\r\n                .object(\"chunk/\"+i)//对象名 放在子目录下\r\n                .build();\r\n\r\n        //上传文件\r\n        minioClient.uploadObject(uploadObjectArgs);\r\n        System.out.println(\"上传分块\"+i+\"成功\");\r\n    }\r\n\r\n}\r\n```\r\n\r\n \r\n\r\n2、通过minio的合并文件\r\n\r\n```java\r\n//合并文件，要求分块文件最小5M\r\n    @Test\r\n    public void testMerge() throws Exception {\r\n\r\n//        List<ComposeSource> sources = new ArrayList<>();\r\n//        for (int i = 0; i < 30; i++) {\r\n//            //指定分块文件的信息\r\n//            ComposeSource composeSource = ComposeSource.builder().bucket(\"testbucket\").object(\"chunk/\" + i).build();\r\n//            sources.add(composeSource);\r\n//        }\r\n\r\n        List<ComposeSource> sources = Stream.iterate(0, i -> ++i).limit(3).map(i -> ComposeSource.builder().bucket(\"testbucket\").object(\"chunk/\" + i).build()).collect(Collectors.toList());\r\n\r\n        //指定合并后的objectName等信息\r\n        ComposeObjectArgs composeObjectArgs = ComposeObjectArgs.builder()\r\n                .bucket(\"testbucket\")\r\n                .object(\"merge01.mp4\")\r\n                .sources(sources)//指定源文件\r\n                .build();\r\n        //合并文件,\r\n        //报错size 1048576 must be greater than 5242880，minio默认的分块文件大小为5M\r\n        minioClient.composeObject(composeObjectArgs);\r\n\r\n    }\r\n//清除分块文件\r\n@Test\r\npublic void test_removeObjects(){\r\n    //合并分块完成将分块文件清除\r\n    List<DeleteObject> deleteObjects = Stream.iterate(0, i -> ++i)\r\n            .limit(6)\r\n            .map(i -> new DeleteObject(\"chunk/\".concat(Integer.toString(i))))\r\n            .collect(Collectors.toList());\r\n\r\n    RemoveObjectsArgs removeObjectsArgs = RemoveObjectsArgs.builder().bucket(\"testbucket\").objects(deleteObjects).build();\r\n    Iterable<Result<DeleteError>> results = minioClient.removeObjects(removeObjectsArgs);\r\n    results.forEach(r->{\r\n        DeleteError deleteError = null;\r\n        try {\r\n            deleteError = r.get();\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        }\r\n    });\r\n}\r\n```\r\n\r\n使用minio合并文件报错：`java.lang.IllegalArgumentException: source testbucket/chunk/0: size 1048576 must be greater than 5242880`\r\n\r\nminio合并文件默认分块最小5M，我们将分块改为5M再次测试。\r\n\r\n \r\n\r\n \r\n\r\n### **3.3 接口定义**\r\n\r\n根据上传视频流程，定义接口，与前端的约定是操作成功返回`{code:0}`否则返回`{code:-1}`\r\n\r\n从课程资料中拷贝`RestResponse.java`类到base工程下的model包下。\r\n\r\n定义接口如下：\r\n\r\n```java\r\n@Api(value = \"大文件上传接口\", tags = \"大文件上传接口\")\r\n@RestController\r\npublic class BigFilesController {\r\n\r\n\r\n    @ApiOperation(value = \"文件上传前检查文件\")\r\n    @PostMapping(\"/upload/checkfile\")\r\n    public RestResponse<Boolean> checkfile(\r\n            @RequestParam(\"fileMd5\") String fileMd5\r\n    ) throws Exception {\r\n        return null;\r\n    }\r\n\r\n\r\n    @ApiOperation(value = \"分块文件上传前的检测\")\r\n    @PostMapping(\"/upload/checkchunk\")\r\n    public RestResponse<Boolean> checkchunk(@RequestParam(\"fileMd5\") String fileMd5,\r\n                                            @RequestParam(\"chunk\") int chunk) throws Exception {\r\n       return null;\r\n    }\r\n\r\n    @ApiOperation(value = \"上传分块文件\")\r\n    @PostMapping(\"/upload/uploadchunk\")\r\n    public RestResponse uploadchunk(@RequestParam(\"file\") MultipartFile file,\r\n                                    @RequestParam(\"fileMd5\") String fileMd5,\r\n                                    @RequestParam(\"chunk\") int chunk) throws Exception {\r\n        return null;\r\n    }\r\n\r\n    @ApiOperation(value = \"合并文件\")\r\n    @PostMapping(\"/upload/mergechunks\")\r\n    public RestResponse mergechunks(@RequestParam(\"fileMd5\") String fileMd5,\r\n                                    @RequestParam(\"fileName\") String fileName,\r\n                                    @RequestParam(\"chunkTotal\") int chunkTotal) throws Exception {\r\n        return null;\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n### **3.4 上传分块开发**\r\n\r\n#### **3.4.1 DAO开发**\r\n\r\n向媒资数据库的文件表插入记录，使用自动生成的Mapper接口即可满足要求。\r\n\r\n#### **3.4.2 Service开发**\r\n\r\n##### **3.4.2.1 检查文件和分块**\r\n\r\n接口完成进行接口实现，首先实现检查文件方法和检查分块方法。\r\n\r\n在MediaFileService中定义service接口如下：\r\n\r\n```java\r\n/**\r\n * @description 检查文件是否存在\r\n * @param fileMd5 文件的md5\r\n * @return com.xuecheng.base.model.RestResponse<java.lang.Boolean> false不存在，true存在\r\n*/\r\npublic RestResponse<Boolean> checkFile(String fileMd5);\r\n\r\n/**\r\n * @description 检查分块是否存在\r\n * @param fileMd5  文件的md5\r\n * @param chunkIndex  分块序号\r\n * @return com.xuecheng.base.model.RestResponse<java.lang.Boolean> false不存在，true存在\r\n*/\r\npublic RestResponse<Boolean> checkChunk(String fileMd5, int chunkIndex);\r\n```\r\n\r\n \r\n\r\nservice接口实现方法：\r\n\r\n```java\r\n@Override\r\npublic RestResponse<Boolean> checkFile(String fileMd5) {\r\n    //查询文件信息\r\n    MediaFiles mediaFiles = mediaFilesMapper.selectById(fileMd5);\r\n    if (mediaFiles != null) {\r\n        //桶\r\n        String bucket = mediaFiles.getBucket();\r\n        //存储目录\r\n        String filePath = mediaFiles.getFilePath();\r\n        //文件流\r\n        InputStream stream = null;\r\n        try {\r\n            stream = minioClient.getObject(\r\n                    GetObjectArgs.builder()\r\n                            .bucket(bucket)\r\n                            .object(filePath)\r\n                            .build());\r\n\r\n            if (stream != null) {\r\n                //文件已存在\r\n                return RestResponse.success(true);\r\n            }\r\n        } catch (Exception e) {\r\n           \r\n        }\r\n    }\r\n    //文件不存在\r\n    return RestResponse.success(false);\r\n}\r\n\r\n\r\n\r\n@Override\r\npublic RestResponse<Boolean> checkChunk(String fileMd5, int chunkIndex) {\r\n\r\n    //得到分块文件目录\r\n    String chunkFileFolderPath = getChunkFileFolderPath(fileMd5);\r\n    //得到分块文件的路径\r\n    String chunkFilePath = chunkFileFolderPath + chunkIndex;\r\n\r\n    //文件流\r\n    InputStream fileInputStream = null;\r\n    try {\r\n        fileInputStream = minioClient.getObject(\r\n                GetObjectArgs.builder()\r\n                        .bucket(bucket_videoFiles)\r\n                        .object(chunkFilePath)\r\n                        .build());\r\n\r\n        if (fileInputStream != null) {\r\n            //分块已存在\r\n            return RestResponse.success(true);\r\n        }\r\n    } catch (Exception e) {\r\n        \r\n    }\r\n    //分块未存在\r\n    return RestResponse.success(false);\r\n}\r\n\r\n//得到分块文件的目录\r\nprivate String getChunkFileFolderPath(String fileMd5) {\r\n    return fileMd5.substring(0, 1) + \"/\" + fileMd5.substring(1, 2) + \"/\" + fileMd5 + \"/\" + \"chunk\" + \"/\";\r\n}\r\n\r\n\r\n```\r\n\r\n \r\n\r\n##### **3.4.2.2 上传分块**\r\n\r\n定义service接口\r\n\r\n```java\r\n/**\r\n * @description 上传分块\r\n * @param fileMd5  文件md5\r\n * @param chunk  分块序号\r\n * @param localChunkFilePath  分块文件本地路径\r\n * @return com.xuecheng.base.model.RestResponse\r\n */\r\npublic RestResponse uploadChunk(String fileMd5,int chunk,String localChunkFilePath);\r\n```\r\n\r\n接口实现：\r\n\r\n```java\r\n@Override\r\npublic RestResponse uploadChunk(String fileMd5, int chunk, String localChunkFilePath) {\r\n\r\n    //得到分块文件的目录路径\r\n    String chunkFileFolderPath = getChunkFileFolderPath(fileMd5);\r\n    //得到分块文件的路径\r\n    String chunkFilePath = chunkFileFolderPath + chunk;\r\n    //mimeType\r\n    String mimeType = getMimeType(null);\r\n    //将文件存储至minIO\r\n    boolean b = addMediaFilesToMinIO(localChunkFilePath, mimeType, bucket_videoFiles, chunkFilePath);\r\n    if (!b) {\r\n        log.debug(\"上传分块文件失败:{}\", chunkFilePath);\r\n        return RestResponse.validfail(false, \"上传分块失败\");\r\n    }\r\n    log.debug(\"上传分块文件成功:{}\",chunkFilePath);\r\n    return RestResponse.success(true);\r\n\r\n}\r\n```\r\n\r\n\r\n\r\n##### **3.4.2.3 上传分块测试**\r\n\r\n完善接口层：\r\n\r\n```java\r\n@ApiOperation(value = \"文件上传前检查文件\")\r\n@PostMapping(\"/upload/checkfile\")\r\npublic RestResponse<Boolean> checkfile(\r\n        @RequestParam(\"fileMd5\") String fileMd5\r\n) throws Exception {\r\n    return mediaFileService.checkFile(fileMd5);\r\n}\r\n\r\n\r\n@ApiOperation(value = \"分块文件上传前的检测\")\r\n@PostMapping(\"/upload/checkchunk\")\r\npublic RestResponse<Boolean> checkchunk(@RequestParam(\"fileMd5\") String fileMd5,\r\n                                        @RequestParam(\"chunk\") int chunk) throws Exception {\r\n    return mediaFileService.checkChunk(fileMd5,chunk);\r\n}\r\n\r\n@ApiOperation(value = \"上传分块文件\")\r\n@PostMapping(\"/upload/uploadchunk\")\r\npublic RestResponse uploadchunk(@RequestParam(\"file\") MultipartFile file,\r\n                                @RequestParam(\"fileMd5\") String fileMd5,\r\n                                @RequestParam(\"chunk\") int chunk) throws Exception {\r\n\r\n    //创建临时文件\r\n    File tempFile = File.createTempFile(\"minio\", \"temp\");\r\n    //上传的文件拷贝到临时文件\r\n    file.transferTo(tempFile);\r\n    //文件路径\r\n    String absolutePath = tempFile.getAbsolutePath();\r\n    return mediaFileService.uploadChunk(fileMd5,chunk,absolutePath);\r\n}\r\n\r\n```\r\n\r\n启动前端工程，进入上传视频界面进行前后端联调测试。\r\n\r\n \r\n\r\n前端对文件分块的大小为5MB，SpringBoot web默认上传文件的大小限制为1MB，这里需要在media-api工程修改配置如下：\r\n\r\n```yaml\r\nspring:\r\n  servlet:\r\n    multipart:\r\n      max-file-size: 50MB\r\n      max-request-size: 50MB\r\n\r\n```\r\n\r\n`max-file-size`：单个文件的大小限制\r\n\r\n`Max-request-size`: 单次请求的大小限制\r\n\r\n上传分块时被限制大小，在本地`nginx.conf`配置：\r\n\r\n```apl\r\n#gzip  on;\r\n#文件服务\r\nclient_max_body_size 50m;\r\n```\r\n\r\n\r\n\r\n### **3.5 合并分块开发**\r\n\r\n#### **3.5.1 service开发**\r\n\r\n定义service接口：\r\n\r\n```java\r\n/**\r\n * @description 合并分块\r\n * @param companyId  机构id\r\n * @param fileMd5  文件md5\r\n * @param chunkTotal 分块总和\r\n * @param uploadFileParamsDto 文件信息\r\n * @return com.xuecheng.base.model.RestResponse\r\n */\r\npublic RestResponse mergechunks(Long companyId,String fileMd5,int chunkTotal,UploadFileParamsDto uploadFileParamsDto);\r\n```\r\n\r\nservice实现：\r\n\r\n```java\r\nJava\r\n@Override\r\npublic RestResponse mergechunks(Long companyId, String fileMd5, int chunkTotal, UploadFileParamsDto uploadFileParamsDto) {\r\n    //=====获取分块文件路径=====\r\n    String chunkFileFolderPath = getChunkFileFolderPath(fileMd5);\r\n    //组成将分块文件路径组成 List<ComposeSource>\r\n    List<ComposeSource> sourceObjectList = Stream.iterate(0, i -> ++i)\r\n            .limit(chunkTotal)\r\n            .map(i -> ComposeSource.builder()\r\n                    .bucket(bucket_videoFiles)\r\n                    .object(chunkFileFolderPath.concat(Integer.toString(i)))\r\n                    .build())\r\n            .collect(Collectors.toList());\r\n    //=====合并=====\r\n    //文件名称\r\n    String fileName = uploadFileParamsDto.getFilename();\r\n    //文件扩展名\r\n    String extName = fileName.substring(fileName.lastIndexOf(\".\"));\r\n    //合并文件路径\r\n    String mergeFilePath = getFilePathByMd5(fileMd5, extName);\r\n    try {\r\n        //合并文件\r\n        ObjectWriteResponse response = minioClient.composeObject(\r\n                ComposeObjectArgs.builder()\r\n                        .bucket(bucket_videoFiles)\r\n                        .object(mergeFilePath)\r\n                        .sources(sourceObjectList)\r\n                        .build());\r\n        log.debug(\"合并文件成功:{}\",mergeFilePath);\r\n    } catch (Exception e) {\r\n        log.debug(\"合并文件失败,fileMd5:{},异常:{}\",fileMd5,e.getMessage(),e);\r\n        return RestResponse.validfail(false, \"合并文件失败。\");\r\n    }\r\n\r\n    // ====验证md5====\r\n    //下载合并后的文件\r\n    File minioFile = downloadFileFromMinIO(bucket_videoFiles,mergeFilePath);\r\n    if(minioFile == null){\r\n        log.debug(\"下载合并后文件失败,mergeFilePath:{}\",mergeFilePath);\r\n        return RestResponse.validfail(false, \"下载合并后文件失败。\");\r\n    }\r\n\r\n    try (InputStream newFileInputStream = new FileInputStream(minioFile)) {\r\n        //minio上文件的md5值\r\n        String md5Hex = DigestUtils.md5Hex(newFileInputStream);\r\n        //比较md5值，不一致则说明文件不完整\r\n        if(!fileMd5.equals(md5Hex)){\r\n            return RestResponse.validfail(false, \"文件合并校验失败，最终上传失败。\");\r\n        }\r\n        //文件大小\r\n        uploadFileParamsDto.setFileSize(minioFile.length());\r\n    }catch (Exception e){\r\n        log.debug(\"校验文件失败,fileMd5:{},异常:{}\",fileMd5,e.getMessage(),e);\r\n        return RestResponse.validfail(false, \"文件合并校验失败，最终上传失败。\");\r\n    }finally {\r\n       if(minioFile!=null){\r\n           minioFile.delete();\r\n       }\r\n    }\r\n\r\n    //文件入库\r\n    currentProxy.addMediaFilesToDb(companyId,fileMd5,uploadFileParamsDto,bucket_videoFiles,mergeFilePath);\r\n    //=====清除分块文件=====\r\n    clearChunkFiles(chunkFileFolderPath,chunkTotal);\r\n    return RestResponse.success(true);\r\n}\r\n\r\n/**\r\n * 从minio下载文件\r\n * @param bucket 桶\r\n * @param objectName 对象名称\r\n * @return 下载后的文件\r\n */\r\npublic File downloadFileFromMinIO(String bucket,String objectName){\r\n    //临时文件\r\n    File minioFile = null;\r\n    FileOutputStream outputStream = null;\r\n    try{\r\n        InputStream stream = minioClient.getObject(GetObjectArgs.builder()\r\n                .bucket(bucket)\r\n                .object(objectName)\r\n                .build());\r\n        //创建临时文件\r\n        minioFile=File.createTempFile(\"minio\", \".merge\");\r\n        outputStream = new FileOutputStream(minioFile);\r\n        IOUtils.copy(stream,outputStream);\r\n        return minioFile;\r\n    } catch (Exception e) {\r\n       e.printStackTrace();\r\n    }finally {\r\n        if(outputStream!=null){\r\n            try {\r\n                outputStream.close();\r\n            } catch (IOException e) {\r\n                e.printStackTrace();\r\n            }\r\n        }\r\n    }\r\n    return null;\r\n}\r\n/**\r\n * 得到合并后的文件的地址\r\n * @param fileMd5 文件id即md5值\r\n * @param fileExt 文件扩展名\r\n * @return\r\n */\r\nprivate String getFilePathByMd5(String fileMd5,String fileExt){\r\n    return   fileMd5.substring(0,1) + \"/\" + fileMd5.substring(1,2) + \"/\" + fileMd5 + \"/\" +fileMd5 +fileExt;\r\n}\r\n\r\n/**\r\n * 清除分块文件\r\n * @param chunkFileFolderPath 分块文件路径\r\n * @param chunkTotal 分块文件总数\r\n */\r\nprivate void clearChunkFiles(String chunkFileFolderPath,int chunkTotal){\r\n\r\n    try {\r\n        List<DeleteObject> deleteObjects = Stream.iterate(0, i -> ++i)\r\n                .limit(chunkTotal)\r\n                .map(i -> new DeleteObject(chunkFileFolderPath.concat(Integer.toString(i))))\r\n                .collect(Collectors.toList());\r\n\r\n        RemoveObjectsArgs removeObjectsArgs = RemoveObjectsArgs.builder().bucket(\"video\").objects(deleteObjects).build();\r\n        Iterable<Result<DeleteError>> results = minioClient.removeObjects(removeObjectsArgs);\r\n        results.forEach(r->{\r\n            DeleteError deleteError = null;\r\n            try {\r\n                deleteError = r.get();\r\n            } catch (Exception e) {\r\n                e.printStackTrace();\r\n                log.error(\"清楚分块文件失败,objectname:{}\",deleteError.objectName(),e);\r\n            }\r\n        });\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n        log.error(\"清楚分块文件失败,chunkFileFolderPath:{}\",chunkFileFolderPath,e);\r\n    }\r\n}\r\n```\r\n\r\n \r\n\r\n \r\n\r\n#### **3.5.2 接口层完善**\r\n\r\n下边完善接口层\r\n\r\n```java\r\n@ApiOperation(value = \"合并文件\")\r\n@PostMapping(\"/upload/mergechunks\")\r\npublic RestResponse mergechunks(@RequestParam(\"fileMd5\") String fileMd5,\r\n                                @RequestParam(\"fileName\") String fileName,\r\n                                @RequestParam(\"chunkTotal\") int chunkTotal) throws Exception {\r\n    Long companyId = 1232141425L;\r\n\r\n    UploadFileParamsDto uploadFileParamsDto = new UploadFileParamsDto();\r\n    uploadFileParamsDto.setFileType(\"001002\");\r\n    uploadFileParamsDto.setTags(\"课程视频\");\r\n    uploadFileParamsDto.setRemark(\"\");\r\n    uploadFileParamsDto.setFilename(fileName);\r\n\r\n    return mediaFileService.mergechunks(companyId,fileMd5,chunkTotal,uploadFileParamsDto);\r\n\r\n}\r\n```\r\n\r\n \r\n\r\n#### **3.5.3 合并分块测试**\r\n\r\n下边进行前后端联调：\r\n\r\n1、上传一个视频测试合并分块的执行逻辑\r\n\r\n进入service方法逐行跟踪。\r\n\r\n2、断点续传测试\r\n\r\n上传一部分后，停止刷新浏览器再重新上传，通过浏览器日志发现已经上传过的分块不再重新上传\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps90.jpg) \r\n\r\n \r\n\r\n## **四 绑定媒资**\r\n\r\n### **4.1 需求分析**\r\n\r\n#### **4.1.1 业务流程**\r\n\r\n到目前为止，媒资管理已完成文件上传、视频处理、我的媒资功能等基本功能，其它模块可以使用媒资文件，本节要讲解课程计划绑定媒资文件。\r\n\r\n如何将课程计划绑定媒资呢？\r\n\r\n首先进入课程计划界面，然后选择要绑定的视频进行绑定即可。\r\n\r\n具体的业务流程如下：\r\n\r\n1.教育机构用户进入课程管理页面并编辑某一个课程，在\"课程大纲\"标签页的某一小节后可点击”添加视频“。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps139.jpg) \r\n\r\n2.弹出添加视频对话框，可通过视频关键字搜索已审核通过的视频媒资。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps140.jpg) \r\n\r\n \r\n\r\n3.选择视频媒资，点击提交按钮，完成课程计划绑定媒资流程。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps141.jpg) \r\n\r\n \r\n\r\n课程计划关联视频后如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps142.jpg) \r\n\r\n点击已经绑定的视频名称即可解除绑定。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps143.jpg) \r\n\r\n#### **4.1.2 数据模型** \r\n\r\n课程计划绑定媒资文件后存储至课程计划绑定媒资表\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps144.jpg) \r\n\r\n### **4.2 接口定义**\r\n\r\n根据业务流程，用户进入课程计划列表，首先确定向哪个课程计划添加视频，点击”添加视频“后用户选择视频，选择视频，点击提交，前端以json格式请求以下参数：\r\n\r\n提交媒资文件id、文件名称、教学计划id\r\n\r\n示例如下：\r\n\r\n```json\r\n{\r\n  \"mediaId\": \"70a98b4a2fffc89e50b101f959cc33ca\",\r\n  \"fileName\": \"22-Hmily实现TCC事务-开发bank2的confirm方法.avi\",\r\n  \"teachplanId\": 257\r\n}\r\n```\r\n\r\n此接口在内容管理模块提供。\r\n\r\n在内容管理模块定义请求参数模型类型：\r\n\r\n```java\r\n@Data\r\n@ApiModel(value=\"BindTeachplanMediaDto\", description=\"教学计划-媒资绑定提交数据\")\r\npublic class BindTeachplanMediaDto {\r\n\r\n@ApiModelProperty(value = \"媒资文件id\", required = true)\r\nprivate String mediaId;\r\n\r\n@ApiModelProperty(value = \"媒资文件名称\", required = true)\r\nprivate String fileName;\r\n\r\n @ApiModelProperty(value = \"课程计划标识\", required = true)\r\n private Long teachplanId;\r\n\r\n\r\n}\r\n```\r\n\r\n \r\n\r\n在TeachplanController类中定义接口如下：\r\n\r\n```java\r\n@ApiOperation(value = \"课程计划和媒资信息绑定\")\r\n@PostMapping(\"/teachplan/association/media\")\r\npublic void associationMedia(@RequestBody BindTeachplanMediaDto bindTeachplanMediaDto){\r\n\r\n}\r\n\r\n```\r\n\r\n\r\n\r\n### **4.3 接口开发**\r\n\r\n#### **4.3.1 DAO开发**\r\n\r\n对teachplanMedia表自动生成Mapper。\r\n\r\n \r\n\r\n#### **4.3.2 Service开发**\r\n\r\n根据需求定义service接口\r\n\r\n```java\r\n/**\r\n * @description 教学计划绑定媒资\r\n * @param bindTeachplanMediaDto\r\n * @return com.xuecheng.content.model.po.TeachplanMedia\r\n * @author Mr.M\r\n * @date 2022/9/14 22:20\r\n*/\r\npublic TeachplanMedia associationMedia(BindTeachplanMediaDto bindTeachplanMediaDto);\r\n\r\n```\r\n\r\n定义接口实现\r\n\r\n```java\r\n @Transactional\r\n @Override\r\npublic TeachplanMedia associationMedia(BindTeachplanMediaDto bindTeachplanMediaDto) {\r\n //教学计划id\r\n Long teachplanId = bindTeachplanMediaDto.getTeachplanId();\r\n Teachplan teachplan = teachplanMapper.selectById(teachplanId);\r\n if(teachplan==null){\r\n  XueChengPlusException.cast(\"教学计划不存在\");\r\n }\r\n Integer grade = teachplan.getGrade();\r\n if(grade!=2){\r\n  XueChengPlusException.cast(\"只允许第二级教学计划绑定媒资文件\");\r\n }\r\n //课程id\r\n Long courseId = teachplan.getCourseId();\r\n\r\n //先删除原来该教学计划绑定的媒资\r\n teachplanMediaMapper.delete(new LambdaQueryWrapper<TeachplanMedia>().eq(TeachplanMedia::getTeachplanId,teachplanId));\r\n\r\n //再添加教学计划与媒资的绑定关系\r\n TeachplanMedia teachplanMedia = new TeachplanMedia();\r\n teachplanMedia.setCourseId(courseId);\r\n teachplanMedia.setTeachplanId(teachplanId);\r\n teachplanMedia.setMediaFilename(bindTeachplanMediaDto.getFileName());\r\n teachplanMedia.setMediaId(bindTeachplanMediaDto.getMediaId());\r\n teachplanMedia.setCreateDate(LocalDateTime.now());\r\n teachplanMediaMapper.insert(teachplanMedia);\r\n return teachplanMedia;\r\n}\r\n\r\n\r\n```\r\n\r\n\r\n\r\n#### **4.3.3 接口层完善**\r\n\r\n完善接口层调用Service层的代码\r\n\r\n```java\r\n@ApiOperation(value = \"课程计划和媒资信息绑定\")\r\n@PostMapping(\"/teachplan/association/media\")\r\nvoid associationMedia(@RequestBody BindTeachplanMediaDto bindTeachplanMediaDto){\r\n    teachplanService.associationMedia(bindTeachplanMediaDto);\r\n}\r\n\r\n\r\n```\r\n\r\n\r\n\r\n#### **4.3.4 接口测试**\r\n\r\n1、使用httpclient测试\r\n\r\n```http\r\n### 课程计划绑定视频\r\nPOST {{media_host}}/media/teachplan/association/media\r\nContent-Type: application/json\r\n\r\n{\r\n  \"mediaId\": \"\",\r\n  \"fileName\": \"\",\r\n  \"teachplanId\": \"\"\r\n}\r\n```\r\n\r\n \r\n\r\n2、前后端联调\r\n\r\n此功能较为简单推荐直接前后端联调\r\n\r\n向指定课程计划添加视频\r\n\r\n \r\n\r\n### **4.4 实战**\r\n\r\n根据接口定义实现解除绑定功能。\r\n\r\n点击已经绑定的视频名称即可解除绑定。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps145.jpg) \r\n\r\n \r\n\r\n接口定义如下：\r\n\r\n`delete /teachplan/association/media/{teachPlanId}/{mediaId}  返回200状态码表示成功。` \r\n\r\n开发完成使用httpclient测试、前后端联调\r\n\r\n```http\r\n### 课程计划接触视频绑定\r\nDELETE {{media_host}}/media/teachplan/association/media/{teachPlanId}/{mediaId}\r\n```\r\n\r\n \r\n"},{"title":"MySQL - 简介与架构","tags":["SQL"],"categories":["MySQL","基础篇"],"author":"imklaus","excerpt":"\r\n## 简介\r\n\r\n### 数据库\r\n\r\n数据库：DataBase，简称 DB，存储和管理数据的仓库\r\n\r\n数据库的优势：\r\n\r\n- 可以持久化存储数据\r\n- 方便存储和管理数据\r\n- 使用了统一的方式操作数据库 SQL\r\n\r\n数据库、数据表、数据的关系介绍：\r\n\r\n- 数据库\r\n\r\n  - 用于存储和管理数据的仓库\r\n  - 一个库中可以包含多个数据表\r\n\r\n- 数据表\r\n\r\n  - 数据库最重要的组成部分之一\r\n  - 由纵向的列和横向的行组成（类似 excel 表格）\r\n  - 可以指定列名、数据类型、约束等\r\n  - 一个表中可以存储多条数据\r\n\r\n- 数据：想要永久化存储的数据\r\n\r\n\r\n\r\n\r\n参考视频：https://www.bilibili.com/video/BV1zJ411M7TB\r\n\r\n参考专栏：https://time.geekbang.org/column/intro/139\r\n\r\n参考书籍：https://book.douban.com/subject/35231266/\r\n\r\n","link":"/posts/MySQL_Basic","content":"\r\n## 简介\r\n\r\n### 数据库\r\n\r\n数据库：DataBase，简称 DB，存储和管理数据的仓库\r\n\r\n数据库的优势：\r\n\r\n- 可以持久化存储数据\r\n- 方便存储和管理数据\r\n- 使用了统一的方式操作数据库 SQL\r\n\r\n数据库、数据表、数据的关系介绍：\r\n\r\n- 数据库\r\n\r\n  - 用于存储和管理数据的仓库\r\n  - 一个库中可以包含多个数据表\r\n\r\n- 数据表\r\n\r\n  - 数据库最重要的组成部分之一\r\n  - 由纵向的列和横向的行组成（类似 excel 表格）\r\n  - 可以指定列名、数据类型、约束等\r\n  - 一个表中可以存储多条数据\r\n\r\n- 数据：想要永久化存储的数据\r\n\r\n\r\n\r\n\r\n参考视频：https://www.bilibili.com/video/BV1zJ411M7TB\r\n\r\n参考专栏：https://time.geekbang.org/column/intro/139\r\n\r\n参考书籍：https://book.douban.com/subject/35231266/\r\n\r\n<!-- more -->\r\n\r\n***\r\n\r\n\r\n\r\n### MySQL\r\n\r\nMySQL 数据库是一个最流行的关系型数据库管理系统之一，关系型数据库是将数据保存在不同的数据表中，而且表与表之间可以有关联关系，提高了灵活性\r\n\r\n缺点：数据存储在磁盘中，导致读写性能差，而且数据关系复杂，扩展性差\r\n\r\nMySQL 所使用的 SQL 语句是用于访问数据库最常用的标准化语言\r\n\r\nMySQL 配置：\r\n\r\n* MySQL 安装：https://www.jianshu.com/p/ba48f1e386f0\r\n\r\n* MySQL 配置：\r\n\r\n  * 修改 MySQL 默认字符集：安装 MySQL 之后第一件事就是修改字符集编码\r\n\r\n    ```bash\r\n    vim /etc/mysql/my.cnf\r\n    \r\n    添加如下内容：\r\n    [mysqld]\r\n    character-set-server=utf8\r\n    collation-server=utf8_general_ci\r\n    \r\n    [client]\r\n    default-character-set=utf8\r\n    ```\r\n\r\n  * 启动 MySQL 服务： \r\n\r\n    ```shell\r\n    systemctl start/restart mysql\r\n    ```\r\n\r\n  * 登录 MySQL：\r\n\r\n    ```shell\r\n    mysql -u root -p  敲回车，输入密码\r\n    初始密码查看：cat /var/log/mysqld.log\r\n    在root@localhost:   后面的就是初始密码\r\n    ```\r\n\r\n  * 查看默认字符集命令：\r\n\r\n    ```bash\r\n    SHOW VARIABLES LIKE 'char%';\r\n    ```\r\n\r\n  * 修改MySQL登录密码：\r\n\r\n    ```bash\r\n    set global validate_password_policy=0;\r\n    set global validate_password_length=1;\r\n      \r\n    set password=password('密码');\r\n    ```\r\n\r\n  * 授予远程连接权限（MySQL 内输入）：\r\n\r\n    ```bash\r\n    -- 授权\r\n    grant all privileges on *.* to 'root' @'%' identified by '密码';\r\n    -- 刷新\r\n    flush privileges;\r\n    ```\r\n\r\n* 修改 MySQL 绑定 IP：\r\n\r\n  ```shell\r\n  cd /etc/mysql/mysql.conf.d\r\n  sudo chmod 666 mysqld.cnf \r\n  vim mysqld.cnf \r\n  # bind-address = 127.0.0.1注释该行\r\n  ```\r\n\r\n* 关闭 Linux 防火墙\r\n\r\n  ```shell\r\n  systemctl stop firewalld.service\r\n  # 放行3306端口\r\n  ```\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n## 体系架构\r\n\r\n### 整体架构\r\n\r\n体系结构详解：\r\n\r\n* 第一层：网络连接层\r\n  * 一些客户端和链接服务，包含本地 Socket 通信和大多数基于客户端/服务端工具实现的 TCP/IP 通信，主要完成一些类似于连接处理、授权认证、及相关的安全方案\r\n  * 在该层上引入了**连接池** Connection Pool 的概念，管理缓冲用户连接，线程处理等需要缓存的需求\r\n  * 在该层上实现基于 SSL 的安全链接，服务器也会为安全接入的每个客户端验证它所具有的操作权限\r\n\r\n- 第二层：核心服务层\r\n  * 查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，所有的内置函数（日期、数学、加密函数等）\r\n    * Management Serveices & Utilities：系统管理和控制工具，备份、安全、复制、集群等\r\n    * SQL Interface：接受用户的 SQL 命令，并且返回用户需要查询的结果\r\n    * Parser：SQL 语句分析器\r\n    * Optimizer：查询优化器\r\n    * Caches & Buffers：查询缓存，服务器会查询内部的缓存，如果缓存空间足够大，可以在大量读操作的环境中提升系统性能\r\n  * 所有**跨存储引擎的功能**在这一层实现，如存储过程、触发器、视图等\r\n  * 在该层服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定表的查询顺序，是否利用索引等， 最后生成相应的执行操作\r\n  * MySQL 中服务器层不管理事务，**事务是由存储引擎实现的**\r\n- 第三层：存储引擎层\r\n  - Pluggable Storage Engines：存储引擎接口，MySQL 区别于其他数据库的重要特点就是其存储引擎的架构模式是插件式的（存储引擎是基于表的，而不是数据库）\r\n  - 存储引擎**真正的负责了 MySQL 中数据的存储和提取**，服务器通过 API 和存储引擎进行通信\r\n  - 不同的存储引擎具有不同的功能，共用一个 Server 层，可以根据开发的需要，来选取合适的存储引擎\r\n- 第四层：系统文件层\r\n  - 数据存储层，主要是将数据存储在文件系统之上，并完成与存储引擎的交互\r\n  - File System：文件系统，保存配置文件、数据文件、日志文件、错误文件、二进制文件等\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-体系结构.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 建立连接\r\n\r\n#### 连接器\r\n\r\n池化技术：对于访问数据库来说，建立连接的代价是比较昂贵的，因为每个连接对应一个用来交互的线程，频繁的创建关闭连接比较耗费资源，有必要建立数据库连接池，以提高访问的性能\r\n\r\n连接建立 TCP 以后需要做**权限验证**，验证成功后可以进行执行 SQL。如果这时管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限，只有再新建的连接才会使用新的权限设置\r\n\r\nMySQL 服务器可以同时和多个客户端进行交互，所以要保证每个连接会话的隔离性（事务机制部分详解）\r\n\r\n整体的执行流程：\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-SQL的执行流程.png\" style=\"zoom: 33%;\" />\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 权限信息\r\n\r\ngrant 语句会同时修改数据表和内存，判断权限的时候使用的是内存数据\r\n\r\nflush privileges 语句本身会用数据表（磁盘）的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下使用，这种不一致往往是由于直接用 DML 语句操作系统权限表导致的，所以尽量不要使用这类语句\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-权限范围.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 连接状态\r\n\r\n客户端如果长时间没有操作，连接器就会自动断开，时间是由参数 wait_timeout 控制的，默认值是 8 小时。如果在连接被断开之后，客户端**再次发送请求**的话，就会收到一个错误提醒：`Lost connection to MySQL server during query`\r\n\r\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接；短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个\r\n\r\n为了减少连接的创建，推荐使用长连接，但是**过多的长连接会造成 OOM**，解决方案：\r\n\r\n* 定期断开长连接，使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连\r\n\r\n  ```bash\r\n  KILL CONNECTION id\r\n  ```\r\n\r\n* MySQL 5.7 版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源，这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态\r\n\r\nSHOW PROCESSLIST：查看当前 MySQL 在进行的线程，可以实时地查看 SQL 的执行情况，其中的 Command 列显示为 Sleep 的这一行，就表示现在系统里面有一个空闲连接\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-SHOW_PROCESSLIST命令.png)\r\n\r\n| 参数    | 含义                                                         |\r\n| ------- | ------------------------------------------------------------ |\r\n| ID      | 用户登录 mysql 时系统分配的 connection_id，可以使用函数 connection_id() 查看 |\r\n| User    | 显示当前用户，如果不是 root，这个命令就只显示用户权限范围的 sql 语句 |\r\n| Host    | 显示这个语句是从哪个 ip 的哪个端口上发的，可以用来跟踪出现问题语句的用户 |\r\n| db      | 显示这个进程目前连接的是哪个数据库                           |\r\n| Command | 显示当前连接的执行的命令，一般取值为休眠 Sleep、查询 Query、连接 Connect 等 |\r\n| Time    | 显示这个状态持续的时间，单位是秒                             |\r\n| State   | 显示使用当前连接的 sql 语句的状态，以查询为例，需要经过 copying to tmp table、sorting result、sending data等状态才可以完成 |\r\n| Info    | 显示执行的 sql 语句，是判断问题语句的一个重要依据            |\r\n\r\n**Sending data 状态**表示 MySQL 线程开始访问数据行并把结果返回给客户端，而不仅仅只是返回给客户端，是处于执行器过程中的任意阶段。由于在 Sending data 状态下，MySQL 线程需要做大量磁盘读取操作，所以是整个查询中耗时最长的状态\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 执行流程\r\n\r\n#### 查询缓存\r\n\r\n##### 工作流程\r\n\r\n当执行完全相同的 SQL 语句的时候，服务器就会直接从缓存中读取结果，当数据被修改，之前的缓存会失效，修改比较频繁的表不适合做查询缓存\r\n\r\n查询过程：\r\n\r\n1. 客户端发送一条查询给服务器\r\n2. 服务器先会检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果（一般是 K-V 键值对），否则进入下一阶段\r\n3. 分析器进行 SQL 分析，再由优化器生成对应的执行计划\r\n4. 执行器根据优化器生成的执行计划，调用存储引擎的 API 来执行查询\r\n5. 将结果返回给客户端\r\n\r\n大多数情况下不建议使用查询缓存，因为查询缓存往往弊大于利\r\n\r\n* 查询缓存的**失效非常频繁**，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能费力地把结果存起来，还没使用就被一个更新全清空了，对于更新压力大的数据库来说，查询缓存的命中率会非常低\r\n* 除非业务就是有一张静态表，很长时间才会更新一次，比如一个系统配置表，那这张表上的查询才适合使用查询缓存\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 缓存配置\r\n\r\n1. 查看当前 MySQL 数据库是否支持查询缓存：\r\n\r\n   ```bash\r\n   SHOW VARIABLES LIKE 'have_query_cache';\t-- YES\r\n   ```\r\n\r\n2. 查看当前 MySQL 是否开启了查询缓存：\r\n\r\n   ```bash\r\n   SHOW VARIABLES LIKE 'query_cache_type';\t-- OFF\r\n   ```\r\n\r\n   参数说明：\r\n\r\n   * OFF 或 0：查询缓存功能关闭\r\n\r\n   * ON 或 1：查询缓存功能打开，查询结果符合缓存条件即会缓存，否则不予缓存；可以显式指定 SQL_NO_CACHE 不予缓存\r\n\r\n   * DEMAND 或 2：查询缓存功能按需进行，显式指定 SQL_CACHE 的 SELECT 语句才缓存，其它不予缓存\r\n\r\n     ```bash\r\n     SELECT SQL_CACHE id, name FROM customer; -- SQL_CACHE:查询结果可缓存\r\n     SELECT SQL_NO_CACHE id, name FROM customer;-- SQL_NO_CACHE:不使用查询缓存\r\n     ```\r\n\r\n3. 查看查询缓存的占用大小：\r\n\r\n   ```bash\r\n   SHOW VARIABLES LIKE 'query_cache_size';-- 单位是字节 1048576 / 1024 = 1024 = 1KB\r\n   ```\r\n\r\n4. 查看查询缓存的状态变量：\r\n\r\n   ```bash\r\n   SHOW STATUS LIKE 'Qcache%';\r\n   ```\r\n\r\n   <img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-查询缓存的状态变量.png\" style=\"zoom:67%;\" />\r\n\r\n   | 参数                    | 含义                                                         |\r\n   | ----------------------- | ------------------------------------------------------------ |\r\n   | Qcache_free_blocks      | 查询缓存中的可用内存块数                                     |\r\n   | Qcache_free_memory      | 查询缓存的可用内存量                                         |\r\n   | Qcache_hits             | 查询缓存命中数                                               |\r\n   | Qcache_inserts          | 添加到查询缓存的查询数                                       |\r\n   | Qcache_lowmen_prunes    | 由于内存不足而从查询缓存中删除的查询数                       |\r\n   | Qcache_not_cached       | 非缓存查询的数量（由于 query_cache_type 设置而无法缓存或未缓存） |\r\n   | Qcache_queries_in_cache | 查询缓存中注册的查询数                                       |\r\n   | Qcache_total_blocks     | 查询缓存中的块总数                                           |\r\n\r\n5. 配置 my.cnf：\r\n\r\n   ```sh\r\n   sudo chmod 666 /etc/mysql/my.cnf\r\n   vim my.cnf\r\n   # mysqld中配置缓存\r\n   query_cache_type=1\r\n   ```\r\n\r\n   重启服务既可生效，执行 SQL 语句进行验证 ，执行一条比较耗时的 SQL 语句，然后再多执行几次，查看后面几次的执行时间；获取通过查看查询缓存的缓存命中数，来判定是否走查询缓存\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 缓存失效\r\n\r\n查询缓存失效的情况：\r\n\r\n* SQL 语句不一致，要想命中查询缓存，查询的 SQL 语句必须一致，因为**缓存中 key 是查询的语句**，value 是查询结构\r\n\r\n  ```bash\r\n  select count(*) from tb_item;\r\n  Select count(*) from tb_item;\t-- 不走缓存，首字母不一致\r\n  ```\r\n\r\n* 当查询语句中有一些不确定查询时，则不会缓存，比如：now()、current_date()、curdate()、curtime()、rand()、uuid()、user()、database() \r\n\r\n  ```bash\r\n  SELECT * FROM tb_item WHERE updatetime < NOW() LIMIT 1;\r\n  SELECT USER();\r\n  SELECT DATABASE();\r\n  ```\r\n\r\n* 不使用任何表查询语句：\r\n\r\n  ```bash\r\n  SELECT 'A';\r\n  ```\r\n\r\n* 查询 mysql、information_schema、performance_schema 等系统表时，不走查询缓存：\r\n\r\n  ```bash\r\n  SELECT * FROM information_schema.engines;\r\n  ```\r\n\r\n* 在**跨存储引擎**的存储过程、触发器或存储函数的主体内执行的查询，缓存失效\r\n\r\n* 如果表更改，则使用该表的**所有高速缓存查询都将变为无效**并从高速缓存中删除，包括使用 MERGE 映射到已更改表的表的查询，比如：INSERT、UPDATE、DELETE、ALTER TABLE、DROP TABLE、DROP DATABASE \r\n\r\n  \r\n\r\n***\r\n\r\n\r\n\r\n#### 分析器\r\n\r\n没有命中查询缓存，就开始了 SQL 的真正执行，分析器会对 SQL 语句做解析\r\n\r\n```sql\r\nSELECT * FROM t WHERE id = 1;\r\n```\r\n\r\n解析器：处理语法和解析查询，生成一课对应的解析树\r\n\r\n* 先做**词法分析**，输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么代表什么。从输入的 select 这个关键字识别出来这是一个查询语句；把字符串 t 识别成 表名 t，把字符串 id 识别成列 id\r\n* 然后做**语法分析**，根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。如果语句不对，就会收到 `You have an error in your SQL syntax` 的错误提醒\r\n\r\n预处理器：进一步检查解析树的合法性，比如数据表和数据列是否存在、别名是否有歧义等\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 优化器\r\n\r\n##### 成本分析\r\n\r\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序\r\n\r\n* 根据搜索条件找出所有可能的使用的索引\r\n* 成本分析，执行成本由 I/O 成本和 CPU 成本组成，计算全表扫描和使用不同索引执行 SQL 的代价\r\n* 找到一个最优的执行方案，用最小的代价去执行语句\r\n\r\n在数据库里面，扫描行数是影响执行代价的因素之一，扫描的行数越少意味着访问磁盘的次数越少，消耗的 CPU 资源越少，优化器还会结合是否使用临时表、是否排序等因素进行综合判断\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 统计数据\r\n\r\nMySQL 中保存着两种统计数据：\r\n\r\n* innodb_table_stats 存储了表的统计数据，每一条记录对应着一个表的统计数据\r\n* innodb_index_stats 存储了索引的统计数据，每一条记录对应着一个索引的一个统计项的数据\r\n\r\nMySQL 在真正执行语句之前，并不能精确地知道满足条件的记录有多少条，只能根据统计信息来估算记录，统计信息就是索引的区分度，一个索引上不同的值的个数（比如性别只能是男女，就是 2 ），称之为基数（cardinality），**基数越大说明区分度越好**\r\n\r\n通过**采样统计**来获取基数，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数\r\n\r\n在 MySQL 中，有两种存储统计数据的方式，可以通过设置参数 `innodb_stats_persistent` 的值来选择：\r\n\r\n* ON：表示统计信息会持久化存储（默认），采样页数 N 默认为 20，可以通过 `innodb_stats_persistent_sample_pages` 指定，页数越多统计的数据越准确，但消耗的资源更大\r\n* OFF：表示统计信息只存储在内存，采样页数 N 默认为 8，也可以通过系统变量设置（不推荐，每次重新计算浪费资源）\r\n\r\n数据表是会持续更新的，两种统计信息的更新方式：\r\n\r\n* 设置 `innodb_stats_auto_recalc` 为 1，当发生变动的记录数量超过表大小的 10% 时，自动触发重新计算，不过是**异步进行**\r\n* 调用 `ANALYZE TABLE t` 手动更新统计信息，只对信息做**重新统计**（不是重建表），没有修改数据，这个过程中加了 MDL 读锁并且是同步进行，所以会暂时阻塞系统\r\n\r\n**EXPLAIN 执行计划在优化器阶段生成**，如果 explain 的结果预估的 rows 值跟实际情况差距比较大，可以执行 analyze 命令重新修正信息\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 错选索引\r\n\r\n采样统计本身是估算数据，或者 SQL 语句中的字段选择有问题时，可能导致 MySQL 没有选择正确的执行索引\r\n\r\n解决方法：\r\n\r\n* 采用 force index 强行选择一个索引\r\n\r\n  ```sql\r\n  SELECT * FROM user FORCE INDEX(name) WHERE NAME='seazean';\r\n  ```\r\n\r\n* 可以考虑修改 SQL 语句，引导 MySQL 使用期望的索引\r\n\r\n* 新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 执行器\r\n\r\n开始执行的时候，要先判断一下当前连接对表有没有**执行查询的权限**，如果没有就会返回没有权限的错误，在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。如果有权限，就打开表继续执行，执行器就会根据表的引擎定义，去使用这个引擎提供的接口\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 引擎层\r\n\r\nServer 层和存储引擎层的交互是**以记录为单位的**，存储引擎会将单条记录返回给 Server 层做进一步处理，并不是直接返回所有的记录\r\n\r\n工作流程：\r\n\r\n* 首先根据二级索引选择扫描范围，获取第一条符合二级索引条件的记录，进行回表查询，将聚簇索引的记录返回 Server 层，由 Server 判断记录是否符合要求\r\n* 然后在二级索引上继续扫描下一个符合条件的记录\r\n\r\n\r\n\r\n推荐阅读：https://mp.weixin.qq.com/s/YZ-LckObephrP1f15mzHpA\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 终止流程\r\n\r\n#### 终止语句\r\n\r\n终止线程中正在执行的语句：\r\n\r\n```bash\r\nKILL QUERY thread_id\r\n```\r\n\r\nKILL 不是马上终止的意思，而是告诉执行线程这条语句已经不需要继续执行，可以开始执行停止的逻辑（类似于打断）。因为对表做增删改查操作，会在表上加 MDL 读锁，如果线程被 KILL 时就直接终止，那这个 MDL 读锁就没机会被释放了\r\n\r\n命令 `KILL QUERYthread_id_A` 的执行流程：\r\n\r\n* 把 session A 的运行状态改成 THD::KILL_QUERY（将变量 killed 赋值为 THD::KILL_QUERY）\r\n* 给 session A 的执行线程发一个信号，让 session A 来处理这个 THD::KILL_QUERY 状态\r\n\r\n会话处于等待状态（锁阻塞），必须满足是一个可以被唤醒的等待，必须有机会去**判断线程的状态**，如果不满足就会造成 KILL 失败\r\n\r\n典型场景：innodb_thread_concurrency 为 2，代表并发线程上限数设置为 2\r\n\r\n* session A 执行事务，session B 执行事务，达到线程上限；此时 session C 执行事务会阻塞等待，session D 执行 kill query C 无效\r\n* C 的逻辑是每 10 毫秒判断是否可以进入 InnoDB 执行，如果不行就调用 nanosleep 函数进入 sleep 状态，没有去判断线程状态\r\n\r\n补充：执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接，然后发送一个 KILL QUERY 命令\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 终止连接\r\n\r\n断开线程的连接：\r\n\r\n```bash\r\nKILL CONNECTION id\r\n```\r\n\r\n断开连接后执行 SHOW PROCESSLIST 命令，如果这条语句的 Command 列显示 Killed，代表线程的状态是 KILL_CONNECTION，说明这个线程有语句正在执行，当前状态是停止语句执行中，终止逻辑耗时较长\r\n\r\n* 超大事务执行期间被 KILL，这时回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长\r\n* 大查询回滚，如果查询过程中生成了比较大的临时文件，删除临时文件可能需要等待 IO 资源，导致耗时较长\r\n* DDL 命令执行到最后阶段被 KILL，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久\r\n\r\n总结：KILL CONNECTION 本质上只是把客户端的 SQL 连接断开，后面的终止流程还是要走 KILL QUERY\r\n\r\n一个事务被 KILL 之后，持续处于回滚状态，不应该强行重启整个 MySQL 进程，应该等待事务自己执行完成，因为重启后依然继续做回滚操作的逻辑\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 常用工具\r\n\r\n#### mysql\r\n\r\nmysql 不是指 mysql 服务，而是指 mysql 的客户端工具\r\n\r\n```sh\r\nmysql [options] [database]\r\n```\r\n\r\n* -u  --user=name：指定用户名\r\n* -p  --password[=name]：指定密码\r\n* -h  --host=name：指定服务器IP或域名\r\n* -P  --port=#：指定连接端口\r\n* -e  --execute=name：执行SQL语句并退出，在控制台执行SQL语句，而不用连接到数据库执行\r\n\r\n示例：\r\n\r\n```sh\r\nmysql -h 127.0.0.1 -P 3306 -u root -p\r\nmysql -uroot -p2143 db01 -e \"select * from tb_book\";\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### admin\r\n\r\nmysqladmin 是一个执行管理操作的客户端程序，用来检查服务器的配置和当前状态、创建并删除数据库等\r\n\r\n通过 `mysqladmin --help` 指令查看帮助文档\r\n\r\n```sh\r\nmysqladmin -uroot -p2143 create 'test01';\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### binlog\r\n\r\n服务器生成的日志文件以二进制格式保存，如果需要检查这些文本，就要使用 mysqlbinlog 日志管理工具\r\n\r\n```sh\r\nmysqlbinlog [options]  log-files1 log-files2 ...\r\n```\r\n\r\n* -d  --database=name：指定数据库名称，只列出指定的数据库相关操作\r\n\r\n* -o  --offset=#：忽略掉日志中的前 n 行命令。\r\n\r\n* -r  --result-file=name：将输出的文本格式日志输出到指定文件。\r\n\r\n* -s  --short-form：显示简单格式，省略掉一些信息。\r\n\r\n* --start-datatime=date1  --stop-datetime=date2：指定日期间隔内的所有日志\r\n\r\n* --start-position=pos1 --stop-position=pos2：指定位置间隔内的所有日志\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### dump\r\n\r\n##### 命令介绍\r\n\r\nmysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移，备份内容包含创建表，及插入表的 SQL 语句\r\n\r\n```sh\r\nmysqldump [options] db_name [tables]\r\nmysqldump [options] --database/-B db1 [db2 db3...]\r\nmysqldump [options] --all-databases/-A\r\n```\r\n\r\n连接选项：\r\n\r\n* -u  --user=name：指定用户名\r\n* -p  --password[=name]：指定密码\r\n* -h  --host=name：指定服务器 IP 或域名\r\n* -P  --port=#：指定连接端口\r\n\r\n输出内容选项：\r\n\r\n* --add-drop-database：在每个数据库创建语句前加上 Drop database 语句\r\n* --add-drop-table：在每个表创建语句前加上 Drop table 语句 , 默认开启，不开启 (--skip-add-drop-table)\r\n* -n  --no-create-db：不包含数据库的创建语句\r\n* -t  --no-create-info：不包含数据表的创建语句\r\n* -d --no-data：不包含数据\r\n* -T, --tab=name：自动生成两个文件：一个 .sql 文件，创建表结构的语句；一个 .txt 文件，数据文件，相当于 select into outfile  \r\n\r\n示例：\r\n\r\n```sh\r\nmysqldump -uroot -p2143 db01 tb_book --add-drop-database --add-drop-table > a\r\nmysqldump -uroot -p2143 -T /tmp test city\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 数据备份\r\n\r\n命令行方式：\r\n\r\n* 备份命令：mysqldump -u root -p 数据库名称 > 文件保存路径\r\n* 恢复\r\n  1. 登录MySQL数据库：`mysql -u root p`\r\n  2. 删除已经备份的数据库\r\n  3. 重新创建与备份数据库名称相同的数据库\r\n  4. 使用该数据库\r\n  5. 导入文件执行：`source 备份文件全路径`\r\n\r\n更多方式参考：https://time.geekbang.org/column/article/81925\r\n\r\n图形化界面：\r\n\r\n* 备份\r\n\r\n  ![图形化界面备份](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/图形化界面备份.png)\r\n\r\n* 恢复\r\n\r\n  ![图形化界面恢复](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/图形化界面恢复.png)\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### import\r\n\r\nmysqlimport 是客户端数据导入工具，用来导入mysqldump 加 -T 参数后导出的文本文件\r\n\r\n```sh\r\nmysqlimport [options]  db_name  textfile1  [textfile2...]\r\n```\r\n\r\n示例：\r\n\r\n```sh\r\nmysqlimport -uroot -p2143 test /tmp/city.txt\r\n```\r\n\r\n导入 sql 文件，可以使用 MySQL 中的 source 指令 : \r\n\r\n```bash\r\nsource 文件全路径\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### show\r\n\r\nmysqlshow 客户端对象查找工具，用来很快地查找存在哪些数据库、数据库中的表、表中的列或者索引\r\n\r\n```sh\r\nmysqlshow [options] [db_name [table_name [col_name]]]\r\n```\r\n\r\n* --count：显示数据库及表的统计信息（数据库，表 均可以不指定）\r\n\r\n* -i：显示指定数据库或者指定表的状态信息\r\n\r\n示例：\r\n\r\n```sh\r\n#查询每个数据库的表的数量及表中记录的数量\r\nmysqlshow -uroot -p1234 --count\r\n#查询test库中每个表中的字段书，及行数\r\nmysqlshow -uroot -p1234 test --count\r\n#查询test库中book表的详细情况\r\nmysqlshow -uroot -p1234 test book --count\r\n```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n## 高级结构\r\n\r\n### 视图\r\n\r\n#### 基本介绍\r\n\r\n视图概念：视图是一种虚拟存在的数据表，这个虚拟的表并不在数据库中实际存在\r\n\r\n本质：将一条 SELECT 查询语句的结果封装到了一个虚拟表中，所以在创建视图的时候，工作重心要放在这条 SELECT 查询语句上\r\n\r\n作用：将一些比较复杂的查询语句的结果，封装到一个虚拟表中，再有相同查询需求时，直接查询该虚拟表\r\n\r\n优点：\r\n\r\n* 简单：使用视图的用户不需要关心表的结构、关联条件和筛选条件，因为虚拟表中已经是过滤好的结果集\r\n* 安全：使用视图的用户只能访问查询的结果集，对表的权限管理并不能限制到某个行某个列\r\n\r\n* 数据独立，一旦视图的结构确定，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 视图创建\r\n\r\n* 创建视图\r\n\r\n  ```bash\r\n  CREATE [OR REPLACE] \r\n  VIEW 视图名称 [(列名列表)] \r\n  AS 查询语句\r\n  [WITH [CASCADED | LOCAL] CHECK OPTION];\r\n  ```\r\n\r\n  `WITH [CASCADED | LOCAL] CHECK OPTION` 决定了是否允许更新数据使记录不再满足视图的条件：\r\n\r\n  * LOCAL：只要满足本视图的条件就可以更新\r\n  * CASCADED：必须满足所有针对该视图的所有视图的条件才可以更新， 默认值\r\n\r\n* 例如\r\n\r\n  ```bash\r\n  -- 数据准备 city\r\n  id\tNAME\tcid\r\n  1\t深圳\t \t1\r\n  2\t上海\t\t1\r\n  3\t纽约\t\t2\r\n  4\t莫斯科\t    3\r\n  \r\n  -- 数据准备 country\r\n  id\tNAME\r\n  1\t中国\r\n  2\t美国\r\n  3\t俄罗斯\r\n  \r\n  -- 创建city_country视图，保存城市和国家的信息(使用指定列名)\r\n  CREATE \r\n  VIEW \r\n  \tcity_country (city_id,city_name,country_name)\r\n  AS\r\n      SELECT\r\n          c1.id,\r\n          c1.name,\r\n          c2.name\r\n      FROM\r\n          city c1,\r\n          country c2\r\n      WHERE\r\n          c1.cid=c2.id;\r\n  ```\r\n\r\n  \r\n\r\n***\r\n\r\n\r\n\r\n#### 视图查询\r\n\r\n* 查询所有数据表，视图也会查询出来\r\n\r\n  ```bash\r\n  SHOW TABLES;\r\n  SHOW TABLE STATUS [\\G];\r\n  ```\r\n\r\n* 查询视图\r\n\r\n  ```bash\r\n  SELECT * FROM 视图名称;\r\n  ```\r\n\r\n* 查询某个视图创建\r\n\r\n  ```bash\r\n  SHOW CREATE VIEW 视图名称;\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 视图修改\r\n\r\n视图表数据修改，会**自动修改源表中的数据**，因为更新的是视图中的基表中的数据\r\n\r\n* 修改视图表中的数据\r\n\r\n  ```bash\r\n  UPDATE 视图名称 SET 列名 = 值 WHERE 条件;\r\n  ```\r\n\r\n* 修改视图的结构\r\n\r\n  ```bash\r\n  ALTER [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]\r\n  VIEW 视图名称 [(列名列表)] \r\n  AS 查询语句\r\n  [WITH [CASCADED | LOCAL] CHECK OPTION]\r\n  \r\n  -- 将视图中的country_name修改为name\r\n  ALTER \r\n  VIEW \r\n  \tcity_country (city_id,city_name,name) \r\n  AS\r\n      SELECT\r\n          c1.id,\r\n          c1.name,\r\n          c2.name\r\n      FROM\r\n          city c1,\r\n          country c2\r\n      WHERE\r\n          c1.cid=c2.id;\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 视图删除\r\n\r\n* 删除视图\r\n\r\n  ```bash\r\n  DROP VIEW 视图名称;\r\n  ```\r\n\r\n* 如果存在则删除\r\n\r\n  ```bash\r\n  DROP VIEW IF EXISTS 视图名称;\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 存储过程\r\n\r\n#### 基本介绍\r\n\r\n存储过程和函数：存储过程和函数是事先经过编译并存储在数据库中的一段 SQL 语句的集合\r\n\r\n存储过程和函数的好处：\r\n\r\n* 提高代码的复用性\r\n* 减少数据在数据库和应用服务器之间的传输，提高传输效率\r\n* 减少代码层面的业务处理\r\n* **一次编译永久有效**\r\n\r\n存储过程和函数的区别：\r\n\r\n* 存储函数必须有返回值\r\n* 存储过程可以没有返回值\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 基本操作\r\n\r\nDELIMITER：\r\n\r\n* DELIMITER 关键字用来声明 sql 语句的分隔符，告诉 MySQL 该段命令已经结束\r\n\r\n* MySQL 语句默认的分隔符是分号，但是有时需要一条功能 sql 语句中包含分号，但是并不作为结束标识，这时使用 DELIMITER 来指定分隔符：\r\n\r\n  ```bash\r\n  DELIMITER 分隔符\r\n  ```\r\n\r\n存储过程的创建调用查看和删除：\r\n\r\n* 创建存储过程\r\n\r\n  ```bash\r\n  -- 修改分隔符为$\r\n  DELIMITER $\r\n  \r\n  -- 标准语法\r\n  CREATE PROCEDURE 存储过程名称(参数...)\r\n  BEGIN\r\n  \tsql语句;\r\n  END$\r\n  \r\n  -- 修改分隔符为分号\r\n  DELIMITER ;\r\n  ```\r\n\r\n* 调用存储过程\r\n\r\n  ```bash\r\n  CALL 存储过程名称(实际参数);\r\n  ```\r\n\r\n* 查看存储过程\r\n\r\n  ```bash\r\n  SELECT * FROM mysql.proc WHERE db='数据库名称';\r\n  ```\r\n\r\n* 删除存储过程\r\n\r\n  ```bash\r\n  DROP PROCEDURE [IF EXISTS] 存储过程名称;\r\n  ```\r\n\r\n练习：\r\n\r\n* 数据准备\r\n\r\n  ```bash\r\n  id\tNAME\tage\t\tgender\tscore\r\n  1\t张三\t\t23\t\t男\t\t95\r\n  2\t李四\t\t24\t\t男\t\t98\r\n  3\t王五\t\t25\t\t女\t\t100\r\n  4\t赵六\t\t26\t\t女\t\t90\r\n  ```\r\n\r\n* 创建 stu_group() 存储过程，封装分组查询总成绩，并按照总成绩升序排序的功能\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  \r\n  CREATE PROCEDURE stu_group()\r\n  BEGIN\r\n  \tSELECT gender,SUM(score) getSum FROM student GROUP BY gender ORDER BY getSum ASC; \r\n  END$\r\n  \r\n  DELIMITER ;\r\n  \r\n  -- 调用存储过程\r\n  CALL stu_group();\r\n  -- 删除存储过程\r\n  DROP PROCEDURE IF EXISTS stu_group;\r\n  ```\r\n\r\n  \r\n\r\n***\r\n\r\n\r\n\r\n#### 存储语法\r\n\r\n##### 变量使用\r\n\r\n存储过程是可以进行编程的，意味着可以使用变量、表达式、条件控制语句等，来完成比较复杂的功能\r\n\r\n* 定义变量：DECLARE 定义的是局部变量，只能用在 BEGIN END 范围之内\r\n\r\n  ```bash\r\n  DECLARE 变量名 数据类型 [DEFAULT 默认值];\r\n  ```\r\n\r\n* 变量的赋值\r\n\r\n  ```bash\r\n  SET 变量名 = 变量值;\r\n  SELECT 列名 INTO 变量名 FROM 表名 [WHERE 条件];\r\n  ```\r\n\r\n* 数据准备：表 student\r\n\r\n  ```bash\r\n  id\tNAME\tage\t\tgender\tscore\r\n  1\t张三\t\t23\t\t男\t\t95\r\n  2\t李四\t\t24\t\t男\t\t98\r\n  3\t王五\t\t25\t\t女\t\t100\r\n  4\t赵六\t\t26\t\t女\t\t90\r\n  ```\r\n\r\n* 定义两个 int 变量，用于存储男女同学的总分数\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  CREATE PROCEDURE pro_test3()\r\n  BEGIN\r\n  \t-- 定义两个变量\r\n  \tDECLARE men,women INT;\r\n  \t-- 查询男同学的总分数，为men赋值\r\n  \tSELECT SUM(score) INTO men FROM student WHERE gender='男';\r\n  \t-- 查询女同学的总分数，为women赋值\r\n  \tSELECT SUM(score) INTO women FROM student WHERE gender='女';\r\n  \t-- 使用变量\r\n  \tSELECT men,women;\r\n  END$\r\n  DELIMITER ;\r\n  -- 调用存储过程\r\n  CALL pro_test3();\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### IF语句\r\n\r\n* if 语句标准语法\r\n\r\n  ```bash\r\n  IF 判断条件1 THEN 执行的sql语句1;\r\n  [ELSEIF 判断条件2 THEN 执行的sql语句2;]\r\n  ...\r\n  [ELSE 执行的sql语句n;]\r\n  END IF;\r\n  ```\r\n\r\n* 数据准备：表 student\r\n\r\n  ```bash\r\n  id\tNAME\tage\t\tgender\tscore\r\n  1\t张三\t\t23\t\t男\t\t95\r\n  2\t李四\t\t24\t\t男\t\t98\r\n  3\t王五\t\t25\t\t女\t\t100\r\n  4\t赵六\t\t26\t\t女\t\t90\r\n  ```\r\n\r\n* 根据总成绩判断：全班 380 分及以上学习优秀、320 ~ 380 学习良好、320 以下学习一般\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  CREATE PROCEDURE pro_test4()\r\n  BEGIN\r\n  \tDECLARE total INT;\t\t\t\t\t\t\t-- 定义总分数变量\r\n  \tDECLARE description VARCHAR(10);\t\t\t-- 定义分数描述变量\r\n  \tSELECT SUM(score) INTO total FROM student; \t-- 为总分数变量赋值\r\n  \t-- 判断总分数\r\n  \tIF total >= 380 THEN\r\n  \t\tSET description = '学习优秀';\r\n  \tELSEIF total >=320 AND total < 380 THEN\r\n  \t\tSET description = '学习良好';\r\n  \tELSE\r\n  \t\tSET description = '学习一般';\r\n  \tEND IF;\r\n  END$\r\n  DELIMITER ;\r\n  -- 调用pro_test4存储过程\r\n  CALL pro_test4();\r\n  ```\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 参数传递\r\n\r\n* 参数传递的语法\r\n\r\n  IN：代表输入参数，需要由调用者传递实际数据，默认的\r\n  OUT：代表输出参数，该参数可以作为返回值\r\n  INOUT：代表既可以作为输入参数，也可以作为输出参数\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  \r\n  -- 标准语法\r\n  CREATE PROCEDURE 存储过程名称([IN|OUT|INOUT] 参数名 数据类型)\r\n  BEGIN\r\n  \t执行的sql语句;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  ```\r\n\r\n* 输入总成绩变量，代表学生总成绩，输出分数描述变量，代表学生总成绩的描述\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  \r\n  CREATE PROCEDURE pro_test6(IN total INT, OUT description VARCHAR(10))\r\n  BEGIN\r\n  \t-- 判断总分数\r\n  \tIF total >= 380 THEN \r\n  \t\tSET description = '学习优秀';\r\n  \tELSEIF total >= 320 AND total < 380 THEN \r\n  \t\tSET description = '学习不错';\r\n  \tELSE \r\n  \t\tSET description = '学习一般';\r\n  \tEND IF;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  -- 调用pro_test6存储过程\r\n  CALL pro_test6(310,@description);\r\n  CALL pro_test6((SELECT SUM(score) FROM student), @description);\r\n  -- 查询总成绩描述\r\n  SELECT @description;\r\n  ```\r\n\r\n* 查看参数方法\r\n\r\n  * @变量名 : **用户会话变量**，代表整个会话过程他都是有作用的，类似于全局变量\r\n  * @@变量名 : **系统变量** \r\n\r\n \r\n\r\n***\r\n\r\n\r\n\r\n##### CASE\r\n\r\n* 标准语法 1\r\n\r\n  ```bash\r\n  CASE 表达式\r\n      WHEN 值1 THEN 执行sql语句1;\r\n      [WHEN 值2 THEN 执行sql语句2;]\r\n      ...\r\n      [ELSE 执行sql语句n;]\r\n  END CASE;\r\n  ```\r\n\r\n* 标准语法 2\r\n\r\n  ```bash\r\n  sCASE\r\n      WHEN 判断条件1 THEN 执行sql语句1;\r\n      [WHEN 判断条件2 THEN 执行sql语句2;]\r\n      ...\r\n      [ELSE 执行sql语句n;]\r\n  END CASE;\r\n  ```\r\n\r\n* 演示\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  CREATE PROCEDURE pro_test7(IN total INT)\r\n  BEGIN\r\n  \t-- 定义变量\r\n  \tDECLARE description VARCHAR(10);\r\n  \t-- 使用case判断\r\n  \tCASE\r\n  \tWHEN total >= 380 THEN\r\n  \t\tSET description = '学习优秀';\r\n  \tWHEN total >= 320 AND total < 380 THEN\r\n  \t\tSET description = '学习不错';\r\n  \tELSE \r\n  \t\tSET description = '学习一般';\r\n  \tEND CASE;\r\n  \t\r\n  \t-- 查询分数描述信息\r\n  \tSELECT description;\r\n  END$\r\n  DELIMITER ;\r\n  -- 调用pro_test7存储过程\r\n  CALL pro_test7(390);\r\n  CALL pro_test7((SELECT SUM(score) FROM student));\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### WHILE\r\n\r\n* while 循环语法\r\n\r\n  ```bash\r\n  WHILE 条件判断语句 DO\r\n  \t循环体语句;\r\n  \t条件控制语句;\r\n  END WHILE;\r\n  ```\r\n\r\n* 计算 1~100 之间的偶数和\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  CREATE PROCEDURE pro_test6()\r\n  BEGIN\r\n  \t-- 定义求和变量\r\n  \tDECLARE result INT DEFAULT 0;\r\n  \t-- 定义初始化变量\r\n  \tDECLARE num INT DEFAULT 1;\r\n  \t-- while循环\r\n  \tWHILE num <= 100 DO\r\n  \t\tIF num % 2 = 0 THEN\r\n  \t\t\tSET result = result + num;\r\n  \t\tEND IF;\r\n  \t\tSET num = num + 1;\r\n  \tEND WHILE;\r\n  \t-- 查询求和结果\r\n  \tSELECT result;\r\n  END$\r\n  DELIMITER ;\r\n  \r\n  -- 调用pro_test6存储过程\r\n  CALL pro_test6();\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### REPEAT\r\n\r\n* repeat 循环标准语法\r\n\r\n  ```bash\r\n  初始化语句;\r\n  REPEAT\r\n  \t循环体语句;\r\n  \t条件控制语句;\r\n  \tUNTIL 条件判断语句\r\n  END REPEAT;\r\n  ```\r\n\r\n* 计算 1~10 之间的和\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  CREATE PROCEDURE pro_test9()\r\n  BEGIN\r\n  \t-- 定义求和变量\r\n  \tDECLARE result INT DEFAULT 0;\r\n  \t-- 定义初始化变量\r\n  \tDECLARE num INT DEFAULT 1;\r\n  \t-- repeat循环\r\n  \tREPEAT\r\n  \t\t-- 累加\r\n  \t\tSET result = result + num;\r\n  \t\t-- 让num+1\r\n  \t\tSET num = num + 1;\r\n  \t\t-- 停止循环\r\n  \t\tUNTIL num > 10\r\n  \tEND REPEAT;\r\n  \t-- 查询求和结果\r\n  \tSELECT result;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  -- 调用pro_test9存储过程\r\n  CALL pro_test9();\r\n  ```\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### LOOP\r\n\r\nLOOP 实现简单的循环，退出循环的条件需要使用其他的语句定义，通常可以使用 LEAVE 语句实现，如果不加退出循环的语句，那么就变成了死循环\r\n\r\n* loop 循环标准语法\r\n\r\n  ```bash\r\n  [循环名称:] LOOP\r\n  \t条件判断语句\r\n  \t\t[LEAVE 循环名称;]\r\n  \t循环体语句;\r\n  \t条件控制语句;\r\n  END LOOP 循环名称;\r\n  ```\r\n\r\n* 计算 1~10 之间的和\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  CREATE PROCEDURE pro_test10()\r\n  BEGIN\r\n  \t-- 定义求和变量\r\n  \tDECLARE result INT DEFAULT 0;\r\n  \t-- 定义初始化变量\r\n  \tDECLARE num INT DEFAULT 1;\r\n  \t-- loop循环\r\n  \tl:LOOP\r\n  \t\t-- 条件成立，停止循环\r\n  \t\tIF num > 10 THEN\r\n  \t\t\tLEAVE l;\r\n  \t\tEND IF;\r\n  \t\t-- 累加\r\n  \t\tSET result = result + num;\r\n  \t\t-- 让num+1\r\n  \t\tSET num = num + 1;\r\n  \tEND LOOP l;\r\n  \t-- 查询求和结果\r\n  \tSELECT result;\r\n  END$\r\n  DELIMITER ;\r\n  -- 调用pro_test10存储过程\r\n  CALL pro_test10();\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 游标\r\n\r\n游标是用来存储查询结果集的数据类型，在存储过程和函数中可以使用光标对结果集进行循环的处理\r\n\r\n* 游标可以遍历返回的多行结果，每次拿到一整行数据\r\n* 简单来说游标就类似于集合的迭代器遍历\r\n* MySQL 中的游标只能用在存储过程和函数中\r\n\r\n游标的语法\r\n\r\n* 创建游标\r\n\r\n  ```bash\r\n  DECLARE 游标名称 CURSOR FOR 查询sql语句;\r\n  ```\r\n\r\n* 打开游标\r\n\r\n  ```bash\r\n  OPEN 游标名称;\r\n  ```\r\n\r\n* 使用游标获取数据\r\n\r\n  ```bash\r\n  FETCH 游标名称 INTO 变量名1,变量名2,...;\r\n  ```\r\n\r\n* 关闭游标\r\n\r\n  ```bash\r\n  CLOSE 游标名称;\r\n  ```\r\n\r\n* Mysql 通过一个 Error handler 声明来判断指针是否到尾部，并且必须和创建游标的 SQL 语句声明在一起：\r\n\r\n  ```bash\r\n  DECLARE EXIT HANDLER FOR NOT FOUND (do some action，一般是设置标志变量)\r\n  ```\r\n\r\n  \r\n\r\n游标的基本使用\r\n\r\n* 数据准备：表 student\r\n\r\n  ```bash\r\n  id\tNAME\tage\t\tgender\tscore\r\n  1\t张三\t\t23\t\t男\t\t95\r\n  2\t李四\t\t24\t\t男\t\t98\r\n  3\t王五\t\t25\t\t女\t\t100\r\n  4\t赵六\t\t26\t\t女\t\t90\r\n  ```\r\n\r\n* 创建 stu_score 表\r\n\r\n  ```bash\r\n  CREATE TABLE stu_score(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,\r\n  \tscore INT\r\n  );\r\n  ```\r\n\r\n* 将student表中所有的成绩保存到stu_score表中\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  \r\n  CREATE PROCEDURE pro_test12()\r\n  BEGIN\r\n  \t-- 定义成绩变量\r\n  \tDECLARE s_score INT;\r\n  \t-- 定义标记变量\r\n  \tDECLARE flag INT DEFAULT 0;\r\n  \t\r\n  \t-- 创建游标，查询所有学生成绩数据\r\n  \tDECLARE stu_result CURSOR FOR SELECT score FROM student;\r\n  \t-- 游标结束后，将标记变量改为1  这两个必须声明在一起\r\n  \tDECLARE EXIT HANDLER FOR NOT FOUND SET flag = 1;\r\n  \t\r\n  \t-- 开启游标\r\n  \tOPEN stu_result;\r\n  \t-- 循环使用游标\r\n  \tREPEAT\r\n  \t\t-- 使用游标，遍历结果,拿到数据\r\n  \t\tFETCH stu_result INTO s_score;\r\n  \t\t-- 将数据保存到stu_score表中\r\n  \t\tINSERT INTO stu_score VALUES (NULL,s_score);\r\n  \tUNTIL flag=1\r\n  \tEND REPEAT;\r\n  \t-- 关闭游标\r\n  \tCLOSE stu_result;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  \r\n  -- 调用pro_test12存储过程\r\n  CALL pro_test12();\r\n  -- 查询stu_score表\r\n  SELECT * FROM stu_score;\r\n  ```\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 存储函数\r\n\r\n存储函数和存储过程是非常相似的，存储函数可以做的事情，存储过程也可以做到\r\n\r\n存储函数有返回值，存储过程没有返回值（参数的 out 其实也相当于是返回数据了）\r\n\r\n* 创建存储函数\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  -- 标准语法\r\n  CREATE FUNCTION 函数名称(参数 数据类型)\r\n  RETURNS 返回值类型\r\n  BEGIN\r\n  \t执行的sql语句;\r\n  \tRETURN 结果;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  ```\r\n\r\n* 调用存储函数，因为有返回值，所以使用 SELECT 调用\r\n\r\n  ```bash\r\n  SELECT 函数名称(实际参数);\r\n  ```\r\n\r\n* 删除存储函数\r\n\r\n  ```bash\r\n  DROP FUNCTION 函数名称;\r\n  ```\r\n\r\n* 定义存储函数，获取学生表中成绩大于95分的学生数量\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  CREATE FUNCTION fun_test()\r\n  RETURN INT\r\n  BEGIN\r\n  \t-- 定义统计变量\r\n  \tDECLARE result INT;\r\n  \t-- 查询成绩大于95分的学生数量，给统计变量赋值\r\n  \tSELECT COUNT(score) INTO result FROM student WHERE score > 95;\r\n  \t-- 返回统计结果\r\n  \tSELECT result;\r\n  END\r\n  DELIMITER ;\r\n  -- 调用fun_test存储函数\r\n  SELECT fun_test();\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 触发器\r\n\r\n#### 基本介绍\r\n\r\n触发器是与表有关的数据库对象，在 insert/update/delete 之前或之后触发并执行触发器中定义的 SQL 语句\r\n\r\n* 触发器的这种特性可以协助应用在数据库端确保数据的完整性 、日志记录 、数据校验等操作\r\n\r\n- 使用别名 NEW 和 OLD 来引用触发器中发生变化的记录内容，这与其他的数据库是相似的\r\n- 现在触发器还只支持行级触发，不支持语句级触发\r\n\r\n| 触发器类型      | OLD的含义                      | NEW的含义                      |\r\n| --------------- | ------------------------------ | ------------------------------ |\r\n| INSERT 型触发器 | 无 (因为插入前状态无数据)      | NEW 表示将要或者已经新增的数据 |\r\n| UPDATE 型触发器 | OLD 表示修改之前的数据         | NEW 表示将要或已经修改后的数据 |\r\n| DELETE 型触发器 | OLD 表示将要或者已经删除的数据 | 无 (因为删除后状态无数据)      |\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 基本操作\r\n\r\n* 创建触发器\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  \r\n  CREATE TRIGGER 触发器名称\r\n  BEFORE|AFTER  INSERT|UPDATE|DELETE\r\n  ON 表名\r\n  [FOR EACH ROW]  -- 行级触发器\r\n  BEGIN\r\n  \t触发器要执行的功能;\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  ```\r\n\r\n* 查看触发器的状态、语法等信息\r\n\r\n  ```bash\r\n  SHOW TRIGGERS;\r\n  ```\r\n\r\n* 删除触发器，如果没有指定 schema_name，默认为当前数据库\r\n\r\n  ```bash\r\n  DROP TRIGGER [schema_name.]trigger_name;\r\n  ```\r\n\r\n  \r\n\r\n***\r\n\r\n\r\n\r\n#### 触发演示\r\n\r\n通过触发器记录账户表的数据变更日志。包含：增加、修改、删除\r\n\r\n* 数据准备\r\n\r\n  ```bash\r\n  -- 创建db9数据库\r\n  CREATE DATABASE db9;\r\n  -- 使用db9数据库\r\n  USE db9;\r\n  ```\r\n\r\n  ```bash\r\n  -- 创建账户表account\r\n  CREATE TABLE account(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 账户id\r\n  \tNAME VARCHAR(20),\t\t\t\t\t-- 姓名\r\n  \tmoney DOUBLE\t\t\t\t\t\t-- 余额\r\n  );\r\n  -- 添加数据\r\n  INSERT INTO account VALUES (NULL,'张三',1000),(NULL,'李四',2000);\r\n  ```\r\n\r\n  ```bash\r\n  -- 创建日志表account_log\r\n  CREATE TABLE account_log(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 日志id\r\n  \toperation VARCHAR(20),\t\t\t\t-- 操作类型 (insert update delete)\r\n  \toperation_time DATETIME,\t\t\t-- 操作时间\r\n  \toperation_id INT,\t\t\t\t\t-- 操作表的id\r\n  \toperation_params VARCHAR(200)       -- 操作参数\r\n  );\r\n  ```\r\n\r\n* 创建 INSERT 型触发器\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  \r\n  CREATE TRIGGER account_insert\r\n  AFTER INSERT\r\n  ON account\r\n  FOR EACH ROW\r\n  BEGIN\r\n  \tINSERT INTO account_log VALUES (NULL,'INSERT',NOW(),new.id,CONCAT('插入后{id=',new.id,',name=',new.name,',money=',new.money,'}'));\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  ```\r\n\r\n  ```bash\r\n  -- 向account表添加记录\r\n  INSERT INTO account VALUES (NULL,'王五',3000);\r\n  \r\n  -- 查询日志表\r\n  SELECT * FROM account_log;\r\n  /*\r\n  id\toperation\toperation_time\t\toperation_id\toperation_params\r\n  1\tINSERT\t   \t2021-01-26 19:51:11\t\t3\t     插入后{id=3,name=王五money=2000}\r\n  */\r\n  ```\r\n\r\n  \r\n\r\n* 创建 UPDATE 型触发器\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  \r\n  CREATE TRIGGER account_update\r\n  AFTER UPDATE\r\n  ON account\r\n  FOR EACH ROW\r\n  BEGIN\r\n  \tINSERT INTO account_log VALUES (NULL,'UPDATE',NOW(),new.id,CONCAT('修改前{id=',old.id,',name=',old.name,',money=',old.money,'}','修改后{id=',new.id,',name=',new.name,',money=',new.money,'}'));\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  ```\r\n\r\n  ```bash\r\n  -- 修改account表\r\n  UPDATE account SET money=3500 WHERE id=3;\r\n  \r\n  -- 查询日志表\r\n  SELECT * FROM account_log;\r\n  /*\r\n  id\toperation\toperation_time\t\toperation_id\t  operation_params\r\n  2\tUPDATE\t   \t2021-01-26 19:58:54\t\t2\t\t 更新前{id=2,name=李四money=1000}\r\n  \t\t\t\t\t\t\t\t\t\t\t\t 更新后{id=2,name=李四money=200}\r\n  */\r\n  ```\r\n\r\n  \r\n\r\n* 创建 DELETE 型触发器\r\n\r\n  ```bash\r\n  DELIMITER $\r\n  \r\n  CREATE TRIGGER account_delete\r\n  AFTER DELETE\r\n  ON account\r\n  FOR EACH ROW\r\n  BEGIN\r\n  \tINSERT INTO account_log VALUES (NULL,'DELETE',NOW(),old.id,CONCAT('删除前{id=',old.id,',name=',old.name,',money=',old.money,'}'));\r\n  END$\r\n  \r\n  DELIMITER ;\r\n  ```\r\n\r\n  ```bash\r\n  -- 删除account表数据\r\n  DELETE FROM account WHERE id=3;\r\n  \r\n  -- 查询日志表\r\n  SELECT * FROM account_log;\r\n  /*\r\n  id\toperation\toperation_time\t\toperation_id\toperation_params\r\n  3\tDELETE\t\t2021-01-26 20:02:48\t\t3\t    删除前{id=3,name=王五money=2000}\r\n  */\r\n  ```\r\n\r\n\r\n\r\n****\r\n\r\n## 范式\r\n\r\n### 第一范式\r\n\r\n建立科学的，**规范的数据表**就需要满足一些规则来优化数据的设计和存储，这些规则就称为范式\r\n\r\n**1NF：**数据库表的每一列都是不可分割的原子数据项，不能是集合、数组等非原子数据项。即表中的某个列有多个值时，必须拆分为不同的列。简而言之，**第一范式每一列不可再拆分，称为原子性**\r\n\r\n基本表：\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/普通表.png)\r\n\t\t\t\t\t\r\n\r\n第一范式表：\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/第一范式.png)\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 第二范式\r\n\r\n**2NF：**在满足第一范式的基础上，非主属性完全依赖于主码（主关键字、主键），消除非主属性对主码的部分函数依赖。简而言之，**表中的每一个字段 （所有列）都完全依赖于主键，记录的唯一性**\r\n\r\n作用：遵守第二范式减少数据冗余，通过主键区分相同数据。\r\n\r\n1. 函数依赖：A → B，如果通过 A 属性(属性组)的值，可以确定唯一 B 属性的值，则称 B 依赖于 A\r\n   * 学号 → 姓名；(学号，课程名称) → 分数\r\n2. 完全函数依赖：A → B，如果A是一个属性组，则 B 属性值的确定需要依赖于 A 属性组的所有属性值\r\n   * (学号，课程名称) → 分数\r\n3. 部分函数依赖：A → B，如果 A 是一个属性组，则 B 属性值的确定只需要依赖于 A 属性组的某些属性值\r\n   * (学号，课程名称) → 姓名\r\n4. 传递函数依赖：A → B，B → C，如果通过A属性(属性组)的值，可以确定唯一 B 属性的值，在通过 B 属性(属性组)的值，可以确定唯一 C 属性的值，则称 C 传递函数依赖于 A\r\n   * 学号 → 系名，系名 → 系主任\r\n5. 码：如果在一张表中，一个属性或属性组，被其他所有属性所完全依赖，则称这个属性(属性组)为该表的码\r\n   * 该表中的码：(学号，课程名称)\r\n   * 主属性：码属性组中的所有属性\r\n   * 非主属性：除码属性组以外的属性\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/第二范式.png)\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 第三范式\r\n\r\n**3NF：**在满足第二范式的基础上，表中的任何属性不依赖于其它非主属性，消除传递依赖。简而言之，**非主键都直接依赖于主键，而不是通过其它的键来间接依赖于主键**。\r\n\r\n作用：可以通过主键 id 区分相同数据，修改数据的时候只需要修改一张表（方便修改），反之需要修改多表。\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/第三范式.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 总结\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/三大范式.png)\r\n\r\n\r\n\r\n\r\n\r\n------\r\n\r\n"},{"title":"MySQL - 存储引擎与索引","tags":["SQL"],"categories":["MySQL","索引篇"],"author":"imklaus","excerpt":"\r\n## 存储引擎\r\n\r\n### 基本介绍\r\n\r\n对比其他数据库，MySQL 的架构可以在不同场景应用并发挥良好作用，主要体现在存储引擎，插件式的存储引擎架构将查询处理和其他的系统任务以及数据的存储提取分离，可以针对不同的存储需求可以选择最优的存储引擎\r\n\r\n存储引擎的介绍：\r\n\r\n- MySQL 数据库使用不同的机制存取表文件 , 机制的差别在于不同的存储方式、索引技巧、锁定水平等不同的功能和能力，在 MySQL 中，将这些不同的技术及配套的功能称为存储引擎\r\n- Oracle、SqlServer 等数据库只有一种存储引擎，MySQL **提供了插件式的存储引擎架构**，所以 MySQL 存在多种存储引擎 , 就会让数据库采取了不同的处理数据的方式和扩展功能\r\n- 在关系型数据库中数据的存储是以表的形式存进行，所以存储引擎也称为表类型（存储和操作此表的类型）\r\n- 通过选择不同的引擎，能够获取最佳的方案,  也能够获得额外的速度或者功能，提高程序的整体效果。\r\n\r\nMySQL 支持的存储引擎：\r\n\r\n- MySQL 支持的引擎包括：InnoDB、MyISAM、MEMORY、Archive、Federate、CSV、BLACKHOLE 等\r\n- MySQL5.5 之前的默认存储引擎是 MyISAM，5.5 之后就改为了 InnoDB\r\n\r\n","link":"/posts/MySQL_Index","content":"\r\n## 存储引擎\r\n\r\n### 基本介绍\r\n\r\n对比其他数据库，MySQL 的架构可以在不同场景应用并发挥良好作用，主要体现在存储引擎，插件式的存储引擎架构将查询处理和其他的系统任务以及数据的存储提取分离，可以针对不同的存储需求可以选择最优的存储引擎\r\n\r\n存储引擎的介绍：\r\n\r\n- MySQL 数据库使用不同的机制存取表文件 , 机制的差别在于不同的存储方式、索引技巧、锁定水平等不同的功能和能力，在 MySQL 中，将这些不同的技术及配套的功能称为存储引擎\r\n- Oracle、SqlServer 等数据库只有一种存储引擎，MySQL **提供了插件式的存储引擎架构**，所以 MySQL 存在多种存储引擎 , 就会让数据库采取了不同的处理数据的方式和扩展功能\r\n- 在关系型数据库中数据的存储是以表的形式存进行，所以存储引擎也称为表类型（存储和操作此表的类型）\r\n- 通过选择不同的引擎，能够获取最佳的方案,  也能够获得额外的速度或者功能，提高程序的整体效果。\r\n\r\nMySQL 支持的存储引擎：\r\n\r\n- MySQL 支持的引擎包括：InnoDB、MyISAM、MEMORY、Archive、Federate、CSV、BLACKHOLE 等\r\n- MySQL5.5 之前的默认存储引擎是 MyISAM，5.5 之后就改为了 InnoDB\r\n\r\n<!-- more -->\r\n\r\n****\r\n\r\n\r\n\r\n### 引擎对比\r\n\r\nMyISAM 存储引擎：\r\n\r\n* 特点：不支持事务和外键，读取速度快，节约资源\r\n* 应用场景：**适用于读多写少的场景**，对事务的完整性要求不高，比如一些数仓、离线数据、支付宝的年度总结之类的场景，业务进行只读操作，查询起来会更快\r\n* 存储方式：\r\n  * 每个 MyISAM 在磁盘上存储成 3 个文件，其文件名都和表名相同，拓展名不同\r\n  * 表的定义保存在 .frm 文件，表数据保存在 .MYD (MYData) 文件中，索引保存在 .MYI (MYIndex) 文件中\r\n\r\nInnoDB 存储引擎：(MySQL5.5 版本后默认的存储引擎)\r\n\r\n- 特点：**支持事务**和外键操作，支持并发控制。对比 MyISAM 的存储引擎，InnoDB 写的处理效率差一些，并且会占用更多的磁盘空间以保留数据和索引\r\n- 应用场景：对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，读写频繁的操作\r\n- 存储方式：\r\n  - 使用共享表空间存储， 这种方式创建的表的表结构保存在 .frm 文件中， 数据和索引保存在 innodb_data_home_dir 和 innodb_data_file_path 定义的表空间中，可以是多个文件\r\n  - 使用多表空间存储，创建的表的表结构存在 .frm 文件中，每个表的数据和索引单独保存在 .ibd 中\r\n\r\nMEMORY 存储引擎：\r\n\r\n- 特点：每个 MEMORY 表实际对应一个磁盘文件 ，该文件中只存储表的结构，表数据保存在内存中，且默认**使用 HASH 索引**，所以数据默认就是无序的，但是在需要快速定位记录可以提供更快的访问，**服务一旦关闭，表中的数据就会丢失**，存储不安全\r\n- 应用场景：**缓存型存储引擎**，通常用于更新不太频繁的小表，用以快速得到访问结果\r\n- 存储方式：表结构保存在 .frm 中\r\n\r\nMERGE 存储引擎：\r\n\r\n* 特点：\r\n\r\n  * 是一组 MyISAM 表的组合，这些 MyISAM 表必须结构完全相同，通过将不同的表分布在多个磁盘上\r\n  * MERGE 表本身并没有存储数据，对 MERGE 类型的表可以进行查询、更新、删除操作，这些操作实际上是对内部的 MyISAM 表进行的\r\n\r\n* 应用场景：将一系列等同的 MyISAM 表以逻辑方式组合在一起，并作为一个对象引用他们，适合做数据仓库\r\n\r\n* 操作方式：\r\n\r\n  * 插入操作是通过 INSERT_METHOD 子句定义插入的表，使用 FIRST 或 LAST 值使得插入操作被相应地作用在第一或者最后一个表上；不定义这个子句或者定义为 NO，表示不能对 MERGE 表执行插入操作\r\n  * 对 MERGE 表进行 DROP 操作，但是这个操作只是删除 MERGE 表的定义，对内部的表是没有任何影响的\r\n\r\n  ```bash\r\n  CREATE TABLE order_1(\r\n  )ENGINE = MyISAM DEFAULT CHARSET=utf8;\r\n  \r\n  CREATE TABLE order_2(\r\n  )ENGINE = MyISAM DEFAULT CHARSET=utf8;\r\n  \r\n  CREATE TABLE order_all(\r\n  \t-- 结构与MyISAM表相同\r\n  )ENGINE = MERGE UNION = (order_1,order_2) INSERT_METHOD=LAST DEFAULT CHARSET=utf8;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MERGE.png)\r\n\r\n| 特性         | MyISAM                         | InnoDB        | MEMORY               |\r\n| ------------ | ------------------------------ | ------------- | -------------------- |\r\n| 存储限制     | 有（平台对文件系统大小的限制） | 64TB          | 有（平台的内存限制） |\r\n| **事务安全** | **不支持**                     | **支持**      | **不支持**           |\r\n| **锁机制**   | **表锁**                       | **表锁/行锁** | **表锁**             |\r\n| B+Tree 索引  | 支持                           | 支持          | 支持                 |\r\n| 哈希索引     | 不支持                         | 不支持        | 支持                 |\r\n| 全文索引     | 支持                           | 支持          | 不支持               |\r\n| 集群索引     | 不支持                         | 支持          | 不支持               |\r\n| 数据索引     | 不支持                         | 支持          | 支持                 |\r\n| 数据缓存     | 不支持                         | 支持          | N/A                  |\r\n| 索引缓存     | 支持                           | 支持          | N/A                  |\r\n| 数据可压缩   | 支持                           | 不支持        | 不支持               |\r\n| 空间使用     | 低                             | 高            | N/A                  |\r\n| 内存使用     | 低                             | 高            | 中等                 |\r\n| 批量插入速度 | 高                             | 低            | 高                   |\r\n| **外键**     | **不支持**                     | **支持**      | **不支持**           |\r\n\r\n只读场景 MyISAM 比 InnoDB 更快：\r\n\r\n* 底层存储结构有差别，MyISAM 是非聚簇索引，叶子节点保存的是数据的具体地址，不用回表查询\r\n* InnoDB 每次查询需要维护 MVCC 版本状态，保证并发状态下的读写冲突问题\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 引擎操作\r\n\r\n* 查询数据库支持的存储引擎\r\n\r\n  ```bash\r\n  SHOW ENGINES;\r\n  SHOW VARIABLES LIKE '%storage_engine%'; -- 查看Mysql数据库默认的存储引擎 \r\n  ```\r\n\r\n* 查询某个数据库中所有数据表的存储引擎\r\n\r\n  ```bash\r\n  SHOW TABLE STATUS FROM 数据库名称;\r\n  ```\r\n\r\n* 查询某个数据库中某个数据表的存储引擎\r\n\r\n  ```bash\r\n  SHOW TABLE STATUS FROM 数据库名称 WHERE NAME = '数据表名称';\r\n  ```\r\n\r\n* 创建数据表，指定存储引擎\r\n\r\n  ```bash\r\n  CREATE TABLE 表名(\r\n  \t列名,数据类型,\r\n      ...\r\n  )ENGINE = 引擎名称;\r\n  ```\r\n\r\n* 修改数据表的存储引擎\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 ENGINE = 引擎名称;\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n## 索引机制\r\n\r\n### 索引介绍\r\n\r\n#### 基本介绍\r\n\r\nMySQL 官方对索引的定义为：索引（index）是帮助 MySQL 高效获取数据的一种数据结构，**本质是排好序的快速查找数据结构。**在表数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式指向数据， 这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引\r\n\r\n**索引是在存储引擎层实现的**，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样\r\n\r\n索引使用：一张数据表，用于保存数据；一个索引配置文件，用于保存索引；每个索引都指向了某一个数据\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-索引的介绍.png)\r\n\r\n左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快 Col2 的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据的物理地址的指针，这样就可以运用二叉查找快速获取到相应数据\r\n\r\n索引的优点：\r\n\r\n* 类似于书籍的目录索引，提高数据检索的效率，降低数据库的 IO 成本\r\n* 通过索引列对数据进行排序，降低数据排序的成本，降低 CPU 的消耗\r\n\r\n索引的缺点：\r\n\r\n* 一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式**存储在磁盘**上\r\n* 虽然索引大大提高了查询效率，同时却也降低更新表的速度。对表进行 INSERT、UPDATE、DELETE 操作，MySQL 不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段，还会调整因为更新所带来的键值变化后的索引信息，**但是更新数据也需要先从数据库中获取**，索引加快了获取速度，所以可以相互抵消一下。\r\n* 索引会影响到 WHERE 的查询条件和排序 ORDER BY 两大功能\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 索引分类\r\n\r\n索引一般的分类如下：\r\n\r\n- 功能分类 \r\n\r\n  - 主键索引：一种特殊的唯一索引，不允许有空值，一般在建表时同时创建主键索引\r\n  - 单列索引：一个索引只包含单个列，一个表可以有多个单列索引（普通索引）\r\n  - 联合索引：顾名思义，就是将单列索引进行组合\r\n  - 唯一索引：索引列的值必须唯一，**允许有空值**，如果是联合索引，则列值组合必须唯一\r\n    * NULL 值可以出现多次，因为两个 NULL 比较的结果既不相等，也不不等，结果仍然是未知\r\n    * 可以声明不允许存储 NULL 值的非空唯一索引\r\n  - 外键索引：只有 InnoDB 引擎支持外键索引，用来保证数据的一致性、完整性和实现级联操作\r\n\r\n- 结构分类\r\n\r\n  - BTree 索引：MySQL 使用最频繁的一个索引数据结构，是 InnoDB 和 MyISAM 存储引擎默认的索引类型，底层基于 B+Tree\r\n  - Hash 索引：MySQL中 Memory 存储引擎默认支持的索引类型\r\n  - R-tree 索引（空间索引）：空间索引是 MyISAM 引擎的一个特殊索引类型，主要用于地理空间数据类型\r\n  - Full-text 索引（全文索引）：快速匹配全部文档的方式。MyISAM 支持， InnoDB 不支持 FULLTEXT 类型的索引，但是 InnoDB 可以使用 sphinx 插件支持全文索引，MEMORY 引擎不支持\r\n\r\n  | 索引      | InnoDB           | MyISAM | Memory |\r\n  | --------- | ---------------- | ------ | ------ |\r\n  | BTREE     | 支持             | 支持   | 支持   |\r\n  | HASH      | 不支持           | 不支持 | 支持   |\r\n  | R-tree    | 不支持           | 支持   | 不支持 |\r\n  | Full-text | 5.6 版本之后支持 | 支持   | 不支持 |\r\n\r\n联合索引图示：根据身高年龄建立的组合索引（height、age）\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-组合索引图.png)\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 索引操作\r\n\r\n索引在创建表的时候可以同时创建， 也可以随时增加新的索引\r\n\r\n* 创建索引：如果一个表中有一列是主键，那么会**默认为其创建主键索引**（主键列不需要单独创建索引）\r\n\r\n  ```bash\r\n  CREATE [UNIQUE|FULLTEXT] INDEX 索引名称 [USING 索引类型] ON 表名(列名...);\r\n  -- 索引类型默认是 B+TREE\r\n  ```\r\n\r\n* 查看索引\r\n\r\n  ```bash\r\n  SHOW INDEX FROM 表名;\r\n  ```\r\n\r\n* 添加索引\r\n\r\n  ```bash\r\n  -- 单列索引\r\n  ALTER TABLE 表名 ADD INDEX 索引名称(列名);\r\n  \r\n  -- 组合索引\r\n  ALTER TABLE 表名 ADD INDEX 索引名称(列名1,列名2,...);\r\n  \r\n  -- 主键索引\r\n  ALTER TABLE 表名 ADD PRIMARY KEY(主键列名); \r\n  \r\n  -- 外键索引(添加外键约束，就是外键索引)\r\n  ALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主键列名);\r\n  \r\n  -- 唯一索引\r\n  ALTER TABLE 表名 ADD UNIQUE 索引名称(列名);\r\n  \r\n  -- 全文索引(mysql只支持文本类型)\r\n  ALTER TABLE 表名 ADD FULLTEXT 索引名称(列名);\r\n  ```\r\n\r\n* 删除索引\r\n\r\n  ```bash\r\n  DROP INDEX 索引名称 ON 表名;\r\n  ```\r\n\r\n* 案例练习\r\n\r\n  数据准备：student\r\n\r\n  ```bash\r\n  id\tNAME\t age\tscore\r\n  1\t张三\t\t23\t\t99\r\n  2\t李四\t\t24\t\t95\r\n  3\t王五\t\t25\t\t98\r\n  4\t赵六\t\t26\t\t97\r\n  ```\r\n\r\n  索引操作：\r\n\r\n  ```bash\r\n  -- 为student表中姓名列创建一个普通索引\r\n  CREATE INDEX idx_name ON student(NAME);\r\n  \r\n  -- 为student表中年龄列创建一个唯一索引\r\n  CREATE UNIQUE INDEX idx_age ON student(age);\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 聚簇索引\r\n\r\n#### 索引对比\r\n\r\n聚簇索引是一种数据存储方式，并不是一种单独的索引类型\r\n\r\n* 聚簇索引的叶子节点存放的是主键值和数据行，支持覆盖索引\r\n\r\n* 非聚簇索引的叶子节点存放的是主键值或指向数据行的指针（由存储引擎决定）\r\n\r\n在 Innodb 下主键索引是聚簇索引，在 MyISAM 下主键索引是非聚簇索引\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### Innodb\r\n\r\n##### 聚簇索引\r\n\r\n在 Innodb 存储引擎，B+ 树索引可以分为聚簇索引（也称聚集索引、clustered index）和辅助索引（也称非聚簇索引或二级索引、secondary index、non-clustered index）\r\n\r\nInnoDB 中，聚簇索引是按照每张表的主键构造一颗 B+ 树，叶子节点中存放的就是整张表的数据，将聚簇索引的叶子节点称为数据页\r\n\r\n* 这个特性决定了**数据也是索引的一部分**，所以一张表只能有一个聚簇索引\r\n* 辅助索引的存在不影响聚簇索引中数据的组织，所以一张表可以有多个辅助索引\r\n\r\n聚簇索引的优点：\r\n\r\n* 数据访问更快，聚簇索引将索引和数据保存在同一个 B+ 树中，因此从聚簇索引中获取数据比非聚簇索引更快\r\n* 聚簇索引对于主键的排序查找和范围查找速度非常快\r\n\r\n聚簇索引的缺点：\r\n\r\n* 插入速度严重依赖于插入顺序，按照主键的顺序（递增）插入是最快的方式，否则将会出现页分裂，严重影响性能，所以对于 InnoDB 表，一般都会定义一个自增的 ID 列为主键\r\n\r\n* 更新主键的代价很高，将会导致被更新的行移动，所以对于 InnoDB 表，一般定义主键为不可更新\r\n\r\n* 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 辅助索引\r\n\r\n在聚簇索引之上创建的索引称之为辅助索引，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引等\r\n\r\n辅助索引叶子节点存储的是主键值，而不是数据的物理地址，所以访问数据需要二次查找，推荐使用覆盖索引，可以减少回表查询\r\n\r\n**检索过程**：辅助索引找到主键值，再通过聚簇索引（二分）找到数据页，最后通过数据页中的 Page Directory（二分）找到对应的数据分组，遍历组内所所有的数据找到数据行\r\n\r\n补充：无索引走全表查询，查到数据页后和上述步骤一致\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 索引实现\r\n\r\nInnoDB 使用 B+Tree 作为索引结构，并且 InnoDB 一定有索引\r\n\r\n主键索引：\r\n\r\n* 在 InnoDB 中，表数据文件本身就是按 B+Tree 组织的一个索引结构，这个索引的 key 是数据表的主键，叶子节点 data 域保存了完整的数据记录\r\n\r\n* InnoDB 的表数据文件**通过主键聚集数据**，如果没有定义主键，会选择非空唯一索引代替，如果也没有这样的列，MySQL 会自动为 InnoDB 表生成一个**隐含字段 row_id** 作为主键，这个字段长度为 6 个字节，类型为长整形\r\n\r\n辅助索引：\r\n\r\n* InnoDB 的所有辅助索引（二级索引）都引用主键作为 data 域\r\n\r\n* InnoDB 表是基于聚簇索引建立的，因此 InnoDB 的索引能提供一种非常快速的主键查找性能。不过辅助索引也会包含主键列，所以不建议使用过长的字段作为主键，**过长的主索引会令辅助索引变得过大**\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB聚簇和辅助索引结构.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### MyISAM\r\n\r\n##### 非聚簇\r\n\r\nMyISAM 的主键索引使用的是非聚簇索引，索引文件和数据文件是分离的，**索引文件仅保存数据的地址**\r\n\r\n* 主键索引 B+ 树的节点存储了主键，辅助键索引 B+ 树存储了辅助键，表数据存储在独立的地方，这两颗 B+ 树的叶子节点都使用一个地址指向真正的表数据，对于表数据来说，这两个键没有任何差别\r\n* 由于索引树是独立的，通过辅助索引检索**无需回表查询**访问主键的索引树\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-聚簇索引和辅助索引检锁数据图.jpg)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 索引实现\r\n\r\nMyISAM 的索引方式也叫做非聚集的，之所以这么称呼是为了与 InnoDB 的聚集索引区分\r\n\r\n主键索引：MyISAM 引擎使用 B+Tree 作为索引结构，叶节点的 data 域存放的是数据记录的地址\r\n\r\n辅助索引：MyISAM 中主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求 key 是唯一的，而辅助索引的 key 可以重复\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MyISAM主键和辅助索引结构.png)\r\n\r\n\r\n\r\n\r\n\r\n参考文章：https://blog.csdn.net/lm1060891265/article/details/81482136\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 索引结构\r\n\r\n#### 数据页\r\n\r\n文件系统的最小单元是块（block），一个块的大小是 4K，系统从磁盘读取数据到内存时是以磁盘块为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么\r\n\r\nInnoDB 存储引擎中有页（Page）的概念，页是 MySQL 磁盘管理的最小单位\r\n\r\n* **InnoDB 存储引擎中默认每个页的大小为 16KB，索引中一个节点就是一个数据页**，所以会一次性读取 16KB 的数据到内存\r\n* InnoDB 引擎将若干个地址连接磁盘块，以此来达到页的大小 16KB\r\n* 在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘 I/O 次数，提高查询效率\r\n\r\n超过 16KB 的一条记录，主键索引页只会存储部分数据和指向**溢出页**的指针，剩余数据都会分散存储在溢出页中\r\n\r\n数据页物理结构，从上到下：\r\n\r\n* File Header：上一页和下一页的指针、该页的类型（索引页、数据页、日志页等）、**校验和**、LSN（最近一次修改当前页面时的系统 lsn 值，事务持久性部分详解）等信息\r\n* Page Header：记录状态信息\r\n* Infimum + Supremum：当前页的最小记录和最大记录（头尾指针），Infimum 所在分组只有一条记录，Supremum 所在分组可以有 1 ~ 8 条记录，剩余的分组可以有 4 ~ 8 条记录\r\n* User Records：存储数据的记录\r\n* Free Space：尚未使用的存储空间\r\n* Page Directory：分组的目录，可以通过目录快速定位（二分法）数据的分组\r\n* File Trailer：检验和字段，在刷脏过程中，页首和页尾的校验和一致才能说明页面刷新成功，二者不同说明刷新期间发生了错误；LSN 字段，也是用来校验页面的完整性\r\n\r\n数据页中包含数据行，数据的存储是基于数据行的，数据行有 next_record 属性指向下一个行数据，所以是可以遍历的，但是一组数据至多 8 个行，通过 Page Directory 先定位到组，然后遍历获取所需的数据行即可\r\n\r\n数据行中有三个隐藏字段：trx_id、roll_pointer、row_id（在事务章节会详细介绍它们的作用）\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### BTree\r\n\r\nBTree 的索引类型是基于 B+Tree 树型数据结构的，B+Tree 又是 BTree 数据结构的变种，用在数据库和操作系统中的文件系统，特点是能够保持数据稳定有序\r\n\r\nBTree 又叫多路平衡搜索树，一颗 m 叉的 BTree 特性如下：\r\n\r\n- 树中每个节点最多包含 m 个孩子\r\n- 除根节点与叶子节点外，每个节点至少有 [ceil(m/2)] 个孩子\r\n- 若根节点不是叶子节点，则至少有两个孩子\r\n- 所有的叶子节点都在同一层\r\n- 每个非叶子节点由 n 个 key 与 n+1 个指针组成，其中 [ceil(m/2)-1] <= n <= m-1 \r\n\r\n5 叉，key 的数量 [ceil(m/2)-1] <= n <= m-1 为 2 <= n <=4 ，当 n>4 时中间节点分裂到父节点，两边节点分裂\r\n\r\n插入 C N G A H E K Q M F W L T Z D P R X Y S 数据的工作流程：\r\n\r\n* 插入前 4 个字母 C N G A \r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-BTree工作流程1.png)\r\n\r\n* 插入 H，n>4，中间元素 G 字母向上分裂到新的节点\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-BTree工作流程2.png)\r\n\r\n* 插入 E、K、Q 不需要分裂\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-BTree工作流程3.png)\r\n\r\n* 插入 M，中间元素 M 字母向上分裂到父节点 G\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-BTree工作流程4.png)\r\n\r\n* 插入 F，W，L，T 不需要分裂\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-BTree工作流程5.png)\r\n\r\n* 插入 Z，中间元素 T 向上分裂到父节点中\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-BTree工作流程6.png)\r\n\r\n* 插入 D，中间元素 D 向上分裂到父节点中，然后插入 P，R，X，Y 不需要分裂\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-BTree工作流程7.png)\r\n\r\n* 最后插入 S，NPQR 节点 n>5，中间节点 Q 向上分裂，但分裂后父节点 DGMT 的 n>5，中间节点 M 向上分裂\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-BTree工作流程8.png)\r\n\r\nBTree 树就已经构建完成了，BTree 树和二叉树相比， 查询数据的效率更高， 因为对于相同的数据量来说，**BTree 的层级结构比二叉树少**，所以搜索速度快\r\n\r\nBTree 结构的数据可以让系统高效的找到数据所在的磁盘块，定义一条记录为一个二元组 [key, data] ，key 为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key 值互不相同，BTree 中的每个节点根据实际情况可以包含大量的关键字信息和分支\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/索引的原理1.png)\r\n\r\n缺点：当进行范围查找时会出现回旋查找\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### B+Tree\r\n\r\n##### 数据结构\r\n\r\nBTree 数据结构中每个节点中不仅包含数据的 key 值，还有 data 值。磁盘中每一页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小，当存储的数据量很大时同样会导致 B-Tree 的深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率，所以引入 B+Tree\r\n\r\nB+Tree 为 BTree 的变种，B+Tree 与 BTree 的区别为：\r\n\r\n* n 叉 B+Tree 最多含有 n 个 key（哈希值），而 BTree 最多含有 n-1 个 key\r\n\r\n- 所有**非叶子节点只存储键值 key** 信息，只进行数据索引，使每个非叶子节点所能保存的关键字大大增加\r\n- 所有**数据都存储在叶子节点**，所以每次数据查询的次数都一样\r\n- **叶子节点按照 key 大小顺序排列，左边结尾数据都会保存右边节点开始数据的指针，形成一个链表**\r\n- 所有节点中的 key 在叶子节点中也存在（比如 5)，**key 允许重复**，B 树不同节点不存在重复的 key\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-B加Tree数据结构.png\" style=\"zoom:67%;\" />\r\n\r\nB* 树：是 B+ 树的变体，在 B+ 树的非根和非叶子结点再增加指向兄弟的指针\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 优化结构\r\n\r\nMySQL 索引数据结构对经典的 B+Tree 进行了优化，在原 B+Tree 的基础上，增加一个指向相邻叶子节点的链表指针，就形成了带有顺序指针的 B+Tree，**提高区间访问的性能，防止回旋查找**\r\n\r\n区间访问的意思是访问索引为 5 - 15 的数据，可以直接根据相邻节点的指针遍历\r\n\r\nB+ 树的**叶子节点是数据页**（page），一个页里面可以存多个数据行\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/索引的原理2.png)\r\n\r\n通常在 B+Tree 上有两个头指针，**一个指向根节点，另一个指向关键字最小的叶子节点**，而且所有叶子节点（即数据节点）之间是一种链式环结构。可以对 B+Tree 进行两种查找运算：\r\n\r\n- 有范围：对于主键的范围查找和分页查找\r\n- 有顺序：从根节点开始，进行随机查找，顺序查找\r\n\r\nInnoDB 中每个数据页的大小默认是 16KB，\r\n\r\n* 索引行：一般表的主键类型为 INT（4 字节）或 BIGINT（8 字节），指针大小在 InnoDB 中设置为 6 字节节，也就是说一个页大概存储 16KB/(8B+6B)=1K 个键值（估值）。则一个深度为 3 的 B+Tree 索引可以维护 `10^3 * 10^3 * 10^3 = 10亿` 条记录\r\n* 数据行：一行数据的大小可能是 1k，一个数据页可以存储 16 行\r\n\r\n实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree 的高度一般都在 2-4 层。MySQL 的 InnoDB 存储引擎在设计时是**将根节点常驻内存的**，也就是说查找某一键值的行记录时最多只需要 1~3 次磁盘 I/O 操作\r\n\r\nB+Tree 优点：提高查询速度，减少磁盘的 IO 次数，树形结构较小\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 索引维护\r\n\r\nB+ 树为了保持索引的有序性，在插入新值的时候需要做相应的维护\r\n\r\n每个索引中每个块存储在磁盘页中，可能会出现以下两种情况：\r\n\r\n* 如果所在的数据页已经满了，这时候需要申请一个新的数据页，然后挪动部分数据过去，这个过程称为**页分裂**，原本放在一个页的数据现在分到两个页中，降低了空间利用率\r\n* 当相邻两个页由于删除了数据，利用率很低之后，会将数据页做**页合并**，合并的过程可以认为是分裂过程的逆过程\r\n* 这两个情况都是由 B+ 树的结构决定的\r\n\r\n一般选用数据小的字段做索引，字段长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小\r\n\r\n自增主键的插入数据模式，可以让主键索引尽量地保持递增顺序插入，不涉及到挪动其他记录，**避免了页分裂**，页分裂的目的就是保证后一个数据页中的所有行主键值比前一个数据页中主键值大\r\n\r\n\r\n\r\n参考文章：https://developer.aliyun.com/article/919861\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 设计原则\r\n\r\n索引的设计可以遵循一些已有的原则，创建索引的时候请尽量考虑符合这些原则，便于提升索引的使用效率\r\n\r\n创建索引时的原则：\r\n\r\n- 对查询频次较高，且数据量比较大的表建立索引\r\n- 使用唯一索引，区分度越高，使用索引的效率越高\r\n- 索引字段的选择，最佳候选列应当从 where 子句的条件中提取，使用覆盖索引\r\n- 使用短索引，索引创建之后也是使用硬盘来存储的，因此提升索引访问的 I/O 效率，也可以提升总体的访问效率。假如构成索引的字段总长度比较短，那么在给定大小的存储块内可以存储更多的索引值，相应的可以有效的提升 MySQL 访问索引的 I/O 效率\r\n- 索引可以有效的提升查询数据的效率，但索引数量不是多多益善，索引越多，维护索引的代价越高。对于插入、更新、删除等 DML 操作比较频繁的表来说，索引过多，会引入相当高的维护代价，降低 DML 操作的效率，增加相应操作的时间消耗；另外索引过多的话，MySQL 也会犯选择困难病，虽然最终仍然会找到一个可用的索引，但提高了选择的代价\r\n\r\n* MySQL 建立联合索引时会遵守**最左前缀匹配原则**，即最左优先，在检索数据时从联合索引的最左边开始匹配\r\n\r\n  N 个列组合而成的组合索引，相当于创建了 N 个索引，如果查询时 where 句中使用了组成该索引的**前**几个字段，那么这条查询 SQL 可以利用组合索引来提升查询效率\r\n\r\n  ```bash\r\n  -- 对name、address、phone列建一个联合索引\r\n  ALTER TABLE user ADD INDEX index_three(name,address,phone);\r\n  -- 查询语句执行时会依照最左前缀匹配原则，检索时分别会使用索引进行数据匹配。\r\n  (name,address,phone)\r\n  (name,address)\r\n  (name,phone)\t-- 只有name字段走了索引\r\n  (name)\r\n  \r\n  -- 索引的字段可以是任意顺序的，优化器会帮助我们调整顺序，下面的SQL语句可以命中索引\r\n  SELECT * FROM user WHERE address = '北京' AND phone = '12345' AND name = '张三';\r\n  ```\r\n\r\n  ```bash\r\n  -- 如果联合索引中最左边的列不包含在条件查询中，SQL语句就不会命中索引，比如：\r\n  SELECT * FROM user WHERE address = '北京' AND phone = '12345'; \r\n  ```\r\n\r\n哪些情况不要建立索引：\r\n\r\n* 记录太少的表\r\n* 经常增删改的表\r\n* 频繁更新的字段不适合创建索引\r\n* where 条件里用不到的字段不创建索引\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 索引优化\r\n\r\n#### 覆盖索引\r\n\r\n覆盖索引：包含所有满足查询需要的数据的索引（SELECT 后面的字段刚好是索引字段），可以利用该索引返回 SELECT 列表的字段，而不必根据索引去聚簇索引上读取数据文件\r\n\r\n回表查询：要查找的字段不在非主键索引树上时，需要通过叶子节点的主键值去主键索引上获取对应的行数据\r\n\r\n使用覆盖索引，防止回表查询：\r\n\r\n* 表 user 主键为 id，普通索引为 age，查询语句：\r\n\r\n  ```bash\r\n  SELECT * FROM user WHERE age = 30;\r\n  ```\r\n\r\n  查询过程：先通过普通索引 age=30 定位到主键值 id=1，再通过聚集索引 id=1 定位到行记录数据，需要两次扫描 B+ 树\r\n\r\n* 使用覆盖索引：\r\n\r\n  ```bash\r\n  DROP INDEX idx_age ON user;\r\n  CREATE INDEX idx_age_name ON user(age,name);\r\n  SELECT id,age FROM user WHERE age = 30;\r\n  ```\r\n\r\n  在一棵索引树上就能获取查询所需的数据，无需回表速度更快\r\n\r\n使用覆盖索引，要注意 SELECT 列表中只取出需要的列，不可用 SELECT *，所有字段一起做索引会导致索引文件过大，查询性能下降\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 索引下推\r\n\r\n索引条件下推优化（Index Condition Pushdown，ICP）是 MySQL5.6 添加，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数\r\n\r\n索引下推充分利用了索引中的数据，在查询出整行数据之前过滤掉无效的数据，再去主键索引树上查找\r\n\r\n* 不使用索引下推优化时存储引擎通过索引检索到数据，然后回表查询记录返回给 Server 层，**服务器判断数据是否符合条件**\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-不使用索引下推.png)\r\n\r\n* 使用索引下推优化时，如果**存在某些被索引的列的判断条件**时，由存储引擎在索引遍历的过程中判断数据是否符合传递的条件，将符合条件的数据进行回表，检索出来返回给服务器，由此减少 IO 次数\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-使用索引下推.png)\r\n\r\n**适用条件**：\r\n\r\n* 需要存储引擎将索引中的数据与条件进行判断（所以**条件列必须都在同一个索引中**），所以优化是基于存储引擎的，只有特定引擎可以使用，适用于 InnoDB 和 MyISAM\r\n* 存储引擎没有调用跨存储引擎的能力，跨存储引擎的功能有存储过程、触发器、视图，所以调用这些功能的不可以进行索引下推优化\r\n* 对于 InnoDB 引擎只适用于二级索引，InnoDB 的聚簇索引会将整行数据读到缓冲区，不再需要去回表查询了\r\n\r\n工作过程：用户表 user，(name, age) 是联合索引\r\n\r\n```bash\r\nSELECT * FROM user WHERE name LIKE '张%' AND　age = 10;\t-- 头部模糊匹配会造成索引失效\r\n```\r\n\r\n* 优化前：在非主键索引树上找到满足第一个条件的行，然后通过叶子节点记录的主键值再回到主键索引树上查找到对应的行数据，再对比 AND 后的条件是否符合，符合返回数据，需要 4 次回表\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-索引下推优化1.png)\r\n\r\n* 优化后：检查索引中存储的列信息是否符合索引条件，然后交由存储引擎用剩余的判断条件判断此行数据是否符合要求，**不满足条件的不去读取表中的数据**，满足下推条件的就根据主键值进行回表查询，2 次回表\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-索引下推优化2.png)\r\n\r\n当使用 EXPLAIN 进行分析时，如果使用了索引条件下推，Extra 会显示 Using index condition\r\n\r\n\r\n\r\n参考文章：https://blog.csdn.net/sinat_29774479/article/details/103470244\r\n\r\n参考文章：https://time.geekbang.org/column/article/69636\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 前缀索引\r\n\r\n当要索引的列字符很多时，索引会变大变慢，可以只索引列开始的部分字符串，节约索引空间，提高索引效率\r\n\r\n注意：使用前缀索引就系统就忽略覆盖索引对查询性能的优化了\r\n\r\n优化原则：**降低重复的索引值**\r\n\r\n比如地区表：\r\n\r\n```bash\r\narea\t\t\tgdp\t\tcode\r\nchinaShanghai\t100\t\taaa\r\nchinaDalian\t\t200\t\tbbb\r\nusaNewYork\t\t300\t\tccc\r\nchinaFuxin\t\t400\t\tddd\r\nchinaBeijing\t500\t\teee\r\n```\r\n\r\n发现 area 字段很多都是以 china 开头的，那么如果以前 1-5 位字符做前缀索引就会出现大量索引值重复的情况，索引值重复性越低，查询效率也就越高，所以需要建立前 6 位字符的索引：\r\n\r\n```bash\r\nCREATE INDEX idx_area ON table_name(area(7));\r\n```\r\n\r\n场景：存储身份证\r\n\r\n* 直接创建完整索引，这样可能比较占用空间\r\n* 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引\r\n* 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题（前 6 位相同的很多）\r\n* 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 索引合并\r\n\r\n使用多个索引来完成一次查询的执行方法叫做索引合并 index merge\r\n\r\n* Intersection 索引合并：\r\n\r\n  ```sql\r\n  SELECT * FROM table_test WHERE key1 = 'a' AND key3 = 'b'; # key1 和 key3 列都是单列索引、二级索引\r\n  ```\r\n\r\n  从不同索引中扫描到的记录的 id 值取**交集**（相同 id），然后执行回表操作，要求从每个二级索引获取到的记录都是按照主键值排序\r\n\r\n* Union 索引合并：\r\n\r\n  ```sql\r\n  SELECT * FROM table_test WHERE key1 = 'a' OR key3 = 'b';\r\n  ```\r\n\r\n  从不同索引中扫描到的记录的 id 值取**并集**，然后执行回表操作，要求从每个二级索引获取到的记录都是按照主键值排序\r\n\r\n* Sort-Union 索引合并\r\n\r\n  ```sql\r\n  SELECT * FROM table_test WHERE key1 < 'a' OR key3 > 'b';\r\n  ```\r\n\r\n  先将从不同索引中扫描到的记录的主键值进行排序，再按照 Union 索引合并的方式进行查询\r\n\r\n索引合并算法的效率并不好，通过将其中的一个索引改成联合索引会优化效率\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n"},{"title":"MySQL - 锁","tags":["SQL"],"categories":["MySQL","锁篇"],"author":"imklaus","excerpt":"\r\n### 基本介绍\r\n\r\n锁机制：数据库为了保证数据的一致性，在共享的资源被并发访问时变得安全有序所设计的一种规则\r\n\r\n利用 MVCC 性质进行读取的操作叫**一致性读**，读取数据前加锁的操作叫**锁定读**\r\n","link":"/posts/MySQL_Lock","content":"\r\n### 基本介绍\r\n\r\n锁机制：数据库为了保证数据的一致性，在共享的资源被并发访问时变得安全有序所设计的一种规则\r\n\r\n利用 MVCC 性质进行读取的操作叫**一致性读**，读取数据前加锁的操作叫**锁定读**\r\n<!-- more -->\r\n锁的分类：\r\n\r\n- 按操作分类：\r\n  - 共享锁：也叫读锁。对同一份数据，多个事务读操作可以同时加锁而不互相影响 ，但不能修改数据\r\n  - 排他锁：也叫写锁。当前的操作没有完成前，会阻断其他操作的读取和写入\r\n- 按粒度分类：\r\n  - 表级锁：会锁定整个表，开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低，偏向 MyISAM\r\n  - 行级锁：会锁定当前操作行，开销大，加锁慢；会出现死锁；锁定力度小，发生锁冲突概率低，并发度高，偏向 InnoDB\r\n  - 页级锁：锁的力度、发生冲突的概率和加锁开销介于表锁和行锁之间，会出现死锁，并发性能一般\r\n- 按使用方式分类：\r\n  - 悲观锁：每次查询数据时都认为别人会修改，很悲观，所以查询时加锁\r\n  - 乐观锁：每次查询数据时都认为别人不会修改，很乐观，但是更新时会判断一下在此期间别人有没有去更新这个数据\r\n\r\n* 不同存储引擎支持的锁\r\n\r\n  | 存储引擎 | 表级锁   | 行级锁   | 页级锁 |\r\n  | -------- | -------- | -------- | ------ |\r\n  | MyISAM   | 支持     | 不支持   | 不支持 |\r\n  | InnoDB   | **支持** | **支持** | 不支持 |\r\n  | MEMORY   | 支持     | 不支持   | 不支持 |\r\n  | BDB      | 支持     | 不支持   | 支持   |\r\n\r\n从锁的角度来说：表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如 Web 应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并查询的应用，如一些在线事务处理系统\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 内存结构\r\n\r\n对一条记录加锁的本质就是**在内存中**创建一个锁结构与之关联，结构包括\r\n\r\n* 事务信息：锁对应的事务信息，一个锁属于一个事务\r\n* 索引信息：对于行级锁，需要记录加锁的记录属于哪个索引\r\n* 表锁和行锁信息：表锁记录着锁定的表，行锁记录了 Space ID 所在表空间、Page Number 所在的页号、n_bits 使用了多少比特\r\n* type_mode：一个 32 比特的数，被分成 lock_mode、lock_type、rec_lock_type 三个部分\r\n  * lock_mode：锁模式，记录是共享锁、排他锁、意向锁之类\r\n  * lock_type：代表表级锁还是行级锁\r\n  * rec_lock_type：代表行锁的具体类型和 is_waiting 属性，is_waiting = true 时表示当前事务尚未获取到锁，处于等待状态。事务获取锁后的锁结构是 is_waiting 为 false，释放锁时会检查是否与当前记录关联的锁结构，如果有就唤醒对应事务的线程\r\n\r\n一个事务可能操作多条记录，为了节省内存，满足下面条件的锁使用同一个锁结构：\r\n\r\n* 在同一个事务中的加锁操作\r\n* 被加锁的记录在同一个页面中\r\n* 加锁的类型是一样的\r\n* 加锁的状态是一样的\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### Server\r\n\r\nMySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)\r\n\r\nMDL 叫元数据锁，主要用来保护 MySQL 内部对象的元数据，保证数据读写的正确性，**当对一个表做增删改查的时候，加 MDL 读锁；当要对表做结构变更操作 DDL 的时候，加 MDL 写锁**，两种锁不相互兼容，所以可以保证 DDL、DML、DQL 操作的安全\r\n\r\n说明：DDL 操作执行前会隐式提交当前会话的事务，因为 DDL 一般会在若干个特殊事务中完成，开启特殊事务前需要提交到其他事务\r\n\r\nMDL 锁的特性：\r\n\r\n* MDL 锁不需要显式使用，在访问一个表的时候会被自动加上，在事务开始时申请，整个事务提交后释放（执行完单条语句不释放）\r\n\r\n* MDL 锁是在 Server 中实现，不是 InnoDB 存储引擎层能直接实现的锁\r\n\r\n* MDL 锁还能实现其他粒度级别的锁，比如全局锁、库级别的锁、表空间级别的锁\r\n\r\nFLUSH TABLES WITH READ LOCK 简称（FTWRL），全局读锁，让整个库处于只读状态，DDL DML 都被阻塞，工作流程：\r\n\r\n1. 上全局读锁（lock_global_read_lock）\r\n2. 清理表缓存（close_cached_tables）\r\n3. 上全局 COMMIT 锁（make_global_read_lock_block_commit）\r\n\r\n该命令主要用于备份工具做**一致性备份**，由于 FTWRL 需要持有两把全局的 MDL 锁，并且还要关闭所有表对象，因此杀伤性很大\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### MyISAM\r\n\r\n#### 表级锁\r\n\r\nMyISAM 存储引擎只支持表锁，这也是 MySQL 开始几个版本中唯一支持的锁类型\r\n\r\nMyISAM 引擎在执行查询语句之前，会**自动**给涉及到的所有表加读锁，在执行增删改之前，会**自动**给涉及的表加写锁，这个过程并不需要用户干预，所以用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁\r\n\r\n* 加锁命令：（对 InnoDB 存储引擎也适用）\r\n\r\n  读锁：所有连接只能读取数据，不能修改\r\n\r\n  写锁：其他连接不能查询和修改数据\r\n\r\n  ```bash\r\n  -- 读锁\r\n  LOCK TABLE table_name READ;\r\n  \r\n  -- 写锁\r\n  LOCK TABLE table_name WRITE;\r\n  ```\r\n\r\n* 解锁命令：\r\n\r\n  ```bash\r\n  -- 将当前会话所有的表进行解锁\r\n  UNLOCK TABLES;\r\n  ```\r\n\r\n锁的兼容性：\r\n\r\n* 对 MyISAM 表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求\r\n* 对 MyISAM 表的写操作，则会阻塞其他用户对同一表的读和写操作\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MyISAM 锁的兼容性.png)\r\n\r\n锁调度：**MyISAM 的读写锁调度是写优先**，因为写锁后其他线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成永远阻塞，所以 MyISAM 不适合做写为主的表的存储引擎\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 锁操作\r\n\r\n##### 读锁\r\n\r\n两个客户端操作 Client 1和 Client 2，简化为 C1、C2\r\n\r\n* 数据准备：\r\n\r\n  ```bash\r\n  CREATE TABLE `tb_book` (\r\n    `id` INT(11) AUTO_INCREMENT,\r\n    `name` VARCHAR(50) DEFAULT NULL,\r\n    `publish_time` DATE DEFAULT NULL,\r\n    `status` CHAR(1) DEFAULT NULL,\r\n    PRIMARY KEY (`id`)\r\n  ) ENGINE=MYISAM DEFAULT CHARSET=utf8 ;\r\n  \r\n  INSERT INTO tb_book (id, NAME, publish_time, STATUS) VALUES(NULL,'java编程思想','2088-08-01','1');\r\n  INSERT INTO tb_book (id, NAME, publish_time, STATUS) VALUES(NULL,'mysql编程思想','2088-08-08','0');\r\n  ```\r\n\r\n* C1、C2 加读锁，同时查询可以正常查询出数据\r\n\r\n  ```bash\r\n  LOCK TABLE tb_book READ;\t-- C1、C2\r\n  SELECT * FROM tb_book;\t\t-- C1、C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MyISAM 读锁1.png)\r\n\r\n* C1 加读锁，C1、C2 查询未锁定的表，C1 报错，C2 正常查询\r\n\r\n  ```bash\r\n  LOCK TABLE tb_book READ;\t-- C1\r\n  SELECT * FROM tb_user;\t\t-- C1、C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MyISAM 读锁2.png)\r\n\r\n  C1、C2 执行插入操作，C1 报错，C2 等待获取\r\n\r\n  ```bash\r\n  INSERT INTO tb_book VALUES(NULL,'Spring高级','2088-01-01','1');\t-- C1、C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MyISAM 读锁3.png)\r\n\r\n  当在 C1 中释放锁指令 UNLOCK TABLES，C2 中的 INSERT 语句立即执行\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 写锁\r\n\r\n两个客户端操作 Client 1和 Client 2，简化为 C1、C2\r\n\r\n* C1 加写锁，C1、C2查询表，C1 正常查询，C2 需要等待\r\n\r\n  ```bash\r\n  LOCK TABLE tb_book WRITE;\t-- C1\r\n  SELECT * FROM tb_book;\t\t-- C1、C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MyISAM 写锁1.png)\r\n\r\n  当在 C1 中释放锁指令 UNLOCK TABLES，C2 中的 SELECT 语句立即执行\r\n\r\n* C1、C2 同时加写锁\r\n\r\n  ```bash\r\n  LOCK TABLE tb_book WRITE;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MyISAM 写锁2.png)\r\n\r\n* C1 加写锁，C1、C2查询未锁定的表，C1 报错，C2 正常查询\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 锁状态\r\n\r\n* 查看锁竞争：\r\n\r\n  ```bash\r\n  SHOW OPEN TABLES;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-锁争用情况查看1.png)\r\n\r\n  In_user：表当前被查询使用的次数，如果该数为零，则表是打开的，但是当前没有被使用\r\n\r\n  Name_locked：表名称是否被锁定，名称锁定用于取消表或对表进行重命名等操作\r\n\r\n  ```bash\r\n  LOCK TABLE tb_book READ;\t-- 执行命令\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-锁争用情况查看2.png)\r\n\r\n* 查看锁状态：\r\n\r\n  ```bash\r\n  SHOW STATUS LIKE 'Table_locks%';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MyISAM 锁状态.png)\r\n\r\n  Table_locks_immediate：指的是能立即获得表级锁的次数，每立即获取锁，值加 1\r\n\r\n  Table_locks_waited：指的是不能立即获取表级锁而需要等待的次数，每等待一次，该值加 1，此值高说明存在着较为严重的表级锁争用情况\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### InnoDB\r\n\r\n#### 行级锁\r\n\r\n##### 记录锁\r\n\r\nInnoDB 与 MyISAM 的最大不同有两点：一是支持事务；二是采用了行级锁，**InnoDB 同时支持表锁和行锁**\r\n\r\n行级锁，也称为记录锁（Record Lock），InnoDB  实现了以下两种类型的行锁：\r\n\r\n- 共享锁 (S)：又称为读锁，简称 S 锁，多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改\r\n- 排他锁 (X)：又称为写锁，简称 X 锁，不能与其他锁并存，获取排他锁的事务是可以对数据读取和修改\r\n\r\nRR 隔离界别下，对于 UPDATE、DELETE 和 INSERT 语句，InnoDB 会**自动给涉及数据集加排他锁**（行锁），在 commit 时自动释放；对于普通 SELECT 语句，不会加任何锁（只是针对 InnoDB 层来说的，因为在 Server 层会**加 MDL 读锁**），通过 MVCC 防止并发冲突\r\n\r\n在事务中加的锁，并不是不需要了就释放，而是在事务中止或提交时自动释放，这个就是**两阶段锁协议**。所以一般将更新共享资源（并发高）的 SQL 放到事务的最后执行，可以让其他线程尽量的减少等待时间\r\n\r\n锁的兼容性：\r\n\r\n- 共享锁和共享锁     兼容\r\n- 共享锁和排他锁     冲突\r\n- 排他锁和排他锁     冲突\r\n- 排他锁和共享锁     冲突\r\n\r\n显式给数据集加共享锁或排他锁：**加锁读就是当前读，读取的是最新数据**\r\n\r\n```bash\r\nSELECT * FROM table_name WHERE ... LOCK IN SHARE MODE\t-- 共享锁\r\nSELECT * FROM table_name WHERE ... FOR UPDATE\t\t\t-- 排他锁\r\n```\r\n\r\n注意：**锁默认会锁聚簇索引（锁就是加在索引上）**，但是当使用覆盖索引时，加共享锁只锁二级索引，不锁聚簇索引\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 锁操作\r\n\r\n两个客户端操作 Client 1和 Client 2，简化为 C1、C2\r\n\r\n* 环境准备\r\n\r\n  ```bash\r\n  CREATE TABLE test_innodb_lock(\r\n  \tid INT(11),\r\n  \tname VARCHAR(16),\r\n  \tsex VARCHAR(1)\r\n  )ENGINE = INNODB DEFAULT CHARSET=utf8;\r\n  \r\n  INSERT INTO test_innodb_lock VALUES(1,'100','1');\r\n  -- ..........\r\n  \r\n  CREATE INDEX idx_test_innodb_lock_id ON test_innodb_lock(id);\r\n  CREATE INDEX idx_test_innodb_lock_name ON test_innodb_lock(name);\r\n  ```\r\n\r\n* 关闭自动提交功能：\r\n\r\n  ```bash\r\n  SET AUTOCOMMIT=0;\t-- C1、C2\r\n  ```\r\n\r\n  正常查询数据：\r\n\r\n  ```bash\r\n  SELECT * FROM test_innodb_lock;\t-- C1、C2\r\n  ```\r\n\r\n* 查询 id 为 3 的数据，正常查询：\r\n\r\n  ```bash\r\n  SELECT * FROM test_innodb_lock WHERE id=3;\t-- C1、C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 锁操作1.png)\r\n\r\n* C1 更新 id 为 3 的数据，但不提交：\r\n\r\n  ```bash\r\n  UPDATE test_innodb_lock SET name='300' WHERE id=3;\t-- C1\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 锁操作2.png)\r\n\r\n  C2 查询不到 C1 修改的数据，因为隔离界别为 REPEATABLE READ，C1 提交事务，C2 查询：\r\n\r\n  ```bash\r\n  COMMIT;\t-- C1\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 锁操作3.png)\r\n\r\n  提交后仍然查询不到 C1 修改的数据，因为隔离级别可以防止脏读、不可重复读，所以 C2 需要提交才可以查询到其他事务对数据的修改：\r\n\r\n  ```bash\r\n  COMMIT;\t-- C2\r\n  SELECT * FROM test_innodb_lock WHERE id=3;\t-- C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 锁操作4.png)\r\n\r\n* C1 更新 id 为 3 的数据，但不提交，C2 也更新 id 为 3 的数据：\r\n\r\n  ```bash\r\n  UPDATE test_innodb_lock SET name='3' WHERE id=3;\t-- C1\r\n  UPDATE test_innodb_lock SET name='30' WHERE id=3;\t-- C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 锁操作5.png)\r\n\r\n  当 C1 提交，C2 直接解除阻塞，直接更新\r\n\r\n* 操作不同行的数据：\r\n\r\n  ```bash\r\n  UPDATE test_innodb_lock SET name='10' WHERE id=1;\t-- C1\r\n  UPDATE test_innodb_lock SET name='30' WHERE id=3;\t-- C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 锁操作6.png)\r\n\r\n  由于 C1、C2 操作的不同行，获取不同的行锁，所以都可以正常获取行锁\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 锁分类\r\n\r\n##### 间隙锁\r\n\r\nInnoDB 会对间隙（GAP）进行加锁，就是间隙锁 （RR 隔离级别下才有该锁）。间隙锁之间不存在冲突关系，**多个事务可以同时对一个间隙加锁**，但是间隙锁会阻止往这个间隙中插入一个记录的操作\r\n\r\nInnoDB 加锁的基本单位是 next-key lock，该锁是行锁和 gap lock 的组合（X or S 锁），但是加锁过程是分为间隙锁和行锁两段执行\r\n\r\n* 可以**保护当前记录和前面的间隙**，遵循左开右闭原则，单纯的间隙锁是左开右开\r\n* 假设有 10、11、13，那么可能的间隙锁包括：(负无穷,10]、(10,11]、(11,13]、(13,正无穷)\r\n\r\n几种索引的加锁情况：\r\n\r\n* 唯一索引加锁在值存在时是行锁，next-key lock 会退化为行锁，值不存在会变成间隙锁\r\n* 普通索引加锁会继续向右遍历到不满足条件的值为止，next-key lock 退化为间隙锁\r\n* 范围查询无论是否是唯一索引，都需要访问到不满足条件的第一个值为止\r\n* 对于联合索引且是唯一索引，如果 where 条件只包括联合索引的一部分，那么会加间隙锁\r\n\r\n间隙锁优点：RR 级别下间隙锁可以**解决事务的一部分的幻读问题**，通过对间隙加锁，可以防止读取过程中数据条目发生变化。一部分的意思是不会对全部间隙加锁，只能加锁一部分的间隙\r\n\r\n间隙锁危害：\r\n\r\n* 当锁定一个范围的键值后，即使某些不存在的键值也会被无辜的锁定，造成在锁定的时候无法插入锁定键值范围内的任何数据，在某些场景下这可能会对性能造成很大的危害，影响并发度\r\n* 事务 A B 同时锁住一个间隙后，A 往当前间隙插入数据时会被 B 的间隙锁阻塞，B 也执行插入间隙数据的操作时就会**产生死锁**\r\n\r\n现场演示：\r\n\r\n* 关闭自动提交功能：\r\n\r\n  ```bash\r\n  SET AUTOCOMMIT=0;\t-- C1、C2\r\n  ```\r\n\r\n* 查询数据表：\r\n\r\n  ```bash\r\n  SELECT * FROM test_innodb_lock;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 间隙锁1.png)\r\n\r\n* C1 根据 id 范围更新数据，C2 插入数据：\r\n\r\n  ```bash\r\n  UPDATE test_innodb_lock SET name='8888' WHERE id < 4;\t-- C1\r\n  INSERT INTO test_innodb_lock VALUES(2,'200','2');\t\t-- C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 间隙锁2.png)\r\n\r\n  出现间隙锁，C2 被阻塞，等待 C1 提交事务后才能更新\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 意向锁\r\n\r\nInnoDB 为了支持多粒度的加锁，允许行锁和表锁同时存在，支持在不同粒度上的加锁操作，InnoDB 增加了意向锁（Intention Lock）\r\n\r\n意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度上进行加锁，意向锁分为两种：\r\n\r\n* 意向共享锁（IS）：事务有意向对表加共享锁\r\n* 意向排他锁（IX）：事务有意向对表加排他锁\r\n\r\n**IX，IS 是表级锁**，不会和行级的 X，S 锁发生冲突，意向锁是在加表级锁之前添加，为了在加表级锁时可以快速判断表中是否有记录被上锁，比如向一个表添加表级 X 锁的时：\r\n\r\n- 没有意向锁，则需要遍历整个表判断是否有锁定的记录\r\n- 有了意向锁，首先判断是否存在意向锁，然后判断该意向锁与即将添加的表级锁是否兼容即可，因为意向锁的存在代表有表级锁的存在或者即将有表级锁的存在\r\n\r\n兼容性如下所示：\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-意向锁兼容性.png)\r\n\r\n**插入意向锁** Insert Intention Lock 是在插入一行记录操作之前设置的一种间隙锁，是行级锁\r\n\r\n插入意向锁释放了一种插入信号，即多个事务在相同的索引间隙插入时如果不是插入相同的间隙位置就不需要互相等待。假设某列有索引，只要两个事务插入位置不同，如事务 A 插入 3，事务 B 插入 4，那么就可以同时插入\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 自增锁\r\n\r\n系统会自动给 AUTO_INCREMENT 修饰的列进行递增赋值，实现方式：\r\n\r\n* AUTO_INC 锁：表级锁，执行插入语句时会自动添加，在该语句执行完成后释放，并不是事务结束\r\n* 轻量级锁：为插入语句生成 AUTO_INCREMENT 修饰的列时获取该锁，生成以后释放掉，不需要等到插入语句执行完后释放\r\n\r\n系统变量 `innodb_autoinc_lock_mode` 控制采取哪种方式：\r\n\r\n* 0：全部采用 AUTO_INC 锁\r\n* 1：全部采用轻量级锁\r\n* 2：混合使用，在插入记录的数量确定时采用轻量级锁，不确定时采用 AUTO_INC 锁\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 隐式锁\r\n\r\n一般情况下 INSERT 语句是不需要在内存中生成锁结构的，会进行隐式的加锁，保护的是插入后的安全\r\n\r\n注意：如果插入的间隙被其他事务加了间隙锁，此次插入会被阻塞，并在该间隙插入一个插入意向锁\r\n\r\n* 聚簇索引：索引记录有 trx_id 隐藏列，表示最后改动该记录的事务 id，插入数据后事务 id 就是当前事务。其他事务想获取该记录的锁时会判断当前记录的事务 id 是否是活跃的，如果不是就可以正常加锁；如果是就创建一个 X 的锁结构，该锁的 is_waiting 是 false，为自己的事务创建一个锁结构，is_waiting 是 true（类似 Java 中的锁升级）\r\n* 二级索引：获取数据页 Page Header 中的 PAGE_MAX_TRX_ID 属性，代表修改当前页面的最大的事务 ID，如果小于当前活跃的最小事务 id，就证明插入该数据的事务已经提交，否则就需要获取到主键值进行回表操作\r\n\r\n隐式锁起到了延迟生成锁的效果，如果其他事务与隐式锁没有冲突，就可以避免锁结构的生成，节省了内存资源\r\n\r\nINSERT 在两种情况下会生成锁结构：\r\n\r\n* 重复键：在插入主键或唯一二级索引时遇到重复的键值会报错，在报错前需要对对应的聚簇索引进行加锁\r\n  * 隔离级别 <= Read Uncommitted，加 S 型 Record Lock\r\n  * 隔离级别 >= Repeatable Read，加 S 型 next_key 锁\r\n\r\n* 外键检查：如果待插入的记录在父表中可以找到，会对父表的记录加 S 型 Record Lock。如果待插入的记录在父表中找不到\r\n  * 隔离级别 <= Read Committed，不加锁\r\n  * 隔离级别 >= Repeatable Read，加间隙锁\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 锁优化\r\n\r\n##### 优化锁\r\n\r\nInnoDB 存储引擎实现了行级锁定，虽然在锁定机制的实现方面带来了性能损耗可能比表锁会更高，但是在整体并发处理能力方面要远远优于 MyISAM 的表锁，当系统并发量较高的时候，InnoDB 的整体性能远远好于 MyISAM\r\n\r\n但是使用不当可能会让 InnoDB 的整体性能表现不仅不能比 MyISAM 高，甚至可能会更差\r\n\r\n优化建议：\r\n\r\n- 尽可能让所有数据检索都能通过索引来完成，避免无索引行锁升级为表锁\r\n- 合理设计索引，尽量缩小锁的范围\r\n- 尽可能减少索引条件及索引范围，避免间隙锁\r\n- 尽量控制事务大小，减少锁定资源量和时间长度\r\n- 尽可使用低级别事务隔离（需要业务层面满足需求）\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 锁升级\r\n\r\n索引失效造成**行锁升级为表锁**，不通过索引检索数据，全局扫描的过程中 InnoDB 会将对表中的所有记录加锁，实际效果和**表锁**一样，实际开发过程应避免出现索引失效的状况\r\n\r\n* 查看当前表的索引：\r\n\r\n  ```bash\r\n  SHOW INDEX FROM test_innodb_lock;\r\n  ```\r\n\r\n* 关闭自动提交功能：\r\n\r\n  ```bash\r\n  SET AUTOCOMMIT=0;\t-- C1、C2\r\n  ```\r\n\r\n* 执行更新语句：\r\n\r\n  ```bash\r\n  UPDATE test_innodb_lock SET sex='2' WHERE name=10;\t-- C1\r\n  UPDATE test_innodb_lock SET sex='2' WHERE id=3;\t\t-- C2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 锁升级.png)\r\n\r\n  索引失效：执行更新时 name 字段为 varchar 类型，造成索引失效，最终行锁变为表锁 \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 死锁\r\n\r\n不同事务由于互相持有对方需要的锁而导致事务都无法继续执行的情况称为死锁\r\n\r\n死锁情况：线程 A 修改了 id = 1 的数据，请求修改 id = 2 的数据，线程 B 修改了 id = 2 的数据，请求修改 id = 1 的数据，产生死锁\r\n\r\n解决策略：\r\n\r\n* 直接进入等待直到超时，超时时间可以通过参数 innodb_lock_wait_timeout 来设置，默认 50 秒，但是时间的设置不好控制，超时可能不是因为死锁，而是因为事务处理比较慢，所以一般不采取该方式\r\n\r\n* 主动死锁检测，发现死锁后**主动回滚死锁链条中较小的一个事务**，让其他事务得以继续执行，将参数 `innodb_deadlock_detect` 设置为 on，表示开启该功能（事务较小的意思就是事务执行过程中插入、删除、更新的记录条数）\r\n\r\n  死锁检测并不是每个语句都要检测，只有在加锁访问的行上已经有锁时，当前事务被阻塞了才会检测，也是从当前事务开始进行检测\r\n\r\n通过执行 `SHOW ENGINE INNODB STATUS` 可以查看最近发生的一次死循环，全局系统变量 `innodb_print_all_deadlocks` 设置为 on，就可以将每个死锁信息都记录在 MySQL 错误日志中\r\n\r\n死锁一般是行级锁，当表锁发生死锁时，会在事务中访问其他表时**直接报错**，破坏了持有并等待的死锁条件\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 锁状态\r\n\r\n查看锁信息\r\n\r\n```bash\r\nSHOW STATUS LIKE 'innodb_row_lock%';\r\n```\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB 锁争用.png\" style=\"zoom: 80%;\" />\r\n\r\n参数说明：\r\n\r\n* Innodb_row_lock_current_waits：当前正在等待锁定的数量\r\n\r\n* Innodb_row_lock_time：从系统启动到现在锁定总时间长度\r\n\r\n* Innodb_row_lock_time_avg：每次等待所花平均时长\r\n\r\n* Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花的时间\r\n\r\n* Innodb_row_lock_waits：系统启动后到现在总共等待的次数\r\n\r\n当等待的次数很高，而且每次等待的时长也不短的时候，就需要分析系统中为什么会有如此多的等待，然后根据分析结果制定优化计划\r\n\r\n查看锁状态：\r\n\r\n```bash\r\nSELECT * FROM information_schema.innodb_locks;\t#锁的概况\r\nSHOW ENGINE INNODB STATUS\\G; #InnoDB整体状态，其中包括锁的情况\r\n```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-InnoDB查看锁状态.png)\r\n\r\nlock_id 是锁 id；lock_trx_id 为事务 id；lock_mode 为 X 代表排它锁（写锁）；lock_type 为 RECORD 代表锁为行锁（记录锁）\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 乐观锁\r\n\r\n悲观锁：在整个数据处理过程中，将数据处于锁定状态，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据，修改删除数据时也加锁，其它事务同样无法读取这些数据\r\n\r\n悲观锁和乐观锁使用前提：\r\n\r\n- 对于读的操作远多于写的操作的时候，一个更新操作加锁会阻塞所有的读取操作，降低了吞吐量，最后需要释放锁，锁是需要一些开销的，这时候可以选择乐观锁\r\n- 如果是读写比例差距不是非常大或者系统没有响应不及时，吞吐量瓶颈的问题，那就不要去使用乐观锁，它增加了复杂度，也带来了业务额外的风险，这时候可以选择悲观锁\r\n\r\n乐观锁的实现方式：就是 CAS，比较并交换\r\n\r\n* 版本号\r\n\r\n  1. 给数据表中添加一个 version 列，每次更新后都将这个列的值加 1\r\n\r\n  2. 读取数据时，将版本号读取出来，在执行更新的时候，比较版本号\r\n\r\n  3. 如果相同则执行更新，如果不相同，说明此条数据已经发生了变化\r\n\r\n  4. 用户自行根据这个通知来决定怎么处理，比如重新开始一遍，或者放弃本次更新\r\n\r\n     ```bash\r\n     -- 创建city表\r\n     CREATE TABLE city(\r\n     \tid INT PRIMARY KEY AUTO_INCREMENT,  -- 城市id\r\n     \tNAME VARCHAR(20),                   -- 城市名称\r\n     \tVERSION INT                         -- 版本号\r\n     );\r\n     \r\n     -- 添加数据\r\n     INSERT INTO city VALUES (NULL,'北京',1),(NULL,'上海',1),(NULL,'广州',1),(NULL,'深圳',1);\r\n     \r\n     -- 修改北京为北京市\r\n     -- 1.查询北京的version\r\n     SELECT VERSION FROM city WHERE NAME='北京';\r\n     -- 2.修改北京为北京市，版本号+1。并对比版本号\r\n     UPDATE city SET NAME='北京市',VERSION=VERSION+1 WHERE NAME='北京' AND VERSION=1;\r\n     ```\r\n\r\n* 时间戳\r\n\r\n  - 和版本号方式基本一样，给数据表中添加一个列，名称无所谓，数据类型需要是 **timestamp**\r\n  - 每次更新后都将最新时间插入到此列\r\n  - 读取数据时，将时间读取出来，在执行更新的时候，比较时间\r\n  - 如果相同则执行更新，如果不相同，说明此条数据已经发生了变化\r\n\r\n乐观锁的异常情况：如果 version 被其他事务抢先更新，则在当前事务中更新失败，trx_id 没有变成当前事务的 ID，当前事务再次查询还是旧值，就会出现**值没变但是更新不了**的现象（anomaly）\r\n\r\n解决方案：每次 CAS 更新不管成功失败，就结束当前事务；如果失败则重新起一个事务进行查询更新\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n"},{"title":"MySQL - 日志","tags":["SQL"],"categories":["MySQL","日志篇"],"author":"imklaus","excerpt":"\r\n### 日志分类\r\n\r\n在任何一种数据库中，都会有各种各样的日志，记录着数据库工作的过程，可以帮助数据库管理员追踪数据库曾经发生过的各种事件\r\n\r\nMySQL日志主要包括六种：\r\n\r\n1. 重做日志（redo log）\r\n2. 回滚日志（undo log）\r\n3. 归档日志（binlog）（二进制日志）\r\n4. 错误日志（errorlog）\r\n5. 慢查询日志（slow query log）\r\n6. 一般查询日志（general log）\r\n7. 中继日志（relay log）\r\n\r\n","link":"/posts/MySQL_Log","content":"\r\n### 日志分类\r\n\r\n在任何一种数据库中，都会有各种各样的日志，记录着数据库工作的过程，可以帮助数据库管理员追踪数据库曾经发生过的各种事件\r\n\r\nMySQL日志主要包括六种：\r\n\r\n1. 重做日志（redo log）\r\n2. 回滚日志（undo log）\r\n3. 归档日志（binlog）（二进制日志）\r\n4. 错误日志（errorlog）\r\n5. 慢查询日志（slow query log）\r\n6. 一般查询日志（general log）\r\n7. 中继日志（relay log）\r\n\r\n<!-- more -->\r\n\r\n***\r\n\r\n\r\n\r\n### 错误日志\r\n\r\n错误日志是 MySQL 中最重要的日志之一，记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，可以首先查看此日志\r\n\r\n该日志是默认开启的，默认位置是：`/var/log/mysql/error.log`\r\n\r\n查看指令：\r\n\r\n```bash\r\nSHOW VARIABLES LIKE 'log_error%';\r\n```\r\n\r\n查看日志内容：\r\n\r\n```sh\r\ntail -f /var/log/mysql/error.log\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 归档日志\r\n\r\n#### 基本介绍\r\n\r\n归档日志（BINLOG）也叫二进制日志，是因为采用二进制进行存储，记录了所有的 DDL（数据定义语言）语句和 DML（数据操作语言）语句，但**不包括数据查询语句，在事务提交前的最后阶段写入**\r\n\r\n作用：**灾难时的数据恢复和 MySQL 的主从复制**\r\n\r\n归档日志默认情况下是没有开启的，需要在 MySQL 配置文件中开启，并配置 MySQL 日志的格式：\r\n\r\n```sh\r\ncd /etc/mysql\r\nvim my.cnf\r\n\r\n# 配置开启binlog日志， 日志的文件前缀为 mysqlbin -----> 生成的文件名如: mysqlbin.000001\r\nlog_bin=mysqlbin\r\n# 配置二进制日志的格式\r\nbinlog_format=STATEMENT\r\n```\r\n\r\n日志存放位置：配置时给定了文件名但是没有指定路径，日志默认写入MySQL 的数据目录\r\n\r\n日志格式：\r\n\r\n* STATEMENT：该日志格式在日志文件中记录的都是 **SQL 语句**，每一条对数据进行修改的 SQL 都会记录在日志文件中，通过 mysqlbinlog 工具，可以查看到每条语句的文本。主从复制时，从库会将日志解析为原语句，并在从库重新执行一遍\r\n\r\n  缺点：可能会导致主备不一致，因为记录的 SQL 在不同的环境中可能选择的索引不同，导致结果不同\r\n\r\n* ROW：该日志格式在日志文件中记录的是每一行的**数据变更**，而不是记录 SQL 语句。比如执行 SQL 语句 `update tb_book set status='1'`，如果是 STATEMENT，在日志中会记录一行 SQL 语句； 如果是 ROW，由于是对全表进行更新，就是每一行记录都会发生变更，ROW 格式的日志中会记录每一行的数据变更\r\n\r\n  缺点：记录的数据比较多，占用很多的存储空间\r\n\r\n* MIXED：这是 MySQL 默认的日志格式，混合了STATEMENT 和 ROW 两种格式，MIXED 格式能尽量利用两种模式的优点，而避开它们的缺点\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 日志刷盘\r\n\r\n事务执行过程中，先将日志写（write）到 binlog cache，事务提交时再把 binlog cache 写（fsync）到 binlog 文件中，一个事务的 binlog 是不能被拆开的，所以不论这个事务多大也要确保一次性写入\r\n\r\n事务提交时执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache\r\n\r\nwrite 和 fsync 的时机由参数 sync_binlog 控制的：\r\n\r\n* sync_binlog=0：表示每次提交事务都只 write，不 fsync\r\n* sync_binlog=1：表示每次提交事务都会执行 fsync\r\n* sync_binlog=N(N>1)：表示每次提交事务都 write，但累积 N 个事务后才 fsync，但是如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 日志读取\r\n\r\n日志文件存储位置：/var/lib/mysql\r\n\r\n由于日志以二进制方式存储，不能直接读取，需要用 mysqlbinlog 工具来查看，语法如下：\r\n\r\n```sh\r\nmysqlbinlog log-file;\r\n```\r\n\r\n查看 STATEMENT 格式日志：\r\n\r\n* 执行插入语句：\r\n\r\n  ```bash\r\n  INSERT INTO tb_book VALUES(NULL,'Lucene','2088-05-01','0');\r\n  ```\r\n\r\n* `cd /var/lib/mysql`：\r\n\r\n  ```sh\r\n  -rw-r-----  1 mysql mysql      177 5月  23 21:08 mysqlbin.000001\r\n  -rw-r-----  1 mysql mysql       18 5月  23 21:04 mysqlbin.index\r\n  ```\r\n\r\n  mysqlbin.index：该文件是日志索引文件 ， 记录日志的文件名；\r\n\r\n  mysqlbing.000001：日志文件\r\n\r\n* 查看日志内容：\r\n\r\n  ```sh\r\n  mysqlbinlog mysqlbing.000001;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-日志读取1.png)\r\n\r\n  日志结尾有 COMMIT\r\n\r\n查看 ROW 格式日志：\r\n\r\n* 修改配置：\r\n\r\n  ```sh\r\n  # 配置二进制日志的格式\r\n  binlog_format=ROW\r\n  ```\r\n\r\n* 插入数据：\r\n\r\n  ```bash\r\n  INSERT INTO tb_book VALUES(NULL,'SpringCloud实战','2088-05-05','0');\r\n  ```\r\n\r\n* 查看日志内容：日志格式 ROW，直接查看数据是乱码，可以在 mysqlbinlog 后面加上参数 -vv \r\n\r\n  ```bash\r\n  mysqlbinlog -vv mysqlbin.000002\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-日志读取2.png)\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 日志删除\r\n\r\n对于比较繁忙的系统，生成日志量大，这些日志如果长时间不清除，将会占用大量的磁盘空间，需要删除日志\r\n\r\n* Reset Master 指令删除全部 binlog 日志，删除之后，日志编号将从 xxxx.000001重新开始\r\n\r\n  ```bash\r\n  Reset Master\t-- MySQL指令\r\n  ```\r\n\r\n* 执行指令 `PURGE MASTER LOGS TO 'mysqlbin.***`，该命令将删除 ` ***` 编号之前的所有日志\r\n\r\n* 执行指令 `PURGE MASTER LOGS BEFORE 'yyyy-mm-dd hh:mm:ss'` ，该命令将删除日志为 `yyyy-mm-dd hh:mm:ss` 之前产生的日志\r\n\r\n* 设置参数 `--expire_logs_days=#`，此参数的含义是设置日志的过期天数，过了指定的天数后日志将会被自动删除，这样做有利于减少管理日志的工作量，配置 my.cnf 文件：\r\n\r\n  ```sh\r\n  log_bin=mysqlbin\r\n  binlog_format=ROW\r\n  --expire_logs_days=3\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 数据恢复\r\n\r\n误删库或者表时，需要根据 binlog 进行数据恢复\r\n\r\n一般情况下数据库有定时的全量备份，假如每天 0 点定时备份，12 点误删了库，恢复流程：\r\n\r\n* 取最近一次全量备份，用备份恢复出一个临时库\r\n* 从日志文件中取出凌晨 0 点之后的日志\r\n* 把除了误删除数据的语句外日志，全部应用到临时库\r\n\r\n跳过误删除语句日志的方法：\r\n\r\n* 如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用 –stop-position 参数执行到误操作之前的日志，然后再用 –start-position 从误操作之后的日志继续执行\r\n* 如果实例使用了 GTID 模式，假设误操作命令的 GTID 是 gtid1，那么只需要提交一个空事务先将这个 GTID 加到临时实例的 GTID 集合，之后按顺序执行 binlog 的时就会自动跳过误操作的语句\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 查询日志\r\n\r\n查询日志中记录了客户端的所有操作语句，而二进制日志不包含查询数据的 SQL 语句\r\n\r\n默认情况下，查询日志是未开启的。如果需要开启查询日志，配置 my.cnf：\r\n\r\n```sh\r\n# 该选项用来开启查询日志，可选值0或者1，0代表关闭，1代表开启 \r\ngeneral_log=1\r\n# 设置日志的文件名，如果没有指定，默认的文件名为host_name.log，存放在/var/lib/mysql\r\ngeneral_log_file=mysql_query.log\r\n```\r\n\r\n配置完毕之后，在数据库执行以下操作：\r\n\r\n```bash\r\nSELECT * FROM tb_book;\r\nSELECT * FROM tb_book WHERE id = 1;\r\nUPDATE tb_book SET name = 'lucene入门指南' WHERE id = 5;\r\nSELECT * FROM tb_book WHERE id < 8\r\n```\r\n\r\n执行完毕之后， 再次来查询日志文件：\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-查询日志.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 慢日志\r\n\r\n慢查询日志记录所有执行时间超过 long_query_time 并且扫描记录数不小于 min_examined_row_limit 的所有的 SQL 语句的日志long_query_time 默认为 10 秒，最小为 0， 精度到微秒\r\n\r\n慢查询日志默认是关闭的，可以通过两个参数来控制慢查询日志，配置文件 `/etc/mysql/my.cnf`：\r\n\r\n```sh\r\n# 该参数用来控制慢查询日志是否开启，可选值0或者1，0代表关闭，1代表开启 \r\nslow_query_log=1 \r\n\r\n# 该参数用来指定慢查询日志的文件名，存放在 /var/lib/mysql\r\nslow_query_log_file=slow_query.log\r\n\r\n# 该选项用来配置查询的时间限制，超过这个时间将认为值慢查询，将需要进行日志记录，默认10s\r\nlong_query_time=10\r\n```\r\n\r\n日志读取：\r\n\r\n* 直接通过 cat 指令查询该日志文件：\r\n\r\n  ```sh\r\n  cat slow_query.log\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-慢日志读取1.png)\r\n\r\n* 如果慢查询日志内容很多，直接查看文件比较繁琐，可以借助 mysql 自带的 mysqldumpslow 工具对慢查询日志进行分类汇总：\r\n\r\n  ```sh\r\n  mysqldumpslow slow_query.log\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-慢日志读取2.png)\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n"},{"title":"MySQL - 主从","tags":["SQL"],"categories":["MySQL","主从篇"],"author":"imklaus","excerpt":"\r\n### 基本介绍\r\n\r\n主从复制是指将主数据库的 DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步\r\n\r\nMySQL 支持一台主库同时向多台从库进行复制，从库同时也可以作为其他从服务器的主库，实现链状复制\r\n\r\nMySQL 复制的优点主要包含以下三个方面：\r\n\r\n- 主库出现问题，可以快速切换到从库提供服务\r\n\r\n- 可以在从库上执行查询操作，从主库中更新，实现读写分离\r\n\r\n- 可以在从库中执行备份，以避免备份期间影响主库的服务（备份时会加全局读锁）\r\n\r\n","link":"/posts/MySQL_Master_Slave","content":"\r\n### 基本介绍\r\n\r\n主从复制是指将主数据库的 DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步\r\n\r\nMySQL 支持一台主库同时向多台从库进行复制，从库同时也可以作为其他从服务器的主库，实现链状复制\r\n\r\nMySQL 复制的优点主要包含以下三个方面：\r\n\r\n- 主库出现问题，可以快速切换到从库提供服务\r\n\r\n- 可以在从库上执行查询操作，从主库中更新，实现读写分离\r\n\r\n- 可以在从库中执行备份，以避免备份期间影响主库的服务（备份时会加全局读锁）\r\n\r\n<!-- more -->\r\n\r\n***\r\n\r\n\r\n\r\n### 主从复制\r\n\r\n#### 主从结构\r\n\r\nMySQL 的主从之间维持了一个**长连接**。主库内部有一个线程，专门用于服务从库的长连接，连接过程：\r\n\r\n* 从库执行 change master 命令，设置主库的 IP、端口、用户名、密码以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量\r\n* 从库执行 start slave 命令，这时从库会启动两个线程，就是图中的 io_thread 和 sql_thread，其中 io_thread 负责与主库建立连接\r\n* 主库校验完用户名、密码后，开始按照从传过来的位置，从本地读取 binlog 发给从库，开始主从复制\r\n\r\n主从复制原理图：\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-主从复制原理图.jpg)\r\n\r\n主从复制主要依赖的是 binlog，MySQL 默认是异步复制，需要三个线程：\r\n\r\n- binlog thread：在主库事务提交时，把数据变更记录在日志文件 binlog 中，并通知 slave 有数据更新\r\n- I/O thread：负责从主服务器上**拉取二进制日志**，并将 binlog 日志内容依次写到 relay log 中转日志的最末端，并将新的 binlog 文件名和 offset 记录到 master-info 文件中，以便下一次读取日志时从指定 binlog 日志文件及位置开始读取新的 binlog 日志内容\r\n- SQL thread：监测本地 relay log 中新增了日志内容，读取中继日志并重做其中的 SQL 语句，从库在 relay-log.info 中记录当前应用中继日志的文件名和位点以便下一次执行\r\n\r\n同步与异步：\r\n\r\n* 异步复制有数据丢失风险，例如数据还未同步到从库，主库就给客户端响应，然后主库挂了，此时从库晋升为主库的话数据是缺失的\r\n* 同步复制，主库需要将 binlog 复制到所有从库，等所有从库响应了之后主库才进行其他逻辑，这样的话性能很差，一般不会选择\r\n* MySQL 5.7 之后出现了半同步复制，有参数可以选择成功同步几个从库就返回响应\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 主主结构\r\n\r\n主主结构就是两个数据库之间总是互为主从关系，这样在切换的时候就不用再修改主从关系\r\n\r\n循环复制：在库 A 上更新了一条语句，然后把生成的 binlog 发给库 B，库 B 执行完这条更新语句后也会生成 binlog，会再发给 A\r\n\r\n解决方法：\r\n\r\n* 两个库的 server id 必须不同，如果相同则它们之间不能设定为主主关系\r\n* 一个库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog\r\n* 每个库在收到从主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 主从延迟\r\n\r\n#### 延迟原因\r\n\r\n正常情况主库执行更新生成的所有 binlog，都可以传到从库并被正确地执行，从库就能达到跟主库一致的状态，这就是最终一致性\r\n\r\n主从延迟是主从之间是存在一定时间的数据不一致，就是同一个事务在从库执行完成的时间和主库执行完成的时间的差值，即 T2-T1\r\n\r\n- 主库 A 执行完成一个事务，写入 binlog，该时刻记为 T1\r\n- 日志传给从库 B，从库 B 执行完这个事务，该时刻记为 T2\r\n\r\n通过在从库执行 `show slave status` 命令，返回结果会显示 seconds_behind_master 表示当前从库延迟了多少秒\r\n\r\n- 每一个事务的 binlog 都有一个时间字段，用于记录主库上写入的时间\r\n- 从库取出当前正在执行的事务的时间字段，跟系统的时间进行相减，得到的就是 seconds_behind_master\r\n\r\n主从延迟的原因：\r\n\r\n* 从库的机器性能比主库的差，导致从库的复制能力弱\r\n* 从库的查询压力大，建立一主多从的结构\r\n* 大事务的执行，主库必须要等到事务完成之后才会写入 binlog，导致从节点出现应用 binlog 延迟\r\n* 主库的 DDL，从库与主库的 DDL 同步是串行进行，DDL 在主库执行时间很长，那么从库也会消耗同样的时间\r\n* 锁冲突问题也可能导致从节点的 SQL 线程执行慢\r\n\r\n主从同步问题永远都是**一致性和性能的权衡**，需要根据实际的应用场景，可以采取下面的办法：\r\n\r\n* 优化 SQL，避免慢 SQL，减少批量操作\r\n* 降低多线程大事务并发的概率，优化业务逻辑\r\n* 业务中大多数情况查询操作要比更新操作更多，搭建**一主多从**结构，让这些从库来分担读的压力\r\n\r\n* 尽量采用短的链路，主库和从库服务器的距离尽量要短，提升端口带宽，减少 binlog 传输的网络延时\r\n* 实时性要求高的业务读强制走主库，从库只做备份\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 并行复制\r\n\r\n##### MySQL5.6\r\n\r\n高并发情况下，主库的会产生大量的 binlog，在从库中有两个线程 IO Thread 和 SQL Thread 单线程执行，会导致主库延迟变大。为了改善复制延迟问题，MySQL 5.6 版本增加了并行复制功能，以采用多线程机制来促进执行\r\n\r\ncoordinator 就是原来的 SQL Thread，并行复制中它不再直接更新数据，**只负责读取中转日志和分发事务**：\r\n\r\n* 线程分配完成并不是立即执行，为了防止造成更新覆盖，更新同一 DB 的两个事务必须被分发到同一个工作线程\r\n* 同一个事务不能被拆开，必须放到同一个工作线程\r\n\r\nMySQL 5.6 版本的策略：每个线程对应一个 hash 表，用于保存当前这个线程的执行队列里的事务所涉及的表，hash 表的 key 是数据库名，value 是一个数字，表示队列中有多少个事务修改这个库，适用于主库上有多个 DB 的情况\r\n\r\n每个事务在分发的时候，跟线程的**冲突**（事务操作的是同一个库）关系包括以下三种情况：\r\n\r\n* 如果跟所有线程都不冲突，coordinator 线程就会把这个事务分配给最空闲的线程\r\n* 如果只跟一个线程冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的线程\r\n* 如果跟多于一个线程冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的线程只剩下 1 个\r\n\r\n优缺点：\r\n\r\n* 构造 hash 值的时候很快，只需要库名，而且一个实例上 DB 数也不会很多，不会出现需要构造很多项的情况\r\n* 不要求 binlog 的格式，statement 格式的 binlog 也可以很容易拿到库名（日志章节详解了 binlog）\r\n* 主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果，需要**把相同热度的表均匀分到这些不同的 DB 中**，才可以使用这个策略\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### MySQL5.7\r\n\r\nMySQL 5.7 由参数 slave-parallel-type 来控制并行复制策略：\r\n\r\n* 配置为 DATABASE，表示使用 MySQL 5.6 版本的**按库（DB）并行策略**\r\n* 配置为 LOGICAL_CLOCK，表示的**按提交状态并行**执行\r\n\r\n按提交状态并行复制策略的思想是：\r\n\r\n* 所有处于 commit 状态的事务可以并行执行；同时处于 prepare 状态的事务，在从库执行时是可以并行的\r\n* 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在从库执行时也是可以并行的\r\n\r\nMySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略：\r\n\r\n* COMMIT_ORDER：表示根据同时进入 prepare 和 commit 来判断是否可以并行的策略\r\n\r\n* WRITESET：表示的是对于每个事务涉及更新的每一行，计算出这一行的 hash 值，组成该事务的 writeset 集合，如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行（**按行并行**）\r\n\r\n  为了唯一标识，这个 hash 表的值是通过 `库名 + 表名 + 索引名 + 值`（表示的是某一行）计算出来的\r\n\r\n* WRITESET_SESSION：是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序\r\n\r\n\r\nMySQL 5.7.22 按行并发的优势：\r\n\r\n* writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容，节省了计算量\r\n* 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个线程，更省内存\r\n* 从库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也可以，更节约内存（因为 row 才记录更改的行）\r\n\r\nMySQL 5.7.22 的并行复制策略在通用性上是有保证的，但是对于表上没主键、唯一和外键约束的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型\r\n\r\n\r\n\r\n参考文章：https://time.geekbang.org/column/article/77083\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 读写分离\r\n\r\n#### 读写延迟\r\n\r\n读写分离：可以降低主库的访问压力，提高系统的并发能力\r\n\r\n* 主库不建查询的索引，从库建查询的索引。因为索引需要维护的，比如插入一条数据，不仅要在聚簇索引上面插入，对应的二级索引也得插入\r\n* 将读操作分到从库了之后，可以在主库把查询要用的索引删了，减少写操作对主库的影响\r\n\r\n读写分离产生了读写延迟，造成数据的不一致性。假如客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，可能读到的还是以前的数据，叫过期读\r\n\r\n解决方案：\r\n\r\n* 强制将写之后**立刻读的操作转移到主库**，比如刚注册的用户，直接登录从库查询可能查询不到，先走主库登录\r\n* **二次查询**，如果从库查不到数据，则再去主库查一遍，由 API 封装，比较简单，但导致主库压力大\r\n* 更新主库后，读从库之前先 sleep 一下，类似于执行一条 `select sleep(1)` 命令，大多数情况下主备延迟在 1 秒之内\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 确保机制\r\n\r\n##### 无延迟\r\n\r\n确保主备无延迟的方法：\r\n\r\n* 每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0，如果不等于那就等到参数变为 0 执行查询请求\r\n* 对比位点，Master_Log_File 和 Read_Master_Log_Pos 表示的是读到的主库的最新位点，Relay_Master_Log_File 和 Exec_Master_Log_Pos 表示的是备库执行的最新位点，这两组值完全相同就说明接收到的日志已经同步完成\r\n* 对比 GTID 集合，Retrieved_Gtid_Set 是备库收到的所有日志的 GTID 集合，Executed_Gtid_Set 是备库所有已经执行完成的 GTID 集合，如果这两个集合相同也表示备库接收到的日志都已经同步完成\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 半同步\r\n\r\n半同步复制就是 semi-sync replication，适用于一主一备的场景，工作流程：\r\n\r\n* 事务提交的时候，主库把 binlog 发给从库\r\n* 从库收到 binlog 以后，发回给主库一个 ack，表示收到了\r\n* 主库收到这个 ack 以后，才能给客户端返回事务完成的确认\r\n\r\n在一主多从场景中，主库只要等到一个从库的 ack，就开始给客户端返回确认，这时在从库上执行查询请求，有两种情况：\r\n\r\n* 如果查询是落在这个响应了 ack 的从库上，是能够确保读到最新数据\r\n* 如果查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题\r\n\r\n在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，导致从库来不及处理，那么两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 等位点\r\n\r\n在**从库执行判断位点**的命令，参数 file 和 pos 指的是主库上的文件名和位置，timeout 可选，设置为正整数 N 表示最多等待 N 秒\r\n\r\n```bash\r\nSELECT master_pos_wait(file, pos[, timeout]);\r\n```\r\n\r\n命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务\r\n\r\n* 如果执行期间，备库同步线程发生异常，则返回 NULL\r\n* 如果等待超过 N 秒，就返回 -1\r\n* 如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0\r\n\r\n工作流程：先执行 trx1，再执行一个查询请求的逻辑，要**保证能够查到正确的数据**\r\n\r\n* trx1 事务更新完成后，马上执行 `show master status` 得到当前主库执行到的 File 和 Position\r\n* 选定一个从库执行判断位点语句，如果返回值是 >=0 的正整数，说明从库已经同步完事务，可以在这个从库执行查询语句\r\n* 如果出现其他情况，需要到主库执行查询语句\r\n\r\n注意：如果所有的从库都延迟超过 timeout 秒，查询压力就都跑到主库上，所以需要进行权衡\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 等GTID\r\n\r\n数据库开启了 GTID 模式，MySQL 提供了判断 GTID 的命令\r\n\r\n```bash\r\nSELECT wait_for_executed_gtid_set(gtid_set [, timeout])\r\n```\r\n\r\n* 等待直到这个库执行的事务中包含传入的 gtid_set，返回 0\r\n* 超时返回 1\r\n\r\n工作流程：先执行 trx1，再执行一个查询请求的逻辑，要保证能够查到正确的数据\r\n\r\n* trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid\r\n* 选定一个从库执行查询语句，如果返回值是 0，则在这个从库执行查询语句，否则到主库执行查询语句\r\n\r\n对比等待位点方法，减少了一次 `show master status` 的方法，将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值即可\r\n\r\n总结：所有的等待无延迟的方法，都需要根据具体的业务场景去判断实施\r\n\r\n\r\n\r\n参考文章：https://time.geekbang.org/column/article/77636\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 负载均衡\r\n\r\n负载均衡是应用中使用非常普遍的一种优化方法，机制就是利用某种均衡算法，将固定的负载量分布到不同的服务器上，以此来降低单台服务器的负载，达到优化的效果\r\n\r\n* 分流查询：通过 MySQL 的主从复制，实现读写分离，使增删改操作走主节点，查询操作走从节点，从而可以降低单台服务器的读写压力\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-负载均衡主从复制.jpg)\r\n\r\n* 分布式数据库架构：适合大数据量、负载高的情况，具有良好的拓展性和高可用性。通过在多台服务器之间分布数据，可以实现在多台服务器之间的负载均衡，提高访问效率\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 主从搭建\r\n\r\n#### master\r\n\r\n1. 在master 的配置文件（/etc/mysql/my.cnf）中，配置如下内容：\r\n\r\n   ```sh\r\n   #mysql 服务ID,保证整个集群环境中唯一\r\n   server-id=1\r\n   \r\n   #mysql binlog 日志的存储路径和文件名\r\n   log-bin=/var/lib/mysql/mysqlbin\r\n   \r\n   #错误日志,默认已经开启\r\n   #log-err\r\n   \r\n   #mysql的安装目录\r\n   #basedir\r\n   \r\n   #mysql的临时目录\r\n   #tmpdir\r\n   \r\n   #mysql的数据存放目录\r\n   #datadir\r\n   \r\n   #是否只读,1 代表只读, 0 代表读写\r\n   read-only=0\r\n   \r\n   #忽略的数据, 指不需要同步的数据库\r\n   binlog-ignore-db=mysql\r\n   \r\n   #指定同步的数据库\r\n   #binlog-do-db=db01\r\n   ```\r\n\r\n2. 执行完毕之后，需要重启 MySQL\r\n\r\n3. 创建同步数据的账户，并且进行授权操作：\r\n\r\n   ```bash\r\n   GRANT REPLICATION SLAVE ON *.* TO 'seazean'@'192.168.0.137' IDENTIFIED BY '123456';\r\n   FLUSH PRIVILEGES;\r\n   ```\r\n\r\n4. 查看 master 状态：\r\n\r\n   ```bash\r\n   SHOW MASTER STATUS;\r\n   ```\r\n\r\n   ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-查看master状态.jpg)\r\n\r\n   * File：从哪个日志文件开始推送日志文件 \r\n   * Position：从哪个位置开始推送日志\r\n   * Binlog_Ignore_DB：指定不需要同步的数据库\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### slave\r\n\r\n1. 在 slave 端配置文件中，配置如下内容：\r\n\r\n   ```sh\r\n   #mysql服务端ID,唯一\r\n   server-id=2\r\n   \r\n   #指定binlog日志\r\n   log-bin=/var/lib/mysql/mysqlbin\r\n   ```\r\n\r\n2. 执行完毕之后，需要重启 MySQL\r\n\r\n3. 指定当前从库对应的主库的IP地址、用户名、密码，从哪个日志文件开始的那个位置开始同步推送日志\r\n\r\n   ```bash\r\n   CHANGE MASTER TO MASTER_HOST= '192.168.0.138', MASTER_USER='seazean', MASTER_PASSWORD='seazean', MASTER_LOG_FILE='mysqlbin.000001', MASTER_LOG_POS=413;\r\n   ```\r\n\r\n4. 开启同步操作：\r\n\r\n   ```bash\r\n   START SLAVE;\r\n   SHOW SLAVE STATUS;\r\n   ```\r\n\r\n5. 停止同步操作：\r\n\r\n   ```bash\r\n   STOP SLAVE;\r\n   ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 验证\r\n\r\n1. 在主库中创建数据库，创建表并插入数据：\r\n\r\n   ```bash\r\n   CREATE DATABASE db01;\r\n   USE db01;\r\n   CREATE TABLE user(\r\n   \tid INT(11) NOT NULL AUTO_INCREMENT,\r\n   \tname VARCHAR(50) NOT NULL,\r\n   \tsex VARCHAR(1),\r\n   \tPRIMARY KEY (id)\r\n   )ENGINE=INNODB DEFAULT CHARSET=utf8;\r\n   \r\n   INSERT INTO user(id,NAME,sex) VALUES(NULL,'Tom','1');\r\n   INSERT INTO user(id,NAME,sex) VALUES(NULL,'Trigger','0');\r\n   INSERT INTO user(id,NAME,sex) VALUES(NULL,'Dawn','1');\r\n   ```\r\n\r\n2. 在从库中查询数据，进行验证：\r\n\r\n   在从库中，可以查看到刚才创建的数据库：\r\n\r\n   ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-主从复制验证1.jpg)\r\n\r\n   在该数据库中，查询表中的数据：\r\n\r\n   ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-主从复制验证2.jpg)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 主从切换\r\n\r\n#### 正常切换\r\n\r\n正常切换步骤：\r\n\r\n* 在开始切换之前先对主库进行锁表 `flush tables with read lock`，然后等待所有语句执行完成，切换完成后可以释放锁\r\n\r\n* 检查 slave 同步状态，在 slave 执行 `show processlist`\r\n\r\n* 停止 slave io 线程，执行命令 `STOP SLAVE IO_THREAD`\r\n\r\n* 提升 slave 为 master\r\n\r\n  ```sql\r\n  Stop slave;\r\n  Reset master;\r\n  Reset slave all;\r\n  set global read_only=off;\t-- 设置为可更新状态\r\n  ```\r\n\r\n* 将原来 master 变为 slave（参考搭建流程中的 slave 方法）\r\n\r\n**可靠性优先策略**：\r\n\r\n* 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步\r\n* 把主库 A 改成只读状态，即把 readonly 设置为 true\r\n* 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止（该步骤比较耗时，所以步骤 1 中要尽量等待该值变小）\r\n* 把备库 B 改成可读写状态，也就是把 readonly 设置为 false\r\n* 把业务请求切到备库 B\r\n\r\n可用性优先策略：先做最后两步，会造成主备数据不一致的问题\r\n\r\n\r\n\r\n参考文章：https://time.geekbang.org/column/article/76795\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 健康检测\r\n\r\n主库发生故障后从库会上位，**其他从库指向新的主库**，所以需要一个健康检测的机制来判断主库是否宕机\r\n\r\n* select 1 判断，但是高并发下检测不出线程的锁等待的阻塞问题\r\n\r\n* 查表判断，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行。但是当 binlog 所在磁盘的空间占用率达到 100%，所有的更新和事务提交语句都被阻塞，查询语句可以继续运行\r\n\r\n* 更新判断，在健康检测表中放一个 timestamp 字段，用来表示最后一次执行检测的时间\r\n\r\n  ```bash\r\n  UPDATE mysql.health_check SET t_modified=now();\r\n  ```\r\n\r\n  节点可用性的检测都应该包含主库和备库，为了让主备之间的更新不产生冲突，可以在 mysql.health_check 表上存入多行数据，并用主备的 server_id 做主键，保证主、备库各自的检测命令不会发生冲突\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n#### 基于位点\r\n\r\n主库上位后，从库 B 执行 CHANGE MASTER TO 命令，指定 MASTER_LOG_FILE、MASTER_LOG_POS 表示从新主库 A 的哪个文件的哪个位点开始同步，这个位置就是**同步位点**，对应主库的文件名和日志偏移量\r\n\r\n寻找位点需要找一个稍微往前的，然后再通过判断跳过那些在从库 B 上已经执行过的事务，获取位点方法：\r\n\r\n* 等待新主库 A 把中转日志（relay log）全部同步完成\r\n* 在 A 上执行 show master status 命令，得到当前 A 上最新的 File 和 Position\r\n* 取原主库故障的时刻 T，用 mysqlbinlog 工具解析新主库 A 的 File，得到 T 时刻的位点\r\n\r\n通常情况下该值并不准确，在切换的过程中会发生错误，所以要先主动跳过这些错误：\r\n\r\n* 切换过程中，可能会重复执行一个事务，所以需要主动跳过所有重复的事务\r\n\r\n  ```bash\r\n  SET GLOBAL sql_slave_skip_counter=1;\r\n  START SLAVE;\r\n  ```\r\n\r\n* 设置 slave_skip_errors 参数，直接设置跳过指定的错误，保证主从切换的正常进行\r\n\r\n  * 1062 错误是插入数据时唯一键冲突\r\n  * 1032 错误是删除数据时找不到行\r\n\r\n  该方法针对的是主备切换时，由于找不到精确的同步位点，只能采用这种方法来创建从库和新主库的主备关系。等到主备间的同步关系建立完成并稳定执行一段时间后，还需要把这个参数设置为空，以免真的出现了主从数据不一致也跳过了\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 基于GTID\r\n\r\n##### GTID\r\n\r\nGTID 的全称是 Global Transaction Identifier，全局事务 ID，是一个事务**在提交时生成**的，是这个事务的唯一标识，组成：\r\n\r\n```bash\r\nGTID=source_id:transaction_id\r\n```\r\n\r\n* source_id：是一个实例第一次启动时自动生成的，是一个全局唯一的值\r\n* transaction_id：初始值是 1，每次提交事务的时候分配给这个事务，并加 1，是连续的（区分事务 ID，事务 ID 是在执行时生成）\r\n\r\n启动 MySQL 实例时，加上参数 `gtid_mode=on` 和 `enforce_gtid_consistency=on` 就可以启动 GTID 模式，每个事务都会和一个 GTID 一一对应，每个 MySQL 实例都维护了一个 GTID 集合，用来存储当前实例**执行过的所有事务**\r\n\r\nGTID 有两种生成方式，使用哪种方式取决于 session 变量 gtid_next：\r\n\r\n* `gtid_next=automatic`：使用默认值，把 source_id:transaction_id （递增）分配给这个事务，然后加入本实例的 GTID 集合\r\n\r\n  ```bash\r\n  @@SESSION.GTID_NEXT = 'source_id:transaction_id';\r\n  ```\r\n\r\n* `gtid_next=GTID`：指定的 GTID 的值，如果该值已经存在于实例的 GTID 集合中，接下来执行的事务会直接被系统忽略；反之就将该值分配给接下来要执行的事务，系统不需要给这个事务生成新的 GTID，也不用加 1\r\n\r\n  注意：一个 GTID 只能给一个事务使用，所以执行下一个事务，要把 gtid_next 设置成另外一个 GTID 或者 automatic\r\n\r\n业务场景：\r\n\r\n* 主库 X 和从库 Y 执行一条相同的指令后进行事务同步\r\n\r\n  ```bash\r\n  INSERT INTO t VALUES(1,1);\r\n  ```\r\n\r\n* 当 Y 同步 X 时，会出现主键冲突，导致实例 X 的同步线程停止，解决方法：\r\n\r\n  ```bash\r\n  SET gtid_next='(这里是主库 X 的 GTID 值)';\r\n  BEGIN;\r\n  COMMIT;\r\n  SET gtid_next=automatic;\r\n  START SLAVE;\r\n  ```\r\n\r\n  前三条语句通过**提交一个空事务**，把 X 的 GTID 加到实例 Y 的 GTID 集合中，实例 Y 就会直接跳过这个事务\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 切换\r\n\r\n在 GTID 模式下，CHANGE MASTER TO 不需要指定日志名和日志偏移量，指定 `master_auto_position=1` 代表使用 GTID 模式\r\n\r\n新主库实例 A 的 GTID 集合记为 set_a，从库实例 B 的 GTID 集合记为 set_b，主备切换逻辑：\r\n\r\n* 实例 B 指定主库 A，基于主备协议建立连接，实例 B 并把 set_b 发给主库 A\r\n* 实例 A 算出 set_a 与 set_b 的差集，就是所有存在于 set_a 但不存在于 set_b 的 GTID 的集合，判断 A 本地是否包含了这个**差集**需要的所有 binlog 事务\r\n  * 如果不包含，表示 A 已经把实例 B 需要的 binlog 给删掉了，直接返回错误\r\n  * 如果确认全部包含，A 从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B\r\n* 实例 A 之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行\r\n\r\n\r\n\r\n参考文章：https://time.geekbang.org/column/article/77427\r\n\r\n\r\n\r\n***\r\n\r\n\r\n"},{"title":"MySQL - 系统优化","tags":["SQL"],"categories":["MySQL","优化篇"],"author":"imklaus","excerpt":"\r\n目录指引：\r\n\r\n[[toc]]\r\n\r\n## 表优化\r\n\r\n### 分区表\r\n\r\n#### 基本介绍\r\n\r\n分区表是将大表的数据按分区字段分成许多小的子集，建立一个以 ftime 年份为分区的表：","link":"/posts/MySQL_Optimization","content":"\r\n目录指引：\r\n\r\n[[toc]]\r\n\r\n## 表优化\r\n\r\n### 分区表\r\n\r\n#### 基本介绍\r\n\r\n分区表是将大表的数据按分区字段分成许多小的子集，建立一个以 ftime 年份为分区的表：\r\n\r\n```bash\r\nCREATE TABLE `t` (\r\n    `ftime` datetime NOT NULL,\r\n    `c` int(11) DEFAULT NULL,\r\n    KEY (`ftime`)\r\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\r\nPARTITION BY RANGE (YEAR(ftime))\r\n(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,\r\n PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,\r\n PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,\r\n PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);\r\nINSERT INTO t VALUES('2017-4-1',1),('2018-4-1',1);-- 这两行记录分别落在 p_2018 和 p_2019 这两个分区上\r\n```\r\n\r\n这个表包含了一个.frm 文件和 4 个.ibd 文件，每个分区对应一个.ibd 文件\r\n\r\n* 对于引擎层来说，这是 4 个表，针对每个分区表的操作不会相互影响\r\n* 对于 Server 层来说，这是 1 个表\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 分区策略\r\n\r\n打开表行为：第一次访问一个分区表时，MySQL 需要**把所有的分区都访问一遍**，如果分区表的数量很多，超过了 open_files_limit 参数（默认值 1024），那么就会在访问这个表时打开所有的文件，导致打开表文件的个数超过了上限而报错\r\n\r\n通用分区策略：MyISAM 分区表使用的分区策略，每次访问分区都由 Server 层控制，在文件管理、表管理的实现上很粗糙，因此有比较严重的性能问题\r\n\r\n本地分区策略：从 MySQL 5.7.9 开始，InnoDB 引擎内部自己管理打开分区的行为，InnoDB 引擎打开文件超过 innodb_open_files 时就会**关掉一些之前打开的文件**，所以即使分区个数大于 open_files_limit，也不会报错\r\n\r\n从 MySQL 8.0 版本开始，就不允许创建 MyISAM 分区表，只允许创建已经实现了本地分区策略的引擎，目前只有 InnoDB 和 NDB 这两个引擎支持了本地分区策略\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### Server 层\r\n\r\n从 Server 层看一个分区表就只是一个表\r\n\r\n* Session A：\r\n\r\n  ```bash\r\n  SELECT * FROM t WHERE ftime = '2018-4-1';\r\n  ```\r\n\r\n* Session B：\r\n\r\n  ```bash\r\n  ALTER TABLE t TRUNCATE PARTITION p_2017; -- blocked\r\n  ```\r\n\r\n现象：Session B 只操作 p_2017 分区，但是由于 Session A 持有整个表 t 的 MDL 读锁，就导致 B 的 ALTER 语句获取 MDL 写锁阻塞\r\n\r\n分区表的特点：\r\n\r\n* 第一次访问的时候需要访问所有分区\r\n* 在 Server 层认为这是同一张表，因此**所有分区共用同一个 MDL 锁**\r\n* 在引擎层认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问需要的分区\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 应用场景\r\n\r\n分区表的优点：\r\n\r\n* 对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁\r\n\r\n* 分区表可以很方便的清理历史数据。按照时间分区的分区表，就可以直接通过 `alter table t drop partition` 这个语法直接删除分区文件，从而删掉过期的历史数据，与使用 drop 语句删除数据相比，优势是速度快、对系统影响小\r\n\r\n使用分区表，不建议创建太多的分区，注意事项：\r\n\r\n* 分区并不是越细越好，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表\r\n* 分区不要提前预留太多，在使用之前预先创建即可。比如是按月分区，每年年底时再把下一年度的 12 个新分区创建上即可，并且对于没有数据的历史分区，要及时的 drop 掉\r\n\r\n\r\n\r\n参考文档：https://time.geekbang.org/column/article/82560\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 临时表\r\n\r\n#### 基本介绍\r\n\r\n临时表分为内部临时表和用户临时表\r\n\r\n* 内部临时表：系统执行 SQL 语句优化时产生的表，例如 Join 连接查询、去重查询等\r\n\r\n* 用户临时表：用户主动创建的临时表\r\n\r\n  ```bash\r\n  CREATE TEMPORARY TABLE temp_t like table_1;\r\n  ```\r\n\r\n临时表可以是内存表，也可以是磁盘表（多表操作 → 嵌套查询章节提及）\r\n\r\n* 内存表指的是使用 Memory 引擎的表，建立哈希索引，建表语法是 `create table … engine=memory`，这种表的数据都保存在内存里，系统重启时会被清空，但是表结构还在\r\n* 磁盘表是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，建立 B+ 树索引，写数据的时候是写到磁盘上的\r\n\r\n临时表的特点：\r\n\r\n* 一个临时表只能被创建它的 session 访问，对其他线程不可见，所以不同 session 的临时表是**可以重名**的\r\n* 临时表可以与普通表同名，会话内有同名的临时表和普通表时，执行 show create 语句以及增删改查语句访问的都是临时表\r\n* show tables 命令不显示临时表\r\n* 数据库发生异常重启不需要担心数据删除问题，临时表会**自动回收**\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 重名原理\r\n\r\n执行创建临时表的 SQL：\r\n\r\n```bash\r\ncreate temporary table temp_t(id int primary key)engine=innodb;\r\n```\r\n\r\nMySQL 给 InnoDB 表创建一个 frm 文件保存表结构定义，在 ibd 保存表数据。frm 文件放在临时文件目录下，文件名的后缀是 .frm，**前缀是** `#sql{进程 id}_{线程 id}_ 序列号`，使用 `select @@tmpdir` 命令，来显示实例的临时文件目录\r\n\r\nMySQL 维护数据表，除了物理磁盘上的文件外，内存里也有一套机制区别不同的表，每个表都对应一个 table_def_key\r\n\r\n* 一个普通表的 table_def_key 的值是由 `库名 + 表名` 得到的，所以如果在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现 table_def_key 已经存在了\r\n* 对于临时表，table_def_key 在 `库名 + 表名` 基础上，又加入了 `server_id + thread_id`，所以不同线程之间，临时表可以重名\r\n\r\n实现原理：每个线程都维护了自己的临时表链表，每次 session 内操作表时，先遍历链表，检查是否有这个名字的临时表，如果有就**优先操作临时表**，如果没有再操作普通表；在 session 结束时对链表里的每个临时表，执行 `DROP TEMPORARY TABLE + 表名` 操作\r\n\r\n执行 rename table 语句无法修改临时表，因为会按照 `库名 / 表名.frm` 的规则去磁盘找文件，但是临时表文件名的规则是 `#sql{进程 id}_{线程 id}_ 序列号.frm`，因此会报找不到文件名的错误\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 主备复制\r\n\r\n创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。主库在线程退出时会自动删除临时表，但备库同步线程是持续在运行的并不会退出，所以这时就需要在主库上再写一个 DROP TEMPORARY TABLE 传给备库执行\r\n\r\nbinlog 日志写入规则：\r\n\r\n* binlog_format=row，跟临时表有关的语句就不会记录到 binlog\r\n* binlog_format=statment/mixed，binlog 中才会记录临时表的操作，也就会记录 `DROP TEMPORARY TABLE` 这条命令\r\n\r\n主库上不同的线程创建同名的临时表是不冲突的，但是备库只有一个执行线程，所以 MySQL 在记录 binlog 时会把主库执行这个语句的线程 id 写到 binlog 中，在备库的应用线程就可以获取执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key\r\n\r\n* session A 的临时表 t1，在备库的 table_def_key 就是：`库名 + t1 +“M 的 serverid\" + \"session A 的 thread_id”`\r\n* session B 的临时表 t1，在备库的 table_def_key 就是 ：`库名 + t1 +\"M 的 serverid\" + \"session B 的 thread_id\"`\r\n\r\nMySQL 在记录 binlog 的时不论是 create table 还是 alter table 语句都是原样记录，但是如果执行 drop table，系统记录 binlog 就会被服务端改写\r\n\r\n```bash\r\nDROP TABLE `t_normal` /* generated by server */\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 跨库查询\r\n\r\n分库分表系统的跨库查询使用临时表不用担心线程之间的重名冲突，分库分表就是要把一个逻辑上的大表分散到不同的数据库实例上\r\n\r\n比如将一个大表 ht，按照字段 f，拆分成 1024 个分表，分布到 32 个数据库实例上，一般情况下都有一个中间层 proxy 解析 SQL 语句，通过分库规则通过分表规则（比如 N%1024）确定将这条语句路由到哪个分表做查询\r\n\r\n```bash\r\nselect v from ht where f=N;\r\n```\r\n\r\n如果这个表上还有另外一个索引 k，并且查询语句：\r\n\r\n```bash\r\nselect v from ht where k >= M order by t_modified desc limit 100;\r\n```\r\n\r\n查询条件里面没有用到分区字段 f，只能**到所有的分区**中去查找满足条件的所有行，然后统一做 order by 操作，两种方式：\r\n\r\n* 在 proxy 层的进程代码中实现排序，拿到分库的数据以后，直接在内存中参与计算，但是对 proxy 端的压力比较大，很容易出现内存不够用和 CPU 瓶颈问题\r\n* 把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作，执行流程：\r\n  * 在汇总库上创建一个临时表 temp_ht，表里包含三个字段 v、k、t_modified\r\n  * 在各个分库执行：`select v,k,t_modified from ht_x where k >= M order by t_modified desc limit 100`\r\n  * 把分库执行的结果插入到 temp_ht 表中\r\n  * 在临时表上执行：`select v from temp_ht order by t_modified desc limit 100`\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n## 优化步骤\r\n\r\n### 执行频率\r\n\r\nMySQL 客户端连接成功后，查询服务器状态信息：\r\n\r\n```bash\r\nSHOW [SESSION|GLOBAL] STATUS LIKE '';\r\n-- SESSION: 显示当前会话连接的统计结果，默认参数\r\n-- GLOBAL: 显示自数据库上次启动至今的统计结果\r\n```\r\n\r\n* 查看 SQL 执行频率：\r\n\r\n  ```bash\r\n  SHOW STATUS LIKE 'Com_____';\r\n  ```\r\n\r\n  Com_xxx 表示每种语句执行的次数\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-SQL语句执行频率.png)\r\n\r\n* 查询 SQL 语句影响的行数：\r\n\r\n  ```bash\r\n  SHOW STATUS LIKE 'Innodb_rows_%';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-SQL语句影响的行数.png)\r\n\r\nCom_xxxx：这些参数对于所有存储引擎的表操作都会进行累计\r\n\r\nInnodb_xxxx：这几个参数只是针对 InnoDB 存储引擎的，累加的算法也略有不同\r\n\r\n| 参数                 | 含义                                                         |\r\n| :------------------- | ------------------------------------------------------------ |\r\n| Com_select           | 执行 SELECT 操作的次数，一次查询只累加 1                     |\r\n| Com_insert           | 执行 INSERT 操作的次数，对于批量插入的 INSERT 操作，只累加一次 |\r\n| Com_update           | 执行 UPDATE 操作的次数                                       |\r\n| Com_delete           | 执行 DELETE 操作的次数                                       |\r\n| Innodb_rows_read     | 执行 SELECT 查询返回的行数                                   |\r\n| Innodb_rows_inserted | 执行 INSERT 操作插入的行数                                   |\r\n| Innodb_rows_updated  | 执行 UPDATE 操作更新的行数                                   |\r\n| Innodb_rows_deleted  | 执行 DELETE 操作删除的行数                                   |\r\n| Connections          | 试图连接 MySQL 服务器的次数                                  |\r\n| Uptime               | 服务器工作时间                                               |\r\n| Slow_queries         | 慢查询的次数                                                 |\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 定位低效\r\n\r\nSQL 执行慢有两种情况：\r\n\r\n* 偶尔慢：DB 在刷新脏页（学完事务就懂了）\r\n  * redo log 写满了\r\n  * 内存不够用，要从 LRU 链表中淘汰\r\n  * MySQL 认为系统空闲的时候\r\n  * MySQL 关闭时\r\n* 一直慢的原因：索引没有设计好、SQL 语句没写好、MySQL 选错了索引\r\n\r\n通过以下两种方式定位执行效率较低的 SQL 语句\r\n\r\n* 慢日志查询： 慢查询日志在查询结束以后才记录，执行效率出现问题时查询日志并不能定位问题\r\n\r\n  配置文件修改：修改 .cnf 文件 `vim /etc/mysql/my.cnf`，重启 MySQL 服务器\r\n\r\n  ```sh\r\n  slow_query_log=ON\r\n  slow_query_log_file=/usr/local/mysql/var/localhost-slow.log\r\n  long_query_time=1\t#记录超过long_query_time秒的SQL语句的日志\r\n  log-queries-not-using-indexes = 1\r\n  ```\r\n\r\n  使用命令配置：\r\n\r\n  ```bash\r\n  mysql> SET slow_query_log=ON;\r\n  mysql> SET GLOBAL slow_query_log=ON;\r\n  ```\r\n\r\n  查看是否配置成功：\r\n\r\n  ```bash\r\n  SHOW VARIABLES LIKE '%query%'\r\n  ```\r\n\r\n* SHOW PROCESSLIST：**实时查看**当前 MySQL 在进行的连接线程，包括线程的状态、是否锁表、SQL 的执行情况，同时对一些锁表操作进行优化\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-SHOW_PROCESSLIST命令.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### EXPLAIN\r\n\r\n#### 执行计划\r\n\r\n通过 EXPLAIN 命令获取执行 SQL 语句的信息，包括在 SELECT 语句执行过程中如何连接和连接的顺序，执行计划在优化器优化完成后、执行器之前生成，然后执行器会调用存储引擎检索数据\r\n\r\n查询 SQL 语句的执行计划：\r\n\r\n```bash\r\nEXPLAIN SELECT * FROM table_1 WHERE id = 1;\r\n```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-explain查询SQL语句的执行计划.png)\r\n\r\n| 字段          | 含义                                                         |\r\n| ------------- | ------------------------------------------------------------ |\r\n| id            | SELECT 的序列号                                              |\r\n| select_type   | 表示 SELECT 的类型                                           |\r\n| table         | 访问数据库中表名称，有时可能是简称或者临时表名称（<table_name>） |\r\n| type          | 表示表的连接类型                                             |\r\n| possible_keys | 表示查询时，可能使用的索引                                   |\r\n| key           | 表示实际使用的索引                                           |\r\n| key_len       | 索引字段的长度                                               |\r\n| ref           | 表示与索引列进行等值匹配的对象，常数、某个列、函数等，type 必须在（range, const] 之间，左闭右开 |\r\n| rows          | 扫描出的行数，表示 MySQL 根据表统计信息及索引选用情况，**估算**的找到所需的记录扫描的行数 |\r\n| filtered      | 条件过滤的行百分比，单表查询没意义，用于连接查询中对驱动表的扇出进行过滤，查询优化器预测所有扇出值满足剩余查询条件的百分比，相乘以后表示多表查询中还要对被驱动执行查询的次数 |\r\n| extra         | 执行情况的说明和描述                                         |\r\n\r\nMySQL **执行计划的局限**：\r\n\r\n* 只是计划，不是执行 SQL 语句，可以随着底层优化器输入的更改而更改\r\n* EXPLAIN 不会告诉显示关于触发器、存储过程的信息对查询的影响情况， 不考虑各种 Cache\r\n* EXPLAIN 不能显示 MySQL 在执行查询时的动态，因为执行计划在执行**查询之前生成**\r\n* EXPALIN 只能解释 SELECT 操作，其他操作要重写为 SELECT 后查看执行计划\r\n* EXPLAIN PLAN 显示的是在解释语句时数据库将如何运行 SQL 语句，由于执行环境和 EXPLAIN PLAN 环境的不同，此计划可能与 SQL 语句**实际的执行计划不同**，部分统计信息是估算的，并非精确值\r\n\r\nSHOW WARINGS：在使用 EXPALIN 命令后执行该语句，可以查询与执行计划相关的拓展信息，展示出 Level、Code、Message 三个字段，当 Code 为 1003 时，Message 字段展示的信息类似于将查询语句重写后的信息，但是不是等价，不能执行复制过来运行\r\n\r\n环境准备：\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-执行计划环境准备.png)\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### id\r\n\r\nid 代表 SQL 执行的顺序的标识，每个 SELECT 关键字对应一个唯一 id，所以在同一个 SELECT 关键字中的表的 id 都是相同的。SELECT 后的 FROM 可以跟随多个表，每个表都会对应一条记录，这些记录的 id 都是相同的，\r\n\r\n* id 相同时，执行顺序由上至下。连接查询的执行计划，记录的 id 值都是相同的，出现在前面的表为驱动表，后面为被驱动表\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM t_role r, t_user u, user_role ur WHERE r.id = ur.role_id AND u.id = ur.user_id ;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-explain之id相同.png)\r\n\r\n* id 不同时，id 值越大优先级越高，越先被执行\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM t_role WHERE id = (SELECT role_id FROM user_role WHERE user_id = (SELECT id FROM t_user WHERE username = 'stu1'))\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-explain之id不同.png)\r\n\r\n* id 有相同也有不同时，id 相同的可以认为是一组，从上往下顺序执行；在所有的组中，id 的值越大的组，优先级越高，越先执行\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM t_role r , (SELECT * FROM user_role ur WHERE ur.`user_id` = '2') a WHERE r.id = a.role_id ; \r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-explain之id相同和不同.png)\r\n\r\n* id 为 NULL 时代表的是临时表\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### select\r\n\r\n表示查询中每个 select 子句的类型（简单 OR 复杂）\r\n\r\n| select_type        | 含义                                                         |\r\n| ------------------ | ------------------------------------------------------------ |\r\n| SIMPLE             | 简单的 SELECT 查询，查询中不包含子查询或者 UNION             |\r\n| PRIMARY            | 查询中若包含任何复杂的子查询，最外层（也就是最左侧）查询标记为该标识 |\r\n| UNION              | 对于 UNION 或者 UNION ALL 的复杂查询，除了最左侧的查询，其余的小查询都是 UNION |\r\n| UNION RESULT       | UNION 需要使用临时表进行去重，临时表的是 UNION RESULT        |\r\n| DEPENDENT UNION    | 对于 UNION 或者 UNION ALL 的复杂查询，如果各个小查询都依赖外层查询，是相关子查询，除了最左侧的小查询为 DEPENDENT SUBQUERY，其余都是 DEPENDENT UNION |\r\n| SUBQUERY           | 子查询不是相关子查询，该子查询第一个 SELECT 代表的查询就是这种类型，会进行物化（该子查询只需要执行一次） |\r\n| DEPENDENT SUBQUERY | 子查询是相关子查询，该子查询第一个 SELECT 代表的查询就是这种类型，不会物化（该子查询需要执行多次） |\r\n| DERIVED            | 在 FROM 列表中包含的子查询，被标记为 DERIVED（衍生），也就是生成物化派生表的这个子查询 |\r\n| MATERIALIZED       | 将子查询物化后与与外层进行连接查询，生成物化表的子查询       |\r\n\r\n子查询为 DERIVED：`SELECT * FROM (SELECT key1 FROM t1) AS derived_1 WHERE key1 > 10`\r\n\r\n子查询为 MATERIALIZED：`SELECT * FROM t1 WHERE key1 IN (SELECT key1 FROM t2)`\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### type\r\n\r\n对表的访问方式，表示 MySQL 在表中找到所需行的方式，又称访问类型\r\n\r\n| type            | 含义                                                         |\r\n| --------------- | ------------------------------------------------------------ |\r\n| ALL             | 全表扫描，如果是 InnoDB 引擎是扫描聚簇索引                   |\r\n| index           | 可以使用覆盖索引，但需要扫描全部索引                         |\r\n| range           | 索引范围扫描，常见于 between、<、> 等的查询                  |\r\n| index_subquery  | 子查询可以普通索引，则子查询的 type 为 index_subquery        |\r\n| unique_subquery | 子查询可以使用主键或唯一二级索引，则子查询的 type 为 index_subquery |\r\n| index_merge     | 索引合并                                                     |\r\n| ref_or_null     | 非唯一性索引（普通二级索引）并且可以存储 NULL，进行等值匹配  |\r\n| ref             | 非唯一性索引与常量等值匹配                                   |\r\n| eq_ref          | 唯一性索引（主键或不存储 NULL 的唯一二级索引）进行等值匹配，如果二级索引是联合索引，那么所有联合的列都要进行等值匹配 |\r\n| const           | 通过主键或者唯一二级索引与常量进行等值匹配                   |\r\n| system          | system 是 const 类型的特例，当查询的表只有一条记录的情况下，使用 system |\r\n| NULL            | MySQL 在优化过程中分解语句，执行时甚至不用访问表或索引       |\r\n\r\n从上到下，性能从差到好，一般来说需要保证查询至少达到 range 级别， 最好达到 ref \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### key\r\n\r\npossible_keys：\r\n\r\n* 指出 MySQL 能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用\r\n* 如果该列是 NULL，则没有相关的索引\r\n\r\nkey：\r\n\r\n* 显示 MySQL 在查询中实际使用的索引，若没有使用索引，显示为 NULL\r\n* 查询中若使用了**覆盖索引**，则该索引可能出现在 key 列表，不出现在 possible_keys\r\n\r\nkey_len：\r\n\r\n* 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度\r\n* key_len 显示的值为索引字段的最大可能长度，并非实际使用长度，即 key_len 是根据表定义计算而得，不是通过表内检索出的\r\n* 在不损失精确性的前提下，长度越短越好 \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### Extra\r\n\r\n其他的额外的执行计划信息，在该列展示：\r\n\r\n* No tables used：查询语句中使用 FROM dual 或者没有 FROM 语句\r\n* Impossible WHERE：查询语句中的 WHERE 子句条件永远为 FALSE，会导致没有符合条件的行\r\n* Using index：该值表示相应的 SELECT 操作中使用了**覆盖索引**（Covering Index）\r\n* Using index condition：第一种情况是搜索条件中虽然出现了索引列，但是部分条件无法形成扫描区间（**索引失效**），会根据可用索引的条件先搜索一遍再匹配无法使用索引的条件，回表查询数据；第二种是使用了**索引条件下推**优化\r\n* Using where：搜索的数据需要在 Server 层判断，无法使用索引下推\r\n* Using join buffer：连接查询被驱动表无法利用索引，需要连接缓冲区来存储中间结果\r\n* Using filesort：无法利用索引完成排序（优化方向），需要对数据使用外部排序算法，将取得的数据在内存或磁盘中进行排序\r\n* Using temporary：表示 MySQL 需要使用临时表来存储结果集，常见于**排序、去重（UNION）、分组**等场景\r\n* Select tables optimized away：说明仅通过使用索引，优化器可能仅从聚合函数结果中返回一行\r\n* No tables used：Query 语句中使用 from dual 或不含任何 from 子句\r\n\r\n\r\n\r\n参考文章：https://www.cnblogs.com/ggjucheng/archive/2012/11/11/2765237.html\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### PROFILES\r\n\r\nSHOW PROFILES 能够在做 SQL 优化时分析当前会话中语句执行的**资源消耗**情况\r\n\r\n* 通过 have_profiling 参数，能够看到当前 MySQL 是否支持 profile：\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-have_profiling.png)\r\n\r\n* 默认 profiling 是关闭的，可以通过 set 语句在 Session 级别开启 profiling：\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-profiling.png)\r\n\r\n  ```bash\r\n  SET profiling=1; #开启profiling 开关；\r\n  ```\r\n\r\n* 执行 SHOW PROFILES 指令， 来查看 SQL 语句执行的耗时:\r\n\r\n  ```bash\r\n  SHOW PROFILES;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-查看SQL语句执行耗时.png)\r\n\r\n* 查看到该 SQL 执行过程中每个线程的状态和消耗的时间：\r\n\r\n  ```bash\r\n  SHOW PROFILE FOR QUERY query_id;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-SQL执行每个状态消耗的时间.png)\r\n\r\n* 在获取到最消耗时间的线程状态后，MySQL 支持选择 all、cpu、block io 、context switch、page faults 等类型查看 MySQL 在使用什么资源上耗费了过高的时间。例如，选择查看 CPU 的耗费时间：\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-SQL执行每个状态消耗的CPU.png)\r\n\r\n  * Status：SQL 语句执行的状态\r\n  * Durationsql：执行过程中每一个步骤的耗时\r\n  * CPU_user：当前用户占有的 CPU\r\n  * CPU_system：系统占有的 CPU\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### TRACE\r\n\r\nMySQL 提供了对 SQL 的跟踪， 通过 trace 文件可以查看优化器**生成执行计划的过程**\r\n\r\n* 打开 trace 功能，设置格式为 JSON，并设置 trace 的最大使用内存，避免解析过程中因默认内存过小而不能够完整展示\r\n\r\n  ```bash\r\n  SET optimizer_trace=\"enabled=on\",end_markers_in_json=ON;\t-- 会话内有效\r\n  SET optimizer_trace_max_mem_size=1000000;\r\n  ```\r\n\r\n* 执行 SQL 语句：\r\n\r\n  ```bash\r\n  SELECT * FROM tb_item WHERE id < 4;\r\n  ```\r\n\r\n* 检查 information_schema.optimizer_trace：\r\n\r\n  ```bash\r\n  SELECT * FROM information_schema.optimizer_trace \\G; -- \\G代表竖列展示\r\n  ```\r\n\r\n  执行信息主要有三个阶段：prepare 阶段、optimize 阶段（成本分析）、execute 阶段（执行）\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n## 索引优化\r\n\r\n### 创建索引\r\n\r\n索引是数据库优化最重要的手段之一，通过索引通常可以帮助用户解决大多数的 MySQL 的性能优化问题\r\n\r\n```bash\r\nCREATE TABLE `tb_seller` (\r\n\t`sellerid` varchar (100),\r\n\t`name` varchar (100),\r\n\t`nickname` varchar (50),\r\n\t`password` varchar (60),\r\n\t`status` varchar (1),\r\n\t`address` varchar (100),\r\n\t`createtime` datetime,\r\n    PRIMARY KEY(`sellerid`)\r\n)ENGINE=INNODB DEFAULT CHARSET=utf8mb4;\r\nINSERT INTO `tb_seller` (`sellerid`, `name`, `nickname`, `password`, `status`, `address`, `createtime`) values('xiaomi','小米科技','小米官方旗舰店','e10adc3949ba59abbe56e057f20f883e','1','西安市','2088-01-01 12:00:00');\r\nCREATE INDEX idx_seller_name_sta_addr ON tb_seller(name, status, address); # 联合索引\r\n```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引环境准备.png)\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 避免失效\r\n\r\n#### 语句错误\r\n\r\n* 全值匹配：对索引中所有列都指定具体值，这种情况索引生效，执行效率高\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name='小米科技' AND status='1' AND address='西安市';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引1.png)\r\n\r\n* **最左前缀法则**：联合索引遵守最左前缀法则\r\n\r\n  匹配最左前缀法则，走索引：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name='小米科技';\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name='小米科技' AND status='1';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引2.png)\r\n\r\n  违法最左前缀法则 ， 索引失效：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE status='1';\r\n  EXPLAIN SELECT * FROM tb_seller WHERE status='1' AND address='西安市';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引3.png)\r\n\r\n  如果符合最左法则，但是出现跳跃某一列，只有最左列索引生效：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name='小米科技' AND address='西安市';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引4.png)\r\n\r\n  虽然索引列失效，但是系统会**使用了索引下推进行了优化**\r\n\r\n* **范围查询**右边的列，不能使用索引：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name='小米科技' AND status>'1' AND address='西安市';\r\n  ```\r\n\r\n  根据前面的两个字段 name ， status 查询是走索引的， 但是最后一个条件 address 没有用到索引，使用了索引下推\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引5.png)\r\n\r\n* 在索引列上**函数或者运算（+ - 数值）操作**， 索引将失效：会破坏索引值的有序性\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE SUBSTRING(name,3,2) = '科技';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引6.png)\r\n\r\n* **字符串不加单引号**，造成索引失效：隐式类型转换，当字符串和数字比较时会**把字符串转化为数字**\r\n\r\n  没有对字符串加单引号，查询优化器会调用 CAST 函数将 status 转换为 int 进行比较，造成索引失效\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name='小米科技' AND status = 1;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引7.png)\r\n\r\n  如果 status 是 int 类型，SQL 为 `SELECT * FROM tb_seller WHERE status = '1' ` 并不会造成索引失效，因为会将 `'1'` 转换为 `1`，并**不会对索引列产生操作**\r\n\r\n* 多表连接查询时，如果两张表的**字符集不同**，会造成索引失效，因为会进行类型转换\r\n\r\n  解决方法：CONVERT 函数是加在输入参数上、修改表的字符集\r\n\r\n* **用 OR 分割条件，索引失效**，导致全表查询：\r\n\r\n  OR 前的条件中的列有索引而后面的列中没有索引或 OR 前后两个列是同一个复合索引，都造成索引失效\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name='阿里巴巴' OR createtime = '2088-01-01 12:00:00';\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name='小米科技' OR status='1';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引10.png)\r\n\r\n  **AND 分割的条件不影响**：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name='阿里巴巴' AND createtime = '2088-01-01 12:00:00';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引11.png)\r\n\r\n* **以 % 开头的 LIKE 模糊查询**，索引失效：\r\n\r\n  如果是尾部模糊匹配，索引不会失效；如果是头部模糊匹配，索引失效\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name like '%科技%';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引12.png)\r\n\r\n  解决方案：通过覆盖索引来解决 \r\n\r\n  ```bash\r\n  EXPLAIN SELECT sellerid,name,status FROM tb_seller WHERE name like '%科技%';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引13.png)\r\n\r\n  原因：在覆盖索引的这棵 B+ 数上只需要进行 like 的匹配，或者是基于覆盖索引查询再进行 WHERE 的判断就可以获得结果\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 系统优化\r\n\r\n系统优化为全表扫描：\r\n\r\n* 如果 MySQL 评估使用索引比全表更慢，则不使用索引，索引失效：\r\n\r\n  ```bash\r\n  CREATE INDEX idx_address ON tb_seller(address);\r\n  EXPLAIN SELECT * FROM tb_seller WHERE address='西安市';\r\n  EXPLAIN SELECT * FROM tb_seller WHERE address='北京市';\r\n  ```\r\n\r\n  北京市的键值占 9/10（区分度低），所以优化为全表扫描，type = ALL\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引14.png)\r\n\r\n* IS  NULL、IS NOT NULL  **有时**索引失效：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name IS NULL;\r\n  EXPLAIN SELECT * FROM tb_seller WHERE name IS NOT NULL;\r\n  ```\r\n\r\n  NOT NULL 失效的原因是 name 列全部不是 null，优化为全表扫描，当 NULL 过多时，IS NULL 失效\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引15.png)\r\n\r\n* IN 肯定会走索引，但是当 IN 的取值范围较大时会导致索引失效，走全表扫描：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller WHERE sellerId IN ('alibaba','huawei');-- 都走索引\r\n  EXPLAIN SELECT * FROM tb_seller WHERE sellerId NOT IN ('alibaba','huawei');\r\n  ```\r\n\r\n* [MySQL 实战 45 讲](https://time.geekbang.org/column/article/74687)该章节最后提出了一种慢查询场景，获取到数据以后 Server 层还会做判断\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 底层原理\r\n\r\n索引失效一般是针对联合索引，联合索引一般由几个字段组成，排序方式是先按照第一个字段进行排序，然后排序第二个，依此类推，图示（a, b）索引，**a 相等的情况下 b 是有序的**\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-索引失效底层原理1.png\" style=\"zoom:67%;\" />\r\n\r\n* 最左前缀法则：当不匹配前面的字段的时候，后面的字段都是无序的。这种无序不仅体现在叶子节点，也会**导致查询时扫描的非叶子节点也是无序的**，因为索引树相当于忽略的第一个字段，就无法使用二分查找\r\n\r\n* 范围查询右边的列，不能使用索引，比如语句： `WHERE a > 1 AND b = 1 `，在 a 大于 1 的时候，b 是无序的，a > 1 是扫描时有序的，但是找到以后进行寻找 b 时，索引树就不是有序的了\r\n\r\n  <img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-索引失效底层原理2.png\" style=\"zoom:67%;\" />\r\n\r\n* 以 % 开头的 LIKE 模糊查询，索引失效，比如语句：`WHERE a LIKE '%d'`，前面的不确定，导致不符合最左匹配，直接去索引中搜索以 d 结尾的节点，所以没有顺序\r\n      ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-索引失效底层原理3.png)\r\n\r\n\r\n\r\n参考文章：https://mp.weixin.qq.com/s/B_M09dzLe9w7cT46rdGIeQ\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 查看索引\r\n\r\n```bash\r\nSHOW STATUS LIKE 'Handler_read%';\t\r\nSHOW GLOBAL STATUS LIKE 'Handler_read%';\r\n```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL查看索引使用情况.png)\r\n\r\n* Handler_read_first：索引中第一条被读的次数，如果较高，表示服务器正执行大量全索引扫描（这个值越低越好）\r\n\r\n* Handler_read_key：如果索引正在工作，这个值代表一个行被索引值读的次数，值越低表示索引不经常使用（这个值越高越好）\r\n\r\n* Handler_read_next：按照键顺序读下一行的请求数，如果范围约束或执行索引扫描来查询索引列，值增加\r\n\r\n* Handler_read_prev：按照键顺序读前一行的请求数，该读方法主要用于优化 ORDER BY ... DESC\r\n\r\n* Handler_read_rnd：根据固定位置读一行的请求数，如果执行大量查询并对结果进行排序则该值较高，可能是使用了大量需要 MySQL 扫描整个表的查询或连接，这个值较高意味着运行效率低，应该建立索引来解决\r\n\r\n* Handler_read_rnd_next：在数据文件中读下一行的请求数，如果正进行大量的表扫描，该值较高，说明表索引不正确或写入的查询没有利用索引\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n## SQL 优化\r\n\r\n### 自增主键\r\n\r\n#### 自增机制\r\n\r\n自增主键可以让主键索引尽量地保持在数据页中递增顺序插入，不自增需要寻找其他页插入，导致随机 IO 和页分裂的情况\r\n\r\n表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值，不同的引擎对于自增值的保存策略不同：\r\n\r\n* MyISAM 引擎的自增值保存在数据文件中\r\n* InnoDB 引擎的自增值保存在了内存里，每次打开表都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为当前的自增值；8.0 版本后，才有了自增值持久化的能力，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值\r\n\r\n在插入一行数据的时候，自增值的行为如下：\r\n\r\n* 如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段\r\n* 如果插入数据时 id 字段指定了具体的值，比如某次要插入的值是 X，当前的自增值是 Y\r\n  * 如果 X<Y，那么这个表的自增值不变\r\n  * 如果 X≥Y，就需要把当前自增值修改为新的自增值\r\n\r\n参数说明：auto_increment_offset 和 auto_increment_increment 分别表示自增的初始值和步长，默认值都是 1\r\n\r\n语句执行失败也不回退自增 id，所以保证了自增 id 是递增的，但不保证是连续的（不能回退，所以有些回滚事务的自增 id 就不会重新使用，导致出现不连续）\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 自增 ID\r\n\r\nMySQL 不同的自增 id 在达到上限后的表现不同：\r\n\r\n* 表的自增 id 如果是 int 类型，达到上限 2^32-1 后，再申请时值就不会改变，进而导致继续插入数据时报主键冲突的错误\r\n\r\n* row_id 长度为 6 个字节，达到上限后则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据，造成旧数据丢失，影响的是数据可靠性，所以应该在 InnoDB 表中主动创建自增主键报主键冲突，插入失败影响的是可用性，而一般情况下，**可靠性优先于可用性**\r\n\r\n* Xid 长度 8 字节，由 Server 层维护，只需要不在同一个 binlog 文件中出现重复值即可，虽然理论上会出现重复值，但是概率极小\r\n\r\n* InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，重启也不会重置为 0，所以会导致一直增加到达上限，然后从 0 开始，这时原事务 0 修改的数据对当前事务就是可见的，产生脏读的现象\r\n\r\n  只读事务不分配 trx_id，所以 trx_id 的增加速度变慢了\r\n\r\n* thread_id 长度 4 个字节，到达上限后就会重置为 0，MySQL 设计了一个唯一数组的逻辑，给新线程分配 thread_id 时做判断，保证不会出现两个相同的 thread_id：\r\n\r\n  ```c++\r\n  do {\r\n  \tnew_id = thread_id_counter++;\r\n  } while (!thread_ids.insert_unique(new_id).second);\r\n  ```\r\n\r\n\r\n\r\n参考文章：https://time.geekbang.org/column/article/83183\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 覆盖索引\r\n\r\n复合索引叶子节点不仅保存了复合索引的值，还有主键索引，所以使用覆盖索引的时候，加上主键也会用到索引\r\n\r\n尽量使用覆盖索引，避免 SELECT *：\r\n\r\n```bash\r\nEXPLAIN SELECT name,status,address FROM tb_seller WHERE name='小米科技' AND status='1' AND address='西安市';\r\n```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引8.png)\r\n\r\n如果查询列，超出索引列，也会降低性能：\r\n\r\n```bash\r\nEXPLAIN SELECT name,status,address,password FROM tb_seller WHERE name='小米科技' AND status='1' AND address='西安市';\r\n```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用索引9.png)\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 减少访问\r\n\r\n避免对数据进行重复检索：能够一次连接就获取到结果的，就不用两次连接，这样可以大大减少对数据库无用的重复请求\r\n\r\n* 查询数据：\r\n\r\n  ```bash\r\n  SELECT id,name FROM tb_book;\r\n  SELECT id,status FROM tb_book; -- 向数据库提交两次请求，数据库就要做两次查询操作\r\n  -- > 优化为:\r\n  SELECT id,name,statu FROM tb_book;\r\n  ```\r\n\r\n* 插入数据：\r\n\r\n  ```bash\r\n  INSERT INTO tb_test VALUES(1,'Tom');\r\n  INSERT INTO tb_test VALUES(2,'Cat');\r\n  INSERT INTO tb_test VALUES(3,'Jerry');\t-- 连接三次数据库\r\n  -- >优化为\r\n  INSERT INTO tb_test VALUES(1,'Tom'),(2,'Cat')，(3,'Jerry');\t-- 连接一次\r\n  ```\r\n\r\n* 在事务中进行数据插入：\r\n\r\n  ```bash\r\n  start transaction;\r\n  INSERT INTO tb_test VALUES(1,'Tom');\r\n  INSERT INTO tb_test VALUES(2,'Cat');\r\n  INSERT INTO tb_test VALUES(3,'Jerry');\r\n  commit;\t-- 手动提交，分段提交\r\n  ```\r\n\r\n* 数据有序插入：\r\n\r\n  ```bash\r\n  INSERT INTO tb_test VALUES(1,'Tom');\r\n  INSERT INTO tb_test VALUES(2,'Cat');\r\n  INSERT INTO tb_test VALUES(3,'Jerry');\r\n  ```\r\n\r\n增加 cache 层：在应用中增加缓存层来达到减轻数据库负担的目的。可以部分数据从数据库中抽取出来放到应用端以文本方式存储，或者使用框架（Mybatis）提供的一级缓存 / 二级缓存，或者使用 Redis 数据库来缓存数据 \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 数据插入\r\n\r\n当使用 load 命令导入数据的时候，适当的设置可以提高导入的效率：\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL load data.png)\r\n\r\n```bash\r\nLOAD DATA LOCAL INFILE = '/home/seazean/sql1.log' INTO TABLE `tb_user_1` FIELD TERMINATED BY ',' LINES TERMINATED BY '\\n'; -- 文件格式如上图\r\n```\r\n\r\n对于 InnoDB 类型的表，有以下几种方式可以提高导入的效率：\r\n\r\n1. **主键顺序插入**：因为 InnoDB 类型的表是按照主键的顺序保存的，所以将导入的数据按照主键的顺序排列，可以有效的提高导入数据的效率，如果 InnoDB 表没有主键，那么系统会自动默认创建一个内部列作为主键\r\n\r\n   主键是否连续对性能影响不大，只要是递增的就可以，比如雪花算法产生的 ID 不是连续的，但是是递增的，因为递增可以让主键索引尽量地保持顺序插入，**避免了页分裂**，因此索引更紧凑\r\n\r\n   * 插入 ID 顺序排列数据：\r\n\r\n   ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL插入ID顺序排列数据.png)\r\n\r\n   * 插入 ID 无序排列数据：\r\n\r\n   ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL插入ID无序排列数据.png)\r\n\r\n2. **关闭唯一性校验**：在导入数据前执行 `SET UNIQUE_CHECKS=0`，关闭唯一性校验；导入结束后执行 `SET UNIQUE_CHECKS=1`，恢复唯一性校验，可以提高导入的效率。\r\n\r\n   ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL插入数据关闭唯一性校验.png)\r\n\r\n3. **手动提交事务**：如果应用使用自动提交的方式，建议在导入前执行`SET AUTOCOMMIT=0`，关闭自动提交；导入结束后再打开自动提交，可以提高导入的效率。\r\n\r\n   事务需要控制大小，事务太大可能会影响执行的效率。MySQL 有 innodb_log_buffer_size 配置项，超过这个值的日志会写入磁盘数据，效率会下降，所以在事务大小达到配置项数据级前进行事务提交可以提高效率\r\n\r\n   ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL插入数据手动提交事务.png)\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 分组排序\r\n\r\n#### ORDER\r\n\r\n数据准备：\r\n\r\n```bash\r\nCREATE TABLE `emp` (\r\n  `id` INT(11) NOT NULL AUTO_INCREMENT,\r\n  `name` VARCHAR(100) NOT NULL,\r\n  `age` INT(3) NOT NULL,\r\n  `salary` INT(11) DEFAULT NULL,\r\n  PRIMARY KEY (`id`)\r\n) ENGINE=INNODB DEFAULT CHARSET=utf8mb4;\r\nINSERT INTO `emp` (`id`, `name`, `age`, `salary`) VALUES('1','Tom','25','2300');-- ...\r\nCREATE INDEX idx_emp_age_salary ON emp(age, salary);\r\n```\r\n\r\n* 第一种是通过对返回数据进行排序，所有不通过索引直接返回结果的排序都叫 FileSort 排序，会在内存中重新排序\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM emp ORDER BY age DESC;\t-- 年龄降序\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL ORDER BY排序1.png)\r\n\r\n* 第二种通过有序索引顺序扫描直接返回**有序数据**，这种情况为 Using index，不需要额外排序，操作效率高\r\n\r\n  ```bash\r\n  EXPLAIN SELECT id, age, salary FROM emp ORDER BY age DESC;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL ORDER BY排序2.png)\r\n\r\n* 多字段排序：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT id,age,salary FROM emp ORDER BY age DESC, salary DESC;\r\n  EXPLAIN SELECT id,age,salary FROM emp ORDER BY salary DESC, age DESC;\r\n  EXPLAIN SELECT id,age,salary FROM emp ORDER BY age DESC, salary ASC;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL ORDER BY排序3.png)\r\n\r\n  尽量减少额外的排序，通过索引直接返回有序数据。**需要满足 Order by 使用相同的索引、Order By 的顺序和索引顺序相同、Order  by 的字段都是升序或都是降序**，否则需要额外的操作，就会出现 FileSort\r\n\r\n* ORDER BY RAND() 命令用来进行随机排序，会使用了临时内存表，临时内存表排序的时使用 rowid 排序方法\r\n\r\n优化方式：创建合适的索引能够减少 Filesort 的出现，但是某些情况下条件限制不能让 Filesort 消失，就要加快 Filesort 的排序操作\r\n\r\n内存临时表，MySQL 有两种 Filesort 排序算法：\r\n\r\n* rowid 排序：首先根据条件取出排序字段和信息，然后在**排序区 sort buffer（Server 层）**中排序，如果 sort buffer 不够，则在临时表 temporary table 中存储排序结果。完成排序后再根据行指针**回表读取记录**，该操作可能会导致大量随机 I/O 操作\r\n\r\n  说明：对于临时内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，不会导致多访问磁盘，优先选择该方式\r\n\r\n* 全字段排序：一次性取出满足条件的所有数据，需要回表，然后在排序区 sort  buffer 中排序后直接输出结果集。排序时内存开销较大，但是排序效率比两次扫描算法高\r\n\r\n具体的选择方式：\r\n\r\n* MySQL 通过比较系统变量 max_length_for_sort_data 的大小和 Query 语句取出的字段的大小，来判定使用哪种排序算法。如果前者大，则说明 sort  buffer 空间足够，使用第二种优化之后的算法，否则使用第一种。\r\n\r\n* 可以适当提高 sort_buffer_size  和 max_length_for_sort_data 系统变量，来增大排序区的大小，提高排序的效率\r\n\r\n  ```bash\r\n  SET @@max_length_for_sort_data = 10000; \t\t-- 设置全局变量\r\n  SET max_length_for_sort_data = 10240; \t\t\t-- 设置会话变量\r\n  SHOW VARIABLES LIKE 'max_length_for_sort_data';\t-- 默认1024\r\n  SHOW VARIABLES LIKE 'sort_buffer_size';\t\t\t-- 默认262114\r\n  ```\r\n\r\n磁盘临时表：排序使用优先队列（堆）的方式\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### GROUP\r\n\r\nGROUP BY 也会进行排序操作，与 ORDER BY 相比，GROUP BY 主要只是多了排序之后的分组操作，所以在 GROUP BY 的实现过程中，与 ORDER BY 一样也可以利用到索引\r\n\r\n* 分组查询：\r\n\r\n  ```bash\r\n  DROP INDEX idx_emp_age_salary ON emp;\r\n  EXPLAIN SELECT age,COUNT(*) FROM emp GROUP BY age;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL GROUP BY排序1.png)\r\n\r\n  Using temporary：表示 MySQL 需要使用临时表（不是 sort buffer）来存储结果集，常见于排序和分组查询\r\n\r\n* 查询包含 GROUP BY 但是用户想要避免排序结果的消耗， 则可以执行 ORDER BY NULL 禁止排序：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT age,COUNT(*) FROM emp GROUP BY age ORDER BY NULL;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL GROUP BY排序2.png)\r\n\r\n* 创建索引：索引本身有序，不需要临时表，也不需要再额外排序\r\n\r\n  ```bash\r\n  CREATE INDEX idx_emp_age_salary ON emp(age, salary);\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL GROUP BY排序3.png)\r\n\r\n* 数据量很大时，使用 SQL_BIG_RESULT 提示优化器直接使用直接用磁盘临时表\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 联合查询\r\n\r\n对于包含 OR 的查询子句，如果要利用索引，则 OR 之间的**每个条件列都必须用到索引，而且不能使用到条件之间的复合索引**，如果没有索引，则应该考虑增加索引\r\n\r\n* 执行查询语句：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM emp WHERE id = 1 OR age = 30;\t-- 两个索引，并且不是复合索引\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL OR条件查询1.png)\r\n\r\n  ```sh\r\n  Extra: Using sort_union(idx_emp_age_salary,PRIMARY); Using where\r\n  ```\r\n\r\n* 使用 UNION 替换 OR，求并集：\r\n\r\n  注意：该优化只针对多个索引列有效，如果有列没有被索引，查询效率可能会因为没有选择 OR 而降低\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM emp WHERE id = 1 UNION SELECT * FROM emp WHERE age = 30;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL OR条件查询2.png)\r\n\r\n* UNION 要优于 OR 的原因：\r\n\r\n  * UNION 语句的 type 值为 ref，OR 语句的 type 值为 range\r\n  * UNION 语句的 ref 值为 const，OR 语句的 ref 值为 null，const 表示是常量值引用，非常快\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 嵌套查询\r\n\r\nMySQL 4.1 版本之后，开始支持 SQL 的子查询\r\n\r\n* 可以使用 SELECT 语句来创建一个单列的查询结果，然后把结果作为过滤条件用在另一个查询中\r\n* 使用子查询可以一次性的完成逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死\r\n* 在有些情况下，**子查询是可以被更高效的连接（JOIN）替代**\r\n\r\n例如查找有角色的所有的用户信息：\r\n\r\n* 执行计划：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM t_user WHERE id IN (SELECT user_id FROM user_role);\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL嵌套查询1.png)\r\n\r\n* 优化后：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM t_user u , user_role ur WHERE u.id = ur.user_id;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL嵌套查询2.png)\r\n\r\n  连接查询之所以效率更高 ，是因为**不需要在内存中创建临时表**来完成逻辑上需要两个步骤的查询工作\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 分页查询\r\n\r\n一般分页查询时，通过创建覆盖索引能够比较好地提高性能\r\n\r\n一个常见的问题是 `LIMIT 200000,10`，此时需要 MySQL 扫描前 200010 记录，仅仅返回 200000 - 200010 之间的记录，其他记录丢弃，查询排序的代价非常大\r\n\r\n* 分页查询：\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_user_1 LIMIT 200000,10;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL分页查询1.png)\r\n\r\n* 优化方式一：内连接查询，在索引列 id 上完成排序分页操作，最后根据主键关联回原表查询所需要的其他列内容\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_user_1 t,(SELECT id FROM tb_user_1 ORDER BY id LIMIT 200000,10) a WHERE t.id = a.id;\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL分页查询2.png)\r\n\r\n* 优化方式二：方案适用于主键自增的表，可以把 LIMIT 查询转换成某个位置的查询\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_user_1 WHERE id > 200000 LIMIT 10;\t\t\t-- 写法 1\r\n  EXPLAIN SELECT * FROM tb_user_1 WHERE id BETWEEN 200000 and 200010;\t-- 写法 2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL分页查询3.png)\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 使用提示\r\n\r\nSQL 提示，是优化数据库的一个重要手段，就是在 SQL 语句中加入一些提示来达到优化操作的目的\r\n\r\n* USE INDEX：在查询语句中表名的后面添加 USE INDEX 来提供 MySQL 去参考的索引列表，可以让 MySQL 不再考虑其他可用的索引\r\n\r\n  ```bash\r\n  CREATE INDEX idx_seller_name ON tb_seller(name);\r\n  EXPLAIN SELECT * FROM tb_seller USE INDEX(idx_seller_name) WHERE name='小米科技';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用提示1.png)\r\n\r\n* IGNORE INDEX：让 MySQL 忽略一个或者多个索引，则可以使用 IGNORE INDEX 作为提示\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller IGNORE INDEX(idx_seller_name) WHERE name = '小米科技';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用提示2.png)\r\n\r\n* FORCE INDEX：强制 MySQL 使用一个特定的索引\r\n\r\n  ```bash\r\n  EXPLAIN SELECT * FROM tb_seller FORCE INDEX(idx_seller_name_sta_addr) WHERE NAME='小米科技';\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-优化SQL使用提示3.png)\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 统计计数\r\n\r\n在不同的 MySQL 引擎中，count(*) 有不同的实现方式：\r\n\r\n* MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高，但不支持事务\r\n* show table status 命令通过采样估算可以快速获取，但是不准确\r\n* InnoDB 表执行 count(*) 会遍历全表，虽然结果准确，但会导致性能问题\r\n\r\n解决方案：\r\n\r\n* 计数保存在 Redis 中，但是更新 MySQL 和 Redis 的操作不是原子的，会存在数据一致性的问题\r\n\r\n* 计数直接放到数据库里单独的一张计数表中，利用事务解决计数精确问题：\r\n\r\n  <img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-计数count优化.png\" style=\"zoom: 50%;\" />\r\n\r\n  会话 B 的读操作在 T3 执行的，这时更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见，因此会话 B 查询的计数值和最近 100 条记录，返回的结果逻辑上就是一致的\r\n\r\n  并发系统性能的角度考虑，应该先插入操作记录再更新计数表，因为更新计数表涉及到行锁的竞争，**先插入再更新能最大程度地减少事务之间的锁等待，提升并发度**\r\n\r\ncount 函数的按照效率排序：`count(字段) < count(主键id) < count(1) ≈ count(*)`，所以建议尽量使用 count(*)\r\n\r\n* count(主键 id)：InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来返回给 Server 层，Server 判断 id 不为空就按行累加\r\n* count(1)：InnoDB 引擎遍历整张表但不取值，Server 层对于返回的每一行，放一个数字 1 进去，判断不为空就按行累加\r\n* count(字段)：如果这个字段是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；如果这个字段定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加\r\n* count(*)：不取值，按行累加\r\n\r\n\r\n\r\n参考文章：https://time.geekbang.org/column/article/72775\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n## 缓冲优化\r\n\r\n### 优化原则\r\n\r\n三个原则：\r\n\r\n* 将尽量多的内存分配给 MySQL 做缓存，但也要给操作系统和其他程序预留足够内存\r\n* MyISAM 存储引擎的数据文件读取依赖于操作系统自身的 IO 缓存，如果有 MyISAM 表，就要预留更多的内存给操作系统做 IO 缓存\r\n* 排序区、连接区等缓存是分配给每个数据库会话（Session）专用的，值的设置要根据最大连接数合理分配，如果设置太大，不但浪费资源，而且在并发数较高时会导致物理内存耗尽\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 缓冲内存\r\n\r\nBuffer Pool 本质上是 InnoDB 向操作系统申请的一段连续的内存空间。InnoDB 的数据是按数据页为单位来读写，每个数据页的大小默认是 16KB。数据是存放在磁盘中，每次读写数据都需要进行磁盘 IO 将数据读入内存进行操作，效率会很低，所以提供了 Buffer Pool 来暂存这些数据页，缓存中的这些页又叫缓冲页\r\n\r\n工作原理：\r\n\r\n* 从数据库读取数据时，会首先从缓存中读取，如果缓存中没有，则从磁盘读取后放入 Buffer Pool\r\n* 向数据库写入数据时，会写入缓存，缓存中修改的数据会**定期刷新**到磁盘，这一过程称为刷脏\r\n\r\nBuffer Pool 中每个缓冲页都有对应的控制信息，包括表空间编号、页号、偏移量、链表信息等，控制信息存放在占用的内存称为控制块，控制块与缓冲页是一一对应的，但并不是物理上相连的，都在缓冲池中\r\n\r\nMySQL 提供了缓冲页的快速查找方式：**哈希表**，使用表空间号和页号作为 Key，缓冲页控制块的地址作为 Value 创建一个哈希表，获取数据页时根据 Key 进行哈希寻址：\r\n\r\n* 如果不存在对应的缓存页，就从 free 链表中选一个空闲缓冲页，把磁盘中的对应页加载到该位置\r\n* 如果存在对应的缓存页，直接获取使用，提高查询数据的效率\r\n\r\n当内存数据页跟磁盘数据页内容不一致时，称这个内存页为脏页；内存数据写入磁盘后，内存和磁盘上的数据页一致，称为干净页\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 内存管理\r\n\r\n#### Free 链表\r\n\r\nMySQL 启动时完成对 Buffer Pool 的初始化，先向操作系统申请连续的内存空间，然后将内存划分为若干对控制块和缓冲页。为了区分空闲和已占用的数据页，将所有空闲缓冲页对应的**控制块作为一个节点**放入一个链表中，就是 Free 链表（**空闲链表**）\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-空闲链表.png\" style=\"zoom: 50%;\" />\r\n\r\n基节点：是一块单独申请的内存空间（占 40 字节），并不在 Buffer Pool 的那一大片连续内存空间里\r\n\r\n磁盘加载页的流程：\r\n\r\n* 从 Free 链表中取出一个空闲的缓冲页\r\n* 把缓冲页对应的控制块的信息填上（页所在的表空间、页号之类的信息）\r\n* 把缓冲页对应的 Free 链表节点（控制块）从链表中移除，表示该缓冲页已经被使用\r\n\r\n\r\n\r\n参考文章：https://blog.csdn.net/li1325169021/article/details/121124440\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### Flush 链表\r\n\r\nFlush 链表是一个用来**存储脏页**的链表，对于已经修改过的缓冲脏页，第一次修改后加入到**链表头部**，以后每次修改都不会重新加入，只修改部分控制信息，出于性能考虑并不是直接更新到磁盘，而是在未来的某个时间进行刷脏\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-脏页链表.png\" style=\"zoom:50%;\" />\r\n\r\n**后台有专门的线程每隔一段时间把脏页刷新到磁盘**：\r\n\r\n* 从 Flush 链表中刷新一部分页面到磁盘：\r\n  * **后台线程定时**从 Flush 链表刷脏，根据系统的繁忙程度来决定刷新速率，这种方式称为 BUF_FLUSH_LIST\r\n  * 线程刷脏的比较慢，导致用户线程加载一个新的数据页时发现没有空闲缓冲页，此时会尝试从 LRU 链表尾部寻找缓冲页直接释放，如果该页面是已经修改过的脏页就**同步刷新**到磁盘，速度较慢，这种方式称为 BUF_FLUSH_SINGLE_PAGE\r\n* 从 LRU 链表的冷数据中刷新一部分页面到磁盘，即：BUF_FLUSH_LRU\r\n  * 后台线程会定时从 LRU 链表的尾部开始扫描一些页面，扫描的页面数量可以通过系统变量 `innodb_lru_scan_depth` 指定，如果在 LRU 链表中发现脏页，则把它们刷新到磁盘，这种方式称为 BUF_FLUSH_LRU\r\n  * 控制块里会存储该缓冲页是否被修改的信息，所以可以很容易的获取到某个缓冲页是否是脏页\r\n\r\n\r\n\r\n参考文章：https://blog.csdn.net/li1325169021/article/details/121125765\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### LRU 链表\r\n\r\nBuffer Pool 需要保证缓存的命中率，所以 MySQL 创建了一个 LRU 链表，当访问某个页时：\r\n\r\n* 如果该页不在 Buffer Pool 中，把该页从磁盘加载进来后会将该缓冲页对应的控制块作为节点放入 **LRU 链表的头部**，保证热点数据在链表头\r\n* 如果该页在 Buffer Pool 中，则直接把该页对应的控制块移动到 LRU 链表的头部，所以 LRU 链表尾部就是最近最少使用的缓冲页\r\n\r\nMySQL 基于局部性原理提供了预读功能：\r\n\r\n* 线性预读：系统变量 `innodb_read_ahead_threshold`，如果顺序访问某个区（extent：16 KB 的页，连续 64 个形成一个区，一个区默认 1MB 大小）的页面数超过了该系统变量值，就会触发一次**异步读取**下一个区中全部的页面到 Buffer Pool 中\r\n* 随机预读：如果某个区 13 个连续的页面都被加载到 Buffer Pool，无论这些页面是否是顺序读取，都会触发一次**异步读取**本区所有的其他页面到 Buffer Pool 中\r\n\r\n预读会造成加载太多用不到的数据页，造成那些使用频率很高的数据页被挤到 LRU 链表尾部，所以 InnoDB 将 LRU 链表分成两段，**冷热数据隔离**：\r\n\r\n* 一部分存储使用频率很高的数据页，这部分链表也叫热数据，young 区，靠近链表头部的区域\r\n* 一部分存储使用频率不高的冷数据，old 区，靠近链表尾部，默认占 37%，可以通过系统变量 `innodb_old_blocks_pct` 指定\r\n\r\n当磁盘上的某数据页被初次加载到 Buffer Pool 中会被放入 old 区，淘汰时优先淘汰 old 区\r\n\r\n* 当对 old 区的数据进行访问时，会在控制块记录下访问时间，等待后续的访问时间与第一次访问的时间是否在某个时间间隔内，通过系统变量 `innodb_old_blocks_time` 指定时间间隔，默认 1000ms，成立就**移动到 young 区的链表头部**\r\n* `innodb_old_blocks_time` 为 0 时，每次访问一个页面都会放入 young 区的头部\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 参数优化\r\n\r\nInnoDB 用一块内存区做 IO 缓存池，该缓存池不仅用来缓存 InnoDB 的索引块，也用来缓存 InnoDB 的数据块，可以通过下面的指令查看 Buffer Pool 的状态信息：\r\n\r\n```bash\r\nSHOW ENGINE INNODB STATUS\\G\r\n```\r\n\r\n`Buffer pool hit rate` 字段代表**内存命中率**，表示 Buffer Pool 对查询的加速效果\r\n\r\n核心参数：\r\n\r\n* `innodb_buffer_pool_size`：该变量决定了 Innodb 存储引擎表数据和索引数据的最大缓存区大小，默认 128M\r\n\r\n  ```bash\r\n  SHOW VARIABLES LIKE 'innodb_buffer_pool_size';\r\n  ```\r\n\r\n  在保证操作系统及其他程序有足够内存可用的情况下，`innodb_buffer_pool_size` 的值越大，缓存命中率越高，建议设置成可用物理内存的 60%~80%\r\n\r\n  ```sh\r\n  innodb_buffer_pool_size=512M\r\n  ```\r\n\r\n* `innodb_log_buffer_size`：该值决定了 Innodb 日志缓冲区的大小，保存要写入磁盘上的日志文件数据\r\n\r\n  对于可能产生大量更新记录的大事务，增加该值的大小，可以避免 Innodb 在事务提交前就执行不必要的日志写入磁盘操作，影响执行效率，通过配置文件修改：\r\n\r\n  ```sh\r\n  innodb_log_buffer_size=10M\r\n  ```\r\n\r\n在多线程下，访问 Buffer Pool 中的各种链表都需要加锁，所以将 Buffer Pool 拆成若干个小实例，**每个线程对应一个实例**，独立管理内存空间和各种链表（类似 ThreadLocal），多线程访问各自实例互不影响，提高了并发能力\r\n\r\nMySQL 5.7.5 之前 `innodb_buffer_pool_size` 只支持在系统启动时修改，现在已经支持运行时修改 Buffer Pool 的大小，但是每次调整参数都会重新向操作系统申请一块连续的内存空间，**将旧的缓冲池的内容拷贝到新空间**非常耗时，所以 MySQL 开始以一个 chunk 为单位向操作系统申请内存，所以一个 Buffer Pool 实例可以由多个 chunk 组成\r\n\r\n* 在系统启动时设置系统变量 `innodb_buffer_pool_instance` 可以指定 Buffer Pool 实例的个数，但是当 Buffer Pool 小于 1GB 时，设置多个实例时无效的\r\n* 指定系统变量 `innodb_buffer_pool_chunk_size` 来改变 chunk 的大小，只能在启动时修改，运行中不能修改，而且该变量并不包含缓冲页的控制块的内存大小\r\n* `innodb_buffer_pool_size` 必须是 `innodb_buffer_pool_chunk_size × innodb_buffer_pool_instance` 的倍数，默认值是 `128M × 16 = 2G`，Buffer Pool 必须是 2G 的整数倍，如果指定 5G，会自动调整成 6G\r\n* 如果启动时 `chunk × instances` > `pool_size`，那么 chunk 的值会自动设置为 `pool_size ÷ instances`\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n## 内存优化\r\n\r\n### Change\r\n\r\nInnoDB 管理的 Buffer Pool 中有一块内存叫 Change Buffer 用来对**增删改操作**提供缓存，可以通过参数来动态设置，设置为 50 时表示 Change Buffer 的大小最多占用 Buffer Pool 的 50%\r\n\r\n* 唯一索引的更新不能使用 Change Buffer，需要将数据页读入内存，判断没有冲突在写入\r\n* 普通索引可以使用 Change Buffer，**直接写入 Buffer 就结束**，不用校验唯一性\r\n\r\nChange Buffer 并不是数据页，只是对操作的缓存，所以需要将 Change Buffer 中的操作应用到旧数据页，得到新的数据页（脏页）的过程称为 Merge\r\n\r\n* 触发时机：访问数据页时会触发 Merge、后台有定时线程进行 Merge、在数据库正常关闭（shutdown）的过程中也会触发\r\n* 工作流程：首先从磁盘读入数据页到内存（因为 Buffer Pool 中不一定存在对应的数据页），从 Change Buffer 中找到对应的操作应用到数据页，得到新的数据页即为脏页，然后写入 redo log，等待刷脏即可\r\n\r\n说明：Change Buffer 中的记录，在事务提交时也会写入 redo log，所以是可以保证不丢失的\r\n\r\n业务场景：\r\n\r\n* 对于**写多读少**的业务来说，页面在写完以后马上被访问到的概率比较小，此时 Change Buffer 的使用效果最好，常见的就是账单类、日志类的系统\r\n\r\n* 一个业务的更新模式是写入后马上做查询，那么即使满足了条件，将更新先记录在 Change Buffer，但之后由于马上要访问这个数据页，会立即触发 Merge 过程，这样随机访问 IO 的次数不会减少，并且增加了 Change Buffer 的维护代价\r\n\r\n补充：Change Buffer 的前身是 Insert Buffer，只能对 Insert 操作优化，后来增加了 Update/Delete 的支持，改为 Change Buffer\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Net\r\n\r\nServer 层针对优化**查询**的内存为 Net Buffer，内存的大小是由参数 `net_buffer_length`定义，默认 16k，实现流程：\r\n\r\n* 获取一行数据写入 Net Buffer，重复获取直到 Net Buffer 写满，调用网络接口发出去\r\n* 若发送成功就清空 Net Buffer，然后继续取下一行；若发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，表示本地网络栈 `socket send buffer` 写满了，**进入等待**，直到网络栈重新可写再继续发送\r\n\r\nMySQL 采用的是边读边发的逻辑，因此对于数据量很大的查询来说，不会在 Server 端保存完整的结果集，如果客户端读结果不及时，会堵住 MySQL 的查询过程，但是**不会把内存打爆导致 OOM**\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-查询内存优化.png\" style=\"zoom:50%;\" />\r\n\r\nSHOW PROCESSLIST 获取线程信息后，处于 Sending to client 状态代表服务器端的网络栈写满，等待客户端接收数据\r\n\r\n假设有一个业务的逻辑比较复杂，每读一行数据以后要处理很久的逻辑，就会导致客户端要过很久才会去取下一行数据，导致 MySQL 的阻塞，一直处于 Sending to client 的状态\r\n\r\n解决方法：如果一个查询的返回结果很是很多，建议使用 mysql_store_result 这个接口，直接把查询结果保存到本地内存\r\n\r\n\r\n\r\n参考文章：https://blog.csdn.net/qq_33589510/article/details/117673449\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Read\r\n\r\nread_rnd_buffer 是 MySQL 的随机读缓冲区，当按任意顺序读取记录行时将分配一个随机读取缓冲区，进行排序查询时，MySQL 会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，大小是由 read_rnd_buffer_size 参数控制的\r\n\r\nMulti-Range Read 优化，**将随机 IO 转化为顺序 IO** 以降低查询过程中 IO 开销，因为大多数的数据都是按照主键递增顺序插入得到，所以按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能\r\n\r\n二级索引为 a，聚簇索引为 id，优化回表流程：\r\n\r\n* 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中\r\n* 将 read_rnd_buffer 中的 id 进行**递增排序**\r\n* 排序后的 id 数组，依次回表到主键 id 索引中查记录，并作为结果返回\r\n\r\n说明：如果步骤 1 中 read_rnd_buffer 放满了，就会先执行步骤 2 和 3，然后清空 read_rnd_buffer，之后继续找索引 a 的下个记录\r\n\r\n使用 MRR 优化需要设进行设置：\r\n\r\n```bash\r\nSET optimizer_switch='mrr_cost_based=off'\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Key\r\n\r\nMyISAM 存储引擎使用 key_buffer 缓存索引块，加速 MyISAM 索引的读写速度。对于 MyISAM 表的数据块没有特别的缓存机制，完全依赖于操作系统的 IO 缓存\r\n\r\n* key_buffer_size：该变量决定 MyISAM 索引块缓存区的大小，直接影响到 MyISAM 表的存取效率\r\n\r\n  ```bash\r\n  SHOW VARIABLES LIKE 'key_buffer_size';\t-- 单位是字节\r\n  ```\r\n\r\n  在 MySQL 配置文件中设置该值，建议至少将1/4可用内存分配给 key_buffer_size：\r\n\r\n  ```sh\r\n  vim /etc/mysql/my.cnf\r\n  key_buffer_size=1024M\r\n  ```\r\n\r\n* read_buffer_size：如果需要经常顺序扫描 MyISAM 表，可以通过增大 read_buffer_size 的值来改善性能。但 read_buffer_size 是每个 Session 独占的，如果默认值设置太大，并发环境就会造成内存浪费\r\n\r\n* read_rnd_buffer_size：对于需要做排序的 MyISAM 表的查询，如带有 ORDER BY 子句的语句，适当增加该的值，可以改善此类的 SQL 的性能，但是 read_rnd_buffer_size 是每个 Session 独占的，如果默认值设置太大，就会造成内存浪费\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n## 存储优化\r\n\r\n### 数据存储\r\n\r\n系统表空间是用来放系统信息的，比如数据字典什么的，对应的磁盘文件是 ibdata，数据表空间是一个个的表数据文件，对应的磁盘文件就是表名.ibd\r\n\r\n表数据既可以存在共享表空间里，也可以是单独的文件，这个行为是由参数 innodb_file_per_table 控制的：\r\n\r\n* OFF：表示表的数据放在系统共享表空间，也就是跟数据字典放在一起\r\n* ON ：表示每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中（默认）\r\n\r\n一个表单独存储为一个文件更容易管理，在不需要这个表时通过 drop table 命令，系统就会直接删除这个文件；如果是放在共享表空间中，即使表删掉了，空间也是不会回收的\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 数据删除\r\n\r\nMySQL 的数据删除就是移除掉某个记录后，该位置就被标记为**可复用**，如果有符合范围条件的数据可以插入到这里。符合范围条件的意思是假设删除记录 R4，之后要再插入一个 ID 在 300 和 600 之间的记录时，就会复用这个位置\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-删除数据.png\" style=\"zoom:50%;\" />\r\n\r\nInnoDB 的数据是按页存储的如果删掉了一个数据页上的所有记录，整个数据页就可以被复用了，如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用\r\n\r\n删除命令其实只是把记录的位置，或者**数据页标记为了可复用，但磁盘文件的大小是不会变的**，这些可以复用还没有被使用的空间，看起来就像是空洞，造成数据库的稀疏，因此需要进行紧凑处理\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 重建数据\r\n\r\n重建表就是按照主键 ID 递增的顺序，把数据一行一行地从旧表中读出来再插入到新表中，让数据更加紧凑。重建表时 MySQL 会自动完成转存数据、交换表名、删除旧表的操作，线上操作会阻塞大量的线程增删改查的操作\r\n\r\n重建命令：\r\n\r\n```sql\r\nALTER TABLE A ENGINE=InnoDB\r\n```\r\n\r\n工作流程：新建临时表 tmp_table B（在 Server 层创建的），把表 A 中的数据导入到表 B 中，操作完成后用表 B 替换表 A，完成重建\r\n\r\n重建表的步骤需要 DDL 不是 Online 的，因为在导入数据的过程有新的数据要写入到表 A 的话，就会造成数据丢失\r\n\r\nMySQL 5.6 版本开始引入的 **Online DDL**，重建表的命令默认执行此步骤：\r\n\r\n* 建立一个临时文件 tmp_file（InnoDB 创建），扫描表 A 主键的所有数据页\r\n* 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中\r\n* 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态\r\n* 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3\r\n* 用临时文件替换表 A 的数据文件\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-重建表.png\" style=\"zoom: 67%;\" />\r\n\r\nOnline DDL 操作会先获取 MDL 写锁，再退化成 MDL 读锁。但 MDL 写锁持有时间比较短，所以可以称为 Online； 而 MDL 读锁，不阻止数据增删查改，但会阻止其它线程修改表结构（可以对比 `ANALYZE TABLE t`  命令）\r\n\r\n问题：重建表可以收缩表空间，但是执行指令后整体占用空间增大\r\n\r\n原因：在重建表后 InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新使用。表在未整理之前页已经占用 15/16 以上，收缩之后需要保持数据占用空间在 15/16，所以文件占用空间更大才能保持\r\n\r\n注意：临时文件也要占用空间，如果空间不足会重建失败\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 原地置换\r\n\r\nDDL 中的临时表 tmp_table 是在 Server 层创建的，Online DDL 中的临时文件 tmp_file 是 InnoDB 在内部创建出来的，整个 DDL 过程都在 InnoDB 内部完成，对于 Server 层来说，没有把数据挪动到临时表，是一个原地操作，这就是 inplace\r\n\r\n两者的关系：\r\n\r\n* DDL 过程如果是 Online 的，就一定是 inplace 的\r\n* inplace 的 DDL，有可能不是 Online 的，截止到 MySQL 8.0，全文索引（FULLTEXT）和空间索引（SPATIAL）属于这种情况\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n## 并发优化\r\n\r\nMySQL Server 是多线程结构，包括后台线程和客户服务线程。多线程可以有效利用服务器资源，提高数据库的并发性能。在 MySQL 中，控制并发连接和线程的主要参数：\r\n\r\n* max_connections：控制允许连接到 MySQL 数据库的最大连接数，默认值是 151\r\n\r\n  如果状态变量 connection_errors_max_connections 不为零，并且一直增长，则说明不断有连接请求因数据库连接数已达到允许最大值而失败，这时可以考虑增大 max_connections 的值\r\n\r\n  MySQL 最大可支持的连接数取决于很多因素，包括操作系统平台的线程库的质量、内存大小、每个连接的负荷、CPU的处理速度、期望的响应时间等。在 Linux 平台下，性能好的服务器，可以支持 500-1000 个连接，需要根据服务器性能进行评估设定\r\n\r\n* innodb_thread_concurrency：并发线程数，代表系统内同时运行的线程数量（已经被移除）\r\n\r\n* back_log：控制 MySQL 监听 TCP 端口时的积压请求栈的大小\r\n\r\n  如果 Mysql 的连接数达到 max_connections 时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即 back_log。如果等待连接的数量超过 back_log，将不被授予连接资源直接报错\r\n\r\n  5.6.6 版本之前默认值为 50，之后的版本默认为 `50 + (max_connections/5)`，但最大不超过900，如果需要数据库在较短的时间内处理大量连接请求， 可以考虑适当增大 back_log 的值\r\n\r\n* table_open_cache：控制所有 SQL 语句执行线程可打开表缓存的数量\r\n\r\n  在执行 SQL 语句时，每个执行线程至少要打开1个表缓存，该参数的值应该根据设置的最大连接数以及每个连接执行关联查询中涉及的表的最大数量来设定：`max_connections * N`\r\n\r\n* thread_cache_size：可控制 MySQL 缓存客户服务线程的数量\r\n\r\n  为了加快连接数据库的速度，MySQL 会缓存一定数量的客户服务线程以备重用，池化思想\r\n\r\n* innodb_lock_wait_timeout：设置 InnoDB 事务等待行锁的时间，默认值是 50ms\r\n\r\n  对于需要快速反馈的业务系统，可以将行锁的等待时间调小，以避免事务被长时间挂起； 对于后台运行的批量处理程序来说，可以将行锁的等待时间调大，以避免发生大的回滚操作\r\n\r\n\r\n\r\n"},{"title":"MySQL - 表","tags":["SQL"],"categories":["MySQL","基础篇"],"author":"imklaus","excerpt":"\r\n\r\n\r\n## 单表操作\r\n\r\n### SQL\r\n\r\n- SQL\r\n\r\n  - Structured Query Language：结构化查询语言\r\n  - 定义了操作所有关系型数据库的规则，每种数据库操作的方式可能会存在不一样的地方，称为“方言”\r\n\r\n- SQL 通用语法\r\n\r\n  - SQL 语句可以单行或多行书写，以**分号结尾**。\r\n  - 可使用空格和缩进来增强语句的可读性。\r\n  - MySQL 数据库的 SQL 语句不区分大小写，**关键字建议使用大写**。\r\n  - 数据库的注释：\r\n    - 单行注释：-- 注释内容       #注释内容（MySQL 特有）\r\n    - 多行注释：/* 注释内容 */\r\n\r\n- SQL 分类\r\n\r\n  - DDL（Data Definition Language）数据定义语言\r\n\r\n    - 用来定义数据库对象：数据库，表，列等。关键字：create、drop,、alter 等\r\n\r\n  - DML（Data Manipulation Language）数据操作语言\r\n\r\n    - 用来对数据库中表的数据进行增删改。关键字：insert、delete、update 等\r\n\r\n  - DQL（Data Query Language）数据查询语言\r\n\r\n    - 用来查询数据库中表的记录(数据)。关键字：select、where 等\r\n\r\n  - DCL（Data Control Language）数据控制语言\r\n\r\n    - 用来定义数据库的访问权限和安全级别，及创建用户。关键字：grant， revoke等\r\n\r\n    ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-SQL分类.png)\r\n\r\n","link":"/posts/MySQL_Table","content":"\r\n\r\n\r\n## 单表操作\r\n\r\n### SQL\r\n\r\n- SQL\r\n\r\n  - Structured Query Language：结构化查询语言\r\n  - 定义了操作所有关系型数据库的规则，每种数据库操作的方式可能会存在不一样的地方，称为“方言”\r\n\r\n- SQL 通用语法\r\n\r\n  - SQL 语句可以单行或多行书写，以**分号结尾**。\r\n  - 可使用空格和缩进来增强语句的可读性。\r\n  - MySQL 数据库的 SQL 语句不区分大小写，**关键字建议使用大写**。\r\n  - 数据库的注释：\r\n    - 单行注释：-- 注释内容       #注释内容（MySQL 特有）\r\n    - 多行注释：/* 注释内容 */\r\n\r\n- SQL 分类\r\n\r\n  - DDL（Data Definition Language）数据定义语言\r\n\r\n    - 用来定义数据库对象：数据库，表，列等。关键字：create、drop,、alter 等\r\n\r\n  - DML（Data Manipulation Language）数据操作语言\r\n\r\n    - 用来对数据库中表的数据进行增删改。关键字：insert、delete、update 等\r\n\r\n  - DQL（Data Query Language）数据查询语言\r\n\r\n    - 用来查询数据库中表的记录(数据)。关键字：select、where 等\r\n\r\n  - DCL（Data Control Language）数据控制语言\r\n\r\n    - 用来定义数据库的访问权限和安全级别，及创建用户。关键字：grant， revoke等\r\n\r\n    ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-SQL分类.png)\r\n\r\n<!-- more -->\r\n\r\n***\r\n\r\n\r\n\r\n### DDL\r\n\r\n#### 数据库\r\n\r\n* R(Retrieve)：查询\r\n\r\n  * 查询所有数据库：\r\n\r\n    ```bash\r\n    SHOW DATABASES;\r\n    ```\r\n\r\n  * 查询某个数据库的创建语句\r\n\r\n    ```sql\r\n    SHOW CREATE DATABASE 数据库名称;  -- 标准语法\r\n    \r\n    SHOW CREATE DATABASE mysql;     -- 查看mysql数据库的创建格式\r\n    ```\r\n\r\n    \r\n\r\n* C(Create)：创建\r\n\r\n  * 创建数据库\r\n\r\n    ```bash\r\n    CREATE DATABASE 数据库名称;-- 标准语法\r\n    \r\n    CREATE DATABASE db1;     -- 创建db1数据库\r\n    ```\r\n\r\n  * 创建数据库（判断，如果不存在则创建）\r\n\r\n    ```bash\r\n    CREATE DATABASE IF NOT EXISTS 数据库名称;\r\n    ```\r\n\r\n  * 创建数据库，并指定字符集\r\n\r\n    ```bash\r\n    CREATE DATABASE 数据库名称 CHARACTER SET 字符集名称;\r\n    ```\r\n\r\n  * 例如：创建db4数据库、如果不存在则创建，指定字符集为gbk\r\n\r\n    ```bash\r\n    -- 创建db4数据库、如果不存在则创建，指定字符集为gbk\r\n    CREATE DATABASE IF NOT EXISTS db4 CHARACTER SET gbk;\r\n    \r\n    -- 查看db4数据库的字符集\r\n    SHOW CREATE DATABASE db4;\r\n    ```\r\n\r\n    \r\n\r\n* U(Update)：修改\r\n\r\n  * 修改数据库的字符集\r\n\r\n    ```bash\r\n    ALTER DATABASE 数据库名称 CHARACTER SET 字符集名称;\r\n    ```\r\n\r\n  * 常用字符集：\r\n\r\n    ```bash\r\n    --查询所有支持的字符集\r\n    SHOW CHARSET;\r\n    --查看所有支持的校对规则\r\n    SHOW COLLATION;\r\n    \r\n    -- 字符集: utf8,latinI,GBK,,GBK是utf8的子集\r\n    -- 校对规则: ci 大小定不敏感，cs或bin大小写敏感\r\n    ```\r\n\r\n    \r\n\r\n* D(Delete)：删除\r\n\r\n  * 删除数据库：\r\n\r\n    ```bash\r\n    DROP DATABASE 数据库名称;\r\n    ```\r\n\r\n  * 删除数据库(判断，如果存在则删除)：\r\n\r\n    ```bash\r\n    DROP DATABASE IF EXISTS 数据库名称;\r\n    ```\r\n    \r\n    \r\n\r\n* 使用数据库：\r\n\r\n  * 查询当前正在使用的数据库名称\r\n\r\n    ```bash\r\n    SELECT DATABASE();\r\n    ```\r\n\r\n  * 使用数据库\r\n\r\n    ```bash\r\n    USE 数据库名称； -- 标准语法\r\n    USE db4;\t   -- 使用db4数据库\r\n    ```\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 数据表\r\n\r\n- R(Retrieve)：查询\r\n\r\n  - 查询数据库中所有的数据表\r\n\r\n    ```bash\r\n    USE mysql;-- 使用mysql数据库\r\n    \r\n    SHOW TABLES;-- 查询库中所有的表\r\n    ```\r\n  \r\n  - 查询表结构\r\n\r\n    ```bash\r\n  DESC 表名;\r\n    ```\r\n  \r\n  - 查询表字符集\r\n  \r\n    ```bash\r\n    SHOW TABLE STATUS FROM 库名 LIKE '表名';\r\n    ```\r\n\r\n    \r\n\r\n- C(Create)：创建\r\n\r\n  - 创建数据表\r\n\r\n    ```bash\r\n    CREATE TABLE 表名(\r\n        列名1 数据类型1,\r\n        列名2 数据类型2,\r\n        ....\r\n        列名n 数据类型n\r\n    );\r\n    -- 注意：最后一列，不需要加逗号\r\n    ```\r\n\r\n  - 复制表\r\n\r\n    ```bash\r\n    CREATE TABLE 表名 LIKE 被复制的表名;  -- 标准语法\r\n    \r\n    CREATE TABLE product2 LIKE product; -- 复制product表到product2表\r\n    ```\r\n\r\n  - 数据类型\r\n\r\n    | 数据类型  | 说明                                                         |\r\n    | --------- | ------------------------------------------------------------ |\r\n    | INT       | 整数类型                                                     |\r\n    | DOUBLE    | 小数类型                                                     |\r\n    | DATE      | 日期，只包含年月日：yyyy-MM-dd                               |\r\n    | DATETIME  | 日期，包含年月日时分秒：yyyy-MM-dd HH:mm:ss                  |\r\n    | TIMESTAMP | 时间戳类型，包含年月日时分秒：yyyy-MM-dd HH:mm:ss<br />如果不给这个字段赋值或赋值为 NULL，则默认使用当前的系统时间 |\r\n    | CHAR      | 字符串，定长类型                                             |\r\n    | VARCHAR   | 字符串，**变长类型**<br />name varchar(20) 代表姓名最大 20 个字符：zhangsan 8 个字符，张三 2 个字符 |\r\n  \r\n    `INT(n)`：n 代表位数\r\n  \r\n    * 3：int（9）显示结果为 000000010\r\n    * 3：int（3）显示结果为 010\r\n  \r\n    `varchar(n)`：n 表示的是字符数\r\n  \r\n  - 例如：\r\n  \r\n    ```bash\r\n    -- 使用db3数据库\r\n    USE db3;\r\n    \r\n    -- 创建一个product商品表\r\n    CREATE TABLE product(\r\n    \tid INT,\t\t\t\t-- 商品编号\r\n    \tNAME VARCHAR(30),\t-- 商品名称\r\n    \tprice DOUBLE,\t\t-- 商品价格\r\n    \tstock INT,\t\t\t-- 商品库存\r\n    \tinsert_time DATE    -- 上架时间\r\n    );\r\n    ```\r\n\r\n    \r\n\r\n- U(Update)：修改\r\n\r\n  - 修改表名\r\n\r\n    ```bash\r\n    ALTER TABLE 表名 RENAME TO 新的表名;\r\n    ```\r\n  \r\n  - 修改表的字符集\r\n  \r\n    ```bash\r\n  ALTER TABLE 表名 CHARACTER SET 字符集名称;\r\n    ```\r\n\r\n  - 添加一列\r\n  \r\n    ```bash\r\n    ALTER TABLE 表名 ADD 列名 数据类型;\r\n    ```\r\n  \r\n  - 修改列数据类型\r\n  \r\n    ```bash\r\n    ALTER TABLE 表名 MODIFY 列名 新数据类型;\r\n    ```\r\n\r\n  - 修改列名称和数据类型\r\n\r\n    ```bash\r\n    ALTER TABLE 表名 CHANGE 列名 新列名 新数据类型;\r\n    ```\r\n  \r\n  - 删除列\r\n  \r\n    ```bash\r\n    ALTER TABLE 表名 DROP 列名;\r\n    ```\r\n\r\n    \r\n  \r\n- D(Delete)：删除\r\n\r\n  - 删除数据表\r\n\r\n    ```bash\r\n    DROP TABLE 表名;\r\n    ```\r\n  \r\n  - 删除数据表(判断，如果存在则删除)\r\n  \r\n    ```bash\r\n    DROP TABLE IF EXISTS 表名;\r\n    ```\r\n  \r\n    \r\n\r\n***\r\n\r\n\r\n\r\n### DML\r\n\r\n#### INSERT\r\n\r\n* 新增表数据\r\n\r\n  * 新增格式 1：给指定列添加数据\r\n\r\n    ```bash\r\n    INSERT INTO 表名(列名1,列名2...) VALUES (值1,值2...);\r\n    ```\r\n\r\n  * 新增格式 2：默认给全部列添加数据\r\n\r\n    ```bash\r\n    INSERT INTO 表名 VALUES (值1,值2,值3,...);\r\n    ```\r\n\r\n  * 新增格式 3：批量添加数据\r\n\r\n    ```bash\r\n    -- 给指定列批量添加数据\r\n    INSERT INTO 表名(列名1,列名2,...) VALUES (值1,值2,...),(值1,值2,...)...;\r\n    \r\n    -- 默认给所有列批量添加数据 \r\n    INSERT INTO 表名 VALUES (值1,值2,值3,...),(值1,值2,值3,...)...;\r\n    ```\r\n\r\n* 字符串拼接\r\n\r\n  ```bash\r\n  CONCAT(string1,string2,'',...)\r\n  ```\r\n  \r\n  \r\n  \r\n* 注意事项\r\n\r\n  - 列名和值的数量以及数据类型要对应\r\n  - 除了数字类型，其他数据类型的数据都需要加引号(单引双引都可以，推荐单引)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### UPDATE\r\n\r\n* 修改表数据语法\r\n\r\n  * 标准语法\r\n\r\n    ```bash\r\n    UPDATE 表名 SET 列名1 = 值1,列名2 = 值2,... [where 条件];\r\n    ```\r\n\r\n  * 修改电视的价格为1800、库存为36\r\n\r\n    ```bash\r\n    UPDATE product SET price=1800,stock=36 WHERE NAME='电视';\r\n    SELECT * FROM product;-- 查看所有商品信息\r\n    ```\r\n\r\n* 注意事项\r\n\r\n  - 修改语句中必须加条件\r\n  - 如果不加条件，则将所有数据都修改\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### DELETE\r\n\r\n* 删除表数据语法\r\n\r\n  ```bash\r\n  DELETE FROM 表名 [WHERE 条件];\r\n  ```\r\n\r\n* 注意事项\r\n  * 删除语句中必须加条件\r\n  * 如果不加条件，则将所有数据删除\r\n\r\n\r\n\r\n​    \r\n\r\n***\r\n\r\n\r\n\r\n### DQL\r\n\r\n#### 查询语法\r\n\r\n数据库查询遵循条件在前的原则\r\n\r\n```bash\r\nSELECT DISTINCT\r\n\t<select list>\r\nFROM\r\n\t<left_table> <join_type>\r\nJOIN\r\n\t<right_table> ON <join_condition>\t-- 连接查询在多表查询部分详解\r\nWHERE\r\n\t<where_condition>\r\nGROUP BY\r\n\t<group_by_list>\r\nHAVING\r\n\t<having_condition>\r\nORDER BY\r\n\t<order_by_condition>\r\nLIMIT\r\n\t<limit_params>\r\n```\r\n\r\n执行顺序：\r\n\r\n```bash\r\nFROM\t<left_table>\r\n\r\nON \t\t<join_condition>\r\n\r\n<join_type>\t\tJOIN\t<right_table>\r\n\r\nWHERE\t\t<where_condition>\r\n\r\nGROUP BY \t<group_by_list>\r\n\r\nHAVING\t\t<having_condition>\r\n\r\nSELECT DISTINCT\t\t<select list>\r\n\r\nORDER BY\t<order_by_condition>\r\n\r\nLIMIT\t\t<limit_params>\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 查询全部\r\n\r\n* 查询全部的表数据\r\n\r\n  ```bash\r\n  -- 标准语法\r\n  SELECT * FROM 表名;\r\n  \r\n  -- 查询product表所有数据(常用)\r\n  SELECT * FROM product;\r\n  ```\r\n\r\n* 查询指定字段的表数据\r\n\r\n  ```bash\r\n  SELECT 列名1,列名2,... FROM 表名;\r\n  ```\r\n\r\n* **去除重复查询**：只有值全部重复的才可以去除，需要创建临时表辅助查询\r\n  \r\n  ```bash\r\n  SELECT DISTINCT 列名1,列名2,... FROM 表名;\r\n  ```\r\n  \r\n* 计算列的值（四则运算）\r\n\r\n  ```bash\r\n  SELECT 列名1 运算符(+ - * /) 列名2 FROM 表名;\r\n  \r\n  /*如果某一列值为null，可以进行替换\r\n  \tifnull(表达式1,表达式2)\r\n  \t表达式1：想替换的列\r\n  \t表达式2：想替换的值*/\r\n  ```\r\n\r\n  例如：\r\n\r\n  ```bash\r\n  -- 查询商品名称和库存，库存数量在原有基础上加10\r\n  SELECT NAME,stock+10 FROM product;\r\n  \r\n  -- 查询商品名称和库存，库存数量在原有基础上加10。进行null值判断\r\n  SELECT NAME,IFNULL(stock,0)+10 FROM product;\r\n  ```\r\n\r\n* **起别名**\r\n\r\n  ```bash\r\n  SELECT 列名1,列名2,... AS 别名 FROM 表名;\r\n  ```\r\n\r\n  例如：\r\n\r\n  ```bash\r\n  -- 查询商品名称和库存，库存数量在原有基础上加10。进行null值判断，起别名为getSum,AS可以省略。\r\n  SELECT NAME,IFNULL(stock,0)+10 AS getsum FROM product;\r\n  SELECT NAME,IFNULL(stock,0)+10 getsum FROM product;\r\n  ```\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 条件查询\r\n\r\n* 条件查询语法\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名 WHERE 条件;\r\n  ```\r\n\r\n* 条件分类\r\n\r\n  | 符号                | 功能                                                         |\r\n  | ------------------- | ------------------------------------------------------------ |\r\n  | >                   | 大于                                                         |\r\n  | <                   | 小于                                                         |\r\n  | >=                  | 大于等于                                                     |\r\n  | <=                  | 小于等于                                                     |\r\n  | =                   | 等于                                                         |\r\n  | <> 或 !=            | 不等于                                                       |\r\n  | BETWEEN ... AND ... | 在某个范围之内(都包含)                                       |\r\n  | IN(...)             | 多选一                                                       |\r\n  | LIKE                | **模糊查询**：_单个任意字符、%任意个字符、[] 匹配集合内的字符<br/>`LIKE '[^AB]%' `：不以 A 和 B 开头的任意文本 |\r\n  | IS NULL             | 是NULL                                                       |\r\n  | IS NOT NULL         | 不是NULL                                                     |\r\n  | AND 或 &&           | 并且                                                         |\r\n  | OR 或 \\|\\|          | 或者                                                         |\r\n  | NOT 或 !            | 非，不是                                                     |\r\n  | UNION               | 对两个结果集进行**并集操作并进行去重，同时进行默认规则的排序** |\r\n  | UNION ALL           | 对两个结果集进行并集操作不进行去重，不进行排序               |\r\n\r\n* 例如：\r\n\r\n  ```bash\r\n  -- 查询库存大于20的商品信息\r\n  SELECT * FROM product WHERE stock > 20;\r\n  \r\n  -- 查询品牌为华为的商品信息\r\n  SELECT * FROM product WHERE brand='华为';\r\n  \r\n  -- 查询金额在4000 ~ 6000之间的商品信息\r\n  SELECT * FROM product WHERE price >= 4000 AND price <= 6000;\r\n  SELECT * FROM product WHERE price BETWEEN 4000 AND 6000;\r\n  \r\n  -- 查询库存为14、30、23的商品信息\r\n  SELECT * FROM product WHERE stock=14 OR stock=30 OR stock=23;\r\n  SELECT * FROM product WHERE stock IN(14,30,23);\r\n  \r\n  -- 查询库存为null的商品信息\r\n  SELECT * FROM product WHERE stock IS NULL;\r\n  -- 查询库存不为null的商品信息\r\n  SELECT * FROM product WHERE stock IS NOT NULL;\r\n  \r\n  -- 查询名称以'小米'为开头的商品信息\r\n  SELECT * FROM product WHERE NAME LIKE '小米%';\r\n  \r\n  -- 查询名称第二个字是'为'的商品信息\r\n  SELECT * FROM product WHERE NAME LIKE '_为%';\r\n  \r\n  -- 查询名称为四个字符的商品信息 4个下划线\r\n  SELECT * FROM product WHERE NAME LIKE '____';\r\n  \r\n  -- 查询名称中包含电脑的商品信息\r\n  SELECT * FROM product WHERE NAME LIKE '%电脑%';\r\n  ```\r\n\r\n  <img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-DQL数据准备.png\" style=\"zoom: 80%;\" />\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 函数查询\r\n\r\n##### 聚合函数\r\n\r\n聚合函数：将一列数据作为一个整体，进行纵向的计算\r\n\r\n* 聚合函数语法\r\n\r\n  ```bash\r\n  SELECT 函数名(列名) FROM 表名 [WHERE 条件]\r\n  ```\r\n\r\n* 聚合函数分类\r\n\r\n  | 函数名      | 功能                               |\r\n  | ----------- | ---------------------------------- |\r\n  | COUNT(列名) | 统计数量（一般选用不为 null 的列） |\r\n  | MAX(列名)   | 最大值                             |\r\n  | MIN(列名)   | 最小值                             |\r\n  | SUM(列名)   | 求和                               |\r\n  | AVG(列名)   | 平均值（会忽略 null 行）           |\r\n\r\n* 例如\r\n\r\n  ```bash\r\n  -- 计算product表中总记录条数 7\r\n  SELECT COUNT(*) FROM product;\r\n  \r\n  -- 获取最高价格\r\n  SELECT MAX(price) FROM product;\r\n  -- 获取最高价格的商品名称\r\n  SELECT NAME,price FROM product WHERE price = (SELECT MAX(price) FROM product);\r\n  \r\n  -- 获取最低库存\r\n  SELECT MIN(stock) FROM product;\r\n  -- 获取最低库存的商品名称\r\n  SELECT NAME,stock FROM product WHERE stock = (SELECT MIN(stock) FROM product);\r\n  \r\n  -- 获取总库存数量\r\n  SELECT SUM(stock) FROM product;\r\n  -- 获取品牌为小米的平均商品价格\r\n  SELECT AVG(price) FROM product WHERE brand='小米';\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 文本函数\r\n\r\nCONCAT()：用于连接两个字段\r\n\r\n```sql\r\nSELECT CONCAT(TRIM(col1), '(', TRIM(col2), ')') AS concat_col FROM mytable\r\n-- 许多数据库会使用空格把一个值填充为列宽，连接的结果出现一些不必要的空格，使用TRIM()可以去除首尾空格\r\n```\r\n\r\n| 函数名称  | 作 用                                                        |\r\n| --------- | ------------------------------------------------------------ |\r\n| LENGTH    | 计算字符串长度函数，返回字符串的字节长度                     |\r\n| CONCAT    | 合并字符串函数，返回结果为连接参数产生的字符串，参数可以使一个或多个 |\r\n| INSERT    | 替换字符串函数                                               |\r\n| LOWER     | 将字符串中的字母转换为小写                                   |\r\n| UPPER     | 将字符串中的字母转换为大写                                   |\r\n| LEFT      | 从左侧字截取符串，返回字符串左边的若干个字符                 |\r\n| RIGHT     | 从右侧字截取符串，返回字符串右边的若干个字符                 |\r\n| TRIM      | 删除字符串左右两侧的空格                                     |\r\n| REPLACE   | 字符串替换函数，返回替换后的新字符串                         |\r\n| SUBSTRING | 截取字符串，返回从指定位置开始的指定长度的字符换             |\r\n| REVERSE   | 字符串反转（逆序）函数，返回与原始字符串顺序相反的字符串     |\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 数字函数\r\n\r\n| 函数名称        | 作 用                                                      |\r\n| --------------- | ---------------------------------------------------------- |\r\n| ABS             | 求绝对值                                                   |\r\n| SQRT            | 求二次方根                                                 |\r\n| MOD             | 求余数                                                     |\r\n| CEIL 和 CEILING | 两个函数功能相同，都是返回不小于参数的最小整数，即向上取整 |\r\n| FLOOR           | 向下取整，返回值转化为一个BIGINT                           |\r\n| RAND            | 生成一个0~1之间的随机数，传入整数参数是，用来产生重复序列  |\r\n| ROUND           | 对所传参数进行四舍五入                                     |\r\n| SIGN            | 返回参数的符号                                             |\r\n| POW 和 POWER    | 两个函数的功能相同，都是所传参数的次方的结果值             |\r\n| SIN             | 求正弦值                                                   |\r\n| ASIN            | 求反正弦值，与函数 SIN 互为反函数                          |\r\n| COS             | 求余弦值                                                   |\r\n| ACOS            | 求反余弦值，与函数 COS 互为反函数                          |\r\n| TAN             | 求正切值                                                   |\r\n| ATAN            | 求反正切值，与函数 TAN 互为反函数                          |\r\n| COT             | 求余切值                                                   |\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 日期函数\r\n\r\n| 函数名称                | 作 用                                                        |\r\n| ----------------------- | ------------------------------------------------------------ |\r\n| CURDATE 和 CURRENT_DATE | 两个函数作用相同，返回当前系统的日期值                       |\r\n| CURTIME 和 CURRENT_TIME | 两个函数作用相同，返回当前系统的时间值                       |\r\n| NOW 和  SYSDATE         | 两个函数作用相同，返回当前系统的日期和时间值                 |\r\n| MONTH                   | 获取指定日期中的月份                                         |\r\n| MONTHNAME               | 获取指定日期中的月份英文名称                                 |\r\n| DAYNAME                 | 获取指定曰期对应的星期几的英文名称                           |\r\n| DAYOFWEEK               | 获取指定日期对应的一周的索引位置值                           |\r\n| WEEK                    | 获取指定日期是一年中的第几周，返回值的范围是否为 0〜52 或 1〜53 |\r\n| DAYOFYEAR               | 获取指定曰期是一年中的第几天，返回值范围是1~366              |\r\n| DAYOFMONTH              | 获取指定日期是一个月中是第几天，返回值范围是1~31             |\r\n| YEAR                    | 获取年份，返回值范围是 1970〜2069                            |\r\n| TIME_TO_SEC             | 将时间参数转换为秒数                                         |\r\n| SEC_TO_TIME             | 将秒数转换为时间，与TIME_TO_SEC 互为反函数                   |\r\n| DATE_ADD 和 ADDDATE     | 两个函数功能相同，都是向日期添加指定的时间间隔               |\r\n| DATE_SUB 和 SUBDATE     | 两个函数功能相同，都是向日期减去指定的时间间隔               |\r\n| ADDTIME                 | 时间加法运算，在原始时间上添加指定的时间                     |\r\n| SUBTIME                 | 时间减法运算，在原始时间上减去指定的时间                     |\r\n| DATEDIFF                | 获取两个日期之间间隔，返回参数 1 减去参数 2 的值             |\r\n| DATE_FORMAT             | 格式化指定的日期，根据参数返回指定格式的值                   |\r\n| WEEKDAY                 | 获取指定日期在一周内的对应的工作日索引                       |\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 正则查询\r\n\r\n正则表达式（Regular Expression）是指一个用来描述或者匹配一系列符合某个句法规则的字符串的单个字符串\r\n\r\n```bash\r\nSELECT * FROM emp WHERE name REGEXP '^T';\t-- 匹配以T开头的name值\r\nSELECT * FROM emp WHERE name REGEXP '2$';\t-- 匹配以2结尾的name值\r\nSELECT * FROM emp WHERE name REGEXP '[uvw]';-- 匹配包含 uvw 的name值\r\n```\r\n\r\n| 符号   | 含义                          |\r\n| ------ | ----------------------------- |\r\n| ^      | 在字符串开始处进行匹配        |\r\n| $      | 在字符串末尾处进行匹配        |\r\n| .      | 匹配任意单个字符, 包括换行符  |\r\n| [...]  | 匹配出括号内的任意字符        |\r\n| [^...] | 匹配不出括号内的任意字符      |\r\n| a*     | 匹配零个或者多个a(包括空串)   |\r\n| a+     | 匹配一个或者多个a(不包括空串) |\r\n| a?     | 匹配零个或者一个a             |\r\n| a1\\|a2 | 匹配a1或a2                    |\r\n| a(m)   | 匹配m个a                      |\r\n| a(m,)  | 至少匹配m个a                  |\r\n| a(m,n) | 匹配m个a 到 n个a              |\r\n| a(,n)  | 匹配0到n个a                   |\r\n| (...)  | 将模式元素组成单一元素        |\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 排序查询\r\n\r\n* 排序查询语法\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名 [WHERE 条件] ORDER BY 列名1 排序方式1,列名2 排序方式2;\r\n  ```\r\n\r\n* 排序方式\r\n\r\n  ```bash\r\n  ASC:升序\r\n  DESC:降序\r\n  ```\r\n\r\n  注意：多个排序条件，当前边的条件值一样时，才会判断第二条件\r\n\r\n* 例如\r\n\r\n  ```bash\r\n  -- 按照库存升序排序\r\n  SELECT * FROM product ORDER BY stock ASC;\r\n  \r\n  -- 查询名称中包含手机的商品信息。按照金额降序排序\r\n  SELECT * FROM product WHERE NAME LIKE '%手机%' ORDER BY price DESC;\r\n  \r\n  -- 按照金额升序排序，如果金额相同，按照库存降序排列\r\n  SELECT * FROM product ORDER BY price ASC,stock DESC;\r\n  ```\r\n\r\n  \r\n\r\n***\r\n\r\n\r\n\r\n#### 分组查询\r\n\r\n分组查询会进行去重\r\n\r\n* 分组查询语法\r\n\r\n  ````bash\r\n  SELECT 列名 FROM 表名 [WHERE 条件] GROUP BY 分组列名 [HAVING 分组后条件过滤] [ORDER BY 排序列名 排序方式];\r\n  ````\r\n\r\n  WHERE 过滤行，HAVING 过滤分组，行过滤应当先于分组过滤\r\n\r\n  分组规定：\r\n\r\n  * GROUP BY 子句出现在 WHERE 子句之后，ORDER BY 子句之前\r\n  * NULL 的行会单独分为一组\r\n  * 大多数 SQL 实现不支持 GROUP BY 列具有可变长度的数据类型\r\n\r\n* 例如\r\n\r\n  ```bash\r\n  -- 按照品牌分组，获取每组商品的总金额\r\n  SELECT brand,SUM(price) FROM product GROUP BY brand;\r\n  \r\n  -- 对金额大于4000元的商品，按照品牌分组,获取每组商品的总金额\r\n  SELECT brand,SUM(price) FROM product WHERE price > 4000 GROUP BY brand;\r\n  \r\n  -- 对金额大于4000元的商品，按照品牌分组，获取每组商品的总金额，只显示总金额大于7000元的\r\n  SELECT brand,SUM(price) AS getSum FROM product WHERE price > 4000 GROUP BY brand HAVING getSum > 7000;\r\n  \r\n  -- 对金额大于4000元的商品，按照品牌分组，获取每组商品的总金额，只显示总金额大于7000元的、并按照总金额的降序排列\r\n  SELECT brand,SUM(price) AS getSum FROM product WHERE price > 4000 GROUP BY brand HAVING getSum > 7000 ORDER BY getSum DESC;\r\n  ```\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 分页查询\r\n\r\n* 分页查询语法\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名 [WHERE 条件] GROUP BY 分组列名 [HAVING 分组后条件过滤] [ORDER BY 排序列名 排序方式] LIMIT 开始索引,查询条数;\r\n  ```\r\n\r\n* 公式：开始索引 = (当前页码-1) * 每页显示的条数\r\n\r\n* 例如\r\n\r\n  ```bash\r\n  SELECT * FROM product LIMIT 0,2;  -- 第一页 开始索引=(1-1) * 2\r\n  SELECT * FROM product LIMIT 2,2;  -- 第二页 开始索引=(2-1) * 2\r\n  SELECT * FROM product LIMIT 4,2;  -- 第三页 开始索引=(3-1) * 2\r\n  SELECT * FROM product LIMIT 6,2;  -- 第四页 开始索引=(4-1) * 2\r\n  ```\r\n\r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-DQL分页查询图解.png)\r\n\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n## 多表操作\r\n\r\n### 约束分类\r\n\r\n#### 约束介绍\r\n\r\n约束：对表中的数据进行限定，保证数据的正确性、有效性、完整性\r\n\r\n约束的分类：\r\n\r\n| 约束                          | 说明           |\r\n| ----------------------------- | -------------- |\r\n| PRIMARY KEY                   | 主键约束       |\r\n| PRIMARY KEY AUTO_INCREMENT    | 主键、自动增长 |\r\n| UNIQUE                        | 唯一约束       |\r\n| NOT NULL                      | 非空约束       |\r\n| FOREIGN KEY                   | 外键约束       |\r\n| FOREIGN KEY ON UPDATE CASCADE | 外键级联更新   |\r\n| FOREIGN KEY ON DELETE CASCADE | 外键级联删除   |\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 主键约束\r\n\r\n* 主键约束特点：\r\n\r\n  * 主键约束默认包含**非空和唯一**两个功能\r\n  * 一张表只能有一个主键\r\n  * 主键一般用于表中数据的唯一标识\r\n\r\n* 建表时添加主键约束\r\n\r\n  ```bash\r\n  CREATE TABLE 表名(\r\n  \t列名 数据类型 PRIMARY KEY,\r\n      列名 数据类型,\r\n      ...\r\n  );\r\n  ```\r\n\r\n* 删除主键约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 DROP PRIMARY KEY;\r\n  ```\r\n\r\n* 建表后单独添加主键约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 MODIFY 列名 数据类型 PRIMARY KEY;\r\n  ```\r\n\r\n* 例如\r\n\r\n  ```bash\r\n  -- 创建student表\r\n  CREATE TABLE student(\r\n  \tid INT PRIMARY KEY  -- 给id添加主键约束\r\n  );\r\n  \r\n  -- 添加数据\r\n  INSERT INTO student VALUES (1),(2);\r\n  -- 主键默认唯一，添加重复数据，会报错\r\n  INSERT INTO student VALUES (2);\r\n  -- 主键默认非空，不能添加null的数据\r\n  INSERT INTO student VALUES (NULL);\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 主键自增\r\n\r\n主键自增约束可以为空，并自动增长。删除某条数据不影响自增的下一个数值，依然按照前一个值自增\r\n\r\n* 建表时添加主键自增约束\r\n\r\n  ```bash\r\n  CREATE TABLE 表名(\r\n  \t列名 数据类型 PRIMARY KEY AUTO_INCREMENT,\r\n      列名 数据类型,\r\n      ...\r\n  );\r\n  ```\r\n\r\n* 删除主键自增约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 MODIFY 列名 数据类型;\r\n  ```\r\n\r\n* 建表后单独添加主键自增约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 MODIFY 列名 数据类型 AUTO_INCREMENT;\r\n  ```\r\n\r\n* 例如\r\n\r\n  ```bash\r\n  -- 创建student2表\r\n  CREATE TABLE student2(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT    -- 给id添加主键自增约束\r\n  );\r\n  \r\n  -- 添加数据\r\n  INSERT INTO student2 VALUES (1),(2);\r\n  -- 添加null值，会自动增长\r\n  INSERT INTO student2 VALUES (NULL),(NULL);-- 3，4\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 唯一约束\r\n\r\n唯一约束：约束不能有重复的数据\r\n\r\n* 建表时添加唯一约束\r\n\r\n  ```bash\r\n  CREATE TABLE 表名(\r\n  \t列名 数据类型 UNIQUE,\r\n      列名 数据类型,\r\n      ...\r\n  );\r\n  ```\r\n\r\n* 删除唯一约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 DROP INDEX 列名;\r\n  ```\r\n\r\n* 建表后单独添加唯一约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 MODIFY 列名 数据类型 UNIQUE;\r\n  ```\r\n\r\n  \r\n\r\n***\r\n\r\n\r\n\r\n#### 非空约束\r\n\r\n* 建表时添加非空约束\r\n\r\n  ```bash\r\n  CREATE TABLE 表名(\r\n  \t列名 数据类型 NOT NULL,\r\n      列名 数据类型,\r\n      ...\r\n  );\r\n  ```\r\n\r\n* 删除非空约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 MODIFY 列名 数据类型;\r\n  ```\r\n\r\n* 建表后单独添加非空约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 MODIFY 列名 数据类型 NOT NULL;\r\n  ```\r\n\r\n \r\n\r\n***\r\n\r\n\r\n\r\n#### 外键约束\r\n\r\n  外键约束：让表和表之间产生关系，从而保证数据的准确性\r\n\r\n* 建表时添加外键约束\r\n\r\n  ```bash\r\n  CREATE TABLE 表名(\r\n  \t列名 数据类型 约束,\r\n      ...\r\n      CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主表主键列名)\r\n  );\r\n  ```\r\n\r\n* 删除外键约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 DROP FOREIGN KEY 外键名;\r\n  ```\r\n\r\n* 建表后单独添加外键约束\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主表主键列名);\r\n  ```\r\n\r\n* 例如\r\n\r\n  ```bash\r\n  -- 创建user用户表\r\n  CREATE TABLE USER(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,    -- id\r\n  \tname VARCHAR(20) NOT NULL             -- 姓名\r\n  );\r\n  -- 添加用户数据\r\n  INSERT INTO USER VALUES (NULL,'张三'),(NULL,'李四'),(NULL,'王五');\r\n  \r\n  -- 创建orderlist订单表\r\n  CREATE TABLE orderlist(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,    -- id\r\n  \tnumber VARCHAR(20) NOT NULL,          -- 订单编号\r\n  \tuid INT,                              -- 订单所属用户\r\n  \tCONSTRAINT ou_fk1 FOREIGN KEY (uid) REFERENCES USER(id)   -- 添加外键约束\r\n  );\r\n  -- 添加订单数据\r\n  INSERT INTO orderlist VALUES (NULL,'hm001',1),(NULL,'hm002',1),\r\n  (NULL,'hm003',2),(NULL,'hm004',2),\r\n  (NULL,'hm005',3),(NULL,'hm006',3);\r\n  \r\n  -- 添加一个订单，但是没有所属用户。无法添加\r\n  INSERT INTO orderlist VALUES (NULL,'hm007',8);\r\n  -- 删除王五这个用户，但是订单表中王五还有很多个订单呢。无法删除\r\n  DELETE FROM USER WHERE NAME='王五';\r\n  ```\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 外键级联\r\n\r\n级联操作：当把主表中的数据进行删除或更新时，从表中有关联的数据的相应操作，包括 RESTRICT、CASCADE、SET NULL 和 NO ACTION\r\n\r\n* RESTRICT 和 NO ACTION相同， 是指限制在子表有关联记录的情况下， 父表不能更新\r\n\r\n* CASCADE 表示父表在更新或者删除时，更新或者删除子表对应的记录\r\n\r\n* SET NULL 则表示父表在更新或者删除的时候，子表的对应字段被SET NULL\r\n\r\n级联操作：\r\n\r\n* 添加级联更新\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主表主键列名) ON UPDATE [CASCADE | RESTRICT | SET NULL];\r\n  ```\r\n\r\n* 添加级联删除\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主表主键列名) ON DELETE CASCADE;\r\n  ```\r\n\r\n* 同时添加级联更新和级联删除\r\n\r\n  ```bash\r\n  ALTER TABLE 表名 ADD CONSTRAINT 外键名 FOREIGN KEY (本表外键列名) REFERENCES 主表名(主表主键列名) ON UPDATE CASCADE ON DELETE CASCADE;\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n### 多表设计\r\n\r\n#### 一对一\r\n\r\n多表：有多张数据表，而表与表之间有一定的关联关系，通过外键约束实现，分为一对一、一对多、多对多三类\r\n\r\n举例：人和身份证\r\n\r\n实现原则：在任意一个表建立外键，去关联另外一个表的主键\r\n\r\n```bash\r\n-- 创建person表\r\nCREATE TABLE person(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 主键id\r\n\tNAME VARCHAR(20)                        -- 姓名\r\n);\r\n-- 添加数据\r\nINSERT INTO person VALUES (NULL,'张三'),(NULL,'李四');\r\n\r\n-- 创建card表\r\nCREATE TABLE card(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 主键id\r\n\tnumber VARCHAR(20) UNIQUE NOT NULL,\t-- 身份证号\r\n\tpid INT UNIQUE,                         -- 外键列\r\n\tCONSTRAINT cp_fk1 FOREIGN KEY (pid) REFERENCES person(id)\r\n);\r\n-- 添加数据\r\nINSERT INTO card VALUES (NULL,'12345',1),(NULL,'56789',2);\r\n```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/多表设计一对一.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 一对多\r\n\r\n举例：用户和订单、商品分类和商品\r\n\r\n实现原则：在多的一方，建立外键约束，来关联一的一方主键\r\n\r\n```bash\r\n-- 创建user表\r\nCREATE TABLE USER(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 主键id\r\n\tNAME VARCHAR(20)                        -- 姓名\r\n);\r\n-- 添加数据\r\nINSERT INTO USER VALUES (NULL,'张三'),(NULL,'李四');\r\n\r\n-- 创建orderlist表\r\nCREATE TABLE orderlist(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 主键id\r\n\tnumber VARCHAR(20),                     -- 订单编号\r\n\tuid INT,\t\t\t\t-- 外键列\r\n\tCONSTRAINT ou_fk1 FOREIGN KEY (uid) REFERENCES USER(id)\r\n);\r\n-- 添加数据\r\nINSERT INTO orderlist VALUES (NULL,'hm001',1),(NULL,'hm002',1),(NULL,'hm003',2),(NULL,'hm004',2);\r\n```\r\n\r\n![多表设计一对多](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/多表设计一对多.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 多对多\r\n\r\n举例：学生和课程。一个学生可以选择多个课程，一个课程也可以被多个学生选择\r\n\r\n实现原则：借助第三张表中间表，中间表至少包含两个列，这两个列作为中间表的外键，分别关联两张表的主键\r\n\r\n```bash\r\n-- 创建student表\r\nCREATE TABLE student(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 主键id\r\n\tNAME VARCHAR(20)\t\t\t-- 学生姓名\r\n);\r\n-- 添加数据\r\nINSERT INTO student VALUES (NULL,'张三'),(NULL,'李四');\r\n\r\n-- 创建course表\r\nCREATE TABLE course(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 主键id\r\n\tNAME VARCHAR(10)\t\t\t-- 课程名称\r\n);\r\n-- 添加数据\r\nINSERT INTO course VALUES (NULL,'语文'),(NULL,'数学');\r\n\r\n-- 创建中间表\r\nCREATE TABLE stu_course(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 主键id\r\n\tsid INT,  -- 用于和student表中的id进行外键关联\r\n\tcid INT,  -- 用于和course表中的id进行外键关联\r\n\tCONSTRAINT sc_fk1 FOREIGN KEY (sid) REFERENCES student(id), -- 添加外键约束\r\n\tCONSTRAINT sc_fk2 FOREIGN KEY (cid) REFERENCES course(id)   -- 添加外键约束\r\n);\r\n-- 添加数据\r\nINSERT INTO stu_course VALUES (NULL,1,1),(NULL,1,2),(NULL,2,1),(NULL,2,2);\r\n```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/多表设计多对多.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 连接查询\r\n\r\n#### 内外连接\r\n\r\n##### 内连接\r\n\r\n连接查询的是两张表有交集的部分数据，两张表分为**驱动表和被驱动表**，如果结果集中的每条记录都是两个表相互匹配的组合，则称这样的结果集为笛卡尔积\r\n\r\n内连接查询，若驱动表中的记录在被驱动表中找不到匹配的记录时，则该记录不会加到最后的结果集\r\n\r\n* 显式内连接：\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名1 [INNER] JOIN 表名2 ON 条件;\r\n  ```\r\n\r\n* 隐式内连接：内连接中 WHERE 子句和 ON 子句是等价的\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名1,表名2 WHERE 条件;\r\n  ```\r\n\r\nSTRAIGHT_JOIN与 JOIN 类似，只不过左表始终在右表之前读取，只适用于内连接\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 外连接\r\n\r\n外连接查询，若驱动表中的记录在被驱动表中找不到匹配的记录时，则该记录也会加到最后的结果集，只是对于被驱动表中**不匹配过滤条件**的记录，各个字段使用 NULL 填充\r\n\r\n应用实例：查学生成绩，也想展示出缺考的人的成绩\r\n\r\n* 左外连接：选择左侧的表为驱动表，查询左表的全部数据，和左右两张表有交集部分的数据\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名1 LEFT [OUTER] JOIN 表名2 ON 条件;\r\n  ```\r\n\r\n* 右外连接：选择右侧的表为驱动表，查询右表的全部数据，和左右两张表有交集部分的数据\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名1 RIGHT [OUTER] JOIN 表名2 ON 条件;\r\n  ```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-JOIN查询图.png)\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n#### 关联查询\r\n\r\n自关联查询：同一张表中有数据关联，可以多次查询这同一个表\r\n\r\n* 数据准备\r\n\r\n  ```bash\r\n  -- 创建员工表\r\n  CREATE TABLE employee(\r\n  \tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 员工编号\r\n  \tNAME VARCHAR(20),\t\t\t\t\t-- 员工姓名\r\n  \tmgr INT,\t\t\t\t\t\t\t-- 上级编号\r\n  \tsalary DOUBLE\t\t\t\t\t\t-- 员工工资\r\n  );\r\n  -- 添加数据\r\n  INSERT INTO employee VALUES (1001,'孙悟空',1005,9000.00),..,(1009,'宋江',NULL,16000.00);\r\n  ```\r\n  \r\n  ![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/自关联查询数据准备.png)\r\n  \r\n* 数据查询\r\n\r\n  ```bash\r\n  -- 查询所有员工的姓名及其直接上级的姓名，没有上级的员工也需要查询\r\n  /*\r\n  分析\r\n  \t员工信息 employee表\r\n  \t条件：employee.mgr = employee.id\r\n  \t查询左表的全部数据，和左右两张表有交集部分数据，左外连接\r\n  */\r\n  SELECT\r\n  \te1.id,\r\n  \te1.name,\r\n  \te1.mgr,\r\n  \te2.id,\r\n  \te2.name\r\n  FROM\r\n  \temployee e1\r\n  LEFT OUTER JOIN\r\n  \temployee e2\r\n  ON\r\n  \te1.mgr = e2.id;\t\r\n  ```\r\n\r\n* 查询结果\r\n\r\n  ```\r\n  id\t\tname\tmgr\t   id\t  name\r\n  1001\t孙悟空\t  1005\t1005\t唐僧\r\n  1002\t猪八戒\t  1005\t1005\t唐僧\r\n  1003\t沙和尚\t  1005\t1005\t唐僧\r\n  1004\t小白龙\t  1005\t1005\t唐僧\r\n  1005\t唐僧\t   NULL\t NULL\t NULL\r\n  1006\t武松\t   1009\t 1009\t 宋江\r\n  1007\t李逵\t   1009\t 1009\t 宋江\r\n  1008\t林冲\t   1009\t 1009\t 宋江\r\n  1009\t宋江\t   NULL\t NULL\t NULL\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 连接原理\r\n\r\nIndex Nested-Loop Join 算法：查询驱动表得到**数据集**，然后根据数据集中的每一条记录的**关联字段再分别**到被驱动表中查找匹配（**走索引**），所以驱动表只需要访问一次，被驱动表要访问多次\r\n\r\nMySQL 将查询驱动表后得到的记录成为驱动表的扇出，连接查询的成本：单次访问驱动表的成本 + 扇出值 * 单次访问被驱动表的成本，优化器会选择成本最小的表连接顺序（确定谁是驱动表，谁是被驱动表）生成执行计划，进行连接查询，优化方式：\r\n\r\n* 减少驱动表的扇出（让数据量小的表来做驱动表）\r\n* 降低访问被驱动表的成本\r\n\r\n说明：STRAIGHT_JOIN 是查一条驱动表，然后根据关联字段去查被驱动表，要访问多次驱动表，所以需要优化为 INL 算法\r\n\r\nBlock Nested-Loop Join 算法：一种**空间换时间**的优化方式，基于块的循环连接，执行连接查询前申请一块固定大小的内存作为连接缓冲区 Join Buffer，先把若干条驱动表中的扇出暂存在缓冲区，每一条被驱动表中的记录一次性的与 Buffer 中多条记录进行匹配（扫描全部数据，一条一条的匹配），因为是在内存中完成，所以速度快，并且降低了 I/O 成本\r\n\r\nJoin Buffer 可以通过参数 `join_buffer_size` 进行配置，默认大小是 256 KB\r\n\r\n在成本分析时，对于很多张表的连接查询，连接顺序有非常多，MySQL 如果挨着进行遍历计算成本，会消耗很多资源\r\n\r\n* 提前结束某种连接顺序的成本评估：维护一个全局变量记录当前成本最小的连接方式，如果一种顺序只计算了一部分就已经超过了最小成本，可以提前结束计算\r\n* 系统变量 optimizer_search_depth：如果连接表的个数小于该变量，就继续穷举分析每一种连接数量，反之只对数量与 depth 值相同的表进行分析，该值越大成本分析的越精确\r\n\r\n* 系统变量 optimizer_prune_level：控制启发式规则的启用，这些规则就是根据以往经验指定的，不满足规则的连接顺序不分析成本\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 连接优化\r\n\r\n##### BKA\r\n\r\nBatched Key Access 算法是对 NLJ 算法的优化，在读取被驱动表的记录时使用顺序 IO，Extra 信息中会有 Batched Key Access 信息\r\n\r\n使用 BKA 的表的 JOIN 过程如下：\r\n\r\n* 连接驱动表将满足条件的记录放入 Join Buffer，并将两表连接的字段放入一个 DYNAMIC_ARRAY ranges 中\r\n* 在进行表的过接过程中，会将 ranges 相关的信息传入 Buffer 中，进行被驱动表主建的查找及排序操作\r\n* 调用步骤 2 中产生的有序主建，**顺序读取被驱动表的数据**\r\n* 当缓冲区的数据被读完后，会重复进行步骤 2、3，直到记录被读取完\r\n\r\n使用 BKA 优化需要设进行设置：\r\n\r\n```bash\r\nSET optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';\r\n```\r\n\r\n说明：前两个参数的作用是启用 MRR，因为 BKA 算法的优化要依赖于 MRR（系统优化 → 内存优化 → Read 详解）\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### BNL\r\n\r\n###### 问题\r\n\r\nBNL 即 Block Nested-Loop Join 算法，由于要访问多次被驱动表，会产生两个问题：\r\n\r\n* Join 语句多次扫描一个冷表，并且语句执行时间小于 1 秒，就会在再次扫描冷表时，把冷表的数据页移到 LRU 链表头部，导致热数据被淘汰，影响业务的正常运行\r\n\r\n  这种情况冷表的数据量要小于整个 Buffer Pool 的 old 区域，能够完全放入 old 区，才会再次被读时加到 young，否则读取下一段时就已经把上一段淘汰\r\n\r\n* Join 语句在循环读磁盘和淘汰内存页，进入 old 区域的数据页很可能在 1 秒之内就被淘汰，就会导致 MySQL 实例的 Buffer Pool 在这段时间内 young 区域的数据页没有被合理地淘汰\r\n\r\n大表 Join 操作虽然对 IO 有影响，但是在语句执行结束后对 IO 的影响随之结束。但是对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率\r\n\r\n\r\n\r\n###### 优化\r\n\r\n将 BNL 算法转成 BKA 算法，优化方向：\r\n\r\n* 在被驱动表上建索引，这样就可以根据索引进行顺序 IO\r\n* 使用临时表，**在临时表上建立索引**，将被驱动表和临时表进行连接查询\r\n\r\n驱动表 t1，被驱动表 t2，使用临时表的工作流程：\r\n\r\n* 把表 t1 中满足条件的数据放在临时表 tmp_t 中\r\n* 给临时表 tmp_t 的关联字段加上索引，使用 BKA 算法\r\n* 让表 t2 和 tmp_t 做 Join 操作（临时表是被驱动表）\r\n\r\n补充：MySQL 8.0 支持 hash join，join_buffer 维护的不再是一个无序数组，而是一个哈希表，查询效率更高，执行效率比临时表更高\r\n\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 嵌套查询\r\n\r\n#### 查询分类\r\n\r\n查询语句中嵌套了查询语句，**将嵌套查询称为子查询**，FROM 子句后面的子查询的结果集称为派生表\r\n\r\n根据结果分类：\r\n\r\n* 结果是单行单列：可以将查询的结果作为另一条语句的查询条件，使用运算符判断\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名 WHERE 列名=(SELECT 列名/聚合函数(列名) FROM 表名 [WHERE 条件]);\r\n  ```\r\n\r\n* 结果是多行单列：可以作为条件，使用运算符 IN 或 NOT IN 进行判断\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名 WHERE 列名 [NOT] IN (SELECT 列名 FROM 表名 [WHERE 条件]); \r\n  ```\r\n\r\n* 结果是多行多列：查询的结果可以作为一张虚拟表参与查询\r\n\r\n  ```bash\r\n  SELECT 列名 FROM 表名 [别名],(SELECT 列名 FROM 表名 [WHERE 条件]) [别名] [WHERE 条件];\r\n  \r\n  -- 查询订单表orderlist中id大于4的订单信息和所属用户USER信息\r\n  SELECT \r\n  \t* \r\n  FROM \r\n  \tUSER u,\r\n  \t(SELECT * FROM orderlist WHERE id>4) o \r\n  WHERE \r\n  \tu.id=o.uid;\r\n  ```\r\n\r\n相关性分类：\r\n\r\n* 不相关子查询：子查询不依赖外层查询的值，可以单独运行出结果\r\n* 相关子查询：子查询的执行需要依赖外层查询的值\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 查询优化\r\n\r\n不相关子查询的结果集会被写入一个临时表，并且在写入时**去重**，该过程称为**物化**，存储结果集的临时表称为物化表\r\n\r\n系统变量 tmp_table_size 或者 max_heap_table_size 为表的最值\r\n\r\n* 小于系统变量时，内存中可以保存，会为建立**基于内存**的 MEMORY 存储引擎的临时表，并建立哈希索引\r\n* 大于任意一个系统变量时，物化表会使用**基于磁盘**的 InnoDB 存储引擎来保存结果集中的记录，索引类型为 B+ 树\r\n\r\n物化后，嵌套查询就相当于外层查询的表和物化表进行内连接查询，然后经过优化器选择成本最小的表连接顺序执行查询\r\n\r\n子查询物化会产生建立临时表的成本，但是将子查询转化为连接查询可以充分发挥优化器的作用，所以引入：半连接\r\n\r\n* t1 和 t2 表进行半连接，对于 t1 表中的某条记录，只需要关心在 t2 表中是否存在，而不需要关心有多少条记录与之匹配，最终结果集只保留 t1 的记录\r\n* 半连接只是执行子查询的一种方式，MySQL 并没有提供面向用户的半连接语法\r\n\r\n\r\n\r\n参考书籍：https://book.douban.com/subject/35231266/\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 联合查询\r\n\r\nUNION 是取这两个子查询结果的并集，并进行去重，同时进行默认规则的排序（union 是行加起来，join 是列加起来）\r\n\r\nUNION ALL 是对两个结果集进行并集操作不进行去重，不进行排序\r\n\r\n```bash\r\n(select 1000 as f) union (select id from t1 order by id desc limit 2); #t1表中包含id 为 1-1000 的数据\r\n```\r\n\r\n语句的执行流程：\r\n\r\n* 创建一个内存临时表，这个临时表只有一个整型字段 f，并且 f 是主键字段\r\n* 执行第一个子查询，得到 1000 这个值，并存入临时表中\r\n* 执行第二个子查询，拿到第一行 id=1000，试图插入临时表中，但由于 1000 这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行\r\n* 取到第二行 id=999，插入临时表成功\r\n* 从临时表中按行取出数据，返回结果并删除临时表，结果中包含两行数据分别是 1000 和 999\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 查询练习\r\n\r\n数据准备：\r\n\r\n```bash\r\n-- 创建db4数据库\r\nCREATE DATABASE db4;\r\n-- 使用db4数据库\r\nUSE db4;\r\n\r\n-- 创建user表\r\nCREATE TABLE USER(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 用户id\r\n\tNAME VARCHAR(20),\t\t\t\t\t-- 用户姓名\r\n\tage INT                             -- 用户年龄\r\n);\r\n\r\n-- 订单表\r\nCREATE TABLE orderlist(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,\t-- 订单id\r\n\tnumber VARCHAR(30),\t\t\t\t\t-- 订单编号\r\n\tuid INT,   \t\t\t\t\t\t\t-- 外键字段\r\n\tCONSTRAINT ou_fk1 FOREIGN KEY (uid) REFERENCES USER(id)\r\n);\r\n\r\n-- 商品分类表\r\nCREATE TABLE category(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,  -- 商品分类id\r\n\tNAME VARCHAR(10)                    -- 商品分类名称\r\n);\r\n\r\n-- 商品表\r\nCREATE TABLE product(\r\n\tid INT PRIMARY KEY AUTO_INCREMENT,   -- 商品id\r\n\tNAME VARCHAR(30),                    -- 商品名称\r\n\tcid INT, -- 外键字段\r\n\tCONSTRAINT cp_fk1 FOREIGN KEY (cid) REFERENCES category(id)\r\n);\r\n\r\n-- 中间表\r\nCREATE TABLE us_pro(\r\n\tupid INT PRIMARY KEY AUTO_INCREMENT,  -- 中间表id\r\n\tuid INT, \t\t\t\t\t\t\t  -- 外键字段。需要和用户表的主键产生关联\r\n\tpid INT,\t\t\t\t\t\t\t  -- 外键字段。需要和商品表的主键产生关联\r\n\tCONSTRAINT up_fk1 FOREIGN KEY (uid) REFERENCES USER(id),\r\n\tCONSTRAINT up_fk2 FOREIGN KEY (pid) REFERENCES product(id)\r\n);\r\n```\r\n\r\n![多表练习架构设计](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/多表练习架构设计.png)\r\n\r\n\r\n\r\n**数据查询：**\r\n\r\n1. 查询用户的编号、姓名、年龄、订单编号\r\n   \r\n   数据：用户的编号、姓名、年龄在 user 表，订单编号在 orderlist 表\r\n   \r\n   条件：user.id = orderlist.uid\r\n   \r\n   ```bash\r\n   SELECT\r\n   \tu.*,\r\n   \to.number\r\n   FROM\r\n   \tUSER u,\r\n   \torderlist o\r\n   WHERE\r\n   \tu.id = o.uid;\r\n   ```\r\n   \r\n2. 查询所有的用户，显示用户的编号、姓名、年龄、订单编号。\r\n\r\n   ```bash\r\n   SELECT\r\n   \tu.*,\r\n   \to.number\r\n   FROM\r\n   \tUSER u\r\n   LEFT OUTER JOIN\r\n   \torderlist o\r\n   ON\r\n   \tu.id = o.uid;\r\n   ```\r\n\r\n3. 查询用户年龄大于 23 岁的信息，显示用户的编号、姓名、年龄、订单编号\r\n\r\n   ```bash\r\n   SELECT\r\n   \tu.*,\r\n   \to.number\r\n   FROM\r\n   \tUSER u,\r\n   \torderlist o\r\n   WHERE\r\n   \tu.id = o.uid\r\n   \tAND\r\n   \tu.age > 23;\r\n   ```\r\n\r\n   ```bash\r\n   SELECT\r\n   \tu.*,\r\n   \to.number\r\n   FROM\r\n   \t(SELECT * FROM USER WHERE age > 23) u,-- 嵌套查询\r\n   \torderlist o\r\n   WHERE\r\n   \tu.id = o.uid;\r\n   ```\r\n\r\n4. 查询张三和李四用户的信息，显示用户的编号、姓名、年龄、订单编号。\r\n\r\n   ````bash\r\n   SELECT\r\n   \tu.*,\r\n   \to.number\r\n   FROM\r\n   \tUSER u,\r\n   \torderlist o\r\n   WHERE\r\n   \tu.id=o.uid\r\n   \tAND\r\n   \tu.name IN ('张三','李四');\r\n   ````\r\n\r\n5. 查询所有的用户和该用户能查看的所有的商品，显示用户的编号、姓名、年龄、商品名称\r\n   \r\n   数据：用户的编号、姓名、年龄在 user 表，商品名称在 product 表，中间表 us_pro\r\n   \r\n   条件：us_pro.uid = user.id AND us_pro.pid = product.id\r\n   \r\n   ```bash\r\n   SELECT\r\n   \tu.id,\r\n   \tu.name,\r\n   \tu.age,\r\n   \tp.name\r\n   FROM\r\n   \tUSER u,\r\n   \tproduct p,\r\n   \tus_pro up\r\n   WHERE\r\n   \tup.uid = u.id\r\n   \tAND\r\n   \tup.pid=p.id;\r\n   ```\r\n   \r\n6. 查询张三和李四这两个用户可以看到的商品，显示用户的编号、姓名、年龄、商品名称。\r\n\r\n   ```bash\r\n   SELECT\r\n   \tu.id,\r\n   \tu.name,\r\n   \tu.age,\r\n   \tp.name\r\n   FROM\r\n   \tUSER u,\r\n   \tproduct p,\r\n   \tus_pro up\r\n   WHERE\r\n   \tup.uid=u.id\r\n   \tAND\r\n   \tup.pid=p.id\r\n   \tAND\r\n   \tu.name IN ('张三','李四');\r\n   ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n***"},{"title":"MySQL - 事务","tags":["SQL"],"categories":["MySQL","事务篇"],"author":"imklaus","excerpt":"\r\n### 基本介绍\r\n\r\n事务（Transaction）是访问和更新数据库的程序执行单元；事务中可能包含一个或多个 SQL 语句，这些语句要么都执行，要么都不执行，作为一个关系型数据库，MySQL 支持事务。\r\n\r\n单元中的每条 SQL 语句都相互依赖，形成一个整体\r\n\r\n* 如果某条 SQL 语句执行失败或者出现错误，那么整个单元就会回滚，撤回到事务最初的状态\r\n\r\n* 如果单元中所有的 SQL 语句都执行成功，则事务就顺利执行\r\n\r\n事务的四大特征：ACID\r\n\r\n- 原子性 (atomicity)\r\n- 一致性 (consistency)\r\n- 隔离性 (isolaction)\r\n- 持久性 (durability)\r\n\r\n事务的几种状态：\r\n\r\n* 活动的（active）：事务对应的数据库操作正在执行中\r\n* 部分提交的（partially committed）：事务的最后一个操作执行完，但是内存还没刷新至磁盘\r\n* 失败的（failed）：当事务处于活动状态或部分提交状态时，如果数据库遇到了错误或刷脏失败，或者用户主动停止当前的事务\r\n* 中止的（aborted）：失败状态的事务回滚完成后的状态\r\n* 提交的（committed）：当处于部分提交状态的事务刷脏成功，就处于提交状态\r\n\r\n","link":"/posts/MySQL_Transaction","content":"\r\n### 基本介绍\r\n\r\n事务（Transaction）是访问和更新数据库的程序执行单元；事务中可能包含一个或多个 SQL 语句，这些语句要么都执行，要么都不执行，作为一个关系型数据库，MySQL 支持事务。\r\n\r\n单元中的每条 SQL 语句都相互依赖，形成一个整体\r\n\r\n* 如果某条 SQL 语句执行失败或者出现错误，那么整个单元就会回滚，撤回到事务最初的状态\r\n\r\n* 如果单元中所有的 SQL 语句都执行成功，则事务就顺利执行\r\n\r\n事务的四大特征：ACID\r\n\r\n- 原子性 (atomicity)\r\n- 一致性 (consistency)\r\n- 隔离性 (isolaction)\r\n- 持久性 (durability)\r\n\r\n事务的几种状态：\r\n\r\n* 活动的（active）：事务对应的数据库操作正在执行中\r\n* 部分提交的（partially committed）：事务的最后一个操作执行完，但是内存还没刷新至磁盘\r\n* 失败的（failed）：当事务处于活动状态或部分提交状态时，如果数据库遇到了错误或刷脏失败，或者用户主动停止当前的事务\r\n* 中止的（aborted）：失败状态的事务回滚完成后的状态\r\n* 提交的（committed）：当处于部分提交状态的事务刷脏成功，就处于提交状态\r\n\r\n<!-- more -->\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 事务管理\r\n\r\n#### 基本操作\r\n\r\n事务管理的三个步骤\r\n\r\n1. 开启事务：记录回滚点，并通知服务器，将要执行一组操作，要么同时成功、要么同时失败\r\n\r\n2. 执行 SQL 语句：执行具体的一条或多条 SQL 语句\r\n\r\n3. 结束事务（提交|回滚）\r\n\r\n   - 提交：没出现问题，数据进行更新\r\n   - 回滚：出现问题，数据恢复到开启事务时的状态\r\n\r\n\r\n事务操作：\r\n\r\n* 显式开启事务\r\n\r\n  ```bash\r\n  START TRANSACTION [READ ONLY|READ WRITE|WITH CONSISTENT SNAPSHOT]; #可以跟一个或多个状态，最后的是一致性读\r\n  BEGIN [WORK];\r\n  ```\r\n\r\n  说明：不填状态默认是读写事务\r\n\r\n* 回滚事务，用来手动中止事务\r\n\r\n  ```bash\r\n  ROLLBACK;\r\n  ```\r\n\r\n* 提交事务，显示执行是手动提交，MySQL 默认为自动提交\r\n\r\n  ```bash\r\n  COMMIT;\r\n  ```\r\n\r\n* 保存点：在事务的执行过程中设置的还原点，调用 ROLLBACK 时可以指定回滚到哪个点\r\n\r\n  ```bash\r\n  SAVEPOINT point_name;\t\t\t\t\t\t#设置保存点\r\n  RELEASE point_name\t\t\t\t\t\t\t#删除保存点\r\n  ROLLBACK [WORK] TO [SAVEPOINT] point_name\t#回滚至某个保存点，不填默认回滚到事务执行之前的状态\r\n  ```\r\n\r\n* 操作演示\r\n\r\n  ```bash\r\n  -- 开启事务\r\n  START TRANSACTION;\r\n  \r\n  -- 张三给李四转账500元\r\n  -- 1.张三账户-500\r\n  UPDATE account SET money=money-500 WHERE NAME='张三';\r\n  -- 2.李四账户+500\r\n  UPDATE account SET money=money+500 WHERE NAME='李四';\r\n  \r\n  -- 回滚事务(出现问题)\r\n  ROLLBACK;\r\n  \r\n  -- 提交事务(没出现问题)\r\n  COMMIT;\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 提交方式\r\n\r\n提交方式的相关语法：\r\n\r\n- 查看事务提交方式\r\n\r\n  ```bash\r\n  SELECT @@AUTOCOMMIT;  \t\t-- 会话，1 代表自动提交    0 代表手动提交\r\n  SELECT @@GLOBAL.AUTOCOMMIT;\t-- 系统\r\n  ```\r\n\r\n- 修改事务提交方式\r\n\r\n  ```bash\r\n  SET @@AUTOCOMMIT=数字;\t-- 系统\r\n  SET AUTOCOMMIT=数字;\t\t-- 会话\r\n  ```\r\n\r\n- **系统变量的操作**：\r\n\r\n  ```sql\r\n  SET [GLOBAL|SESSION] 变量名 = 值;\t\t\t\t\t-- 默认是会话\r\n  SET @@[(GLOBAL|SESSION).]变量名 = 值;\t\t\t\t-- 默认是系统\r\n  ```\r\n\r\n  ```sql\r\n  SHOW [GLOBAL|SESSION] VARIABLES [LIKE '变量%'];\t  -- 默认查看会话内系统变量值\r\n  ```\r\n\r\n工作原理：\r\n\r\n* 自动提交：如果没有 START TRANSACTION 显式地开始一个事务，那么**每条 SQL 语句都会被当做一个事务执行提交操作**；显式开启事务后，会在本次事务结束（提交或回滚）前暂时关闭自动提交\r\n* 手动提交：不需要显式的开启事务，所有的 SQL 语句都在一个事务中，直到执行了提交或回滚，然后进入下一个事务\r\n* 隐式提交：存在一些特殊的命令，在事务中执行了这些命令会马上**强制执行 COMMIT 提交事务**\r\n  * **DDL 语句** (CREATE/DROP/ALTER)、LOCK TABLES 语句、LOAD DATA 导入数据语句、主从复制语句等\r\n  * 当一个事务还没提交或回滚，显式的开启一个事务会隐式的提交上一个事务\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 事务 ID\r\n\r\n事务在执行过程中对某个表执行了**增删改操作或者创建表**，就会为当前事务分配一个独一无二的事务 ID（对临时表并不会分配 ID），如果当前事务没有被分配 ID，默认是 0\r\n\r\n说明：只读事务不能对普通的表进行增删改操作，但是可以对临时表增删改，读写事务可以对数据表执行增删改查操作\r\n\r\n事务 ID 本质上就是一个数字，服务器在内存中维护一个全局变量：\r\n\r\n* 每当需要为某个事务分配 ID，就会把全局变量的值赋值给事务 ID，然后变量自增 1\r\n* 每当变量值为 256 的倍数时，就将该变量的值刷新到系统表空间的 Max Trx ID 属性中，该属性占 8 字节\r\n* 系统再次启动后，会读取表空间的 Max Trx ID 属性到内存，加上 256 后赋值给全局变量，因为关机时的事务 ID 可能并不是 256 的倍数，会比 Max Trx ID 大，所以需要加上 256 保持事务 ID 是一个**递增的数字**\r\n\r\n**聚簇索引**的行记录除了完整的数据，还会自动添加 trx_id、roll_pointer 隐藏列，如果表中没有主键并且没有非空唯一索引，也会添加一个 row_id 的隐藏列作为聚簇索引\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 隔离级别\r\n\r\n#### 四种级别\r\n\r\n事务的隔离级别：多个客户端操作时，各个客户端的事务之间应该是隔离的，**不同的事务之间不该互相影响**，而如果多个事务操作同一批数据时，则需要设置不同的隔离级别，否则就会产生问题。\r\n\r\n隔离级别分类：\r\n\r\n| 隔离级别         | 名称     | 会引发的问题           | 数据库默认隔离级别  |\r\n| ---------------- | -------- | ---------------------- | ------------------- |\r\n| Read Uncommitted | 读未提交 | 脏读、不可重复读、幻读 |                     |\r\n| Read Committed   | 读已提交 | 不可重复读、幻读       | Oracle / SQL Server |\r\n| Repeatable Read  | 可重复读 | 幻读                   | MySQL               |\r\n| Serializable     | 可串行化 | 无                     |                     |\r\n\r\n一般来说，隔离级别越低，系统开销越低，可支持的并发越高，但隔离性也越差\r\n\r\n* 脏写 (Dirty Write)：当两个或多个事务选择同一行，最初的事务修改的值被后面事务修改的值覆盖，所有的隔离级别都可以避免脏写（又叫丢失更新），因为有行锁\r\n\r\n* 脏读 (Dirty Reads)：在一个事务处理过程中读取了另一个**未提交**的事务中修改过的数据\r\n\r\n* 不可重复读 (Non-Repeatable Reads)：在一个事务处理过程中读取了另一个事务中修改并**已提交**的数据\r\n\r\n  > 可重复读的意思是不管读几次，结果都一样，可以重复的读，可以理解为快照读，要读的数据集不会发生变化\r\n\r\n* 幻读 (Phantom Reads)：在事务中按某个条件先后两次查询数据库，后一次查询查到了前一次查询没有查到的行，**数据条目**发生了变化。比如查询某数据不存在，准备插入此记录，但执行插入时发现此记录已存在，无法插入\r\n\r\n隔离级别操作语法：\r\n\r\n* 查询数据库隔离级别\r\n\r\n  ```bash\r\n  SELECT @@TX_ISOLATION;\t\t\t-- 会话\r\n  SELECT @@GLOBAL.TX_ISOLATION;\t-- 系统\r\n  ```\r\n\r\n* 修改数据库隔离级别\r\n\r\n  ```bash\r\n  SET GLOBAL TRANSACTION ISOLATION LEVEL 级别字符串;\r\n  ```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 加锁分析\r\n\r\nInnoDB 存储引擎支持事务，所以加锁分析是基于该存储引擎\r\n\r\n* Read Uncommitted 级别，任何操作都不会加锁\r\n\r\n* Read Committed 级别，增删改操作会加写锁（行锁），读操作不加锁\r\n\r\n  在 Server 层过滤条件时发现不满足的记录会调用 unlock_row 方法释放该记录的行锁，保证最后只有满足条件的记录加锁，但是扫表过程中每条记录的**加锁操作不能省略**。所以对数据量很大的表做批量修改时，如果无法使用相应的索引（全表扫描），在 Server 过滤数据时就会特别慢，出现虽然没有修改某些行的数据，但是还是被锁住了的现象（锁表），这种情况同样适用于  RR\r\n\r\n* Repeatable Read 级别，增删改操作会加写锁，读操作不加锁。因为读写锁不兼容，**加了读锁后其他事务就无法修改数据**，影响了并发性能，为了保证隔离性和并发性，MySQL 通过 MVCC 解决了读写冲突。RR 级别下的锁有很多种，锁机制章节详解\r\n\r\n* Serializable 级别，读加共享锁，写加排他锁，读写互斥，使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差\r\n\r\n  * 串行化：让所有事务按顺序单独执行，写操作会加写锁，读操作会加读锁\r\n  * 可串行化：让所有操作相同数据的事务顺序执行，通过加锁实现\r\n\r\n\r\n\r\n参考文章：https://tech.meituan.com/2014/08/20/innodb-lock.html\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 原子特性\r\n\r\n#### 实现方式\r\n\r\n原子性是指事务是一个不可分割的工作单位，事务的操作如果成功就必须要完全应用到数据库，失败则不能对数据库有任何影响。比如事务中一个 SQL 语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态\r\n\r\nInnoDB 存储引擎提供了两种事务日志：redo log（重做日志）和 undo log（回滚日志）\r\n\r\n* redo log 用于保证事务持久性\r\n* undo log 用于保证事务原子性和隔离性\r\n\r\nundo log 属于**逻辑日志**，根据每行操作进行记录，记录了 SQL 执行相关的信息，用来回滚行记录到某个版本\r\n\r\n当事务对数据库进行修改时，InnoDB 会先记录对应的 undo log，如果事务执行失败或调用了 rollback 导致事务回滚，InnoDB 会根据 undo log 的内容**做与之前相反的操作**：\r\n\r\n* 对于每个 insert，回滚时会执行 delete\r\n\r\n* 对于每个 delete，回滚时会执行 insert\r\n\r\n* 对于每个 update，回滚时会执行一个相反的 update，把数据修改回去\r\n\r\n\r\n\r\n参考文章：https://www.cnblogs.com/kismetv/p/10331633.html\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### DML 解析\r\n\r\n##### INSERT\r\n\r\n乐观插入：当前数据页的剩余空间充足，直接将数据进行插入\r\n\r\n悲观插入：当前数据页的剩余空间不足，需要进行页分裂，申请一个新的页面来插入数据，会造成更多的 redo log，undo log 影响不大\r\n\r\n当向某个表插入一条记录，实际上需要向聚簇索引和所有二级索引都插入一条记录，但是 undo log **只针对聚簇索引记录**，在回滚时会根据聚簇索引去所有的二级索引进行回滚操作\r\n\r\nroll_pointer 是一个指针，**指向记录对应的 undo log 日志**，一条记录就是一个数据行，行格式中的 roll_pointer 就指向 undo log\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### DELETE\r\n\r\n插入到页面中的记录会根据 next_record 属性组成一个单向链表，这个链表称为正常链表，被删除的记录也会通过 next_record 组成一个垃圾链表，该链表中所占用的存储空间可以被重新利用，并不会直接清除数据\r\n\r\n在页面 Page Header 中，PAGE_FREE 属性指向垃圾链表的头节点，删除的工作过程：\r\n\r\n* 将要删除的记录的 delete_flag 位置为 1，其他不做修改，这个过程叫 **delete mark**\r\n\r\n* 在事务提交前，delete_flag = 1 的记录一直都会处于中间状态\r\n\r\n* 事务提交后，有专门的线程将 delete_flag = 1 的记录从正常链表移除并加入垃圾链表，这个过程叫 **purge**\r\n\r\n  purge 线程在执行删除操作时会创建一个 ReadView，根据事务的可见性移除数据（隔离特性部分详解）\r\n\r\n当有新插入的记录时，首先判断 PAGE_FREE 指向的头节点是否足够容纳新纪录：\r\n\r\n* 如果可以容纳新纪录，就会直接重用已删除的记录的存储空间，然后让 PAGE_FREE 指向垃圾链表的下一个节点\r\n* 如果不能容纳新纪录，就直接向页面申请新的空间存储，并不会遍历垃圾链表\r\n\r\n重用已删除的记录空间，可能会造成空间碎片，当数据页容纳不了一条记录时，会判断将碎片空间加起来是否可以容纳，判断为真就会重新组织页内的记录：\r\n\r\n* 开辟一个临时页面，将页内记录一次插入到临时页面，此时临时页面时没有碎片的\r\n* 把临时页面的内容复制到本页，这样就解放出了内存碎片，但是会耗费很大的性能资源\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### UPDATE\r\n\r\n执行 UPDATE 语句，对于更新主键和不更新主键有两种不同的处理方式\r\n\r\n不更新主键的情况：\r\n\r\n* 就地更新（in-place update），如果更新后的列和更新前的列占用的存储空间一样大，就可以直接在原记录上修改\r\n\r\n* 先删除旧纪录，再插入新纪录，这里的删除不是 delete mark，而是直接将记录加入垃圾链表，并且修改页面的相应的控制信息，执行删除的线程不是 purge，是执行更新的用户线程，插入新记录时可能造成页空间不足，从而导致页分裂\r\n\r\n\r\n更新主键的情况：\r\n\r\n* 将旧纪录进行 delete mark，在更新语句提交后由 purge 线程移入垃圾链表\r\n* 根据更新的各列的值创建一条新纪录，插入到聚簇索引中\r\n\r\n在对一条记录修改前会**将记录的隐藏列 trx_id 和 roll_pointer 的旧值记录到当前 undo log 对应的属性中**，这样当前记录的 roll_pointer 指向当前 undo log 记录，当前 undo log 记录的 roll_pointer 指向旧的 undo log 记录，**形成一个版本链**\r\n\r\nUPDATE、DELETE 操作产生的 undo 日志会用于其他事务的 MVCC 操作，所以不能立即删除，INSERT 可以删除的原因是 MVCC 是对现有数据的快照\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 回滚日志\r\n\r\nundo log 是采用段的方式来记录，Rollback Segement 称为回滚段，本质上就是一个类型是 Rollback Segement Header 的页面\r\n\r\n每个回滚段中有 1024 个 undo slot，每个 slot 存放 undo 链表页面的头节点页号，每个链表对应一个叫 undo log segment 的段\r\n\r\n* 在以前老版本，只支持 1 个 Rollback Segement，只能记录 1024 个 undo log segment\r\n* MySQL5.5 开始支持 128 个 Rollback Segement，支持 128*1024 个 undo 操作\r\n\r\n工作流程：\r\n\r\n* 事务执行前需要到系统表空间第 5 号页面中分配一个回滚段（页），获取一个 Rollback Segement Header 页面的地址\r\n\r\n* 回滚段页面有 1024 个 undo slot，首先去回滚段的两个 cached 链表获取缓存的 slot，缓存中没有就在回滚段页面中找一个可用的 undo slot 分配给当前事务\r\n\r\n* 如果是缓存中获取的 slot，则该 slot 对应的 undo log segment 已经分配了，需要重新分配，然后从 undo log segment 中申请一个页面作为日志链表的头节点，并填入对应的 slot 中\r\n\r\n* 每个事务 undo 日志在记录的时候**占用两个 undo 页面的组成链表**，分别为 insert undo 链表和 update undo 链表，链表的头节点页面为 first undo page 会包含一些管理信息，其他页面为 normal undo page\r\n\r\n  说明：事务执行过程的临时表也需要两个 undo 链表，不和普通表共用，这些链表并不是事务开始就分配，而是按需分配\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 隔离特性\r\n\r\n#### 实现方式\r\n\r\n隔离性是指，事务内部的操作与其他事务是隔离的，多个并发事务之间要相互隔离，不能互相干扰\r\n\r\n* 严格的隔离性，对应了事务隔离级别中的 serializable，实际应用中对性能考虑很少使用可串行化\r\n\r\n* 与原子性、持久性侧重于研究事务本身不同，隔离性研究的是**不同事务**之间的相互影响\r\n\r\n隔离性让并发情形下的事务之间互不干扰：\r\n\r\n- 一个事务的写操作对另一个事务的写操作（写写）：锁机制保证隔离性\r\n- 一个事务的写操作对另一个事务的读操作（读写）：MVCC 保证隔离性\r\n\r\n锁机制：事务在修改数据之前，需要先获得相应的锁，获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁（详解见锁机制）\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 并发控制\r\n\r\nMVCC 全称 Multi-Version Concurrency Control，即多版本并发控制，用来**解决读写冲突的无锁并发控制**，可以在发生读写请求冲突时不用加锁解决，这个读是指的快照读（也叫一致性读或一致性无锁读），而不是当前读：\r\n\r\n* 快照读：实现基于 MVCC，因为是多版本并发，所以快照读读到的数据不一定是当前最新的数据，有可能是历史版本的数据\r\n* 当前读：又叫加锁读，读取数据库记录是当前**最新的版本**（产生幻读、不可重复读），可以对读取的数据进行加锁，防止其他事务修改数据，是悲观锁的一种操作，读写操作加共享锁或者排他锁和串行化事务的隔离级别都是当前读\r\n\r\n数据库并发场景：\r\n\r\n* 读-读：不存在任何问题，也不需要并发控制\r\n\r\n* 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读\r\n\r\n* 写-写：有线程安全问题，可能会存在脏写（丢失更新）问题\r\n\r\nMVCC 的优点：\r\n\r\n* 在并发读写数据库时，做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了并发读写的性能\r\n* 可以解决脏读，不可重复读等事务隔离问题（加锁也能解决），但不能解决更新丢失问题（写锁会解决）\r\n\r\n提高读写和写写的并发性能：\r\n\r\n* MVCC + 悲观锁：MVCC 解决读写冲突，悲观锁解决写写冲突\r\n* MVCC + 乐观锁：MVCC 解决读写冲突，乐观锁解决写写冲突\r\n\r\n\r\n\r\n参考文章：https://www.jianshu.com/p/8845ddca3b23\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 实现原理\r\n\r\n##### 隐藏字段\r\n\r\n实现原理主要是隐藏字段，undo日志，Read View 来实现的\r\n\r\nInnoDB 存储引擎，数据库中的**聚簇索引**每行数据，除了自定义的字段，还有数据库隐式定义的字段：\r\n\r\n* DB_TRX_ID：最近修改事务 ID，记录创建该数据或最后一次修改该数据的事务 ID\r\n* DB_ROLL_PTR：回滚指针，**指向记录对应的 undo log 日志**，undo log 中又指向上一个旧版本的 undo log\r\n* DB_ROW_ID：隐含的自增 ID（**隐藏主键**），如果数据表没有主键，InnoDB 会自动以 DB_ROW_ID 作为聚簇索引\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MVCC版本链隐藏字段.png)\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 版本链\r\n\r\nundo log 是逻辑日志，记录的是每个事务对数据执行的操作，而不是记录的全部数据，要**根据 undo log 逆推出以往事务的数据**\r\n\r\nundo log 的作用：\r\n\r\n* 保证事务进行 rollback 时的原子性和一致性，当事务进行回滚的时候可以用 undo log 的数据进行恢复\r\n* 用于 MVCC 快照读，通过读取 undo log 的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据\r\n\r\nundo log 主要分为两种：\r\n\r\n* insert undo log：事务在 insert 新记录时产生的 undo log，只在事务回滚时需要，并且在事务提交后可以被立即丢弃\r\n\r\n* update undo log：事务在进行 update 或 delete 时产生的 undo log，在事务回滚时需要，在快照读时也需要。不能随意删除，只有在当前读或事务回滚不涉及该日志时，对应的日志才会被 purge 线程统一清除\r\n\r\n每次对数据库记录进行改动，都会产生的新版本的 undo log，随着更新次数的增多，所有的版本都会被 roll_pointer 属性连接成一个链表，把这个链表称之为**版本链**，版本链的头节点就是当前的最新的 undo log，链尾就是最早的旧 undo log\r\n\r\n说明：因为 DELETE 删除记录，都是移动到垃圾链表中，不是真正的删除，所以才可以通过版本链访问原始数据\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MVCC版本链.png\" style=\"zoom: 80%;\" />\r\n\r\n注意：undo 是逻辑日志，这里只是直观的展示出来\r\n\r\n工作流程：\r\n\r\n* 有个事务插入 persion 表一条新记录，name 为 Jerry，age 为 24\r\n* 事务 1 修改该行数据时，数据库会先对该行加排他锁，然后先记录 undo log，然后修改该行 name 为 Tom，并且修改隐藏字段的事务 ID 为当前事务 1 的 ID（默认为 1 之后递增），回滚指针指向拷贝到 undo log 的副本记录，事务提交后，释放锁\r\n* 以此类推\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 读视图\r\n\r\nRead View 是事务进行读数据操作时产生的读视图，该事务执行快照读的那一刻会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的 ID，用来做可见性判断，根据视图判断当前事务能够看到哪个版本的数据\r\n\r\n注意：这里的快照并不是把所有的数据拷贝一份副本，而是由 undo log 记录的逻辑日志，根据库中的数据进行计算出历史数据\r\n\r\n工作流程：将版本链的头节点的事务 ID（最新数据事务 ID，大概率不是当前线程）DB_TRX_ID 取出来，与系统当前活跃事务的 ID 对比进行可见性分析，不可见就通过 DB_ROLL_PTR 回滚指针去取出 undo log 中的下一个 DB_TRX_ID 比较，直到找到最近的满足可见性的 DB_TRX_ID，该事务 ID 所在的旧记录就是当前事务能看见的最新的记录\r\n\r\nRead View 几个属性：\r\n\r\n- m_ids：生成 Read View 时当前系统中活跃的事务 id 列表（未提交的事务集合，当前事务也在其中）\r\n- min_trx_id：生成 Read View 时当前系统中活跃的最小的事务 id，也就是 m_ids 中的最小值（已提交的事务集合）\r\n- max_trx_id：生成 Read View 时当前系统应该分配给下一个事务的 id 值，m_ids 中的最大值加 1（未开始事务）\r\n- creator_trx_id：生成该 Read View 的事务的事务 id，就是判断该 id 的事务能读到什么数据\r\n\r\ncreator 创建一个 Read View，进行可见性算法分析：（解决了读未提交）\r\n\r\n*  db_trx_id == creator_trx_id：表示这个数据就是当前事务自己生成的，自己生成的数据自己肯定能看见，所以此数据对 creator 是可见的\r\n*  db_trx_id <  min_trx_id：该版本对应的事务 ID 小于 Read view 中的最小活跃事务 ID，则这个事务在当前事务之前就已经被提交了，对 creator 可见（因为比已提交的最大事务 ID 小的并不一定已经提交，所以应该判断是否在活跃事务列表）\r\n\r\n*  db_trx_id >= max_trx_id：该版本对应的事务 ID 大于 Read view 中当前系统的最大事务 ID，则说明该数据是在当前 Read view 创建之后才产生的，对 creator 不可见\r\n*  min_trx_id<= db_trx_id < max_trx_id：判断 db_trx_id 是否在活跃事务列表 m_ids 中\r\n   * 在列表中，说明该版本对应的事务正在运行，数据不能显示（**不能读到未提交的数据**）\r\n   * 不在列表中，说明该版本对应的事务已经被提交，数据可以显示（**可以读到已经提交的数据**）\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 工作流程\r\n\r\n表 user 数据\r\n\r\n```sh\r\nid\t\tname\t\tage\r\n1\t\t张三\t\t   18\t\r\n```\r\n\r\nTransaction 20：\r\n\r\n```bash\r\nSTART TRANSACTION;\t-- 开启事务\r\nUPDATE user SET name = '李四' WHERE id = 1;\r\nUPDATE user SET name = '王五' WHERE id = 1;\r\n```\r\n\r\nTransaction 60：\r\n\r\n```bash\r\nSTART TRANSACTION;\t-- 开启事务\r\n-- 操作表的其他数据\r\n```\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MVCC工作流程1.png)\r\n\r\nID 为 0 的事务创建 Read View：\r\n\r\n* m_ids：20、60\r\n* min_trx_id：20\r\n* max_trx_id：61\r\n* creator_trx_id：0\r\n\r\n![](https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-MVCC工作流程2.png)\r\n\r\n只有红框部分才复合条件，所以只有张三对应的版本的数据可以被看到\r\n\r\n\r\n\r\n参考视频：https://www.bilibili.com/video/BV1t5411u7Fg\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 二级索引\r\n\r\n只有在聚簇索引中才有 trx_id 和 roll_pointer 的隐藏列，对于二级索引判断可见性的方式：\r\n\r\n* 二级索引页面的 Page Header 中有一个 PAGE_MAX_TRX_ID 属性，代表修改当前页面的最大的事务 ID，SELECT 语句访问某个二级索引时会判断 ReadView 的 min_trx_id 是否大于该属性，大于说明该页面的所有属性对 ReadView 可见\r\n* 如果属性判断不可见，就需要利用二级索引获取主键值进行**回表操作**，得到聚簇索引后按照聚簇索引的可见性判断的方法操作\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### RC RR\r\n\r\nRead View 用于支持 RC（Read Committed，读已提交）和 RR（Repeatable Read，可重复读）隔离级别的实现，所以 **SELECT 在 RC 和 RR 隔离级别使用 MVCC 读取记录**\r\n\r\nRR、RC 生成时机：\r\n\r\n- RC 隔离级别下，每次读取数据前都会生成最新的 Read View（当前读）\r\n- RR 隔离级别下，在第一次数据读取时才会创建 Read View（快照读）\r\n\r\nRC、RR 级别下的 InnoDB 快照读区别\r\n\r\n- RC 级别下，事务中每次快照读都会新生成一个 Read View，这就是在 RC 级别下的事务中可以看到别的事务提交的更新的原因\r\n\r\n- RR 级别下，某个事务的对某条记录的**第一次快照读**会创建一个 Read View， 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，使用的是同一个 Read View，所以一个事务的查询结果每次都是相同的\r\n\r\n  RR 级别下，通过 `START TRANSACTION WITH CONSISTENT SNAPSHOT` 开启事务，会在执行该语句后立刻生成一个 Read View，不是在执行第一条 SELECT 语句时生成（所以说 `START TRANSACTION` 并不是事务的起点，执行第一条语句才算起点）\r\n\r\n解决幻读问题：\r\n\r\n- 快照读：通过 MVCC 来进行控制的，在可重复读隔离级别下，普通查询是快照读，是不会看到别的事务插入的数据的，但是**并不能完全避免幻读**\r\n\r\n  场景：RR 级别，T1 事务开启，创建 Read View，此时 T2 去 INSERT 新的一行然后提交，然后 T1 去 UPDATE 该行会发现更新成功，并且把这条新记录的 trx_id 变为当前的事务 id，所以对当前事务就是可见的。因为 **Read View 并不能阻止事务去更新数据，更新数据都是先读后写并且是当前读**，读取到的是最新版本的数据\r\n\r\n- 当前读：通过 next-key 锁（行锁 + 间隙锁）来解决问题\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 持久特性\r\n\r\n#### 实现方式\r\n\r\n持久性是指一个事务一旦被提交了，那么对数据库中数据的改变就是永久性的，接下来的其他操作或故障不应该对其有任何影响。\r\n\r\nBuffer Pool 的使用提高了读写数据的效率，但是如果 MySQL 宕机，此时 Buffer Pool 中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证，所以引入了 redo log 日志：\r\n\r\n* redo log **记录数据页的物理修改**，而不是某一行或某几行的修改，用来恢复提交后的数据页，只能**恢复到最后一次提交**的位置\r\n* redo log 采用的是 WAL（Write-ahead logging，**预写式日志**），所有修改要先写入日志，再更新到磁盘，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求\r\n* 简单的 redo log 是纯粹的物理日志，复杂的 redo log 会存在物理日志和逻辑日志\r\n\r\n工作过程：MySQL 发生了宕机，InnoDB 会判断一个数据页在崩溃恢复时丢失了更新，就会将它读到内存，然后根据 redo log 内容更新内存，更新完成后，内存页变成脏页，然后进行刷脏\r\n\r\n缓冲池的**刷脏策略**：\r\n\r\n* redo log 文件是固定大小的，如果写满了就要擦除以前的记录，在擦除之前需要把对应的更新持久化到磁盘中\r\n* Buffer Pool 内存不足，需要淘汰部分数据页（LRU 链表尾部），如果淘汰的是脏页，就要先将脏页写到磁盘（要避免大事务）\r\n* 系统空闲时，后台线程会自动进行刷脏（Flush 链表部分已经详解）\r\n* MySQL 正常关闭时，会把内存的脏页都刷新到磁盘上\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 重做日志\r\n\r\n##### 日志缓冲\r\n\r\n服务器启动时会向操作系统申请一片连续内存空间作为 redo log buffer（重做日志缓冲区），可以通过 `innodb_log_buffer_size` 系统变量指定 redo log buffer 的大小，默认是 16MB\r\n\r\nlog buffer 被划分为若干 redo log block（块，类似数据页的概念），每个默认大小 512 字节，每个 block 由 12 字节的 log block head、496 字节的 log block body、4 字节的 log block trailer 组成\r\n\r\n* 当数据修改时，先修改 Change Buffer 中的数据，然后在 redo log buffer 记录这次操作，写入 log buffer 的过程是**顺序写入**的（先写入前面的 block，写满后继续写下一个）\r\n* log buffer 中有一个指针 buf_free，来标识该位置之前都是填满的 block，该位置之后都是空闲区域\r\n\r\nMySQL 规定对底层页面的一次原子访问称为一个 Mini-Transaction（MTR），比如在 B+ 树上插入一条数据就算一个 MTR\r\n\r\n* 一个事务包含若干个 MTR，一个 MTR 对应一组若干条 redo log，一组 redo log 是不可分割的，在进行数据恢复时也把一组 redo log 当作一个不可分割的整体处理\r\n\r\n* 不是每生成一条 redo 日志就将其插入到 log buffer 中，而是一个 MTR 结束后**将一组 redo 日志写入**\r\n\r\nInnoDB 的 redo log 是**固定大小**的，redo 日志在磁盘中以文件组的形式存储，同一组中的每个文件大小一样格式一样\r\n\r\n* `innodb_log_group_home_dir` 代表磁盘存储 redo log 的文件目录，默认是当前数据目录\r\n* `innodb_log_file_size` 代表文件大小，默认 48M，`innodb_log_files_in_group` 代表文件个数，默认 2 最大 100，所以日志的文件大小为 `innodb_log_file_size * innodb_log_files_in_group`\r\n\r\nredo 日志文件也是由若干个 512 字节的 block 组成，日志文件的前 2048 个字节（前 4 个 block）用来存储一些管理信息，以后的用来存储 log buffer 中的 block 镜像\r\n\r\n注意：block 并不代表一组 redo log，一组日志可能占用不到一个 block 或者几个 block，依赖于 MTR 的大小\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 日志刷盘\r\n\r\nredo log 需要在事务提交时将日志写入磁盘，但是比 Buffer Pool 修改的数据写入磁盘的速度快，原因：\r\n\r\n* 刷脏是随机 IO，因为每次修改的数据位置随机；redo log 和 binlog 都是**顺序写**，磁盘的顺序 IO 比随机 IO 速度要快\r\n* 刷脏是以数据页（Page）为单位的，一个页上的一个小修改都要整页写入；redo log 中只包含真正需要写入的部分，好几页的数据修改可能只记录在一个 redo log 页中，减少无效 IO\r\n* **组提交机制**，可以大幅度降低磁盘的 IO 消耗\r\n\r\nInnoDB 引擎会在适当的时候，把内存中 redo log buffer 持久化（fsync）到磁盘，具体的**刷盘策略**：\r\n\r\n* 在事务提交时需要进行刷盘，通过修改参数 `innodb_flush_log_at_trx_commit` 设置：\r\n  * 0：表示当提交事务时，并不将缓冲区的 redo 日志写入磁盘，而是等待**后台线程每秒刷新一次**\r\n  * 1：在事务提交时将缓冲区的 redo 日志**同步写入**到磁盘，保证一定会写入成功（默认值）\r\n  * 2：在事务提交时将缓冲区的 redo 日志异步写入到磁盘，不能保证提交时肯定会写入，只是有这个动作。日志已经在操作系统的缓存，如果操作系统没有宕机而 MySQL 宕机，也是可以恢复数据的\r\n* 写入 redo log buffer 的日志超过了总容量的一半，就会将日志刷入到磁盘文件，这会影响执行效率，所以开发中应**避免大事务**\r\n* 服务器关闭时\r\n* 并行的事务提交（组提交）时，会将将其他事务的 redo log 持久化到磁盘。假设事务 A 已经写入 redo log  buffer 中，这时另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么事务 B 要把 redo log buffer 里的日志全部持久化到磁盘，**因为多个事务共用一个 redo log buffer**，所以一次 fsync 可以刷盘多个事务的 redo log，提升了并发量\r\n\r\n服务器启动后 redo 磁盘空间不变，所以 redo 磁盘中的日志文件是被**循环使用**的，采用循环写数据的方式，写完尾部重新写头部，所以要确保头部 log 对应的修改已经持久化到磁盘\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 日志序号\r\n\r\nlsn (log sequence number) 代表已经写入的 redo 日志量、flushed_to_disk_lsn 指刷新到磁盘中的 redo 日志量，两者都是**全局变量**，如果两者的值相同，说明 log buffer 中所有的 redo 日志都已经持久化到磁盘\r\n\r\n工作过程：写入 log buffer 数据时，buf_free 会进行偏移，偏移量就会加到 lsn 上\r\n\r\nMTR 的执行过程中修改过的页对应的控制块会加到 Buffer Pool 的 flush 链表中，链表中脏页是按照第一次修改的时间进行排序的（头插），控制块中有两个指针用来记录脏页被修改的时间：\r\n\r\n* oldest_modification：第一次修改 Buffer Pool 中某个缓冲页时，将修改该页的 MTR **开始时**对应的 lsn 值写入这个属性\r\n* newest_modification：每次修改页面，都将 MTR 结束时全局的 lsn 值写入这个属性，所以该值是该页面最后一次修改后的 lsn 值\r\n\r\n全局变量 checkpoint_lsn 表示**当前系统可以被覆盖的 redo 日志总量**，当 redo 日志对应的脏页已经被刷新到磁盘后，该文件空间就可以被覆盖重用，此时执行一次 checkpoint 来更新 checkpoint_lsn 的值存入管理信息（刷脏和执行一次 checkpoint 并不是同一个线程），该值的增量就代表磁盘文件中当前位置向后可以被覆盖的文件的量，所以该值是一直增大的\r\n\r\n**checkpoint**：从 flush 链表尾部中找出还未刷脏的页面，该页面是当前系统中最早被修改的脏页，该页面之前产生的脏页都已经刷脏，然后将该页 oldest_modification 值赋值给 checkpoint_lsn，因为 lsn 小于该值时产生的 redo 日志都可以被覆盖了\r\n\r\n但是在系统忙碌时，后台线程的刷脏操作不能将脏页快速刷出，导致系统无法及时执行 checkpoint ，这时需要用户线程从 flush 链表中把最早修改的脏页刷新到磁盘中，然后执行 checkpoint\r\n\r\n```java\r\nwrite pos ------- checkpoint_lsn // 两值之间的部分表示可以写入的日志量，当 pos 追赶上 lsn 时必须执行 checkpoint\r\n```\r\n\r\n使用命令可以查看当前 InnoDB 存储引擎各种 lsn 的值：\r\n\r\n```bash\r\nSHOW ENGINE INNODB STATUS\\G\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n##### 崩溃恢复\r\n\r\n恢复的起点：在从 redo 日志文件组的管理信息中获取最近发生 checkpoint 的信息，**从 checkpoint_lsn 对应的日志文件开始恢复**\r\n\r\n恢复的终点：扫描日志文件的 block，block 的头部记录着当前 block 使用了多少字节，填满的 block 总是 512 字节， 如果某个 block 不是 512 字节，说明该 block 就是需要恢复的最后一个 block\r\n\r\n恢复的过程：按照 redo log 依次执行恢复数据，优化方式\r\n\r\n* 使用哈希表：根据 redo log 的 space id 和 page number 属性计算出哈希值，将对同一页面的修改放入同一个槽里，可以一次性完成对某页的恢复，**避免了随机 IO**\r\n* 跳过已经刷新到磁盘中的页面：数据页的 File Header 中的 FILE_PAGE_LSN 属性（类似 newest_modification）表示最近一次修改页面时的 lsn 值，数据页被刷新到磁盘中，那么该页 lsn 属性肯定大于 checkpoint_lsn \r\n\r\n\r\n\r\n参考书籍：https://book.douban.com/subject/35231266/\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 工作流程\r\n\r\n##### 日志对比\r\n\r\nMySQL 中还存在 binlog（二进制日志）也可以记录写操作并用于数据的恢复，**保证数据不丢失**，二者的区别是：\r\n\r\n* 作用不同：redo log 是用于 crash recovery （故障恢复），保证 MySQL 宕机也不会影响持久性；binlog 是用于 point-in-time recovery 的，保证服务器可以基于时间点恢复数据，此外 binlog 还用于主从复制\r\n* 层次不同：redo log 是 InnoDB 存储引擎实现的，而 binlog 是MySQL的 Server 层实现的，同时支持 InnoDB 和其他存储引擎\r\n* 内容不同：redo log 是物理日志，内容基于磁盘的 Page；binlog 的内容是二进制的，根据 binlog_format 参数的不同，可能基于SQL 语句、基于数据本身或者二者的混合（日志部分详解）\r\n* 写入时机不同：binlog 在事务提交时一次写入；redo log 的写入时机相对多元\r\n\r\nbinlog 为什么不支持崩溃恢复？\r\n\r\n* binlog 记录的是语句，并不记录数据页级的数据（哪个页改了哪些地方），所以没有能力恢复数据页\r\n* binlog 是追加写，保存全量的日志，没有标志确定从哪个点开始的数据是已经刷盘了，而 redo log 只要在 checkpoint_lsn 后面的就是没有刷盘的\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 更新记录\r\n\r\n更新一条记录的过程：写之前一定先读\r\n\r\n* 在 B+ 树中定位到该记录，如果该记录所在的页面不在 Buffer Pool 里，先将其加载进内存\r\n\r\n* 首先更新该记录对应的聚簇索引，更新聚簇索引记录时：\r\n\r\n  * 更新记录前向 undo 页面写 undo 日志，由于这是更改页面，所以需要记录一下相应的 redo 日志\r\n\r\n    注意：修改 undo 页面也是在**修改页面**，事务只要修改页面就需要先记录相应的 redo 日志\r\n\r\n  * 然后**记录对应的 redo 日志**（等待 MTR 提交后写入 redo log buffer），**最后进行真正的更新记录**\r\n\r\n* 更新其他的二级索引记录，不会再记录 undo log，只记录 redo log 到 buffer 中\r\n\r\n* 在一条更新语句执行完成后（也就是将所有待更新记录都更新完了），就会开始记录该语句对应的 binlog 日志，此时记录的 binlog 并没有刷新到硬盘上，还在内存中，在事务提交时才会统一将该事务运行过程中的所有 binlog 日志刷新到硬盘\r\n\r\n假设表中有字段 id 和 a，存在一条 `id = 1, a = 2` 的记录，此时执行更新语句：\r\n\r\n```sql\r\nupdate table set a=2 where id=1;\r\n```\r\n\r\nInnoDB 会真正的去执行把值修改成 (1,2) 这个操作，先加行锁，在去更新，并不会提前判断相同就不修改了\r\n\r\n\r\n\r\n参考文章：https://mp.weixin.qq.com/s/wcJ2KisSaMnfP4nH5NYaQA\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 两段提交\r\n\r\n当客户端执行 COMMIT 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，分两阶段来完成 XA 事务的提交：\r\n\r\n```sql\r\nupdate T set c=c+1 where ID=2;\r\n```\r\n\r\n<img src=\"https://seazean.oss-cn-beijing.aliyuncs.com/img/DB/MySQL-update的执行流程.png\" style=\"zoom: 33%;\" />\r\n\r\n流程说明：执行引擎将这行新数据读入到内存中（Buffer Pool）后，先将此次更新操作记录到 redo log buffer 里，然后更新记录。最后将 redo log 刷盘后事务处于 prepare 状态，执行器会生成这个操作的 binlog，并**把 binlog 写入磁盘**，完成提交\r\n\r\n两阶段：\r\n\r\n* Prepare 阶段：存储引擎将该事务的 **redo 日志刷盘**，并且将本事务的状态设置为 PREPARE，代表执行完成随时可以提交事务\r\n* Commit 阶段：先将事务执行过程中产生的 binlog 刷新到硬盘，再执行存储引擎的提交工作，引擎把 redo log 改成提交状态\r\n\r\n存储引擎层的 redo log 和 server 层的 binlog 可以认为是一个分布式事务， 都可以用于表示事务的提交状态，而**两阶段提交就是让这两个状态保持逻辑上的一致**，也有利于主从复制，更好的保持主从数据的一致性\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 数据恢复\r\n\r\n系统崩溃前没有提交的事务的 redo log 可能已经刷盘（定时线程或者 checkpoint），怎么处理崩溃恢复？\r\n\r\n工作流程：获取 undo 链表首节点页面的 undo segement header 中的 TRX_UNDO_STATE 属性，表示当前链表的事务属性，**事务状态是活跃（未提交）的就全部回滚**，如果是 PREPARE 状态，就需要根据 binlog 的状态进行判断：\r\n\r\n* 如果在时刻 A 发生了崩溃（crash），由于此时 binlog 还没完成，所以需要进行回滚\r\n* 如果在时刻 B 发生了崩溃，redo log 和 binlog 有一个共**同的数据字段叫 XID**，崩溃恢复的时候，会按顺序扫描 redo log：\r\n  * 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，说明 binlog 也已经记录完整，直接从 redo log 恢复数据\r\n  * 如果 redo log 里面的事务只有 prepare，就根据 XID 去 binlog 中判断对应的事务是否存在并完整，如果完整可以恢复数据\r\n\r\n\r\n判断一个事务的 binlog 是否完整的方法：\r\n\r\n* statement 格式的 binlog，最后会有 COMMIT\r\n* row 格式的 binlog，最后会有一个 XID event\r\n* MySQL 5.6.2 版本以后，引入了 binlog-checksum 参数用来验证 binlog 内容的正确性（可能日志中间出错）\r\n\r\n\r\n\r\n参考文章：https://time.geekbang.org/column/article/73161\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 刷脏优化\r\n\r\n系统在进行刷脏时会占用一部分系统资源，会影响系统的性能，**产生系统抖动**\r\n\r\n* 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长\r\n* 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的\r\n\r\nInnoDB 刷脏页的控制策略：\r\n\r\n* `innodb_io_capacity` 参数代表磁盘的读写能力，建议设置成磁盘的 IOPS（每秒的 IO 次数）\r\n* 刷脏速度参考两个因素：脏页比例和 redo log 写盘速度\r\n  * 参数 `innodb_max_dirty_pages_pct` 是脏页比例上限，默认值是 75%，InnoDB 会根据当前的脏页比例，算出一个范围在 0 到 100 之间的数字\r\n  * InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，InnoDB 根据差值算出一个范围在 0 到 100 之间的数字\r\n  * 两者较大的值记为 R，执行引擎按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度\r\n* `innodb_flush_neighbors` 参数置为 1 代表控制刷脏时检查相邻的数据页，如果也是脏页就一起刷脏，并检查邻居的邻居，这个行为会一直蔓延直到不是脏页，在 MySQL 8.0 中该值的默认值是 0，不建议开启此功能\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 一致特性\r\n\r\n一致性是指事务执行前后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。\r\n\r\n数据库的完整性约束包括但不限于：实体完整性（如行的主键存在且唯一）、列完整性（如字段的类型、大小、长度要符合要求）、外键约束、用户自定义完整性（如转账前后，两个账户余额的和应该不变）\r\n\r\n实现一致性的措施：\r\n\r\n- 保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证\r\n- 数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等\r\n- 应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n"},{"title":"Netty","tags":["Netty"],"categories":["Java","未分类"],"author":"imklaus","excerpt":"\r\n参考视频：[满神Netty深入浅出Java网络编程教程](https://www.bilibili.com/video/BV1py4y1E7oA)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n","link":"/posts/Netty","content":"\r\n参考视频：[满神Netty深入浅出Java网络编程教程](https://www.bilibili.com/video/BV1py4y1E7oA)\r\n\r\n笔记的整体结构依据视频编写，并随着学习的深入补充了很多知识\r\n\r\n<!-- more -->\r\n\r\n目录指引：\r\n\r\n[[toc]]\r\n\r\n\r\n\r\n## 基本介绍\r\n\r\nNetty 是一个异步事件驱动的网络应用程序框架，用于快速开发可维护、高性能的网络服务器和客户端\r\n\r\nNetty 官网：https://netty.io/\r\n\r\nNetty 的对 JDK 自带的 NIO 的 API 进行封装，解决上述问题，主要特点有：\r\n\r\n- 设计优雅，适用于各种传输类型的统一 API， 阻塞和非阻塞 Socket 基于灵活且可扩展的事件模型\r\n- 使用方便，详细记录的 Javadoc、用户指南和示例，没有其他依赖项\r\n- 高性能，吞吐量更高，延迟更低，减少资源消耗，最小化不必要的内存复制\r\n- 安全，完整的 SSL/TLS 和 StartTLS 支持\r\n\r\n\r\n\r\nNetty 的功能特性：\r\n\r\n* 传输服务：支持 BIO 和 NIO\r\n* 容器集成：支持 OSGI、JBossMC、Spring、Guice 容器\r\n* 协议支持：HTTP、Protobuf、二进制、文本、WebSocket 等一系列协议都支持，也支持通过实行编码解码逻辑来实现自定义协议\r\n* Core 核心：可扩展事件模型、通用通信 API、支持零拷贝的 ByteBuf 缓冲对象\r\n\r\n![image-20241006231240655](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231240655.png)\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n## 线程模型\r\n\r\n### 阻塞模型\r\n\r\n传统阻塞型 I/O 模式，每个连接都需要独立的线程完成数据的输入，业务处理，数据返回\r\n\r\n![image-20241006231321181](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231321181.png)\r\n\r\n模型缺点：\r\n\r\n- 当并发数较大时，需要创建大量线程来处理连接，系统资源占用较大\r\n- 连接建立后，如果当前线程暂时没有数据可读，则线程就阻塞在 read 操作上，造成线程资源浪费\r\n\r\n\r\n\r\n参考文章：https://www.jianshu.com/p/2965fca6bb8f\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Reactor\r\n\r\n#### 设计思想\r\n\r\nReactor 模式，通过一个或多个输入同时传递给服务处理器的**事件驱动处理模式**。 服务端程序处理传入的多路请求，并将它们同步分派给对应的处理线程，Reactor 模式也叫 Dispatcher 模式，即 I/O 多路复用统一监听事件，收到事件后分发（Dispatch 给某线程）\r\n\r\n**I/O 复用结合线程池**，就是 Reactor 模式基本设计思想：\r\n\r\n![image-20241006231348776](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231348776.png)\r\n\r\nReactor 模式关键组成：\r\n\r\n- Reactor：在一个单独的线程中运行，负责**监听和分发事件**，分发给适当的处理程序来对 I/O 事件做出反应\r\n- Handler：处理程序执行 I/O 要完成的实际事件，Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行**非阻塞操作**\r\n\r\nReactor 模式具有如下的优点：\r\n\r\n- 响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的\r\n- 编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销\r\n- 可扩展性，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源\r\n- 可复用性，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性\r\n\r\n根据 Reactor 的数量和处理资源池线程的数量不同，有三种典型的实现：\r\n\r\n- 单 Reactor 单线程\r\n- 单 Reactor 多线程\r\n- 主从 Reactor 多线程\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 单R单线程\r\n\r\nReactor 对象通过 select 监控客户端请求事件，收到事件后通过 dispatch 进行分发：\r\n\r\n* 如果是建立连接请求事件，则由 Acceptor 通过 accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理\r\n\r\n* 如果不是建立连接事件，则 Reactor 会分发给连接对应的 Handler 来响应，Handler 会完成 read、业务处理、send 的完整流程\r\n\r\n  说明：**Handler 和 Acceptor 属于同一个线程**\r\n\r\n![image-20241006231415161](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231415161.png)\r\n\r\n模型优点：模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成\r\n\r\n模型缺点：\r\n\r\n* 性能问题：只有一个线程，无法发挥多核 CPU 的性能，Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈\r\n* 可靠性问题：线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障\r\n\r\n使用场景：客户端的数量有限，业务处理非常快速，比如 Redis，业务处理的时间复杂度 O(1)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 单R多线程\r\n\r\n执行流程通同单 Reactor 单线程，不同的是：\r\n\r\n* Handler 只负责响应事件，不做具体业务处理，通过 read 读取数据后，会分发给后面的 Worker 线程池进行业务处理\r\n\r\n* Worker 线程池会分配独立的线程完成真正的业务处理，将响应结果发给 Handler 进行处理，最后由 Handler 收到响应结果后通过 send 将响应结果返回给 Client\r\n\r\n![image-20241006231433735](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231433735.png)\r\n\r\n模型优点：可以充分利用多核 CPU 的处理能力\r\n\r\n模型缺点：\r\n\r\n* 多线程数据共享和访问比较复杂\r\n* Reactor 承担所有事件的监听和响应，在单线程中运行，高并发场景下容易成为性能瓶颈\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 主从模型\r\n\r\n采用多个 Reactor ，执行流程：\r\n\r\n* Reactor 主线程 MainReactor 通过 select **监控建立连接事件**，收到事件后通过 Acceptor 接收，处理建立连接事件，处理完成后 MainReactor 会将连接分配给 Reactor 子线程的 SubReactor（有多个）处理\r\n\r\n* SubReactor 将连接加入连接队列进行监听其他事件，并创建一个 Handler 用于处理该连接的事件，当有新的事件发生时，SubReactor 会调用连接对应的 Handler 进行响应\r\n\r\n* Handler 通过 read 读取数据后，会分发给 Worker 线程池进行业务处理\r\n\r\n* Worker 线程池会分配独立的线程完成真正的业务处理，将响应结果发给 Handler 进行处理，最后由 Handler 收到响应结果后通过 send 将响应结果返回给 Client\r\n\r\n![image-20241006231457281](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231457281.png)\r\n\r\n模型优点\r\n\r\n- **父线程与子线程**的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理\r\n- 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据\r\n\r\n使用场景：Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### Proactor\r\n\r\nReactor 模式中，Reactor 等待某个事件的操作状态发生变化（文件描述符可读写，socket 可读写），然后把事件传递给事先注册的 Handler 来做实际的读写操作，其中的读写操作都需要应用程序同步操作，所以 **Reactor 是非阻塞同步网络模型（NIO）**\r\n\r\n把 I/O 操作改为异步，交给操作系统来完成就能进一步提升性能，这就是异步网络模型 Proactor（AIO）：\r\n\r\n![image-20241006231558168](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231558168.png)\r\n\r\n工作流程：\r\n\r\n* ProactorInitiator 创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 通过 Asynchronous Operation Processor（AsyOptProcessor）注册到内核\r\n* AsyOptProcessor 处理注册请求，并处理 I/O 操作，完成I/O后通知 Proactor\r\n* Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理，最后由 Handler 完成业务处理\r\n\r\n对比：Reactor 在事件发生时就通知事先注册的处理器（读写在应用程序线程中处理完成）；Proactor 是在事件发生时基于异步 I/O 完成读写操作（内核完成），I/O 完成后才回调应用程序的处理器进行业务处理\r\n\r\n模式优点：异步 I/O 更加充分发挥 DMA（Direct Memory Access 直接内存存取）的优势\r\n\r\n模式缺点：\r\n\r\n* 编程复杂性，由于异步操作流程的事件的初始化和事件完成在时间和空间上都是相互分离的，因此开发异步应用程序更加复杂，应用程序还可能因为反向的流控而变得更加难以调试\r\n* 内存使用，缓冲区在读或写操作的时间段内必须保持住，可能造成持续的不确定性，并且每个并发操作都要求有独立的缓存，Reactor 模式在 socket 准备好读或写之前是不要求开辟缓存的\r\n* 操作系统支持，Windows 下通过 IOCP 实现了真正的异步 I/O，而在 Linux 系统下，Linux2.6 才引入异步 I/O，目前还不完善，所以在 Linux 下实现高并发网络编程都是以 Reactor 模型为主\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### Netty\r\n\r\nNetty 主要基于主从 Reactors 多线程模型做了一定的改进，Netty 的工作架构图：\r\n\r\n![image-20241006231638664](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231638664.png)\r\n\r\n工作流程：\r\n\r\n1. Netty 抽象出两组线程池 BossGroup 专门负责接收客户端的连接，WorkerGroup 专门负责网络的读写\r\n\r\n2. BossGroup 和 WorkerGroup 类型都是 NioEventLoopGroup，该 Group 相当于一个事件循环组，含有多个事件循环，每一个事件循环是 NioEventLoop，所以可以有多个线程\r\n\r\n3. NioEventLoop 表示一个**循环处理任务的线程**，每个 NioEventLoop 都有一个 Selector，用于监听绑定在其上的 Socket 的通讯\r\n\r\n4. 每个 Boss NioEventLoop 循环执行的步骤：\r\n\r\n   - 轮询 accept 事件\r\n   - 处理 accept 事件，与 client 建立连接，生成 NioScocketChannel，并将其**注册到某个 Worker 中**的某个 NioEventLoop 上的 Selector，连接就与 NioEventLoop 绑定\r\n   - 处理任务队列的任务，即 runAllTasks\r\n\r\n5. 每个 Worker NioEventLoop 循环执行的步骤：\r\n\r\n   - 轮询 read、write 事件\r\n   - 处理 I/O 事件，即 read，write 事件，在对应 NioSocketChannel 处理\r\n   - 处理任务队列的任务，即 runAllTasks\r\n\r\n6. 每个 Worker NioEventLoop 处理业务时，会使用 Pipeline（管道），Pipeline 中包含了 Channel，即通过 Pipeline 可以获取到对应通道，管道中维护了很多的处理器 Handler\r\n\r\n   ![image-20241006231702313](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231702313.png)\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n## 基本实现\r\n\r\n开发简单的服务器端和客户端，基本介绍：\r\n\r\n* Channel 理解为数据的通道，把 msg 理解为流动的数据，最开始输入是 ByteBuf，但经过 Pipeline 的加工，会变成其它类型对象，最后输出又变成 ByteBuf\r\n* Handler 理解为数据的处理工序，Pipeline 负责发布事件传播给每个 Handler，Handler 对自己感兴趣的事件进行处理（重写了相应事件处理方法），分 Inbound 和 Outbound 两类\r\n* EventLoop 理解为处理数据的执行者，既可以执行 IO 操作，也可以进行任务处理。每个执行者有任务队列，队列里可以堆放多个 Channel 的待处理任务，任务分为普通任务、定时任务。按照 Pipeline 顺序，依次按照 Handler 的规划（代码）处理数据\r\n\r\n代码实现：\r\n\r\n* pom.xml\r\n\r\n  ```xml\r\n  <dependency>\r\n      <groupId>io.netty</groupId>\r\n      <artifactId>netty-all</artifactId>\r\n      <version>4.1.20.Final</version>\r\n  </dependency>\r\n  ```\r\n\r\n\r\n* Server.java\r\n\r\n  ```java\r\n  public class HelloServer {\r\n      public static void main(String[] args) {\r\n          EventLoopGroup boss = new NioEventLoopGroup();\r\n          EventLoopGroup worker = new NioEventLoopGroup(2);\r\n          // 1. 启动器，负责组装 netty 组件，启动服务器\r\n          new ServerBootstrap()\r\n                  // 2. 线程组，boss 只负责【处理 accept 事件】， worker 只【负责 channel 上的读写】\r\n                  .group(boss, worker)\r\n             \t \t//.option() \t\t// 给 ServerSocketChannel 配置参数\r\n              \t//.childOption()   \t// 给 SocketChannel 配置参数\r\n                  // 3. 选择服务器的 ServerSocketChannel 实现\r\n                  .channel(NioServerSocketChannel.class)\r\n                  // 4. boss 负责处理连接，worker(child) 负责处理读写，决定了能执行哪些操作(handler)\r\n                  .childHandler(new ChannelInitializer<NioSocketChannel>() {\r\n                      // 5. channel 代表和客户端进行数据读写的通道 Initializer 初始化，负责添加别的 handler\r\n                      // 7. 连接建立后，执行初始化方法\r\n                      @Override\r\n                      protected void initChannel(NioSocketChannel ch) throws Exception {\r\n                          // 添加具体的 handler\r\n                          ch.pipeline().addLast(new StringDecoder());// 将 ByteBuf 转成字符串\r\n                          ch.pipeline().addLast(new ChannelInboundHandlerAdapter() { // 自定义 handler\r\n                              // 读事件\r\n                              @Override\r\n                              public void channelRead(ChannelHandlerContext ctx, Object msg) {\r\n                                  // 打印转换好的字符串\r\n                                  System.out.println(msg);\r\n                              }\r\n                          });\r\n                      }\r\n                  })\r\n                  // 6. 绑定监听端口\r\n                  .bind(8080);\r\n      }\r\n  }\r\n  ```\r\n\r\n* Client.java\r\n\r\n  ```java\r\n  public class HelloClient {\r\n      public static void main(String[] args) throws InterruptedException {\r\n          // 1. 创建启动器类\r\n          new Bootstrap()\r\n                  // 2. 添加 EventLoop\r\n                  .group(new NioEventLoopGroup())\r\n              \t//.option()，给 SocketChannel 配置参数\r\n                  // 3. 选择客户端 channel 实现\r\n                  .channel(NioSocketChannel.class)\r\n                  // 4. 添加处理器\r\n                  .handler(new ChannelInitializer<NioSocketChannel>() {\r\n                      // 4.1 连接建立后被调用\r\n                      @Override\r\n                      protected void initChannel(NioSocketChannel ch) throws Exception {\r\n                          // 将 Hello World 转为 ByteBuf\r\n                          ch.pipeline().addLast(new StringEncoder());\r\n                      }\r\n                  })\r\n                  // 5. 连接到服务器，然后调用 4.1\r\n                  .connect(new InetSocketAddress(\"127.0.0.1\",8080))\r\n                  // 6. 阻塞方法，直到连接建立\r\n                  .sync()\r\n                  // 7. 代表连接对象\r\n                  .channel()\r\n                  // 8. 向服务器发送数据\r\n                  .writeAndFlush(\"Hello World\");\r\n      }\r\n  }\r\n  ```\r\n\r\n\r\n\r\n参考视频：https://www.bilibili.com/video/BV1py4y1E7oA\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n\r\n\r\n## 组件介绍\r\n\r\n### EventLoop\r\n\r\n#### 基本介绍\r\n\r\n事件循环对象 EventLoop，**本质是一个单线程执行器同时维护了一个 Selector**，有 run 方法处理 Channel 上源源不断的 IO 事件\r\n\r\n事件循环组 EventLoopGroup 是一组 EventLoop，Channel 会调用 Boss EventLoopGroup 的 register 方法来绑定其中一个 Worker 的 EventLoop，后续这个 Channel 上的 IO 事件都由此 EventLoop 来处理，保证了事件处理时的线程安全\r\n\r\nEventLoopGroup 类 API：\r\n\r\n* `EventLoop next()`：获取集合中下一个 EventLoop，EventLoopGroup 实现了 Iterable 接口提供遍历 EventLoop 的能力\r\n* `Future<?> shutdownGracefully()`：优雅关闭的方法，会首先切换 EventLoopGroup 到关闭状态从而拒绝新的任务的加入，然后在任务队列的任务都处理完成后，停止线程的运行，从而确保整体应用是在正常有序的状态下退出的\r\n\r\n* `<T> Future<T> submit(Callable<T> task)`：提交任务\r\n* `ScheduledFuture<?> scheduleWithFixedDelay`：提交定时任务\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 任务传递\r\n\r\n把要调用的代码封装为一个任务对象，由下一个 handler 的线程来调用\r\n\r\n```java\r\npublic class EventLoopServer {\r\n    public static void main(String[] args) {\r\n        EventLoopGroup group = new DefaultEventLoopGroup();\r\n        new ServerBootstrap()\r\n                .group(new NioEventLoopGroup(), new NioEventLoopGroup(2))\r\n                .channel(NioServerSocketChannel.class)\r\n                .childHandler(new ChannelInitializer<NioSocketChannel>() {\r\n                    @Override\r\n                    protected void initChannel(NioSocketChannel ch) {\r\n                        ch.pipeline().addLast(\"handler1\", new ChannelInboundHandlerAdapter() {\r\n                            @Override\r\n                            public void channelRead(ChannelHandlerContext ctx, Object msg) {\r\n                                ByteBuf buf = (ByteBuf) msg;\r\n                                log.debug(buf.toString(Charset.defaultCharset()));\r\n                                ctx.fireChannelRead(msg);   // 让消息【传递】给下一个 handler\r\n                            }\r\n                        }).addLast(group, \"handler2\", new ChannelInboundHandlerAdapter() {\r\n                            @Override\r\n                            public void channelRead(ChannelHandlerContext ctx, Object msg) {\r\n                                ByteBuf buf = (ByteBuf) msg;\r\n                                log.debug(buf.toString(Charset.defaultCharset()));\r\n                            }\r\n                        });\r\n                    }\r\n                })\r\n                .bind(8080);\r\n    }\r\n}\r\n```\r\n\r\n源码分析：\r\n\r\n```java\r\npublic ChannelHandlerContext fireChannelRead(final Object msg) {\r\n    invokeChannelRead(findContextInbound(MASK_CHANNEL_READ), msg);\r\n    return this;\r\n}\r\nstatic void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) {\r\n    final Object m = next.pipeline.touch(ObjectUtil.checkNotNull(msg, \"msg\"), next);\r\n    EventExecutor executor = next.executor();\r\n    // 下一个 handler 的事件循环是否与当前的事件循环是同一个线程\r\n    if (executor.inEventLoop()) {\r\n        // 是，直接调用\r\n        next.invokeChannelRead(m);\r\n    } else {\r\n        // 不是，将要执行的代码作为任务提交给下一个 handler 处理\r\n        executor.execute(new Runnable() {\r\n            @Override\r\n            public void run() {\r\n                next.invokeChannelRead(m);\r\n            }\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### Channel\r\n\r\n#### 连接操作\r\n\r\nChannel 类 API：\r\n\r\n* `ChannelFuture close()`：关闭通道\r\n* `ChannelPipeline pipeline()`：添加处理器\r\n* `ChannelFuture write(Object msg)`：数据写入缓冲区\r\n* `ChannelFuture writeAndFlush(Object msg)`：数据写入缓冲区并且刷出\r\n\r\nChannelFuture 类 API：\r\n\r\n* `ChannelFuture sync()`：同步阻塞等待连接成功\r\n* `ChannelFuture addListener(GenericFutureListener listener)`：异步等待\r\n\r\n代码实现：\r\n\r\n* connect 方法是异步的，不等连接建立完成就返回，因此 channelFuture 对象中不能立刻获得到正确的 Channel 对象，需要等待\r\n* 连接未建立 channel 打印为 `[id: 0x2e1884dd]`；建立成功打印为 `[id: 0x2e1884dd, L:/127.0.0.1:57191 - R:/127.0.0.1:8080]`\r\n\r\n```java\r\npublic class ChannelClient {\r\n    public static void main(String[] args) throws InterruptedException {\r\n        ChannelFuture channelFuture = new Bootstrap()\r\n                .group(new NioEventLoopGroup())\r\n                .channel(NioSocketChannel.class)\r\n                .handler(new ChannelInitializer<NioSocketChannel>() {\r\n                    @Override\r\n                    protected void initChannel(NioSocketChannel ch) throws Exception {\r\n                        ch.pipeline().addLast(new StringEncoder());\r\n                    }\r\n                })\r\n                // 1. 连接服务器，【异步非阻塞】，main 调用 connect 方法，真正执行连接的是 nio 线程\r\n                .connect(new InetSocketAddress(\"127.0.0.1\", 8080));\r\n        // 2.1 使用 sync 方法【同步】处理结果，阻塞当前线程，直到 nio 线程连接建立完毕\r\n        channelFuture.sync();\r\n        Channel channel = channelFuture.channel();\r\n        System.out.println(channel); // 【打印】\r\n        // 向服务器发送数据\r\n        channel.writeAndFlush(\"hello world\");\r\n        \r\n**************************************************************************************二选一\r\n        // 2.2 使用 addListener 方法【异步】处理结果\r\n        channelFuture.addListener(new ChannelFutureListener() {\r\n            @Override\r\n            // nio 线程连接建立好以后，回调该方法\r\n            public void operationComplete(ChannelFuture future) throws Exception {\r\n                if (future.isSuccess()) {\r\n                    Channel channel = future.channel();\r\n                \tchannel.writeAndFlush(\"hello, world\");\r\n                } else {\r\n                    // 建立失败，需要关闭\r\n                    future.channel().close();\r\n                }\r\n            }\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 关闭操作\r\n\r\n关闭 EventLoopGroup 的运行，分为同步关闭和异步关闭\r\n\r\n```java\r\npublic class CloseFutureClient {\r\n    public static void main(String[] args) throws InterruptedException {\r\n        NioEventLoopGroup group = new NioEventLoopGroup();\r\n        ChannelFuture channelFuture = new Bootstrap()\r\n                // ....\r\n                .connect(new InetSocketAddress(\"127.0.0.1\", 8080));\r\n        Channel channel = channelFuture.sync().channel();\r\n        // 发送数据\r\n        new Thread(() -> {\r\n            Scanner sc = new Scanner(System.in);\r\n            while (true) {\r\n                String line = sc.nextLine();\r\n                if (line.equals(\"q\")) {\r\n                    channel.close();\r\n                    break;\r\n                }\r\n                channel.writeAndFlush(line);\r\n            }\r\n        }, \"input\").start();\r\n        // 获取 CloseFuture 对象\r\n        ChannelFuture closeFuture = channel.closeFuture();\r\n        \r\n        // 1. 同步处理关闭\r\n        System.out.println(\"waiting close...\");\r\n        closeFuture.sync();\r\n        System.out.println(\"处理关闭后的操作\");\r\n****************************************************\r\n        // 2. 异步处理关闭\r\n        closeFuture.addListener(new ChannelFutureListener() {\r\n            @Override\r\n            public void operationComplete(ChannelFuture future) throws Exception {\r\n                System.out.println(\"处理关闭后的操作\");\r\n                group.shutdownGracefully();\r\n            }\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### Future\r\n\r\n#### 基本介绍\r\n\r\nNetty 中的 Future 与 JDK 中的 Future 同名，但是功能的实现不同\r\n\r\n```java\r\npackage io.netty.util.concurrent;\r\npublic interface Future<V> extends java.util.concurrent.Future<V>\r\n```\r\n\r\nFuture 类 API：\r\n\r\n* `V get()`：阻塞等待获取任务执行结果\r\n* `V getNow()`：非阻塞获取任务结果，还未产生结果时返回 null\r\n* `Throwable cause()`：非阻塞获取失败信息，如果没有失败，返回 null\r\n* `Future<V> sync()`：等待任务结束，如果任务失败，抛出异常\r\n* `boolean cancel(boolean mayInterruptIfRunning)`：取消任务\r\n* `Future<V> addListener(GenericFutureListener listener)`：添加回调，异步接收结果\r\n* `boolean isSuccess()`：判断任务是否成功\r\n* `boolean isCancellable()`：判断任务是否取消\r\n\r\n```java\r\npublic class NettyFutureDemo {\r\n    public static void main(String[] args) throws Exception {\r\n        NioEventLoopGroup group = new NioEventLoopGroup();\r\n        EventLoop eventLoop = group.next();\r\n        Future<Integer> future = eventLoop.submit(new Callable<Integer>() {\r\n            @Override\r\n            public Integer call() throws Exception {\r\n                System.out.println(\"执行计算\");\r\n                Thread.sleep(1000);\r\n                return 70;\r\n            }\r\n        });\r\n        future.getNow();\r\n        System.out.println(new Date() + \"等待结果\");\r\n        System.out.println(new Date() + \"\" + future.get());\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 扩展子类\r\n\r\nPromise 类是 Future 的子类，可以脱离任务独立存在，作为两个线程间传递结果的容器\r\n\r\n```java\r\npublic interface Promise<V> extends Future<V>\r\n```\r\n\r\nPromise 类 API：\r\n\r\n* `Promise<V> setSuccess(V result)`：设置成功结果\r\n* `Promise<V> setFailure(Throwable cause)`：设置失败结果\r\n\r\n```java\r\npublic class NettyPromiseDemo {\r\n    public static void main(String[] args) throws Exception {\r\n        // 1. 准备 EventLoop 对象\r\n        EventLoop eventLoop = new NioEventLoopGroup().next();\r\n        // 2. 主动创建 promise\r\n        DefaultPromise<Integer> promise = new DefaultPromise<>(eventLoop);\r\n        // 3. 任意一个线程执行计算，计算完毕后向 promise 填充结果\r\n        new Thread(() -> {\r\n            try {\r\n                Thread.sleep(1000);\r\n            } catch (InterruptedException e) {\r\n                e.printStackTrace();\r\n            }\r\n            promise.setSuccess(200);\r\n        }).start();\r\n\r\n        // 4. 接受结果的线程\r\n        System.out.println(new Date() + \"等待结果\");\r\n        System.out.println(new Date() + \"\" + promise.get());\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### Pipeline\r\n\r\nChannelHandler 用来处理 Channel 上的各种事件，分为入站出站两种，所有 ChannelHandler 连接成双向链表就是 Pipeline\r\n\r\n* 入站处理器通常是 ChannelInboundHandlerAdapter 的子类，主要用来读取客户端数据，写回结果\r\n* 出站处理器通常是 ChannelOutboundHandlerAdapter 的子类，主要对写回结果进行加工（入站和出站是对于服务端来说的）\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    new ServerBootstrap()\r\n        .group(new NioEventLoopGroup())\r\n        .channel(NioServerSocketChannel.class)\r\n        .childHandler(new ChannelInitializer<NioSocketChannel>() {\r\n            @Override\r\n            protected void initChannel(NioSocketChannel ch) throws Exception {\r\n                // 1. 通过 channel 拿到 pipeline\r\n                ChannelPipeline pipeline = ch.pipeline();\r\n                // 2. 添加处理器 head -> h1 -> h2 -> h3 -> h4 -> tail\r\n                pipeline.addLast(\"h1\", new ChannelInboundHandlerAdapter() {\r\n                    @Override\r\n                    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\r\n                        log.debug(\"1\");\r\n                        ByteBuf buf = (ByteBuf) msg;\r\n                        String s = buf.toString(Charset.defaultCharset());\r\n                        // 将数据传递给下一个【入站】handler，如果不调用该方法则链会断开\r\n                        super.channelRead(ctx, s);\r\n                    }\r\n                });\r\n                pipeline.addLast(\"h2\", new ChannelInboundHandlerAdapter() {\r\n                    @Override\r\n                    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\r\n                        log.debug(\"2\");\r\n                        // 从【尾部开始向前触发】出站处理器\r\n                        ch.writeAndFlush(ctx.alloc().buffer().writeBytes(\"server\".getBytes()));\r\n                        // 该方法会让管道从【当前 handler 向前】寻找出站处理器\r\n                        // ctx.writeAndFlush();\r\n                    }\r\n                });\r\n                pipeline.addLast(\"h3\", new ChannelOutboundHandlerAdapter() {\r\n                    @Override\r\n                    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {\r\n                        log.debug(\"3\");\r\n                        super.write(ctx, msg, promise);\r\n                    }\r\n                });\r\n                pipeline.addLast(\"h4\", new ChannelOutboundHandlerAdapter() {\r\n                    @Override\r\n                    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception {\r\n                        log.debug(\"4\");\r\n                        super.write(ctx, msg, promise);\r\n                    }\r\n                });\r\n            }\r\n        })\r\n        .bind(8080);\r\n}\r\n```\r\n\r\n服务器端依次打印：1 2 4 3 ，所以**入站是按照 addLast 的顺序执行的，出站是按照 addLast 的逆序执行**\r\n\r\n一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组成的双向链表，并且每个 ChannelHandlerContext 中关联着一个 ChannelHandler\r\n\r\n入站事件和出站事件在一个双向链表中，两种类型的 handler 互不干扰：\r\n\r\n* 入站事件会从链表 head 往后传递到最后一个入站的 handler\r\n* 出站事件会从链表 tail 往前传递到最前一个出站的 handler\r\n\r\n![](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/Netty-ChannelPipeline.png)\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### ByteBuf\r\n\r\n#### 基本介绍\r\n\r\nByteBuf 是对字节数据的封装，优点：\r\n\r\n* 池化，可以重用池中 ByteBuf 实例，更节约内存，减少内存溢出的可能\r\n* 读写指针分离，不需要像 ByteBuffer 一样切换读写模式\r\n* 可以自动扩容\r\n* 支持链式调用，使用更流畅\r\n* 零拷贝思想，例如 slice、duplicate、CompositeByteBuf\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 创建方法\r\n\r\n创建方式\r\n\r\n* `ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(10)`：创建了一个默认的 ByteBuf，初始容量是 10\r\n\r\n  ```java\r\n  public ByteBuf buffer() {\r\n      if (directByDefault) {\r\n          return directBuffer();\r\n      }\r\n      return heapBuffer();\r\n  }\r\n  ```\r\n\r\n* `ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer(10)`：创建池化基于堆的 ByteBuf\r\n\r\n* `ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer(10)`：创建池化基于直接内存的 ByteBuf\r\n\r\n* **推荐**的创建方式：在添加处理器的方法中\r\n\r\n  ```java\r\n  pipeline.addLast(new ChannelInboundHandlerAdapter() {\r\n      @Override\r\n      public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\r\n          ByteBuf buffer = ctx.alloc().buffer();\r\n      }\r\n  });\r\n  ```\r\n\r\n直接内存对比堆内存：\r\n\r\n* 直接内存创建和销毁的代价昂贵，但读写性能高（少一次内存复制），适合配合池化功能一起用\r\n* 直接内存对 GC 压力小，因为这部分内存不受 JVM 垃圾回收的管理，但也要注意及时主动释放\r\n\r\n池化的意义在于可以**重用 ByteBuf**，高并发时池化功能更节约内存，减少内存溢出的可能，与非池化对比：\r\n\r\n* 非池化，每次都要创建新的 ByteBuf 实例，这个操作对直接内存代价昂贵，堆内存会增加 GC 压力\r\n* 池化，可以重用池中 ByteBuf 实例，并且采用了与 jemalloc 类似的内存分配算法提升分配效率\r\n\r\n池化功能的开启，可以通过下面的系统环境变量来设置：\r\n\r\n```sh\r\n-Dio.netty.allocator.type={unpooled|pooled}\t # VM 参数\r\n```\r\n\r\n* 4.1 以后，非 Android 平台默认启用池化实现，Android 平台启用非池化实现\r\n* 4.1 之前，池化功能还不成熟，默认是非池化实现\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 读写操作\r\n\r\nByteBuf 由四部分组成，最开始读写指针（**双指针**）都在 0 位置\r\n\r\n![image-20241006231846130](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231846130.png)\r\n\r\n写入方法：\r\n\r\n| 方法名                                           | 说明                   | 备注                                        |\r\n| ------------------------------------------------ | ---------------------- | ------------------------------------------- |\r\n| writeBoolean(boolean value)                      | 写入 boolean 值        | 用一字节 01\\|00 代表 true\\|false            |\r\n| writeByte(int value)                             | 写入 byte 值           |                                             |\r\n| writeInt(int value)                              | 写入 int 值            | Big Endian，即 0x250，写入后 00 00 02 50    |\r\n| writeIntLE(int value)                            | 写入 int 值            | Little Endian，即 0x250，写入后 50 02 00 00 |\r\n| writeBytes(ByteBuf src)                          | 写入 ByteBuf           |                                             |\r\n| writeBytes(byte[] src)                           | 写入 byte[]            |                                             |\r\n| writeBytes(ByteBuffer src)                       | 写入 NIO 的 ByteBuffer |                                             |\r\n| int writeCharSequence(CharSequence s, Charset c) | 写入字符串             |                                             |\r\n\r\n* 这些方法的未指明返回值的，其返回值都是 ByteBuf，意味着可以链式调用\r\n* 写入几位写指针后移几位，指向可以写入的位置\r\n* 网络传输，默认习惯是 Big Endian\r\n\r\n扩容：写入数据时，容量不够了（初始容量是 10），这时会引发**扩容**\r\n\r\n* 如果写入后数据大小未超过 512，则选择下一个 16 的整数倍，例如写入后大小为 12 ，则扩容后 capacity 是 16\r\n* 如果写入后数据大小超过 512，则选择下一个 2^n，例如写入后大小为 513，则扩容后 capacity 是 2^10 = 1024（2^9=512 不够）\r\n* 扩容不能超过 max capacity 会报错\r\n\r\n读取方法：\r\n\r\n* `byte readByte()`：读取一个字节，读指针后移\r\n* `byte getByte(int index)`：读取指定索引位置的字节，读指针不动\r\n* `ByteBuf markReaderIndex()`：标记读数据的位置\r\n* `ByteBuf resetReaderIndex()`：重置到标记位置，可以重复读取标记位置向后的数据\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 内存释放\r\n\r\nNetty 中三种内存的回收：\r\n\r\n* UnpooledHeapByteBuf 使用的是 JVM 内存，只需等 GC 回收内存\r\n* UnpooledDirectByteBuf 使用的就是直接内存了，需要特殊的方法来回收内存\r\n* PooledByteBuf 和子类使用了池化机制，需要更复杂的规则来回收内存\r\n\r\nNetty 采用了引用计数法来控制回收内存，每个 ByteBuf 都实现了 ReferenceCounted 接口，回收的规则：\r\n\r\n* 每个 ByteBuf 对象的初始计数为 1\r\n* 调用 release 方法计数减 1，如果计数为 0，ByteBuf 内存被回收\r\n* 调用 retain 方法计数加 1，表示调用者没用完之前，其它 handler 即使调用了 release 也不会造成回收\r\n* 当计数为 0 时，底层内存会被回收，这时即使 ByteBuf 对象还在，其各个方法均无法正常使用\r\n\r\n```java\r\nByteBuf buf = .ByteBufAllocator.DEFAULT.buffer(10)\r\ntry {\r\n    // 逻辑处理\r\n} finally {\r\n    buf.release();\r\n}\r\n```\r\n\r\nPipeline 的存在，需要将 ByteBuf 传递给下一个 ChannelHandler，如果在 finally 中 release 了，就失去了传递性，处理规则：\r\n\r\n* 创建 ByteBuf 放入 Pipeline\r\n\r\n* 入站 ByteBuf 处理原则\r\n\r\n  * 对原始 ByteBuf 不做处理，调用 ctx.fireChannelRead(msg) 向后传递，这时无须 release，反之不传递需要\r\n\r\n  * 将原始 ByteBuf 转换为其它类型的 Java 对象，这时 ByteBuf 就没用了，此时必须 release\r\n\r\n  * 如果出现异常，ByteBuf 没有成功传递到下一个 ChannelHandler，必须 release\r\n\r\n  * 假设消息一直向后传，那么 TailContext 会负责释放未处理消息（原始的 ByteBuf）\r\n\r\n    ```java\r\n    // io.netty.channel.DefaultChannelPipeline#onUnhandledInboundMessage(java.lang.Object)\r\n    protected void onUnhandledInboundMessage(Object msg) {\r\n        try {\r\n            logger.debug();\r\n        } finally {\r\n            ReferenceCountUtil.release(msg);\r\n        }\r\n    }\r\n    // io.netty.util.ReferenceCountUtil#release(java.lang.Object)\r\n    public static boolean release(Object msg) {\r\n        if (msg instanceof ReferenceCounted) {\r\n            return ((ReferenceCounted) msg).release();\r\n        }\r\n        return false;\r\n    }\r\n    ```\r\n\r\n* 出站 ByteBuf 处理原则\r\n\r\n  * 出站消息最终都会转为 ByteBuf 输出，一直向前传，由 HeadContext flush 后 release\r\n\r\n* 不确定 ByteBuf 被引用了多少次，但又必须彻底释放，可以循环调用 release 直到返回 true\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 拷贝操作\r\n\r\n零拷贝方法：\r\n\r\n* `ByteBuf slice(int index, int length)`：对原始 ByteBuf 进行切片成多个 ByteBuf，切片后的 ByteBuf 并没有发生内存复制，**共用原始 ByteBuf 的内存**，切片后的 ByteBuf 维护独立的 read，write 指针\r\n\r\n  ```java\r\n  public static void main(String[] args) {\r\n      ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(10);\r\n      buf.writeBytes(new byte[]{'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'});\r\n      // 在切片过程中并没有发生数据复制\r\n      ByteBuf f1 = buf.slice(0, 5);\r\n      f1.retain();\r\n      ByteBuf f2 = buf.slice(5, 5);\r\n      f2.retain();\r\n      // 对 f1 进行相关的操作也会体现在 buf 上\r\n  }\r\n  ```\r\n\r\n* `ByteBuf duplicate()`：截取原始 ByteBuf 所有内容，并且没有 max capacity 的限制，也是与原始 ByteBuf 使用同一块底层内存，只是读写指针是独立的\r\n\r\n* `CompositeByteBuf addComponents(boolean increaseWriterIndex, ByteBuf... buffers)`：合并多个 ByteBuf\r\n\r\n  ```java\r\n  public static void main(String[] args) {\r\n      ByteBuf buf1 = ByteBufAllocator.DEFAULT.buffer();\r\n      buf1.writeBytes(new byte[]{1, 2, 3, 4, 5});\r\n  \r\n      ByteBuf buf2 = ByteBufAllocator.DEFAULT.buffer();\r\n      buf1.writeBytes(new byte[]{6, 7, 8, 9, 10});\r\n  \r\n      CompositeByteBuf buf = ByteBufAllocator.DEFAULT.compositeBuffer();\r\n      // true 表示增加新的 ByteBuf 自动递增 write index, 否则 write index 会始终为 0\r\n      buf.addComponents(true, buf1, buf2);\r\n  }\r\n  ```\r\n\r\n  CompositeByteBuf 是一个组合的 ByteBuf，内部维护了一个 Component 数组，每个 Component 管理一个 ByteBuf，记录了这个 ByteBuf 相对于整体偏移量等信息，代表着整体中某一段的数据\r\n\r\n  * 优点：对外是一个虚拟视图，组合这些 ByteBuf 不会产生内存复制\r\n  * 缺点：复杂了很多，多次操作会带来性能的损耗\r\n\r\n深拷贝：\r\n\r\n* `ByteBuf copy()`：将底层内存数据进行深拷贝，因此无论读写，都与原始 ByteBuf 无关\r\n\r\n池化相关：\r\n\r\n* Unpooled 是一个工具类，提供了非池化的 ByteBuf 创建、组合、复制等操作\r\n\r\n  ```java\r\n  ByteBuf buf1 = ByteBufAllocator.DEFAULT.buffer(5);\r\n  buf1.writeBytes(new byte[]{1, 2, 3, 4, 5});\r\n  ByteBuf buf2 = ByteBufAllocator.DEFAULT.buffer(5);\r\n  buf2.writeBytes(new byte[]{6, 7, 8, 9, 10});\r\n  \r\n  // 当包装 ByteBuf 个数超过一个时, 底层使用了 CompositeByteBuf，零拷贝思想\r\n  ByteBuf buf = Unpooled.wrappedBuffer(buf1, buf2);\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n\r\n\r\n## 粘包半包\r\n\r\n### 现象演示\r\n\r\n在 TCP 传输中，客户端发送消息时，实际上是将数据写入 TCP 的缓存，此时数据的大小和缓存的大小就会造成粘包和半包\r\n\r\n* 当数据超过 TCP 缓存容量时，就会被拆分成多个包，通过 Socket 多次发送到服务端，服务端每次从缓存中取数据，产生半包问题\r\n\r\n* 当数据小于 TCP 缓存容量时，缓存中可以存放多个包，客户端和服务端一次通信就可能传递多个包，这时候服务端就可能一次读取多个包，产生粘包的问题\r\n\r\n代码演示：\r\n\r\n* 客户端代码：\r\n\r\n  ```java\r\n  public class HelloWorldClient {\r\n      public static void main(String[] args) {\r\n          send();\r\n      }\r\n  \r\n      private static void send() {\r\n          NioEventLoopGroup worker = new NioEventLoopGroup();\r\n          try {\r\n              Bootstrap bootstrap = new Bootstrap();\r\n              bootstrap.channel(NioSocketChannel.class);\r\n              bootstrap.group(worker);\r\n              bootstrap.handler(new ChannelInitializer<SocketChannel>() {\r\n                  @Override\r\n                  protected void initChannel(SocketChannel ch) throws Exception {\r\n                      ch.pipeline().addLast(new ChannelInboundHandlerAdapter() {\r\n                          // 【在连接 channel 建立成功后，会触发 active 方法】\r\n                          @Override\r\n                          public void channelActive(ChannelHandlerContext ctx) throws Exception {\r\n                              // 发送内容随机的数据包\r\n                              Random r = new Random();\r\n                              char c = '0';\r\n                              ByteBuf buf = ctx.alloc().buffer();\r\n                              for (int i = 0; i < 10; i++) {\r\n                                  byte[] bytes = new byte[10];\r\n                                  for (int j = 0; j < r.nextInt(9) + 1; j++) {\r\n                                      bytes[j] = (byte) c;\r\n                                  }\r\n                                  c++;\r\n                                  buf.writeBytes(bytes);\r\n                              }\r\n                              ctx.writeAndFlush(buf);\r\n                          }\r\n                      });\r\n                  }\r\n              });\r\n              ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 8080).sync();\r\n              channelFuture.channel().closeFuture().sync();\r\n  \r\n          } catch (InterruptedException e) {\r\n              log.error(\"client error\", e);\r\n          } finally {\r\n              worker.shutdownGracefully();\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n* 服务器代码：\r\n\r\n  ```java\r\n  public class HelloWorldServer {\r\n      public static void main(String[] args) {\r\n          NioEventLoopGroup boss = new NioEventLoopGroup(1);\r\n          NioEventLoopGroup worker = new NioEventLoopGroup();\r\n          try {\r\n              ServerBootstrap serverBootstrap = new ServerBootstrap();\r\n              serverBootstrap.channel(NioServerSocketChannel.class);\r\n              // 调整系统的接受缓冲区【滑动窗口】\r\n              //serverBootstrap.option(ChannelOption.SO_RCVBUF, 10);\r\n              // 调整 netty 的接受缓冲区（ByteBuf）\r\n              //serverBootstrap.childOption(ChannelOption.RCVBUF_ALLOCATOR, \r\n              //                            new AdaptiveRecvByteBufAllocator(16, 16, 16));\r\n              serverBootstrap.group(boss, worker);\r\n              serverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\r\n                  @Override\r\n                  protected void initChannel(SocketChannel ch) throws Exception {\r\n                      // 【这里可以添加解码器】\r\n                      // LoggingHandler 用来打印消息\r\n                      ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG));\r\n                  }\r\n              });\r\n              ChannelFuture channelFuture = serverBootstrap.bind(8080);\r\n              channelFuture.sync();\r\n              channelFuture.channel().closeFuture().sync();\r\n          } catch (InterruptedException e) {\r\n              log.error(\"server error\", e);\r\n          } finally {\r\n              boss.shutdownGracefully();\r\n              worker.shutdownGracefully();\r\n              log.debug(\"stop\");\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n* 粘包效果展示：\r\n\r\n  ```java\r\n  09:57:27.140 [nioEventLoopGroup-3-1] DEBUG io.netty.handler.logging.LoggingHandler - [id: 0xddbaaef6, L:/127.0.0.1:8080 - R:/127.0.0.1:8701] READ: 100B\t// 读了 100 字节，发生粘包\r\n           +-------------------------------------------------+\r\n           |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |\r\n  +--------+-------------------------------------------------+----------------+\r\n  |00000000| 30 30 30 30 30 00 00 00 00 00 31 00 00 00 00 00 |00000.....1.....|\r\n  |00000010| 00 00 00 00 32 32 32 32 00 00 00 00 00 00 33 00 |....2222......3.|\r\n  |00000020| 00 00 00 00 00 00 00 00 34 34 00 00 00 00 00 00 |........44......|\r\n  |00000030| 00 00 35 35 35 35 00 00 00 00 00 00 36 36 36 00 |..5555......666.|\r\n  |00000040| 00 00 00 00 00 00 37 37 37 37 00 00 00 00 00 00 |......7777......|\r\n  |00000050| 38 38 38 38 38 00 00 00 00 00 39 39 00 00 00 00 |88888.....99....|\r\n  |00000060| 00 00 00 00                                     |....            |\r\n  +--------+-------------------------------------------------+----------------+\r\n  ```\r\n\r\n解决方法：通过调整系统的接受缓冲区的滑动窗口和 Netty 的接受缓冲区保证每条包只含有一条数据，滑动窗口的大小仅决定了 Netty 读取的**最小单位**，实际每次读取的一般是它的整数倍\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 解决方案\r\n\r\n#### 短连接\r\n\r\n发一个包建立一次连接，这样连接建立到连接断开之间就是消息的边界，缺点就是效率很低\r\n\r\n客户端代码改造：\r\n\r\n```java\r\npublic class HelloWorldClient {\r\n    public static void main(String[] args) {\r\n        // 分 10 次发送\r\n        for (int i = 0; i < 10; i++) {\r\n            send();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 固定长度\r\n\r\n服务器端加入定长解码器，每一条消息采用固定长度。如果是半包消息，会缓存半包消息并等待下个包到达之后进行拼包合并，直到读取一个完整的消息包；如果是粘包消息，空余的位置会进行补 0，会浪费空间\r\n\r\n```java\r\nserverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\r\n    @Override\r\n    protected void initChannel(SocketChannel ch) throws Exception {\r\n        ch.pipeline().addLast(new FixedLengthFrameDecoder(10));\r\n        // LoggingHandler 用来打印消息\r\n        ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG));\r\n    }\r\n});\r\n```\r\n\r\n```java\r\n10:29:06.522 [nioEventLoopGroup-3-1] DEBUG io.netty.handler.logging.LoggingHandler - [id: 0x38a70fbf, L:/127.0.0.1:8080 - R:/127.0.0.1:10144] READ: 10B\r\n         +-------------------------------------------------+\r\n         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |\r\n+--------+-------------------------------------------------+----------------+\r\n|00000000| 31 31 00 00 00 00 00 00 00 00                   |11........      |\r\n+--------+-------------------------------------------------+----------------+\r\n10:29:06.522 [nioEventLoopGroup-3-1] DEBUG io.netty.handler.logging.LoggingHandler - [id: 0x38a70fbf, L:/127.0.0.1:8080 - R:/127.0.0.1:10144] READ: 10B\r\n         +-------------------------------------------------+\r\n         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |\r\n+--------+-------------------------------------------------+----------------+\r\n|00000000| 32 32 32 32 32 32 00 00 00 00                   |222222....      |\r\n+--------+-------------------------------------------------+----------------+\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 分隔符\r\n\r\n服务端加入行解码器，默认以 `\\n` 或 `\\r\\n` 作为分隔符，如果超出指定长度仍未出现分隔符，则抛出异常：\r\n\r\n```java\r\nserverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\r\n    @Override\r\n    protected void initChannel(SocketChannel ch) throws Exception {\r\n        ch.pipeline().addLast(new FixedLengthFrameDecoder(8));\r\n        ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG));\r\n    }\r\n});\r\n```\r\n\r\n客户端在每条消息之后，加入 `\\n` 分隔符：\r\n\r\n```java\r\npublic void channelActive(ChannelHandlerContext ctx) throws Exception {\r\n    Random r = new Random();\r\n    char c = 'a';\r\n    ByteBuf buffer = ctx.alloc().buffer();\r\n    for (int i = 0; i < 10; i++) {\r\n        for (int j = 1; j <= r.nextInt(16)+1; j++) {\r\n            buffer.writeByte((byte) c);\r\n        }\r\n        // 10 代表 '\\n'\r\n        buffer.writeByte(10);\r\n        c++;\r\n    }\r\n    ctx.writeAndFlush(buffer);\r\n}\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 预设长度\r\n\r\nLengthFieldBasedFrameDecoder 解码器自定义长度解决 TCP 粘包黏包问题\r\n\r\n```java\r\nint maxFrameLength\t\t// 数据最大长度\r\nint lengthFieldOffset \t// 长度字段偏移量，从第几个字节开始是内容的长度字段\r\nint lengthFieldLength\t// 长度字段本身的长度\r\nint lengthAdjustment \t// 长度字段为基准，几个字节后才是内容\r\nint initialBytesToStrip\t// 从头开始剥离几个字节解码后显示\r\n```\r\n\r\n```java\r\nlengthFieldOffset   = 1 (= the length of HDR1)\r\nlengthFieldLength   = 2\r\nlengthAdjustment    = 1 (= the length of HDR2)\r\ninitialBytesToStrip = 3 (= the length of HDR1 + LEN)\r\n\r\nBEFORE DECODE (16 bytes)                       AFTER DECODE (13 bytes)//解码\r\n+------+--------+------+----------------+      +------+----------------+\r\n| HDR1 | Length | HDR2 | Actual Content |----->| HDR2 | Actual Content |\r\n| 0xCA | 0x000C | 0xFE | \"HELLO, WORLD\" |      | 0xFE | \"HELLO, WORLD\" |\r\n+------+--------+------+----------------+      +------+----------------+\r\n```\r\n\r\n代码实现：\r\n\r\n```java\r\npublic class LengthFieldDecoderDemo {\r\n    public static void main(String[] args) {\r\n        EmbeddedChannel channel = new EmbeddedChannel(\r\n                // int 占 4 字节，版本号一个字节\r\n                new LengthFieldBasedFrameDecoder(1024, 0, 4, 1,5),\r\n                new LoggingHandler(LogLevel.DEBUG)\r\n        );\r\n\r\n        // 4 个字节的内容长度， 实际内容\r\n        ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer();\r\n        send(buffer, \"Hello, world\");\r\n        send(buffer, \"Hi!\");\r\n        // 写出缓存\r\n        channel.writeInbound(buffer);\r\n    }\r\n    // 写入缓存\r\n    private static void send(ByteBuf buffer, String content) {\r\n        byte[] bytes = content.getBytes();  // 实际内容\r\n        int length = bytes.length;          // 实际内容长度\r\n        buffer.writeInt(length);\r\n        buffer.writeByte(1);                // 表示版本号\r\n        buffer.writeBytes(bytes);\r\n    }\r\n}\r\n```\r\n\r\n```java\r\n10:49:59.344 [main] DEBUG io.netty.handler.logging.LoggingHandler - [id: 0xembedded, L:embedded - R:embedded] READ: 12B\r\n         +-------------------------------------------------+\r\n         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |\r\n+--------+-------------------------------------------------+----------------+\r\n|00000000| 48 65 6c 6c 6f 2c 20 77 6f 72 6c 64             |Hello, world    |\r\n+--------+-------------------------------------------------+----------------+\r\n10:49:59.344 [main] DEBUG io.netty.handler.logging.LoggingHandler - [id: 0xembedded, L:embedded - R:embedded] READ: 3B\r\n         +-------------------------------------------------+\r\n         |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |\r\n+--------+-------------------------------------------------+----------------+\r\n|00000000| 48 69 21                                        |Hi!             |\r\n+--------+-------------------------------------------------+----------------+\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 协议设计\r\n\r\n#### HTTP\r\n\r\n访问 URL：http://localhost:8080/\r\n\r\n```java\r\npublic class HttpDemo {\r\n    public static void main(String[] args) {\r\n        NioEventLoopGroup boss = new NioEventLoopGroup();\r\n        NioEventLoopGroup worker = new NioEventLoopGroup();\r\n        try {\r\n            ServerBootstrap serverBootstrap = new ServerBootstrap();\r\n            serverBootstrap.channel(NioServerSocketChannel.class);\r\n            serverBootstrap.group(boss, worker);\r\n            serverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\r\n                @Override\r\n                protected void initChannel(SocketChannel ch) throws Exception {\r\n                    ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG));\r\n                    ch.pipeline().addLast(new HttpServerCodec());\r\n                    // 只针对某一种类型的请求处理，此处针对 HttpRequest\r\n                    ch.pipeline().addLast(new SimpleChannelInboundHandler<HttpRequest>() {\r\n                        @Override\r\n                        protected void channelRead0(ChannelHandlerContext ctx, HttpRequest msg) {\r\n                            // 获取请求\r\n                            log.debug(msg.uri());\r\n\r\n                            // 返回响应\r\n                            DefaultFullHttpResponse response = new DefaultFullHttpResponse(\r\n                                msg.protocolVersion(), HttpResponseStatus.OK);\r\n\r\n                            byte[] bytes = \"<h1>Hello, world!</h1>\".getBytes();\r\n\r\n                            response.headers().setInt(CONTENT_LENGTH, bytes.length);\r\n                            response.content().writeBytes(bytes);\r\n\r\n                            // 写回响应\r\n                            ctx.writeAndFlush(response);\r\n                        }\r\n                    });\r\n                }\r\n            });\r\n            ChannelFuture channelFuture = serverBootstrap.bind(8080).sync();\r\n            channelFuture.channel().closeFuture().sync();\r\n        } catch (InterruptedException e) {\r\n            log.error(\"n3.server error\", e);\r\n        } finally {\r\n            boss.shutdownGracefully();\r\n            worker.shutdownGracefully();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 自定义\r\n\r\n处理器代码：\r\n\r\n```java\r\n@Slf4j\r\npublic class MessageCodec extends ByteToMessageCodec<Message> {\r\n    // 编码\r\n    @Override\r\n    public void encode(ChannelHandlerContext ctx, Message msg, ByteBuf out) throws Exception {\r\n        // 4 字节的魔数\r\n        out.writeBytes(new byte[]{1, 2, 3, 4});\r\n        // 1 字节的版本,\r\n        out.writeByte(1);\r\n        // 1 字节的序列化方式 jdk 0 , json 1\r\n        out.writeByte(0);\r\n        // 1 字节的指令类型\r\n        out.writeByte(msg.getMessageType());\r\n        // 4 个字节\r\n        out.writeInt(msg.getSequenceId());\r\n        // 无意义，对齐填充, 1 字节\r\n        out.writeByte(0xff);\r\n        // 获取内容的字节数组，msg 对象序列化\r\n        ByteArrayOutputStream bos = new ByteArrayOutputStream();\r\n        ObjectOutputStream oos = new ObjectOutputStream(bos);\r\n        oos.writeObject(msg);\r\n        byte[] bytes = bos.toByteArray();\r\n        // 长度\r\n        out.writeInt(bytes.length);\r\n        // 写入内容\r\n        out.writeBytes(bytes);\r\n    }\r\n\r\n    // 解码\r\n    @Override\r\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\r\n        int magicNum = in.readInt();\r\n        byte version = in.readByte();\r\n        byte serializerType = in.readByte();\r\n        byte messageType = in.readByte();\r\n        int sequenceId = in.readInt();\r\n        in.readByte();\r\n        int length = in.readInt();\r\n        byte[] bytes = new byte[length];\r\n        in.readBytes(bytes, 0, length);\r\n        ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(bytes));\r\n        Message message = (Message) ois.readObject();\r\n        log.debug(\"{}, {}, {}, {}, {}, {}\", magicNum, version, serializerType, messageType, sequenceId, length);\r\n        log.debug(\"{}\", message);\r\n        out.add(message);\r\n    }\r\n}\r\n```\r\n\r\n测试代码：\r\n\r\n```java\r\npublic static void main(String[] args) throws Exception {\r\n    EmbeddedChannel channel = new EmbeddedChannel(new LoggingHandler(), new MessageCodec());\r\n    // encode\r\n    LoginRequestMessage message = new LoginRequestMessage(\"zhangsan\", \"123\");\r\n    channel.writeOutbound(message);\r\n\r\n    // decode\r\n    ByteBuf buf = ByteBufAllocator.DEFAULT.buffer();\r\n    new MessageCodec().encode(null, message, buf);\r\n    // 入站\r\n    channel.writeInbound(buf);\r\n}\r\npublic class LoginRequestMessage extends Message {\r\n    private String username;\r\n    private String password;\r\n    // set + get \r\n}\r\n```\r\n\r\n![image-20241006231929202](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231929202.png)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### Sharable\r\n\r\n@Sharable 注解的添加时机：\r\n\r\n* 当 handler 不保存状态时，就可以安全地在多线程下被共享\r\n\r\n* 对于编解码器类不能继承 ByteToMessageCodec 或 CombinedChannelDuplexHandler，它们的构造方法对 @Sharable 有限制\r\n\r\n  ```java\r\n  protected ByteToMessageCodec(boolean preferDirect) {\r\n      ensureNotSharable();\r\n      outboundMsgMatcher = TypeParameterMatcher.find(this, ByteToMessageCodec.class, \"I\");\r\n      encoder = new Encoder(preferDirect);\r\n  }\r\n  ```\r\n\r\n  ```java\r\n  protected void ensureNotSharable() {\r\n      // 如果类上有该注解\r\n      if (isSharable()) {\r\n          throw new IllegalStateException();\r\n      }\r\n  }\r\n  ```\r\n\r\n* 如果能确保编解码器不会保存状态，可以继承 MessageToMessageCodec 父类\r\n\r\n  ````java\r\n  @Slf4j\r\n  @ChannelHandler.Sharable\r\n  // 必须和 LengthFieldBasedFrameDecoder 一起使用，确保接到的 ByteBuf 消息是完整的\r\n  public class MessageCodecSharable extends MessageToMessageCodec<ByteBuf, Message> {\r\n      @Override\r\n      protected void encode(ChannelHandlerContext ctx, Message msg, List<Object> outList) throws Exception {\r\n          ByteBuf out = ctx.alloc().buffer();\r\n          // 4 字节的魔数\r\n          out.writeBytes(new byte[]{1, 2, 3, 4});\r\n  \t\t// ....\r\n          outList.add(out);\r\n      }\r\n  \r\n      @Override\r\n      protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\r\n          //....\r\n      }\r\n  }\r\n  ````\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n\r\n\r\n## 场景优化\r\n\r\n### 空闲检测\r\n\r\n#### 连接假死\r\n\r\n连接假死就是客户端数据发不出去，服务端也一直收不到数据，保持这种状态，假死的连接占用的资源不能自动释放，而且向假死连接发送数据，得到的反馈是发送超时\r\n\r\n解决方案：每隔一段时间就检查这段时间内是否接收到客户端数据，没有就可以判定为连接假死\r\n\r\nIdleStateHandler 是 Netty 提供的处理空闲状态的处理器，用来判断是不是读空闲时间或写空闲时间过长\r\n\r\n* 参数一 long readerIdleTime：读空闲，表示多长时间没有读\r\n* 参数二 long writerIdleTime：写空闲，表示多长时间没有写\r\n* 参数三 long allIdleTime：读写空闲，表示多长时间没有读写\r\n\r\n```java\r\nserverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\r\n\t@Override\r\n\tprotected void initChannel(SocketChannel ch) throws Exception {\r\n        ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 12, 4, 0, 0));\r\n        ch.pipeline().addLast(new MessageCodec());\r\n        // 5s 内如果没有收到 channel 的数据，会触发一个 IdleState#READER_IDLE 事件，\r\n        ch.pipeline().addLast(new IdleStateHandler(5, 0, 0));\r\n        // ChannelDuplexHandler 【可以同时作为入站和出站】处理器\r\n        ch.pipeline().addLast(new ChannelDuplexHandler() {\r\n            // 用来触发特殊事件\r\n            @Override\r\n            public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception{\r\n                IdleStateEvent event = (IdleStateEvent) evt;\r\n                // 触发了读空闲事件\r\n                if (event.state() == IdleState.READER_IDLE) {\r\n                    log.debug(\"已经 5s 没有读到数据了\");\r\n                    ctx.channel().close();\r\n                }\r\n            }\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### 心跳机制\r\n\r\n客户端定时向服务器端发送数据，**时间间隔要小于服务器定义的空闲检测的时间间隔**，就能防止误判连接假死，这就是心跳机制\r\n\r\n```java\r\nbootstrap.handler(new ChannelInitializer<SocketChannel>() {\r\n    @Override\r\n    protected void initChannel(SocketChannel ch) throws Exception {\r\n        ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 12, 4, 0, 0));\r\n        ch.pipeline().addLast(new MessageCodec());\r\n        // 3s 内如果没有向服务器写数据，会触发一个 IdleState#WRITER_IDLE 事件\r\n        ch.pipeline().addLast(new IdleStateHandler(0, 3, 0));\r\n        // ChannelDuplexHandler 可以同时作为入站和出站处理器\r\n        ch.pipeline().addLast(new ChannelDuplexHandler() {\r\n            // 用来触发特殊事件\r\n            @Override\r\n            public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {\r\n                IdleStateEvent event = (IdleStateEvent) evt;\r\n                // 触发了写空闲事件\r\n                if (event.state() == IdleState.WRITER_IDLE) {\r\n                    // 3s 没有写数据了，【发送一个心跳包】\r\n                    ctx.writeAndFlush(new PingMessage());\r\n                }\r\n            }\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n### 序列化\r\n\r\n#### 普通方式\r\n\r\n序列化，反序列化主要用在消息正文的转换上\r\n\r\n* 序列化时，需要将 Java 对象变为要传输的数据（可以是 byte[]，或 json 等，最终都需要变成 byte[]）\r\n* 反序列化时，需要将传入的正文数据还原成 Java 对象，便于处理\r\n\r\n代码实现：\r\n\r\n* 抽象一个 Serializer 接口\r\n\r\n  ```java\r\n  public interface Serializer {\r\n      // 反序列化方法\r\n      <T> T deserialize(Class<T> clazz, byte[] bytes);\r\n      // 序列化方法\r\n      <T> byte[] serialize(T object);\r\n  }\r\n  ```\r\n\r\n* 提供两个实现\r\n\r\n  ```java\r\n  enum SerializerAlgorithm implements Serializer {\r\n  \t// Java 实现\r\n      Java {\r\n          @Override\r\n          public <T> T deserialize(Class<T> clazz, byte[] bytes) {\r\n              try {\r\n                  ObjectInputStream in = \r\n                      new ObjectInputStream(new ByteArrayInputStream(bytes));\r\n                  Object object = in.readObject();\r\n                  return (T) object;\r\n              } catch (IOException | ClassNotFoundException e) {\r\n                  throw new RuntimeException(\"SerializerAlgorithm.Java 反序列化错误\", e);\r\n              }\r\n          }\r\n  \r\n          @Override\r\n          public <T> byte[] serialize(T object) {\r\n              try {\r\n                  ByteArrayOutputStream out = new ByteArrayOutputStream();\r\n                  new ObjectOutputStream(out).writeObject(object);\r\n                  return out.toByteArray();\r\n              } catch (IOException e) {\r\n                  throw new RuntimeException(\"SerializerAlgorithm.Java 序列化错误\", e);\r\n              }\r\n          }\r\n      }, \r\n      // Json 实现(引入了 Gson 依赖)\r\n      Json {\r\n          @Override\r\n          public <T> T deserialize(Class<T> clazz, byte[] bytes) {\r\n              return new Gson().fromJson(new String(bytes, StandardCharsets.UTF_8), clazz);\r\n          }\r\n  \r\n          @Override\r\n          public <T> byte[] serialize(T object) {\r\n              return new Gson().toJson(object).getBytes(StandardCharsets.UTF_8);\r\n          }\r\n      };\r\n  \r\n      // 需要从协议的字节中得到是哪种序列化算法\r\n      public static SerializerAlgorithm getByInt(int type) {\r\n          SerializerAlgorithm[] array = SerializerAlgorithm.values();\r\n          if (type < 0 || type > array.length - 1) {\r\n              throw new IllegalArgumentException(\"超过 SerializerAlgorithm 范围\");\r\n          }\r\n          return array[type];\r\n      }\r\n  }\r\n  ```\r\n\r\n  \r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n#### ProtoBuf\r\n\r\n##### 基本介绍\r\n\r\nCodec（编解码器）的组成部分有两个：Decoder（解码器）和 Encoder（编码器）。Encoder 负责把业务数据转换成字节码数据，Decoder 负责把字节码数据转换成业务数据\r\n\r\n![image-20241006231953135](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006231953135.png)\r\n\r\n\r\n\r\nProtobuf 是 Google 发布的开源项目，全称  Google Protocol Buffers ，是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。很适合做数据存储或 RPC（远程过程调用 remote procedure call）数据交换格式。目前很多公司从 HTTP + Json 转向 TCP + Protobuf ，效率会更高\r\n\r\nProtobuf 是以 message 的方式来管理数据，支持跨平台、跨语言（客户端和服务器端可以是不同的语言编写的），高性能、高可靠性\r\n\r\n工作过程：使用 Protobuf 编译器自动生成代码，Protobuf 是将类的定义使用 .proto 文件进行描述，然后通过 protoc.exe 编译器根据  .proto 自动生成 .java 文件\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n##### 代码实现\r\n\r\n* 单个 message：\r\n\r\n  ```less\r\n  syntax = \"proto3\"; \t\t\t\t\t\t\t\t// 版本\r\n  option java_outer_classname = \"StudentPOJO\";\t// 生成的外部类名，同时也是文件名\r\n  \r\n  message Student { \t// 在 StudentPOJO 外部类种生成一个内部类 Student，是真正发送的 POJO 对象\r\n      int32 id = 1; \t// Student 类中有一个属性：名字为 id 类型为 int32(protobuf类型) ，1表示属性序号，不是值\r\n      string name = 2;\r\n  }\r\n  ```\r\n\r\n  ![image-20241006232123918](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006232123918.png)\r\n\r\n  编译 `protoc.exe --java_out=.Student.proto`（cmd 窗口输入） 将生成的 StudentPOJO 放入到项目使用\r\n\r\n  Server 端：\r\n\r\n  ```java\r\n  new ServerBootstrap() //...\r\n      .childHandler(new ChannelInitializer<SocketChannel>() {\t// 创建一个通道初始化对象\r\n          // 给pipeline 设置处理器\r\n          @Override\r\n          protected void initChannel(SocketChannel ch) throws Exception {\r\n              // 在pipeline加入ProtoBufDecoder，指定对哪种对象进行解码\r\n              ch.pipeline().addLast(\"decoder\", new ProtobufDecoder(\r\n                  \t\t\t\t\t\t\tStudentPOJO.Student.getDefaultInstance()));\r\n              ch.pipeline().addLast(new NettyServerHandler());\r\n          }\r\n      }); \r\n  }\r\n  ```\r\n\r\n  Client 端：\r\n\r\n  ```java\r\n  new Bootstrap().group(group) \t\t\t// 设置线程组\r\n      .channel(NioSocketChannel.class) \t// 设置客户端通道的实现类(反射)\r\n      .handler(new ChannelInitializer<SocketChannel>() {\r\n          @Override\r\n          protected void initChannel(SocketChannel ch) throws Exception {\r\n              // 在pipeline中加入 ProtoBufEncoder\r\n              ch.pipeline().addLast(\"encoder\", new ProtobufEncoder());\r\n              ch.pipeline().addLast(new NettyClientHandler()); // 加入自定义的业务处理器\r\n          }\r\n      });\r\n  ```\r\n\r\n* 多个 message：Protobuf 可以使用 message 管理其他的 message。假设某个项目需要传输 20 个对象，可以在一个文件里定义 20 个 message，最后再用一个总的 message 来决定在实际传输时真正需要传输哪一个对象\r\n\r\n  ```less\r\n  syntax = \"proto3\";\r\n  option optimize_for = SPEED; \t\t\t\t\t// 加快解析\r\n  option java_package=\"com.atguigu.netty.codec2\";\t// 指定生成到哪个包下\r\n  option java_outer_classname=\"MyDataInfo\"; \t\t// 外部类名, 文件名\r\n  \r\n  message MyMessage {\r\n      // 定义一个枚举类型，DataType 如果是 0 则表示一个 Student 对象实例，DataType 这个名称自定义\r\n      enum DataType {\r\n          StudentType = 0; //在 proto3 要求 enum 的编号从 0 开始\r\n          WorkerType = 1;\r\n      }\r\n  \r\n      // 用 data_type 来标识传的是哪一个枚举类型，这里才真正开始定义 Message 的数据类型\r\n      DataType data_type = 1;  // 所有后面的数字都只是编号而已\r\n  \r\n      // oneof 关键字，表示每次枚举类型进行传输时，限制最多只能传输一个对象。\r\n      // dataBody名称也是自定义的\r\n      // MyMessage 里出现的类型只有两个 DataType 类型，Student 或者 Worker 类型，在真正传输的时候只会有一个出现\r\n      oneof dataBody {\r\n          Student student = 2;  //注意这后面的数字也都只是编号而已，上面DataType data_type = 1  占了第一个序号了\r\n          Worker worker = 3;\r\n      }\r\n  \r\n  \r\n  }\r\n  \r\n  message Student {\r\n      int32 id = 1;\t\t// Student类的属性\r\n      string name = 2; \t//\r\n  }\r\n  message Worker {\r\n      string name=1;\r\n      int32 age=2;\r\n  }\r\n  ```\r\n\r\n  编译：\r\n\r\n  Server 端：\r\n\r\n  ```java\r\n  ch.pipeline().addLast(\"decoder\", new ProtobufDecoder(MyDataInfo.MyMessage.getDefaultInstance()));\r\n  ```\r\n\r\n  Client 端：\r\n\r\n  ```java\r\n  pipeline.addLast(\"encoder\", new ProtobufEncoder());\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 长连接\r\n\r\nHTTP 协议是无状态的，浏览器和服务器间的请求响应一次，下一次会重新创建连接。实现基于 WebSocket 的长连接的全双工的交互，改变 HTTP 协议多次请求的约束\r\n\r\n开发需求：\r\n\r\n* 实现长连接，服务器与浏览器相互通信客户端\r\n* 浏览器和服务器端会相互感知，比如服务器关闭了，浏览器会感知，同样浏览器关闭了，服务器会感知\r\n\r\n代码实现：\r\n\r\n* WebSocket：\r\n\r\n  * WebSocket 的数据是**以帧（frame）形式传递**，WebSocketFrame 下面有六个子类，代表不同的帧格式\r\n\r\n  * 浏览器请求 URL：ws://localhost:8080/xxx\r\n\r\n  ```java\r\n  public class MyWebSocket {\r\n      public static void main(String[] args) throws Exception {\r\n          // 创建两个线程组\r\n          EventLoopGroup bossGroup = new NioEventLoopGroup(1);\r\n          EventLoopGroup workerGroup = new NioEventLoopGroup();\r\n          try {\r\n  \r\n              ServerBootstrap serverBootstrap = new ServerBootstrap();\r\n              serverBootstrap.group(bossGroup, workerGroup);\r\n              serverBootstrap.channel(NioServerSocketChannel.class);\r\n              serverBootstrap.handler(new LoggingHandler(LogLevel.INFO));\r\n              serverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\r\n                  @Override\r\n                  protected void initChannel(SocketChannel ch) throws Exception {\r\n                      ChannelPipeline pipeline = ch.pipeline();\r\n  \r\n                      // 基于 http 协议，使用 http 的编码和解码器\r\n                      pipeline.addLast(new HttpServerCodec());\r\n                      // 是以块方式写，添加 ChunkedWriteHandler 处理器\r\n                      pipeline.addLast(new ChunkedWriteHandler());\r\n  \r\n                      // http 数据在传输过程中是分段, HttpObjectAggregator 就是可以将多个段聚合\r\n                      //  这就就是为什么，当浏览器发送大量数据时，就会发出多次 http 请求\r\n                      pipeline.addLast(new HttpObjectAggregator(8192));\r\n          \r\n                      // WebSocketServerProtocolHandler 核心功能是【将 http 协议升级为 ws 协议】，保持长连接\r\n                      pipeline.addLast(new WebSocketServerProtocolHandler(\"/hello\"));\r\n  \r\n                      // 自定义的handler ，处理业务逻辑\r\n                      pipeline.addLast(new MyTextWebSocketFrameHandler());\r\n                  }\r\n              });\r\n  \r\n              // 启动服务器\r\n              ChannelFuture channelFuture = serverBootstrap.bind(8080).sync();\r\n              channelFuture.channel().closeFuture().sync();\r\n  \r\n          } finally {\r\n              bossGroup.shutdownGracefully();\r\n              workerGroup.shutdownGracefully();\r\n          }\r\n      }\r\n  }\r\n  ```\r\n\r\n* 处理器：\r\n\r\n  ```java\r\n  public class MyTextWebSocketFrameHandler extends SimpleChannelInboundHandler<TextWebSocketFrame> {\r\n      // TextWebSocketFrame 类型，表示一个文本帧(frame)\r\n      @Override\r\n      protected void channelRead0(ChannelHandlerContext ctx, TextWebSocketFrame msg) throws Exception {\r\n          System.out.println(\"服务器收到消息 \" + msg.text());\r\n          // 回复消息\r\n          ctx.writeAndFlush(new TextWebSocketFrame(\"服务器时间\" + LocalDateTime.now() + \" \" + msg.text()));\r\n      }\r\n  \r\n      // 当web客户端连接后， 触发方法\r\n      @Override\r\n      public void handlerAdded(ChannelHandlerContext ctx) throws Exception {\r\n          // id 表示唯一的值，LongText 是唯一的 ShortText 不是唯一\r\n          System.out.println(\"handlerAdded 被调用\" + ctx.channel().id().asLongText());\r\n          System.out.println(\"handlerAdded 被调用\" + ctx.channel().id().asShortText());\r\n      }\r\n  \r\n      @Override\r\n      public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {\r\n          System.out.println(\"handlerRemoved 被调用\" + ctx.channel().id().asLongText());\r\n      }\r\n  \r\n      @Override\r\n      public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\r\n          System.out.println(\"异常发生 \" + cause.getMessage());\r\n          ctx.close(); // 关闭连接\r\n      }\r\n  }\r\n  ```\r\n\r\n* HTML：\r\n\r\n  ```html\r\n  <!DOCTYPE html>\r\n  <html lang=\"en\">\r\n  <head>\r\n      <meta charset=\"UTF-8\">\r\n      <title>Title</title>\r\n  </head>\r\n  <body>\r\n  <script>\r\n      var socket;\r\n      // 判断当前浏览器是否支持websocket\r\n      if(window.WebSocket) {\r\n          //go on\r\n          socket = new WebSocket(\"ws://localhost:8080/hello\");\r\n          //相当于channelReado, ev 收到服务器端回送的消息\r\n          socket.onmessage = function (ev) {\r\n              var rt = document.getElementById(\"responseText\");\r\n              rt.value = rt.value + \"\\n\" + ev.data;\r\n          }\r\n  \r\n          //相当于连接开启(感知到连接开启)\r\n          socket.onopen = function (ev) {\r\n              var rt = document.getElementById(\"responseText\");\r\n              rt.value = \"连接开启了..\"\r\n          }\r\n  \r\n          //相当于连接关闭(感知到连接关闭)\r\n          socket.onclose = function (ev) {\r\n  \r\n              var rt = document.getElementById(\"responseText\");\r\n              rt.value = rt.value + \"\\n\" + \"连接关闭了..\"\r\n          }\r\n      } else {\r\n          alert(\"当前浏览器不支持websocket\")\r\n      }\r\n  \r\n      // 发送消息到服务器\r\n      function send(message) {\r\n          // 先判断socket是否创建好\r\n          if(!window.socket) {\r\n              return;\r\n          }\r\n          if(socket.readyState == WebSocket.OPEN) {\r\n              // 通过socket 发送消息\r\n              socket.send(message)\r\n          } else {\r\n              alert(\"连接没有开启\");\r\n          }\r\n      }\r\n  </script>\r\n      <form onsubmit=\"return false\">\r\n          <textarea name=\"message\" style=\"height: 300px; width: 300px\"></textarea>\r\n          <input type=\"button\" value=\"发生消息\" onclick=\"send(this.form.message.value)\">\r\n          <textarea id=\"responseText\" style=\"height: 300px; width: 300px\"></textarea>\r\n          <input type=\"button\" value=\"清空内容\" onclick=\"document.getElementById('responseText').value=''\">\r\n      </form>\r\n  </body>\r\n  </html>\r\n  ```\r\n\r\n\r\n\r\n\r\n\r\n***\r\n\r\n\r\n\r\n### 参数调优\r\n\r\n#### CONNECT\r\n\r\n参数配置方式：\r\n\r\n* 客户端通过 .option() 方法配置参数，给 SocketChannel 配置参数\r\n* 服务器端：\r\n  * new ServerBootstrap().option()： 给 ServerSocketChannel 配置参数\r\n  * new ServerBootstrap().childOption()：给 SocketChannel 配置参数\r\n\r\nCONNECT_TIMEOUT_MILLIS 参数：\r\n\r\n* 属于 SocketChannal 参数\r\n* 在客户端建立连接时，如果在指定毫秒内无法连接，会抛出 timeout 异常\r\n\r\n* SO_TIMEOUT 主要用在阻塞 IO，阻塞 IO 中 accept，read 等都是无限等待的，如果不希望永远阻塞，可以调整超时时间\r\n\r\n```java\r\npublic class ConnectionTimeoutTest {\r\n    public static void main(String[] args) {\r\n        NioEventLoopGroup group = new NioEventLoopGroup();\r\n        try {\r\n            Bootstrap bootstrap = new Bootstrap()\r\n                    .group(group)\r\n                    .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000)\r\n                    .channel(NioSocketChannel.class)\r\n                    .handler(new LoggingHandler());\r\n            ChannelFuture future = bootstrap.connect(\"127.0.0.1\", 8080);\r\n            future.sync().channel().closeFuture().sync();\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n            log.debug(\"timeout\");\r\n        } finally {\r\n            group.shutdownGracefully();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### SO_BACKLOG\r\n\r\n属于 ServerSocketChannal 参数，通过 `option(ChannelOption.SO_BACKLOG, value)` 来设置大小\r\n\r\n在 Linux 2.2 之前，backlog 大小包括了两个队列的大小，在 2.2 之后，分别用下面两个参数来控制\r\n\r\n* sync queue：半连接队列，大小通过 `/proc/sys/net/ipv4/tcp_max_syn_backlog` 指定，在 `syncookies` 启用的情况下，逻辑上没有最大值限制\r\n* accept queue：全连接队列，大小通过 `/proc/sys/net/core/somaxconn` 指定，在使用 listen 函数时，内核会根据传入的 backlog 参数与系统参数，取二者的较小值。如果 accpet queue 队列满了，server 将**发送一个拒绝连接的错误信息**到 client\r\n\r\n![image-20241006232236836](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20241006232236836.png)\r\n\r\n\r\n\r\n****\r\n\r\n\r\n\r\n#### 其他参数\r\n\r\nALLOCATOR：属于 SocketChannal 参数，用来分配 ByteBuf， ctx.alloc()\r\n\r\nRCVBUF_ALLOCATOR：属于 SocketChannal 参数\r\n\r\n* 控制 Netty 接收缓冲区大小\r\n* 负责入站数据的分配，决定入站缓冲区的大小（并可动态调整），统一采用 direct 直接内存，具体池化还是非池化由 allocator 决定\r\n"},{"title":"认证授权-Spring Security","tags":["Spring Cloud","Spring Boot","Spring Security","JWT","OAuth2","Redis"],"categories":["Java","微系统与第三方框架"],"author":"imklaus","excerpt":"\r\n\r\n参考视频：[黑马学成在线项目](https://www.bilibili.com/video/BV1j8411N7Bm/)\r\n\r\n","link":"/posts/Spring-Security","content":"\r\n\r\n参考视频：[黑马学成在线项目](https://www.bilibili.com/video/BV1j8411N7Bm/)\r\n\r\n<!-- more -->\r\n\r\n\r\n## **1 模块需求分析**\r\n\r\n### **1.1 什么是认证授权**\r\n\r\n截至目前，项目已经完成了课程发布功能，课程发布后用户通过在线学习页面点播视频进行学习。如何去记录学生的学习过程呢？要想掌握学生的学习情况就需要知道用户的身份信息，记录哪个用户在什么时间学习什么课程，如果用户要购买课程也需要知道用户的身份信息。所以，去管理学生的学习过程最基本的要实现用户的身份认证。\r\n\r\n认证授权模块实现平台所有用户的身份认证与用户授权功能。\r\n\r\n什么是用户身份认证？\r\n\r\n​    用户身份认证即用户去访问系统资源时系统要求验证用户的身份信息，身份合法方可继续访问。常见的用户身份认证的表现形式有：用户名密码登录，微信扫码等方式。\r\n\r\n项目包括学生、学习机构的老师、平台运营人员三类用户，不管哪一类用户在访问项目受保护资源时都需要进行身份认证。比如：发布课程操作，需要学习机构的老师首先登录系统成功，然后再执行发布课程操作。创建订单，需要学生用户首先登录系统，才可以创建订单。如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps35.jpg) \r\n\r\n什么是用户授权？\r\n\r\n​    用户认证通过后去访问系统的资源，系统会判断用户是否拥有访问资源的权限，只允许访问有权限的系统资源，没有权限的资源将无法访问，这个过程叫用户授权。比如：用户去发布课程，系统首先进行用户身份认证，认证通过后继续判断用户是否有发布课程的权限，如果没有权限则拒绝继续访问系统，如果有权限则继续发布课程。如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps36.jpg) \r\n\r\n \r\n\r\n### **1.2 业务流程**\r\n\r\n#### **1.2.1 统一认证**\r\n\r\n项目包括学生、学习机构的老师、平台运营人员三类用户，三类用户将使用统一的认证入口，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps37.jpg) \r\n\r\n用户输入账号和密码提交认证，认证通过则继续操作。\r\n\r\n项目由统一认证服务受理用户的认证请求，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps38.jpg) \r\n\r\n认证通过由认证服务向给用户颁发令牌，相当于访问系统的通行证，用户拿着令牌去访问系统的资源。\r\n\r\n#### **1.2.2 单点登录**\r\n\r\n本项目基于微服务架构构建，微服务包括：内容管理服务、媒资管理服务、学习中心服务、系统管理服务等，为了提高用户体验性，用户只需要认证一次便可以在多个拥有访问权限的系统中访问，这个功能叫做单点登录。\r\n\r\n引用百度百科：单点登录（Single Sign On），简称为 SSO，是目前比较流行的企业业务整合的解决方案之一。SSO的定义是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。\r\n\r\n如下图，用户只需要认证一次，便可以在多个拥有访问权限的系统中访问。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps39.jpg) \r\n\r\n \r\n\r\n#### **1.2.3 第三方认证**\r\n\r\n为了提高用户体验，很多网站有扫码登录的功能，如：微信扫码登录、QQ扫码登录等。扫码登录的好处是用户不用输入账号和密码，操作简便，另外一个好处就是有利于用户信息的共享，互联网的优势就是资源共享，用户也是一种资源，对于一个新网站如果让用户去注册是很困难的，如果提供了微信扫码登录将省去用户注册的成本，是一种非常有效的推广手段。\r\n\r\n微信扫码登录其中的原理正是使用了第三方认证，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps40.jpg) \r\n\r\n## **2 Spring Security 认证研究**\r\n\r\n### **2.1 Spring Security介绍**\r\n\r\n认证功能几乎是每个项目都要具备的功能，并且它与业务无关，市面上有很多认证框架，如：Apache Shiro、CAS、Spring Security等。由于本项目基于Spring Cloud技术构建，Spring Security是spring家族的一份子且和Spring Cloud集成的很好，所以本项目选用Spring Security作为认证服务的技术框架。\r\n\r\nSpring Security 是一个功能强大且高度可定制的身份验证和访问控制框架，它是一个专注于为 Java 应用程序提供身份验证和授权的框架。\r\n\r\n项目主页：https://spring.io/projects/spring-security\r\n\r\nSpring cloud Security： https://spring.io/projects/spring-cloud-security\r\n\r\n### **2.2 认证授权入门**\r\n\r\n#### **2.2.1 创建认证服务工程**\r\n\r\n下边我们使用Spring Security框架快速构建认证授权功能体系。\r\n\r\n1、部署认证服务工程\r\n\r\n从课程资料中拷贝xuecheng-plus-auth工程到自己的工程目录下。\r\n\r\n此工程是一个普通的spring boot工程，可以连接数据库。\r\n\r\n此工程不具备认证授权的功能。\r\n\r\n2、创建数据库\r\n\r\n创建xc_users数据库\r\n\r\n导入课程资料中的xcplus_users.sql脚本。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps41.jpg) \r\n\r\n \r\n\r\n在nacos中新增`auth-service-dev.yaml`：\r\n\r\n```yaml\r\n\r\nserver:\r\n  servlet:\r\n    context-path: /auth\r\n  port: 63070\r\nspring:\r\n  datasource:\r\n    driver-class-name: com.mysql.cj.jdbc.Driver\r\n    url: jdbc:mysql://192.168.2.203:3306/xc_users?serverTimezone=UTC&userUnicode=true&useSSL=false&\r\n    username: root\r\n    password: 1234\r\n```\r\n\r\n初始工程自带了一个Controller类，如下：\r\n\r\n```java\r\n\r\n@Slf4j\r\n@RestController\r\npublic class LoginController {\r\n\r\n  @Autowired\r\n  XcUserMapper userMapper;\r\n\r\n  @RequestMapping(\"/login-success\")\r\n  public String loginSuccess(){\r\n\r\n      return \"登录成功\";\r\n  }\r\n\r\n\r\n  @RequestMapping(\"/user/{id}\")\r\n  public XcUser getuser(@PathVariable(\"id\") String id){\r\n    XcUser xcUser = userMapper.selectById(id);\r\n    return xcUser;\r\n  }\r\n\r\n  @RequestMapping(\"/r/r1\")\r\n  public String r1(){\r\n    return \"访问r1资源\";\r\n  }\r\n\r\n  @RequestMapping(\"/r/r2\")\r\n  public String r2(){\r\n    return \"访问r2资源\";\r\n  }\r\n\r\n}\r\n```\r\n\r\n启动工程，尝试访问http://localhost:63070/auth/r/r1 :\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps42.jpg) \r\n\r\n访问用户信息：http://localhost:63070/auth/user/52 \r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps43.jpg) \r\n\r\n以上测试一切正常说明此工程部署成功。\r\n\r\n \r\n\r\n#### **2.2.2 认证测试**\r\n\r\n下边向auth认证工程集成Spring security，向pom.xml加入Spring Security所需要的依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-security</artifactId>\r\n</dependency>\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-oauth2</artifactId>\r\n</dependency>\r\n```\r\n\r\n重启工程，访问http://localhost:63070/auth/r/r1\r\n\r\n自动进入`/login`登录页面，`/login`是spring security提供的,此页面有几个css样式加载会稍微慢点，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps44.jpg) \r\n\r\n \r\n\r\n账号和密码是多少呢？下一步需要进行安全配置。\r\n\r\n拷贝课程资料下的`WebSecurityConfig.java`到config下需要三部分内容：\r\n\r\n1、用户信息\r\n\r\n在内存配置两个用户：`zhangsan、lisi`\r\n\r\nzhangsan用户拥有的权限为p1\r\n\r\nlisi用户拥有的权限为p2\r\n\r\n2、密码方式\r\n\r\n暂时采用明文方式\r\n\r\n3、安全拦截机制\r\n\r\n`/r/**`开头的请求需要认证\r\n\r\n登录成功到成功页面\r\n\r\n代码如下：\r\n\r\n```java\r\n\r\n//配置用户信息服务\r\n@Bean\r\npublic UserDetailsService userDetailsService() {\r\n    //这里配置用户信息,这里暂时使用这种方式将用户存储在内存中\r\n    InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager();\r\n            manager.createUser(User.withUsername(\"zhangsan\").password(\"123\").authorities(\"p1\").build());\r\n    manager.createUser(User.withUsername(\"lisi\").password(\"456\").authorities(\"p2\").build());\r\n    return manager;\r\n}\r\n\r\n    @Bean\r\n    public PasswordEncoder passwordEncoder() {\r\n        //密码为明文方式\r\n        return NoOpPasswordEncoder.getInstance();\r\n    }\r\n\r\n    //配置安全拦截机制\r\n    @Override\r\n    protected void configure(HttpSecurity http) throws Exception {\r\n        http\r\n                .authorizeRequests()\r\n                .antMatchers(\"/r/**\").authenticated()//访问/r开始的请求需要认证通过\r\n                .anyRequest().permitAll()//其它请求全部放行\r\n                .and()\r\n                .formLogin().successForwardUrl(\"/login-success\");//登录成功跳转到/login-success\r\n                http.logout().logoutUrl(\"/logout\");//退出地址\r\n    }\r\n```\r\n\r\n重启工程\r\n\r\n1、访问http://localhost:63070/auth/user/52  可以正常访问\r\n\r\n2、访问http://localhost:63070/auth/r/r1 显示登录页面\r\n\r\n账号zhangsan，密码为123，如果输入的密码不正确会认证失败，输入正确显示登录成功。\r\n\r\n为什么http://localhost:63070/auth/user/52  可以正常访问，访问http://localhost:63070/auth/r/r1 显示登录页面？\r\n\r\n \r\n\r\n`http.logout().logoutUrl(\"/logout\");`配置了退出页面，认证成功后访问`/logout`可退出登录。\r\n\r\n \r\n\r\n#### **2.2.3 授权测试**\r\n\r\n用户认证通过去访问系统资源时spring security进行授权控制，判断用户是否有该资源的访问权限，如果有则继续访问，如果没有则拒绝访问。\r\n\r\n下边测试授权功能：\r\n\r\n1、配置用户拥有哪些权限。\r\n\r\n在WebSecurityConfig类配置zhangsan拥有p1权限，lisi拥有p2权限。\r\n\r\n```java\r\n\r\n    @Bean\r\n    public UserDetailsService userDetailsService() {\r\n        //这里配置用户信息,这里暂时使用这种方式将用户存储在内存中\r\n        InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager();\r\n        manager.createUser(User.withUsername(\"zhangsan\").password(\"123\").authorities(\"p1\").build());\r\n        manager.createUser(User.withUsername(\"lisi\").password(\"456\").authorities(\"p2\").build());\r\n        return manager;\r\n    }\r\n```\r\n\r\n2、指定资源与权限的关系。\r\n\r\n什么是系统的资源？\r\n\r\n比如：查询一个用户的信息，用户信息就是系统的资源，要访问资源需要通过URL，所以我们在controller中定义的每个http的接口就是访问资源的接口。\r\n\r\n下边在controller中配置`/r/r1`需要p1权限，`/r/r2`需要p2权限。\r\n\r\n`hasAuthority('p1')`表示拥有p1权限方可访问。\r\n\r\n代码如下：\r\n\r\n```java\r\n\r\n@RestController\r\npublic class LoginController {\r\n    ....\r\n    @RequestMapping(\"/r/r1\")\r\n    @PreAuthorize(\"hasAuthority('p1')\")//拥有p1权限方可访问\r\n    public String r1(){\r\n      return \"访问r1资源\";\r\n    }\r\n    \r\n    @RequestMapping(\"/r/r2\")\r\n    @PreAuthorize(\"hasAuthority('p2')\")//拥有p2权限方可访问\r\n    public String r2(){\r\n      return \"访问r2资源\";\r\n    }\r\n    ...\r\n```\r\n\r\n现在重启工程。\r\n\r\n当访问以/r/开头的url时会判断用户是否认证，如果没有认证则跳转到登录页面，如果已经认证则判断用户是否具有该URL的访问权限，如果具有该URL的访问权限则继续，否则拒绝访问。\r\n\r\n例如：\r\n\r\n访问`/r/r1`，使用zhangsan登录可以正常访问，因为在`/r/r1`的方法上指定了权限p1，zhangsan用户拥有权限p1,所以可以正常访问。\r\n\r\n访问`/r/r1`，使用lisi登录则拒绝访问，由于lisi用户不具有权限p1需要拒绝访问\r\n\r\n注意：如果访问上不加`@PreAuthorize`，此方法没有授权控制。\r\n\r\n \r\n\r\n整理授权的过程见下图所示：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps45.jpg) \r\n\r\n \r\n\r\n#### **2.2.4 工作原理**\r\n\r\n通过测试认证和授权两个功能，我们了解了Spring Security的基本使用方法，下边了解它的工作流程。\r\n\r\nSpring Security所解决的问题就是**安全访问控制**，而安全访问控制功能其实就是对所有进入系统的请求进行拦截，校验每个请求是否能够访问它所期望的资源。根据前边知识的学习，可以通过Filter或AOP等技术来实现，Spring Security对Web资源的保护是靠Filter实现的，所以从这个Filter来入手，逐步深入Spring Security原理。\r\n\r\n​    当初始化Spring Security时，会创建一个名为SpringSecurityFilterChain的Servlet过滤器，类型为 `org.springframework.security.web.FilterChainProxy`，它实现了`javax.servlet.Filter`，因此外部的请求会经过此类，下图是Spring Security过虑器链结构图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps46.jpg) \r\n\r\nFilterChainProxy是一个代理，真正起作用的是FilterChainProxy中SecurityFilterChain所包含的各个Filter，同时这些Filter作为Bean被Spring管理，它们是Spring Security核心，各有各的职责，但他们并不直接处理用户的**认证**，也不直接处理用户的**授权**，而是把它们交给了认证管理器（AuthenticationManager）和决策管理器（AccessDecisionManager）进行处理。\r\n\r\nspring Security功能的实现主要是由一系列过滤器链相互配合完成。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps47.jpg) \r\n\r\n下面介绍过滤器链中主要的几个过滤器及其作用：\r\n\r\n**SecurityContextPersistenceFilter** 这个Filter是整个拦截过程的入口和出口（也就是第一个和最后一个拦截器），会在请求开始时从配置好的 SecurityContextRepository 中获取 SecurityContext，然后把它设置给 SecurityContextHolder。在请求完成后将 SecurityContextHolder 持有的 SecurityContext 再保存到配置好的 SecurityContextRepository，同时清除 securityContextHolder 所持有的 SecurityContext；\r\n\r\n**UsernamePasswordAuthenticationFilter** 用于处理来自表单提交的认证。该表单必须提供对应的用户名和密码，其内部还有登录成功或失败后进行处理的 AuthenticationSuccessHandler 和 AuthenticationFailureHandler，这些都可以根据需求做相关改变；\r\n\r\n**FilterSecurityInterceptor** 是用于保护web资源的，使用AccessDecisionManager对当前用户进行授权访问，前面已经详细介绍过了；\r\n\r\n**ExceptionTranslationFilter** 能够捕获来自 FilterChain 所有的异常，并进行处理。但是它只会处理两类异常：AuthenticationException 和 AccessDeniedException，其它的异常它会继续抛出。\r\n\r\n \r\n\r\nSpring Security的执行流程如下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps48.jpg) \r\n\r\n1. 用户提交用户名、密码被SecurityFilterChain中的UsernamePasswordAuthenticationFilter过滤器获取到，封装为请求Authentication，通常情况下是UsernamePasswordAuthenticationToken这个实现类。\r\n\r\n2. 然后过滤器将Authentication提交至认证管理器（AuthenticationManager）进行认证\r\n\r\n3. 认证成功后，AuthenticationManager身份管理器返回一个被填充满了信息的（包括上面提到的权限信息，身份信息，细节信息，但密码通常会被移除）Authentication实例。\r\n\r\n4. SecurityContextHolder安全上下文容器将第3步填充了信息的Authentication，通过`SecurityContextHolder.getContext().setAuthentication(…)`方法，设置到其中。\r\n\r\n5. 可以看出AuthenticationManager接口（认证管理器）是认证相关的核心接口，也是发起认证的出发点，它的实现类为ProviderManager。而Spring Security支持多种认证方式，因此ProviderManager维护着一个`List<AuthenticationProvider>`列表，存放多种认证方式，最终实际的认证工作是由AuthenticationProvider完成的。咱们知道web表单的对应的AuthenticationProvider实现类为DaoAuthenticationProvider，它的内部又维护着一个UserDetailsService负责UserDetails的获取。最终AuthenticationProvider将UserDetails填充至Authentication。\r\n\r\n \r\n\r\n \r\n\r\n### **2.3 什么是OAuth2**\r\n\r\n#### **2.3.1 OAuth2认证流程**\r\n\r\n在前边我们提到微信扫码认证，这是一种第三方认证的方式，这种认证方式是基于OAuth2协议实现，\r\n\r\nOAUTH协议为用户资源的授权提供了一个安全的、开放而又简易的标准。同时，任何第三方都可以使用OAUTH认证服务，任何服务提供商都可以实现自身的OAUTH认证服务，因而OAUTH是开放的。业界提供了OAUTH的多种实现如`PHP、JavaScript，Java，Ruby`等各种语言开发包，大大节约了程序员的时间，因而OAUTH是简易的。互联网很多服务如Open API，很多大公司如`Google，Yahoo，Microsoft`等都提供了OAUTH认证服务，这些都足以说明OAUTH标准逐渐成为开放资源授权的标准。\r\n\r\n​    Oauth协议目前发展到2.0版本，1.0版本过于复杂，2.0版本已得到广泛应用。\r\n\r\n参考：https://baike.baidu.com/item/oAuth/7153134?fr=aladdin\r\n\r\nOauth协议：https://tools.ietf.org/html/rfc6749\r\n\r\n下边分析一个Oauth2认证的例子，黑马程序员网站使用微信认证扫码登录的过程：\r\n\r\n![image-20230705222917841](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705222917841.png) \r\n\r\n具体流程如下：\r\n\r\n1、用户点击微信扫码\r\n\r\n用户进入黑马程序的登录页面，点击微信的图标开打微信扫码界面。\r\n\r\n \r\n\r\n![image-20230705223020201](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223020201.png) \r\n\r\n![image-20230705223055747](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223055747.png) \r\n\r\n \r\n\r\n微信扫码的目的是通过微信认证登录黑马程序员官网，黑马程序员网站需要从微信获取当前用户的身份信息才会让当前用户在黑马网站登录成功。\r\n\r\n现在搞清楚几个概念：\r\n\r\n资源：用户信息，在微信中存储。\r\n\r\n资源拥有者：用户是用户信息资源的拥有者。\r\n\r\n认证服务：微信负责认证当前用户的身份，负责为客户端颁发令牌。\r\n\r\n客户端：客户端会携带令牌请求微信获取用户信息，黑马程序员网站即客户端，黑马网站需要在浏览器打开。\r\n\r\n2、用户授权黑马网站访问用户信息\r\n\r\n资源拥有者扫描二维码表示资源拥有者请求微信进行认证，微信认证通过向用户手机返回授权页面，如下图：\r\n\r\n![image-20230705223223906](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223223906.png) \r\n\r\n询问用户是否授权黑马程序员访问自己在微信的用户信息，用户点击“确认登录”表示同意授权，微信认证服务器会颁发一个授权码给黑马程序员的网站。\r\n\r\n只有资源拥有者同意微信才允许黑马网站访问资源。\r\n\r\n3、黑马程序员的网站获取到授权码\r\n\r\n4、携带授权码请求微信认证服务器申请令牌\r\n\r\n此交互过程用户看不到。\r\n\r\n5、微信认证服务器向黑马程序员的网站响应令牌\r\n\r\n此交互过程用户看不到。\r\n\r\n6、黑马程序员网站请求微信资源服务器获取资源即用户信息。\r\n\r\n黑马程序员网站携带令牌请求访问微信服务器获取用户的基本信息。\r\n\r\n7、资源服务器返回受保护资源即用户信息\r\n\r\n8、黑马网站接收到用户信息，此时用户在黑马网站登录成功。\r\n\r\n理解了微信扫码登录黑马网站的流程，接下来认识Oauth2.0的认证流程，如下：\r\n\r\n引自Oauth2.0协议rfc6749 https://tools.ietf.org/html/rfc6749\r\n\r\n![image-20230705223310223](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223310223.png) \r\n\r\nOauth2包括以下角色：\r\n\r\n1、客户端\r\n\r\n本身不存储资源，需要通过资源拥有者的授权去请求资源服务器的资源，比如：手机客户端、浏览器等。\r\n\r\n上边示例中黑马网站即为客户端，它需要通过浏览器打开。\r\n\r\n2、资源拥有者\r\n\r\n通常为用户，也可以是应用程序，即该资源的拥有者。\r\n\r\nA表示 客户端请求资源拥有者授权。\r\n\r\nB表示 资源拥有者授权客户端即黑马网站访问自己的用户信息。\r\n\r\n3、授权服务器（也称认证服务器）\r\n\r\n认证服务器对资源拥有者进行认证，还会对客户端进行认证并颁发令牌。\r\n\r\nC 客户端即黑马网站携带授权码请求认证。\r\n\r\nD认证通过颁发令牌。\r\n\r\n4、资源服务器\r\n\r\n存储资源的服务器。\r\n\r\nE表示客户端即黑马网站携带令牌请求资源服务器获取资源。\r\n\r\nF表示资源服务器校验令牌通过后提供受保护资源。\r\n\r\n \r\n\r\n#### **2.3.2 OAuth2在本项目的应用**\r\n\r\nOauth2是一个标准的开放的授权协议，应用程序可以根据自己的要求去使用Oauth2，本项目使用Oauth2实现如下目标：\r\n\r\n1、学成在线访问第三方系统的资源。\r\n\r\n本项目要接入微信扫码登录所以本项目要使用OAuth2协议访问微信中的用户信息。\r\n\r\n2、外部系统访问学成在线的资源  。\r\n\r\n同样当第三方系统想要访问学成在线网站的资源也可以基于OAuth2协议。\r\n\r\n3、学成在线前端（客户端） 访问学成在线微服务的资源。\r\n\r\n本项目是前后端分离架构，前端访问微服务资源也可以基于OAuth2协议进行认证。\r\n\r\n \r\n\r\n#### **2.3.3 OAuth2的授权模式**\r\n\r\nSpring Security支持OAuth2认证，OAuth2提供授权码模式、密码模式、简化模式、客户端模式等四种授权模式，前边举的微信扫码登录的例子就是基于授权码模式，这四种模式中授权码模式和密码模式应用较多，本节使用Spring Security演示授权码模式、密码模式，其余两种请自行查阅相关资料。\r\n\r\n##### **2.3.3.1 授权码模式**\r\n\r\nOAuth2的几个授权模式是根据不同的应用场景以不同的方式去获取令牌，最终目的是要获取认证服务颁发的令牌，最终通过令牌去获取资源。\r\n\r\n授权码模式简单理解是使用授权码去获取令牌，要想获取令牌先要获取授权码，授权码的获取需要资源拥有者亲自授权同意才可以获取。\r\n\r\n下图是授权码模式的交互图：\r\n\r\n![image-20230705223355846](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223355846.png) \r\n\r\n还以黑马网站微信扫码登录为例进行说明：\r\n\r\n1、用户打开浏览器。\r\n\r\n2、通过浏览器访问客户端即黑马网站。\r\n\r\n3、用户通过浏览器向认证服务请求授权，请求授权时会携带客户端的URL，此URL为下发授权码的重定向地址。\r\n\r\n4、认证服务向资源拥有者返回授权页面。\r\n\r\n5、资源拥有者亲自授权同意。\r\n\r\n6、通过浏览器向认证服务发送授权同意。\r\n\r\n7、认证服务向客户端地址重定向并携带授权码。\r\n\r\n8、客户端即黑马网站收到授权码。\r\n\r\n9、客户端携带授权码向认证服务申请令牌。\r\n\r\n10、认证服务向客户端颁发令牌。\r\n\r\n \r\n\r\n##### **2.3.3.2授权码模式测试**\r\n\r\n要想测试授权模式首先要配置授权服务器即上图中的认证服务器，需要配置授权服务及令牌策略。\r\n\r\n1、从课程资料中拷贝 `AuthorizationServer.java、TokenConfig.java`到认证服务的config包下。\r\n\r\n> 说明：AuthorizationServer用 `@EnableAuthorizationServer` 注解标识并继承AuthorizationServerConfigurerAdapter来配置OAuth2.0 授权服务器。\r\n\r\n```java\r\n\r\n @Configuration\r\n @EnableAuthorizationServer\r\n public class AuthorizationServer extends AuthorizationServerConfigurerAdapter {\r\n ...\r\n \r\n```\r\n\r\nAuthorizationServerConfigurerAdapter要求配置以下几个类：\r\n\r\n```java\r\n\r\npublic class AuthorizationServerConfigurerAdapter implements AuthorizationServerConfigurer {\r\n    public AuthorizationServerConfigurerAdapter() {}\r\n    public void configure(AuthorizationServerSecurityConfigurer security) throws Exception {}\r\n    public void configure(ClientDetailsServiceConfigurer clients) throws Exception {}\r\n    public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {}\r\n}\r\n```\r\n\r\n**1）ClientDetailsServiceConfigurer**：用来配置客户端详情服务（ClientDetailsService），\r\n\r\n随便一个客户端都可以随便接入到它的认证服务吗？答案是否定的，服务提供商会给批准接入的客户端一个身份，用于接入时的凭据，有客户端标识和客户端秘钥，在这里配置批准接入的客户端的详细信息。\r\n\r\n**2）AuthorizationServerEndpointsConfigurer**：用来配置令牌（token）的访问端点和令牌服务(token services)。\r\n\r\n**3）AuthorizationServerSecurityConfigurer**：用来配置令牌端点的安全约束.\r\n\r\n**2、TokenConfig为令牌策略配置类**\r\n\r\n暂时先使用InMemoryTokenStore在内存存储令牌，令牌的有效期等信息配置如下：\r\n\r\n```java\r\n\r\n    //令牌管理服务\r\n    @Bean(name=\"authorizationServerTokenServicesCustom\")\r\n    public AuthorizationServerTokenServices tokenService() {\r\n        DefaultTokenServices service=new DefaultTokenServices();\r\n        service.setSupportRefreshToken(true);//支持刷新令牌\r\n        service.setTokenStore(tokenStore);//令牌存储策略\r\n        service.setAccessTokenValiditySeconds(7200); // 令牌默认有效期2小时\r\n        service.setRefreshTokenValiditySeconds(259200); // 刷新令牌默认有效期3天\r\n        return service;\r\n    }\r\n```\r\n\r\n3、配置认证管理bean\r\n\r\n```java\r\n\r\n@EnableWebSecurity\r\n@EnableGlobalMethodSecurity(securedEnabled = true,prePostEnabled = true)\r\npublic class WebSecurityConfig extends WebSecurityConfigurerAdapter {\r\n\r\n    @Bean\r\n    public AuthenticationManager authenticationManagerBean() throws Exception {\r\n        return super.authenticationManagerBean();\r\n    }\r\n    ....\r\n```\r\n\r\n重启认证服务\r\n\r\n1、get请求获取授权码\r\n\r\n地址: http://localhost:63070/auth/oauth/authorize?client_id=XcWebApp&response_type=code&scope=all&redirect_uri=http://www.51xuecheng.cn\r\n\r\n参数列表如下：\r\n\r\n• `client_id`：客户端准入标识。\r\n\r\n• `response_type`：授权码模式固定为code。\r\n\r\n• `scope`：客户端权限。\r\n\r\n• `redirect_uri`：跳转uri，当授权码申请成功后会跳转到此地址，并在后边带上code参数（授权码）。\r\n\r\n输入账号zhangsan、密码123登录成功，输入`/oauth/authorize?client_id=XcWebApp&response_type=code&scope=all&redirect_uri=http://www.51xuecheng.cn`\r\n\r\n显示授权页面\r\n\r\n![image-20230705223440333](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223440333.png) \r\n\r\n授权“XcWebApp”访问自己的受保护资源?\r\n\r\n选择同意。\r\n\r\n2、请求成功，重定向至http://www.51xuecheng.cn/?code=授权码，比如：http://www.51xuecheng.cn/?code=Wqjb5H\r\n\r\n3、使用httpclient工具post申请令牌\r\n\r\n`/oauth/token?client_id=XcWebApp&client_secret=XcWebApp&grant_type=authorization_code&code=授权码&redirect_uri=http://www.51xuecheng.cn/`\r\n\r\n参数列表如下\r\n\r\n• `client_id`：客户端准入标识。\r\n\r\n• `client_secret`：客户端秘钥。\r\n\r\n• `grant_type`：授权类型，填写authorization_code，表示授权码模式\r\n\r\n• `code`：授权码，就是刚刚获取的授权码，注意：授权码只使用一次就无效了，需要重新申请。\r\n\r\n• `redirect_uri`：申请授权码时的跳转url，一定和申请授权码时用的redirect_uri一致。\r\n\r\nhttpclient脚本如下：\r\n\r\n```http\r\n### 授权码模式\r\n### 第一步申请授权码(浏览器请求)/oauth/authorize?client_id=c1&response_type=code&scope=all&redirect_uri=http://www.51xuecheng.cn\r\n### 第二步申请令牌\r\nPOST {{auth_host}}/auth/oauth/token?client_id=XcWebApp&client_secret=XcWebApp&grant_type=authorization_code&code=CTvCrB&redirect_uri=http://www.51xuecheng.cn\r\n```\r\n\r\n申请令牌成功如下所示：\r\n\r\n```json\r\n\r\n{\r\n  \"access_token\": \"368b1ee7-a9ee-4e9a-aae6-0fcab243aad2\",\r\n  \"token_type\": \"bearer\",\r\n  \"refresh_token\": \"3d56e139-0ee6-4ace-8cbe-1311dfaa991f\",\r\n  \"expires_in\": 7199,\r\n  \"scope\": \"all\"\r\n}\r\n```\r\n\r\n说明：\r\n\r\n1、`access_token`，访问令牌，用于访问资源使用。\r\n\r\n2、`token_type`，bearer是在RFC6750中定义的一种token类型，在携带令牌访问资源时需要在head中加入bearer 空格 令牌内容\r\n\r\n3、`refresh_token`，当令牌快过期时使用刷新令牌可以再次生成令牌。\r\n\r\n4、`expires_in`：过期时间（秒）\r\n\r\n5、`scope`：令牌的权限范围，服务端可以根据令牌的权限范围去对令牌授权。\r\n\r\n \r\n\r\n##### **2.3.3.3 密码模式**\r\n\r\n密码模式相对授权码模式简单，授权码模式需要借助浏览器供用户亲自授权，密码模式不用借助浏览器，如下图：\r\n\r\n![image-20230705223503678](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223503678.png) \r\n\r\n1、资源拥有者提供账号和密码\r\n\r\n2、客户端向认证服务申请令牌，请求中携带账号和密码\r\n\r\n3、认证服务校验账号和密码正确颁发令牌。\r\n\r\n开始测试：\r\n\r\n1、POST请求获取令牌\r\n\r\n`/oauth/token?client_id=XcWebApp&client_secret=XcWebApp&grant_type=password&username=shangsan&password=123`\r\n\r\n参数列表如下：\r\n\r\n- `client_id`：客户端准入标识。\r\n- `client_secret`：客户端秘钥。\r\n- `grant_type`：授权类型，填写password表示密码模式\r\n- `username`：资源拥有者用户名。\r\n- `password`：资源拥有者密码。\r\n\r\n2、授权服务器将令牌（`access_token`）发送给client\r\n\r\n使用httpclient进行测试\r\n\r\n```http\r\n### 密码模式\r\nPOST {{auth_host}}/auth/oauth/token?client_id=XcWebApp&client_secret=XcWebApp&grant_type=password&username=zhangsan&password=123\r\n```\r\n\r\n返回示例：\r\n\r\n```json\r\n\r\n{\r\n  \"access_token\": \"368b1ee7-a9ee-4e9a-aae6-0fcab243aad2\",\r\n  \"token_type\": \"bearer\",\r\n  \"refresh_token\": \"3d56e139-0ee6-4ace-8cbe-1311dfaa991f\",\r\n  \"expires_in\": 6806,\r\n  \"scope\": \"all\"\r\n}\r\n```\r\n\r\n​    这种模式十分简单，但是却意味着直接将用户敏感信息泄漏给了client，因此这就说明这种模式只能用于client是我们自己开发的情况下。\r\n\r\n##### **2.3.3.4 本项目的应用方式**\r\n\r\n通过演示授权码模式和密码模式，授权码模式适合客户端和认证服务非同一个系统的情况，所以本项目使用授权码模式完成微信扫码认证。本项目采用密码模式作为前端请求微服务的认证方式。\r\n\r\n \r\n\r\n### **2.4 JWT**\r\n\r\n#### **2.4.1 普通令牌的问题**\r\n\r\n客户端申请到令牌，接下来客户端携带令牌去访问资源，到资源服务器将会校验令牌的合法性。\r\n\r\n资源服务器如何校验令牌的合法性？\r\n\r\n我们以OAuth2的密码模式为例进行说明：\r\n\r\n![image-20230705223542073](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223542073.png) \r\n\r\n从第4步开始说明：\r\n\r\n1、客户端携带令牌访问资源服务获取资源。\r\n\r\n2、资源服务远程请求认证服务校验令牌的合法性\r\n\r\n3、如果令牌合法资源服务向客户端返回资源。\r\n\r\n这里存在一个问题：\r\n\r\n就是校验令牌需要远程请求认证服务，客户端的每次访问都会远程校验，执行性能低。\r\n\r\n如果能够让资源服务自己校验令牌的合法性将省去远程请求认证服务的成本，提高了性能。如下图：\r\n\r\n![image-20230705223607439](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223607439.png) \r\n\r\n如何解决上边的问题，实现资源服务自行校验令牌。\r\n\r\n令牌采用JWT格式即可解决上边的问题，用户认证通过后会得到一个JWT令牌，JWT令牌中已经包括了用户相关的信息，客户端只需要携带JWT访问资源服务，资源服务根据事先约定的算法自行完成令牌校验，无需每次都请求认证服务完成授权。\r\n\r\n \r\n\r\n#### **2.4.2 什么是JWT**\r\n\r\n什么是JWT？\r\n\r\nJSON Web Token（JWT）是一种使用JSON格式传递数据的网络令牌技术，它是一个开放的行业标准（RFC 7519），它定义了一种简洁的、自包含的协议格式，用于在通信双方传递json对象，传递的信息经过数字签名可以被验证和信任，它可以使用HMAC算法或使用RSA的公钥/私钥对来签名，防止内容篡改。官网：https://jwt.io/\r\n\r\n使用JWT可以实现无状态认证，什么是无状态认证？\r\n\r\n传统的基于session的方式是有状态认证，用户登录成功将用户的身份信息存储在服务端，这样加大了服务端的存储压力，并且这种方式不适合在分布式系统中应用。\r\n\r\n如下图，当用户访问应用服务，每个应用服务都会去服务器查看session信息，如果session中没有该用户则说明用户没有登录，此时就会重新认证，而解决这个问题的方法是Session复制、Session黏贴。\r\n\r\n![image-20230705223645686](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223645686.png) \r\n\r\n如果是基于令牌技术在分布式系统中实现认证则服务端不用存储session，可以将用户身份信息存储在令牌中，用户认证通过后认证服务颁发令牌给用户，用户将令牌存储在客户端，去访问应用服务时携带令牌去访问，服务端从jwt解析出用户信息。这个过程就是无状态认证。\r\n\r\n![image-20230705223829078](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223829078.png)\r\n\r\n \r\n\r\n \r\n\r\nJWT令牌的优点：\r\n\r\n1、jwt基于json，非常方便解析。\r\n\r\n2、可以在令牌中自定义丰富的内容，易扩展。\r\n\r\n3、通过非对称加密算法及数字签名技术，JWT防止篡改，安全性高。\r\n\r\n4、资源服务使用JWT可不依赖认证服务即可完成授权。\r\n\r\n缺点：\r\n\r\n１、JWT令牌较长，占存储空间比较大。\r\n\r\n下边是一个JWT令牌的示例：\r\n\r\n```apl\r\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJ6aGFuZ3NhbiIsInNjb3BlIjpbImFsbCJdLCJleHAiOjE2NjQyNTQ2NzIsImF1dGhvcml0aWVzIjpbInAxIl0sImp0aSI6Ijg4OTEyYjJkLTVkMDUtNGMxNC1iYmMzLWZkZTk5NzdmZWJjNiIsImNsaWVudF9pZCI6ImMxIn0.wkDBL7roLrvdBG2oGnXeoXq-zZRgE9IVV2nxd-ez_oA\r\n```\r\n\r\nJWT令牌由三部分组成，每部分中间使用点（.）分隔，比如：`xxxxx.yyyyy.zzzzz`\r\n\r\n1. Header     \r\n\r\n 头部包括令牌的类型（即JWT）及使用的哈希算法（如HMAC SHA256或RSA）\r\n\r\n 一个例子如下：\r\n\r\n 下边是Header部分的内容\r\n\r\n```json\r\n   {\r\n    \"alg\": \"HS256\",\r\n    \"typ\": \"JWT\"\r\n  }\r\n```\r\n\r\n将上边的内容使用Base64Url编码，得到一个字符串就是JWT令牌的第一部分。\r\n\r\n2. Payload\r\n\r\n 第二部分是负载，内容也是一个json对象，它是存放有效信息的地方，它可以存放jwt提供的信息字段，比如：iss（签发者）,exp（过期时间戳）, sub（面向的用户）等，也可自定义字段。\r\n\r\n 此部分不建议存放敏感信息，因为此部分可以解码还原原始内容。\r\n\r\n 最后将第二部分负载使用Base64Url编码，得到一个字符串就是JWT令牌的第二部分。\r\n\r\n 一个例子：\r\n\r\n```json\r\n\r\n  {\r\n    \"sub\": \"1234567890\",\r\n    \"name\": \"456\",\r\n    \"admin\": true\r\n  }\r\n```\r\n\r\n\r\n\r\n3. Signature\r\n\r\n 第三部分是签名，此部分用于防止jwt内容被篡改。\r\n\r\n 这个部分使用base64url将前两部分进行编码，编码后使用点（.）连接组成字符串，最后使用header中声明的签名算法进行签名。\r\n\r\n 一个例子：\r\n\r\n```json\r\n\r\n  HMACSHA256(\r\n    base64UrlEncode(header) + \".\" +\r\n    base64UrlEncode(payload),\r\n    secret)\r\n```\r\n\r\n\r\n\r\nbase64UrlEncode(header)：jwt令牌的第一部分。\r\n\r\nbase64UrlEncode(payload)：jwt令牌的第二部分。\r\n\r\nsecret：签名所使用的密钥。\r\n\r\n为什么JWT可以防止篡改？\r\n\r\n第三部分使用签名算法对第一部分和第二部分的内容进行签名，常用的签名算法是 HS256，常见的还有md5,sha 等，签名算法需要使用密钥进行签名，密钥不对外公开，并且签名是不可逆的，如果第三方更改了内容那么服务器验证签名就会失败，要想保证验证签名正确必须保证内容、密钥与签名前一致。\r\n\r\n \r\n\r\n![image-20230705223925811](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223925811.png) \r\n\r\n从上图可以看出认证服务和资源服务使用相同的密钥，这叫对称加密，对称加密效率高，如果一旦密钥泄露可以伪造jwt令牌。\r\n\r\nJWT还可以使用非对称加密，认证服务自己保留私钥，将公钥下发给受信任的客户端、资源服务，公钥和私钥是配对的，成对的公钥和私钥才可以正常加密和解密，非对称加密效率低但相比对称加密非对称加密更安全一些。\r\n\r\n \r\n\r\n#### **2.4.3 测试生成JWT令牌**\r\n\r\n在认证服务中配置jwt令牌服务，即可实现生成jwt格式的令牌,  \r\n\r\n```java\r\n\r\n@Configuration\r\npublic class TokenConfig {\r\n\r\n    private String SIGNING_KEY = \"mq123\";\r\n\r\n    @Autowired\r\n    TokenStore tokenStore;\r\n\r\n//    @Bean\r\n//    public TokenStore tokenStore() {\r\n//        //使用内存存储令牌（普通令牌）\r\n//        return new InMemoryTokenStore();\r\n//    }\r\n\r\n    @Autowired\r\n    private JwtAccessTokenConverter accessTokenConverter;\r\n\r\n    @Bean\r\n    public TokenStore tokenStore() {\r\n        return new JwtTokenStore(accessTokenConverter());\r\n    }\r\n\r\n    @Bean\r\n    public JwtAccessTokenConverter accessTokenConverter() {\r\n        JwtAccessTokenConverter converter = new JwtAccessTokenConverter();\r\n        converter.setSigningKey(SIGNING_KEY);\r\n        return converter;\r\n    }\r\n\r\n    //令牌管理服务\r\n    @Bean(name=\"authorizationServerTokenServicesCustom\")\r\n    public AuthorizationServerTokenServices tokenService() {\r\n        DefaultTokenServices service=new DefaultTokenServices();\r\n        service.setSupportRefreshToken(true);//支持刷新令牌\r\n        service.setTokenStore(tokenStore);//令牌存储策略\r\n\r\n        TokenEnhancerChain tokenEnhancerChain = new TokenEnhancerChain();\r\n        tokenEnhancerChain.setTokenEnhancers(Arrays.asList(accessTokenConverter));\r\n        service.setTokenEnhancer(tokenEnhancerChain);\r\n\r\n        service.setAccessTokenValiditySeconds(7200); // 令牌默认有效期2小时\r\n        service.setRefreshTokenValiditySeconds(259200); // 刷新令牌默认有效期3天\r\n        return service;\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n重启认证服务。\r\n\r\n使用httpclient通过密码模式申请令牌\r\n\r\n```http\r\n### 密码模式\r\nPOST {{auth_host}}/oauth/token?client_id=XcWebApp&client_secret=XcWebApp&grant_type=password&username=zhangsan&password=123\r\n```\r\n\r\n生成jwt的示例如下：\r\n\r\n```json\r\n{\r\n  \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJ6aGFuZ3NhbiIsInNjb3BlIjpbImFsbCJdLCJleHAiOjE2NjQzMzE2OTUsImF1dGhvcml0aWVzIjpbInAxIl0sImp0aSI6ImU5ZDNkMGZkLTI0Y2ItNDRjOC04YzEwLTI1NmIzNGY4ZGZjYyIsImNsaWVudF9pZCI6ImMxIn0.-9SKI-qUqKhKcs8Gb80Rascx-JxqsNZxxXoPo82d8SM\",\r\n  \"token_type\": \"bearer\",\r\n  \"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJ6aGFuZ3NhbiIsInNjb3BlIjpbImFsbCJdLCJhdGkiOiJlOWQzZDBmZC0yNGNiLTQ0YzgtOGMxMC0yNTZiMzRmOGRmY2MiLCJleHAiOjE2NjQ1ODM2OTUsImF1dGhvcml0aWVzIjpbInAxIl0sImp0aSI6ImRjNTRjNTRkLTA0YTMtNDIzNS04MmY3LTFkOWZkMmFjM2VmNSIsImNsaWVudF9pZCI6ImMxIn0.Wsw1Jc-Kd_GFqEugzdfoSsMY6inC8OQsraA21WjWtT8\",\r\n  \"expires_in\": 7199,\r\n  \"scope\": \"all\",\r\n  \"jti\": \"e9d3d0fd-24cb-44c8-8c10-256b34f8dfcc\"\r\n}\r\n```\r\n\r\n1、`access_token`，生成的jwt令牌，用于访问资源使用。\r\n\r\n2、`token_type`，bearer是在RFC6750中定义的一种token类型，在携带jwt访问资源时需要在head中加入bearer jwt令牌内容\r\n\r\n3、`refresh_token`，当jwt令牌快过期时使用刷新令牌可以再次生成jwt令牌。\r\n\r\n4、`expires_in`：过期时间（秒）\r\n\r\n5、`scope`，令牌的权限范围，服务端可以根据令牌的权限范围去对令牌授权。\r\n\r\n6、`jti`：令牌的唯一标识。\r\n\r\n \r\n\r\n我们可以通过check_token接口校验jwt令牌\r\n\r\n```http\r\n###校验jwt令牌\r\nPOST {{auth_host}}/oauth/check_token?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJzdHUxIiwic2NvcGUiOlsiYWxsIl0sImV4cCI6MTY2NDM3MTc4MCwiYXV0aG9yaXRpZXMiOlsicDEiXSwianRpIjoiZjBhM2NkZWItMzk5ZC00OGYwLTg4MDQtZWNhNjM4YWQ4ODU3IiwiY2xpZW50X2lkIjoiYzEifQ.qy46CSCJsH3eXWTHgdcntZhzcSzfRQlBU0dxAjZcsUw\r\n```\r\n\r\n响应示例如下：\r\n\r\n```json\r\n{\r\n  \"aud\": [\r\n    \"res1\"\r\n  ],\r\n  \"user_name\": \"zhangsan\",\r\n  \"scope\": [\r\n    \"all\"\r\n  ],\r\n  \"active\": true,\r\n  \"exp\": 1664371780,\r\n  \"authorities\": [\r\n    \"p1\"\r\n  ],\r\n  \"jti\": \"f0a3cdeb-399d-48f0-8804-eca638ad8857\",\r\n  \"client_id\": \"c1\"\r\n}\r\n```\r\n\r\n#### **2.4.4 测试资源服务校验令牌**\r\n\r\n拿到了jwt令牌下一步就要携带令牌去访问资源服务中的资源，本项目各个微服务就是资源服务，比如：内容管理服务，客户端申请到jwt令牌，携带jwt去内容管理服务查询课程信息，此时内容管理服务要对jwt进行校验，只有jwt合法才可以继续访问。如下图：\r\n\r\n![image-20230705223951357](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223951357.png) \r\n\r\n1、在内容管理服务的content-api工程中添加依赖\r\n\r\n```xml\r\n<!--认证相关-->\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-security</artifactId>\r\n</dependency>\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-oauth2</artifactId>\r\n</dependency>\r\n```\r\n\r\n2、在内容管理服务的content-api工程中添加TokenConfig\r\n\r\n```java\r\n\r\n@Configuration\r\npublic class TokenConfig {\r\n\r\n    //jwt签名密钥,与认证服务保持一致\r\n    private String SIGNING_KEY = \"mq123\";\r\n\r\n    @Bean\r\n    public TokenStore tokenStore() {\r\n        //JWT令牌存储方案\r\n        return new JwtTokenStore(accessTokenConverter());\r\n    }\r\n\r\n    @Bean\r\n    public JwtAccessTokenConverter accessTokenConverter() {\r\n        JwtAccessTokenConverter converter = new JwtAccessTokenConverter();\r\n        converter.setSigningKey(SIGNING_KEY);\r\n        return converter;\r\n    }\r\n\r\n   /* @Bean\r\n    public TokenStore tokenStore() {\r\n        //使用内存存储令牌（普通令牌）\r\n        return new InMemoryTokenStore();\r\n    }*/\r\n}\r\n```\r\n\r\n3、添加资源服务配置\r\n\r\n```java\r\n\r\n@Configuration\r\n@EnableResourceServer\r\n@EnableGlobalMethodSecurity(securedEnabled = true,prePostEnabled = true)\r\npublic class ResouceServerConfig extends ResourceServerConfigurerAdapter {\r\n\r\n\r\n    //资源服务标识\r\n    public static final String RESOURCE_ID = \"xuecheng-plus\";\r\n\r\n    @Autowired\r\n    TokenStore tokenStore;\r\n\r\n    @Override\r\n    public void configure(ResourceServerSecurityConfigurer resources) {\r\n        resources.resourceId(RESOURCE_ID)//资源 id\r\n                .tokenStore(tokenStore)\r\n                .stateless(true);\r\n    }\r\n\r\n    @Override\r\n    public void configure(HttpSecurity http) throws Exception {\r\n        http.csrf().disable()\r\n                .authorizeRequests()\r\n                .antMatchers(\"/r/**\",\"/course/**\").authenticated()//所有/r/**的请求必须认证通过\r\n                .anyRequest().permitAll()\r\n        ;\r\n    }\r\n\r\n}\r\n```\r\n\r\n根据配置可知/course/**开头的接口需要认证通过。\r\n\r\n重启内容管理服务\r\n\r\n使用httpclient测试：\r\n\r\n1、访问根据课程id查询课程接口\r\n\r\n```http\r\nGET http://localhost:63040/content/course/2\r\n```\r\n\r\n返回：\r\n\r\n```json\r\n\r\n{\r\n  \"error\": \"unauthorized\",\r\n  \"error_description\": \"Full authentication is required to access this resource\"\r\n}\r\n```\r\n\r\n从返回信息可知当前没有认证。\r\n\r\n下边携带JWT令牌访问接口：\r\n\r\n1、申请jwt令牌\r\n\r\n采用密码模式申请令牌。\r\n\r\n2、携带jwt令牌访问资源服务地址\r\n\r\n```http\r\n### 携带token访问资源服务\r\nGET http://localhost:63040/content/course/2\r\nAuthorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJ6aGFuZ3NhbiIsInNjb3BlIjpbImFsbCJdLCJleHAiOjE2NjQzMzM0OTgsImF1dGhvcml0aWVzIjpbInAxIl0sImp0aSI6IjhhM2M2OTk1LWU1ZGEtNDQ1Yy05ZDAyLTEwNDFlYzk3NTkwOSIsImNsaWVudF9pZCI6ImMxIn0.73eNDxTX5ifttGCjwc7xrd-Sbp_mCfcIerI3lGetZto\r\n```\r\n\r\n如果携带jwt令牌且jwt正确则正常访问资源服务的内容。\r\n\r\n如果不正确则报令牌无效的错误：\r\n\r\n```json\r\n{\r\n  \"error\": \"invalid_token\",\r\n  \"error_description\": \"Cannot convert access token to JSON\"\r\n}\r\n```\r\n\r\n#### **2.4.5 测试获取用户身份**\r\n\r\njwt令牌中记录了用户身份信息，当客户端携带jwt访问资源服务，资源服务验签通过后将前两部分的内容还原即可取出用户的身份信息，并将用户身份信息放在了SecurityContextHolder上下文，SecurityContext与当前线程进行绑定，方便获取用户身份。\r\n\r\n还以查询课程接口为例，进入查询课程接口的代码中，添加获取用户身份的代码\r\n\r\n```java\r\n\r\n@ApiOperation(\"根据课程id查询课程基础信息\")\r\n@GetMapping(\"/course/{courseId}\")\r\npublic CourseBaseInfoDto getCourseBaseById(@PathVariable(\"courseId\") Long courseId){\r\n    //取出当前用户身份\r\n    Object principal = SecurityContextHolder.getContext().getAuthentication().getPrincipal();\r\n    System.out.println(principal);\r\n\r\n    return courseBaseInfoService.getCourseBaseInfo(courseId);\r\n}\r\n```\r\n\r\n测试时需要注意：\r\n\r\n1、首先在资源服务配置中指定安全拦截机制 `/course/`开头的请求需要认证，即请求`/course/{courseId}`接口需要携带jwt令牌且签证通过。\r\n\r\n2、认证服务生成jwt令牌将用户身份信息写入令牌，认证服务哪里获取用户身份。\r\n\r\n目前还是将用户信息硬编码并暂放在内存中，如下：\r\n\r\n```java\r\n\r\n@Bean\r\npublic UserDetailsService userDetailsService() {\r\n    //这里配置用户信息,这里暂时使用这种方式将用户存储在内存中\r\n    InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager();\r\n    manager.createUser(User.withUsername(\"zhangsan\").password(\"123\").authorities(\"p1\").build());\r\n    manager.createUser(User.withUsername(\"lisi\").password(\"456\").authorities(\"p2\").build());\r\n    return manager;\r\n}\r\n```\r\n\r\n3、我们在使用密码模式生成jwt令牌时用的是zhangsan的信息，所以jwt令牌中存储了zhangsan的信息，那么在资源服务中应该取出zhangsan的信息才对。\r\n\r\n清楚了以上内容，下边重启内容管理服务，跟踪取到的用户身份是否正确。\r\n\r\n \r\n\r\n### **2.5 网关认证**\r\n\r\n#### **2.5.1 技术方案**\r\n\r\n到目前为止，测试通过了认证服务颁发jwt令牌，客户端携带jwt访问资源服务，资源服务对jwt的合法性进行验证。如下图：\r\n\r\n![](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705223951357.png) \r\n\r\n仔细观察此图，遗漏了本项目架构中非常重要的组件：网关，加上网关并完善后如下图所示：\r\n\r\n![image-20230705224031161](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224031161.png) \r\n\r\n> 所有访问微服务的请求都要经过网关，在网关进行用户身份的认证可以将很多非法的请求拦截到微服务以外，这叫做网关认证。\r\n\r\n下边需要明确网关的职责：\r\n\r\n1、网站白名单维护\r\n\r\n针对不用认证的URL全部放行。\r\n\r\n2、校验jwt的合法性。\r\n\r\n除了白名单剩下的就是需要认证的请求，网关需要验证jwt的合法性，jwt合法则说明用户身份合法，否则说明身份不合法则拒绝继续访问。\r\n\r\n \r\n\r\n网关负责授权吗？\r\n\r\n网关不负责授权，对请求的授权操作在各个微服务进行，因为微服务最清楚用户有哪些权限访问哪些接口。\r\n\r\n \r\n\r\n#### **2.5.2 实现网关认证**\r\n\r\n下边实现网关认证，实现以下职责：\r\n\r\n1、网站白名单维护\r\n\r\n针对不用认证的URL全部放行。\r\n\r\n2、校验jwt的合法性。\r\n\r\n除了白名单剩下的就是需要认证的请求，网关需要验证jwt的合法性，jwt合法则说明用户身份合法，否则说明身份不合法则拒绝继续访问。\r\n\r\n \r\n\r\n1、在网关工程添加依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-security</artifactId>\r\n</dependency>\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-oauth2</artifactId>\r\n</dependency>\r\n<dependency>\r\n    <groupId>org.projectlombok</groupId>\r\n    <artifactId>lombok</artifactId>\r\n</dependency>\r\n<dependency>\r\n    <groupId>com.alibaba</groupId>\r\n    <artifactId>fastjson</artifactId>\r\n</dependency>\r\n```\r\n\r\n2、拷贝课程资料下网关认证配置类到网关工程的config包下。\r\n\r\n3、配置白名单文件`security-whitelist.properties`\r\n\r\n内容如下（持续补充）\r\n\r\n```properties\r\n/**=临时全部放行\r\n/auth/**=认证地址\r\n/content/open/**=内容管理公开访问接口\r\n/media/open/**=媒资管理公开访问接口\r\n```\r\n\r\n重启网关工程，进行测试\r\n\r\n1、申请令牌\r\n\r\n2、通过网关访问资源服务\r\n\r\n这里访问内容管理服务\r\n\r\n```http\r\n### 通过网关访问资源服务\r\nGET http://localhost:63010/content/course/2\r\nAuthorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOlsicmVzMSJdLCJ1c2VyX25hbWUiOiJ6aGFuZ3NhbiIsInNjb3BlIjpbImFsbCJdLCJleHAiOjE2NjQzNjIzMTAsImF1dGhvcml0aWVzIjpbInAxIl0sImp0aSI6Ijc2OTkwMGNiLWM1ZjItNGRiNC1hZWJmLWY1MzgxZDQxZWMyZCIsImNsaWVudF9pZCI6ImMxIn0.lOITjUgYg2HCh5mDPK9EvJJqz-tIupKVfmP8yWJQIKs\r\n```\r\n\r\n当token正确时可以正常访问资源服务，token验证失败返回token无效：\r\n\r\n```json\r\n{\r\n  \"errMessage\": \"认证令牌无效\"\r\n}\r\n```\r\n\r\n注意：网关鉴权功能调试通过后，由于目前还没有开发认证功能，前端请求网关的URL不在白名单中间时会“没有认证”的错误，暂时在白名单中添加 全部放行配置，待认证功能开发完成再屏蔽全部放行配置，\r\n\r\n![image-20230705224115205](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224115205.png) \r\n\r\n \r\n\r\n \r\n\r\n## **3 用户认证**\r\n\r\n### **3.1 需求分析**\r\n\r\n至此我们了解了使用Spring Security进行认证授权的过程，本节实现用户认证功能。\r\n\r\n目前各大网站的认证方式非常丰富：账号密码认证、手机验证码认证、扫码登录等。\r\n\r\n本项目也要支持多种认证试。\r\n\r\n \r\n\r\n### **3.2 连接用户中心数据库**\r\n\r\n#### **3.2.1 连接数据库认证**\r\n\r\n基于的认证流程在研究Spring Security过程中已经测试通过，到目前为止用户认证流程如下：\r\n\r\n![image-20230705224147514](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224147514.png) \r\n\r\n认证所需要的用户信息存储在用户中心数据库，现在需要将认证服务连接数据库查询用户信息。\r\n\r\n在研究Spring Security的过程中是将用户信息硬编码，如下：\r\n\r\n```java\r\n\r\n@Bean\r\npublic UserDetailsService userDetailsService() {\r\n    //这里配置用户信息,这里暂时使用这种方式将用户存储在内存中\r\n    InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager();\r\n    manager.createUser(User.withUsername(\"zhangsan\").password(\"123\").authorities(\"p1\").build());\r\n    manager.createUser(User.withUsername(\"lisi\").password(\"456\").authorities(\"p2\").build());\r\n    return manager;\r\n}\r\n```\r\n\r\n我们要认证服务中连接用户中心数据库查询用户信息。\r\n\r\n如何使用Spring Security连接数据库认证吗？\r\n\r\n前边学习Spring Security工作原理时有一张执行流程图，如下图：\r\n\r\n![image-20230705224242929](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224242929.png)\r\n\r\n用户提交账号和密码由DaoAuthenticationProvider调用UserDetailsService的`loadUserByUsername()`方法获取UserDetails用户信息。\r\n\r\n查询DaoAuthenticationProvider的源代码如下：\r\n\r\n![image-20230705224313517](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224313517.png) \r\n\r\nUserDetailsService是一个接口，如下：\r\n\r\n```java\r\npackage org.springframework.security.core.userdetails;\r\n\r\npublic interface UserDetailsService {\r\n    UserDetails loadUserByUsername(String var1) throws UsernameNotFoundException;\r\n}\r\n```\r\n\r\nUserDetails是用户信息接口\r\n\r\n```java\r\n\r\npublic interface UserDetails extends Serializable {\r\n    Collection<? extends GrantedAuthority> getAuthorities();\r\n\r\n    String getPassword();\r\n\r\n    String getUsername();\r\n\r\n    boolean isAccountNonExpired();\r\n\r\n    boolean isAccountNonLocked();\r\n\r\n    boolean isCredentialsNonExpired();\r\n\r\n    boolean isEnabled();\r\n}\r\n```\r\n\r\n我们只要实现UserDetailsService 接口查询数据库得到用户信息返回UserDetails 类型的用户信息即可,框架调用`loadUserByUsername()`方法拿到用户信息之后是如何执行的，见下图：\r\n\r\n![image-20230705224342435](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224342435.png) \r\n\r\n首先屏蔽原来定义的UserDetailsService。\r\n\r\n```java\r\n\r\n    //配置用户信息服务\r\n//    @Bean\r\n//    public UserDetailsService userDetailsService() {\r\n//        //这里配置用户信息,这里暂时使用这种方式将用户存储在内存中\r\n//        InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager();\r\n//        manager.createUser(User.withUsername(\"zhangsan\").password(\"123\").authorities(\"p1\").build());\r\n//        manager.createUser(User.withUsername(\"lisi\").password(\"456\").authorities(\"p2\").build());\r\n//        return manager;\r\n//    }\r\n```\r\n\r\n下边自定义UserDetailsService\r\n\r\n```java\r\n\r\n@Service\r\npublic class UserServiceImpl implements UserDetailsService {\r\n\r\n    @Autowired\r\n    XcUserMapper xcUserMapper;\r\n\r\n    /**\r\n     * @description 根据账号查询用户信息\r\n     * @param s  账号\r\n     * @return org.springframework.security.core.userdetails.UserDetails\r\n     * @author Mr.M\r\n     * @date 2022/9/28 18:30\r\n    */\r\n    @Override\r\n    public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException {\r\n\r\n        XcUser user = xcUserMapper.selectOne(new LambdaQueryWrapper<XcUser>().eq(XcUser::getUsername, s));\r\n        if(user==null){\r\n            //返回空表示用户不存在\r\n            return null;\r\n        }\r\n        //取出数据库存储的正确密码\r\n        String password  =user.getPassword();\r\n        //用户权限,如果不加报Cannot pass a null GrantedAuthority collection\r\n        String[] authorities= {\"test\"};\r\n        //创建UserDetails对象,权限信息待实现授权功能时再向UserDetail中加入\r\n        UserDetails userDetails = User.withUsername(user.getUsername()).password(password).authorities(authorities).build();\r\n\r\n        return userDetails;\r\n    }\r\n\r\n\r\n}\r\n```\r\n\r\n数据库中的密码加过密的，用户输入的密码是明文，我们需要修改密码格式器PasswordEncoder，原来使用的是NoOpPasswordEncoder，它是通过明文方式比较密码，现在我们修改为BCryptPasswordEncoder，它是将用户输入的密码编码为BCrypt格式与数据库中的密码进行比对。\r\n\r\n如下：\r\n\r\n```java\r\n\r\n    @Bean\r\n    public PasswordEncoder passwordEncoder() {\r\n//        //密码为明文方式\r\n//        return NoOpPasswordEncoder.getInstance();\r\n        return new BCryptPasswordEncoder();\r\n    }\r\n```\r\n\r\n我们通过测试代码测试BCryptPasswordEncoder，如下：\r\n\r\n```java\r\n\r\npublic static void main(String[] args) {\r\n    String password = \"111111\";\r\n    PasswordEncoder passwordEncoder = new BCryptPasswordEncoder();\r\n    for(int i=0;i<10;i++) {\r\n        //每个计算出的Hash值都不一样\r\n        String hashPass = passwordEncoder.encode(password);\r\n        System.out.println(hashPass);\r\n        //虽然每次计算的密码Hash值不一样但是校验是通过的\r\n        boolean f = passwordEncoder.matches(password, hashPass);\r\n        System.out.println(f);\r\n    }\r\n}\r\n```\r\n\r\n修改数据库中的密码为Bcrypt格式，并且记录明文密码，稍后申请令牌时需要。\r\n\r\n由于修改密码编码方式还需要将客户端的密钥更改为Bcrypt格式.\r\n\r\n```java\r\n\r\n @Override\r\n  public void configure(ClientDetailsServiceConfigurer clients)\r\n          throws Exception {\r\n        clients.inMemory()// 使用in-memory存储\r\n                .withClient(\"XcWebApp\")// client_id\r\n//                .secret(\"secret\")//客户端密钥\r\n                .secret(new BCryptPasswordEncoder().encode(\"XcWebApp\"))//客户端密钥\r\n                .resourceIds(\"xuecheng-plus\")//资源列表\r\n                .authorizedGrantTypes(\"authorization_code\", \"password\",\"client_credentials\",\"implicit\",\"refresh_token\")// 该client允许的授权类型authorization_code,password,refresh_token,implicit,client_credentials\r\n                .scopes(\"all\")// 允许的授权范围\r\n                .autoApprove(false)//false跳转到授权页面\r\n                //客户端接收授权码的重定向地址\r\n                .redirectUris(\"http://www.51xuecheng.cn\")\r\n   ;\r\n  }\r\n```\r\n\r\n现在重启认证服务。\r\n\r\n下边使用httpclient进行测试：\r\n\r\n```http\r\n### 密码模式\r\nPOST {{auth_host}}/oauth/token?client_id=XcWebApp&client_secret=XcWebApp&grant_type=password&username=stu1&password=111111\r\n```\r\n\r\n输入正确的账号和密码，申请令牌成功。\r\n\r\n输入错误的密码，报错：\r\n\r\n```json\r\n{\r\n  \"error\": \"invalid_grant\",\r\n  \"error_description\": \"用户名或密码错误\"\r\n}\r\n```\r\n\r\n输入错误的账号，报错：\r\n\r\n```json\r\n{\r\n  \"error\": \"unauthorized\",\r\n  \"error_description\": \"UserDetailsService returned null, which is an interface contract violation\"\r\n}\r\n```\r\n\r\n#### **3.2.2 扩展用户身份信息**\r\n\r\n用户表中存储了用户的账号、手机号、email，昵称、qq等信息，UserDetails接口只返回了username、密码等信息，如下：\r\n\r\n```java\r\n\r\npublic interface UserDetails extends Serializable {\r\n    Collection<? extends GrantedAuthority> getAuthorities();\r\n\r\n    String getPassword();\r\n\r\n    String getUsername();\r\n\r\n    boolean isAccountNonExpired();\r\n\r\n    boolean isAccountNonLocked();\r\n\r\n    boolean isCredentialsNonExpired();\r\n\r\n    boolean isEnabled();\r\n}\r\n```\r\n\r\n我们需要扩展用户身份的信息，在jwt令牌中存储用户的昵称、头像、qq等信息。\r\n\r\n如何扩展Spring Security的用户身份信息呢？\r\n\r\n在认证阶段DaoAuthenticationProvider会调用UserDetailService查询用户的信息，这里是可以获取到齐全的用户信息的。由于JWT令牌中用户身份信息来源于UserDetails，UserDetails中仅定义了username为用户的身份信息，这里有两个思路：第一是可以扩展UserDetails，使之包括更多的自定义属性，第二也可以扩展username的内容 ，比如存入json数据内容作为username的内容。相比较而言，方案二比较简单还不用破坏UserDetails的结构，我们采用方案二。\r\n\r\n修改UserServiceImpl如下：\r\n\r\n```java\r\n\r\n@Service\r\npublic class UserServiceImpl implements UserDetailsService {\r\n\r\n    @Autowired\r\n    XcUserMapper xcUserMapper;\r\n\r\n    /**\r\n     * @description 根据账号查询用户信息\r\n     * @param s  账号\r\n     * @return org.springframework.security.core.userdetails.UserDetails\r\n     * @author Mr.M\r\n     * @date 2022/9/28 18:30\r\n    */\r\n    @Override\r\n    public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException {\r\n\r\n        XcUser user = xcUserMapper.selectOne(new LambdaQueryWrapper<XcUser>().eq(XcUser::getUsername, s));\r\n        if(user==null){\r\n            //返回空表示用户不存在\r\n            return null;\r\n        }\r\n\r\n        //取出数据库存储的正确密码\r\n        String password  =user.getPassword();\r\n        //用户权限,如果不加报Cannot pass a null GrantedAuthority collection\r\n        String[] authorities = {\"p1\"};\r\n       //为了安全在令牌中不放密码\r\n        user.setPassword(null);\r\n        //将user对象转json\r\n        String userString = JSON.toJSONString(user);\r\n        //创建UserDetails对象\r\n        UserDetails userDetails = User.withUsername(userString).password(password).authorities(authorities).build();\r\n\r\n        return userDetails;\r\n    }\r\n\r\n\r\n}\r\n```\r\n\r\n重启认证服务，重新生成令牌，生成成功。\r\n\r\n我们可以使用`check_token`查询jwt的内容\r\n\r\n```http\r\n###校验jwt令牌\r\nPOST {{auth_host}}/oauth/check_token?token=\r\n```\r\n\r\n响应示例如下，\r\n\r\n```json\r\n\r\n{\r\n  \"aud\": [\r\n    \"res1\"\r\n  ],\r\n  \"user_name\": \"{\\\"birthday\\\":\\\"2022-09-28T19:28:46\\\",\\\"createTime\\\":\\\"2022-09-28T08:32:03\\\",\\\"id\\\":\\\"50\\\",\\\"name\\\":\\\"学生1\\\",\\\"nickname\\\":\\\"大水牛\\\",\\\"password\\\":\\\"$2a$10$0pt7WlfTbnPDTcWtp/.2Mu5CTXvohnNQhR628qq4RoKSc0dGAdEgm\\\",\\\"sex\\\":\\\"1\\\",\\\"status\\\":\\\"1\\\",\\\"username\\\":\\\"stu1\\\",\\\"userpic\\\":\\\"http://file.51xuecheng.cn/dddf\\\",\\\"utype\\\":\\\"101001\\\"}\",\r\n  \"scope\": [\r\n    \"all\"\r\n  ],\r\n  \"active\": true,\r\n  \"exp\": 1664372184,\r\n  \"authorities\": [\r\n    \"p1\"\r\n  ],\r\n  \"jti\": \"73da9f7b-bd8c-45ac-9add-46b711d11fb8\",\r\n  \"client_id\": \"c1\"\r\n}\r\n```\r\n\r\n`user_name`存储了用户信息的json格式，在资源服务中就可以取出该json格式的内容转为用户对象去使用。\r\n\r\n#### **3.2.3 资源服务获取用户身份**\r\n\r\n下边编写一个工具类在各个微服务中去使用，获取当前登录用户的对象。\r\n\r\n在`content-api`中定义此类：\r\n\r\n```java\r\n/**\r\n * @description 获取当前用户身份工具类\r\n */\r\n@Slf4j\r\npublic class SecurityUtil {\r\n\r\n    public static XcUser getUser() {\r\n        try {\r\n            Object principalObj = SecurityContextHolder.getContext().getAuthentication().getPrincipal();\r\n            if (principalObj instanceof String) {\r\n                //取出用户身份信息\r\n                String principal = principalObj.toString();\r\n                //将json转成对象\r\n                XcUser user = JSON.parseObject(principal, XcUser.class);\r\n                return user;\r\n            }\r\n        } catch (Exception e) {\r\n            log.error(\"获取当前登录用户身份出错:{}\", e.getMessage());\r\n            e.printStackTrace();\r\n        }\r\n\r\n        return null;\r\n    }\r\n\r\n\r\n    @Data\r\n    public static class XcUser implements Serializable {\r\n\r\n        private static final long serialVersionUID = 1L;\r\n\r\n        private String id;\r\n\r\n        private String username;\r\n\r\n        private String password;\r\n\r\n        private String salt;\r\n\r\n        private String name;\r\n        private String nickname;\r\n        private String wxUnionid;\r\n        private String companyId;\r\n        /**\r\n         * 头像\r\n         */\r\n        private String userpic;\r\n\r\n        private String utype;\r\n\r\n        private LocalDateTime birthday;\r\n\r\n        private String sex;\r\n\r\n        private String email;\r\n\r\n        private String cellphone;\r\n\r\n        private String qq;\r\n\r\n        /**\r\n         * 用户状态\r\n         */\r\n        private String status;\r\n\r\n        private LocalDateTime createTime;\r\n\r\n        private LocalDateTime updateTime;\r\n\r\n\r\n    }\r\n\r\n\r\n}\r\n```\r\n\r\n下边在内容管理服务中测试此工具类，以查询课程信息接口为例：\r\n\r\n```java\r\n@ApiOperation(\"根据课程id查询课程基础信息\")\r\n@GetMapping(\"/course/{courseId}\")\r\npublic CourseBaseInfoDto getCourseBaseById(@PathVariable(\"courseId\") Long courseId){\r\n    //取出当前用户身份\r\n//    Object principal = SecurityContextHolder.getContext().getAuthentication().getPrincipal();\r\n   SecurityUtil.XcUser user = SecurityUtil.getUser();\r\n    System.out.println(user);\r\n\r\n    return courseBaseInfoService.getCourseBaseInfo(courseId);\r\n}\r\n```\r\n\r\n重启内容管理服务：\r\n\r\n1、启动认证服务、网关、内容管理服务\r\n\r\n2、生成新的令牌\r\n\r\n3、携带令牌访问内容管理服务的查询课程接口\r\n\r\n![image-20230705224419107](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224419107.png) \r\n\r\n \r\n\r\n### **3.3 支持认证方式多样**\r\n\r\n#### **3.3.1 统一认证入口**\r\n\r\n \r\n\r\n目前各大网站的认证方式非常丰富：账号密码认证、手机验证码认证、扫码登录等。基于当前研究的Spring Security认证流程如何支持多样化的认证方式呢？\r\n\r\n1、支持账号和密码认证\r\n\r\n采用OAuth2协议的密码模式即可实现。\r\n\r\n2、支持手机号加验证码认证\r\n\r\n用户认证提交的是手机号和验证码，并不是账号和密码。\r\n\r\n3、微信扫码认证\r\n\r\n基于OAuth2协议与微信交互，学成在线网站向微信服务器申请到一个令牌，然后携带令牌去微信查询用户信息，查询成功则用户在学成在线项目认证通过。\r\n\r\n \r\n\r\n目前我们测试通过OAuth2的密码模式，用户认证会提交账号和密码，由DaoAuthenticationProvider调用UserDetailsService的`loadUserByUsername()`方法获取UserDetails用户信息。\r\n\r\n在前边我们自定义了UserDetailsService接口实现类，通过`loadUserByUsername()`方法根据账号查询用户信息。\r\n\r\n而不同的认证方式提交的数据不一样，比如：手机加验证码方式会提交手机号和验证码，账号密码方式会提交账号、密码、验证码。\r\n\r\n我们可以在`loadUserByUsername()`方法上作文章，将用户原来提交的账号数据改为提交json数据，json数据可以扩展不同认证方式所提交的各种参数。\r\n\r\n首先创建一个DTO类表示认证的参数：\r\n\r\n```java\r\n\r\n\r\n/**\r\n * @description 认证用户请求参数\r\n */\r\n@Data\r\npublic class AuthParamsDto {\r\n\r\n    private String username; //用户名\r\n    private String password; //域  用于扩展\r\n    private String cellphone;//手机号\r\n    private String checkcode;//验证码\r\n    private String checkcodekey;//验证码key\r\n    private String authType; // 认证的类型   password:用户名密码模式类型    sms:短信模式类型\r\n    private Map<String, Object> payload = new HashMap<>();//附加数据，作为扩展，不同认证类型可拥有不同的附加数据。如认证类型为短信时包含smsKey : sms:3d21042d054548b08477142bbca95cfa; 所有情况下都包含clientId\r\n\r\n\r\n}\r\n```\r\n\r\n此时`loadUserByUsername()`方法可以修改如下：\r\n\r\n```java\r\n\r\n\r\n/**\r\n * @description 自定义UserDetailsService用来对接Spring Security\r\n */\r\n@Slf4j\r\n@Service\r\npublic class UserServiceImpl implements UserDetailsService {\r\n\r\n    @Autowired\r\n    XcUserMapper xcUserMapper;\r\n\r\n    /**\r\n     * @description 查询用户信息组成用户身份信息\r\n     * @param s  AuthParamsDto类型的json数据\r\n     * @return org.springframework.security.core.userdetails.UserDetails\r\n     * @author Mr.M\r\n     * @date 2022/9/28 18:30\r\n    */\r\n    @Override\r\n    public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException {\r\n\r\n        AuthParamsDto authParamsDto = null;\r\n        try {\r\n            //将认证参数转为AuthParamsDto类型\r\n            authParamsDto = JSON.parseObject(s, AuthParamsDto.class);\r\n        } catch (Exception e) {\r\n            log.info(\"认证请求不符合项目要求:{}\",s);\r\n            throw new RuntimeException(\"认证请求数据格式不对\");\r\n        }\r\n        //账号\r\n        String username = authParamsDto.getUsername();\r\n        XcUser user = xcUserMapper.selectOne(new LambdaQueryWrapper<XcUser>().eq(XcUser::getUsername, username));\r\n        if(user==null){\r\n            //返回空表示用户不存在\r\n            return null;\r\n        }\r\n        //取出数据库存储的正确密码\r\n        String password  =user.getPassword();\r\n        //用户权限,如果不加报Cannot pass a null GrantedAuthority collection\r\n        String[] authorities = {\"p1\"};\r\n        //将user对象转json\r\n        String userString = JSON.toJSONString(user);\r\n        //创建UserDetails对象\r\n        UserDetails userDetails = User.withUsername(userString).password(password).authorities(authorities).build();\r\n\r\n        return userDetails;\r\n    }\r\n\r\n}\r\n```\r\n\r\n原来的DaoAuthenticationProvider 会进行密码校验，现在重新定义DaoAuthenticationProviderCustom类，重写类的additionalAuthenticationChecks方法。\r\n\r\n```java\r\n\r\npackage com.xuecheng.auth.config;\r\n\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.security.authentication.BadCredentialsException;\r\nimport org.springframework.security.authentication.UsernamePasswordAuthenticationToken;\r\nimport org.springframework.security.authentication.dao.DaoAuthenticationProvider;\r\nimport org.springframework.security.core.AuthenticationException;\r\nimport org.springframework.security.core.userdetails.UserDetails;\r\nimport org.springframework.security.core.userdetails.UserDetailsService;\r\nimport org.springframework.stereotype.Component;\r\n\r\n/**\r\n * @description 自定义DaoAuthenticationProvider\r\n */\r\n@Slf4j\r\n@Component\r\npublic class DaoAuthenticationProviderCustom extends DaoAuthenticationProvider {\r\n\r\n\r\n @Autowired\r\n public void setUserDetailsService(UserDetailsService userDetailsService) {\r\n  super.setUserDetailsService(userDetailsService);\r\n }\r\n\r\n\r\n //屏蔽密码对比\r\n protected void additionalAuthenticationChecks(UserDetails userDetails, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException {\r\n\r\n\r\n }\r\n\r\n}\r\n```\r\n\r\n修改WebSecurityConfig类指定daoAuthenticationProviderCustom\r\n\r\n```java\r\n\r\n@Autowired\r\nDaoAuthenticationProviderCustom daoAuthenticationProviderCustom;\r\n\r\n\r\n@Override\r\nprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\r\n    auth.authenticationProvider(daoAuthenticationProviderCustom);\r\n}\r\n```\r\n\r\n此时可以重启认证服务，测试申请令牌接口，传入的账号信息改为json数据，如下：\r\n\r\n```http\r\n################扩展认证请求参数后######################\r\n###密码模式\r\nPOST {{auth_host}}/auth/oauth/token?client_id=XcWebApp&client_secret=XcWebApp&grant_type=password&username={\"username\":\"stu1\",\"authType\":\"password\",\"password\":\"111111\"}\r\n```\r\n\r\n经过测试发现`loadUserByUsername()`方法可以正常接收到认证请求中的json数据。\r\n\r\n有了这些认证参数我们可以定义一个认证Service接口去进行各种方式的认证。\r\n\r\n定义用户信息，为了扩展性让它继承XcUser\r\n\r\n```java\r\n@Data\r\npublic class XcUserExt extends XcUser {\r\n}\r\n```\r\n\r\n定义认证Service 接口\r\n\r\n```java\r\n\r\n/**\r\n * @description 认证service\r\n */\r\npublic interface AuthService {\r\n\r\n   /**\r\n    * @description 认证方法\r\n    * @param authParamsDto 认证参数\r\n    * @return com.xuecheng.ucenter.model.po.XcUser 用户信息\r\n   */\r\n   XcUserExt execute(AuthParamsDto authParamsDto);\r\n\r\n}\r\n```\r\n\r\nloadUserByUsername()修改如下：\r\n\r\n```java\r\n\r\n@Slf4j\r\n@Service\r\npublic class UserServiceImpl implements UserDetailsService {\r\n\r\n    @Autowired\r\n    XcUserMapper xcUserMapper;\r\n\r\n    @Autowired\r\n    ApplicationContext applicationContext;\r\n\r\n\r\n    /**\r\n     * @description 查询用户信息组成用户身份信息\r\n     * @param s  AuthParamsDto类型的json数据\r\n     * @return org.springframework.security.core.userdetails.UserDetails\r\n    */\r\n    @Override\r\n    public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException {\r\n\r\n        AuthParamsDto authParamsDto = null;\r\n        try {\r\n            //将认证参数转为AuthParamsDto类型\r\n            authParamsDto = JSON.parseObject(s, AuthParamsDto.class);\r\n        } catch (Exception e) {\r\n            log.info(\"认证请求不符合项目要求:{}\",s);\r\n            throw new RuntimeException(\"认证请求数据格式不对\");\r\n        }\r\n        //开始认证\r\n        authService.execute(authParamsDto);\r\n        .....\r\n```\r\n\r\n到此我们基于Spring Security认证流程修改为如下：\r\n\r\n![image-20230705224445890](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224445890.png) \r\n\r\n \r\n\r\n#### **3.3.2 实现账号密码认证**\r\n\r\n上节定义了AuthService认证接口，下边实现该接口实现账号密码认证\r\n\r\n```java\r\n\r\n\r\n/**\r\n * @description 账号密码认证\r\n */\r\n @Service(\"password_authservice\")\r\npublic class PasswordAuthServiceImpl implements AuthService {\r\n\r\n @Autowired\r\n XcUserMapper xcUserMapper;\r\n\r\n @Autowired\r\n PasswordEncoder passwordEncoder;\r\n\r\n\r\n @Override\r\n public XcUserExt execute(AuthParamsDto authParamsDto) {\r\n\r\n  //账号\r\n  String username = authParamsDto.getUsername();\r\n  XcUser user = xcUserMapper.selectOne(new LambdaQueryWrapper<XcUser>().eq(XcUser::getUsername, username));\r\n  if(user==null){\r\n   //返回空表示用户不存在\r\n   throw new RuntimeException(\"账号不存在\");\r\n  }\r\n  XcUserExt xcUserExt = new XcUserExt();\r\n  BeanUtils.copyProperties(user,xcUserExt);\r\n  //校验密码\r\n  //取出数据库存储的正确密码\r\n  String passwordDb  =user.getPassword();\r\n  String passwordForm = authParamsDto.getPassword();\r\n  boolean matches = passwordEncoder.matches(passwordForm, passwordDb);\r\n  if(!matches){\r\n   throw new RuntimeException(\"账号或密码错误\");\r\n  }\r\n  return xcUserExt;\r\n }\r\n}\r\n```\r\n\r\n修改UserServiceImpl类，根据认证方式使用不同的认证bean\r\n\r\n```java\r\n/**\r\n * @description 自定义UserDetailsService用来对接Spring Security\r\n */\r\n@Slf4j\r\n@Service\r\npublic class UserServiceImpl implements UserDetailsService {\r\n\r\n    @Autowired\r\n    XcUserMapper xcUserMapper;\r\n\r\n    @Autowired\r\n    ApplicationContext applicationContext;\r\n\r\n//    @Autowired\r\n//    AuthService authService;\r\n\r\n    /**\r\n     * @description 查询用户信息组成用户身份信息\r\n     * @param s  AuthParamsDto类型的json数据\r\n     * @return org.springframework.security.core.userdetails.UserDetails\r\n    */\r\n    @Override\r\n    public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException {\r\n\r\n        AuthParamsDto authParamsDto = null;\r\n        try {\r\n            //将认证参数转为AuthParamsDto类型\r\n            authParamsDto = JSON.parseObject(s, AuthParamsDto.class);\r\n        } catch (Exception e) {\r\n            log.info(\"认证请求不符合项目要求:{}\",s);\r\n            throw new RuntimeException(\"认证请求数据格式不对\");\r\n        }\r\n\r\n        //认证方法\r\n        String authType = authParamsDto.getAuthType();\r\n        AuthService authService =  applicationContext.getBean(authType + \"_authservice\",AuthService.class);\r\n        XcUserExt user = authService.execute(authParamsDto);\r\n\r\n        return getUserPrincipal(user);\r\n    }\r\n\r\n\r\n    /**\r\n     * @description 查询用户信息\r\n     * @param user  用户id，主键\r\n     * @return com.xuecheng.ucenter.model.po.XcUser 用户信息\r\n    */\r\n    public UserDetails getUserPrincipal(XcUserExt user){\r\n        //用户权限,如果不加报Cannot pass a null GrantedAuthority collection\r\n        String[] authorities = {\"p1\"};\r\n        String password = user.getPassword();\r\n        //为了安全在令牌中不放密码\r\n        user.setPassword(null);\r\n        //将user对象转json\r\n        String userString = JSON.toJSONString(user);\r\n        //创建UserDetails对象\r\n        UserDetails userDetails = User.withUsername(userString).password(password ).authorities(authorities).build();\r\n        return userDetails;\r\n    }\r\n\r\n}\r\n```\r\n\r\n重启认证服务，测试申请令牌接口。\r\n\r\n1、测试账号和密码都正确的情况是否可以申请令牌成功。\r\n\r\n2、测试密码错误的情况。\r\n\r\n3、测试账号不存在情况。\r\n\r\n \r\n\r\n### **3.4 验证码服务**\r\n\r\n#### **3.4.1 创建验证码服务工程**\r\n\r\n在认证时一般都需要输入验证码，验证码有什么用？\r\n\r\n验证码可以防止恶性攻击，比如：XSS跨站脚本攻击、CSRF跨站请求伪造攻击，一些比较复杂的图形验证码可以有效的防止恶性攻击。\r\n\r\n为了保护系统的安全在一些比较重要的操作都需要验证码。\r\n\r\n![image-20230705224522221](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224522221.png) \r\n\r\n验证码的类型也有很多：图片、语音、手机短信验证码等。\r\n\r\n本项目创建单独的验证码服务为各业务提供验证码的生成、校验等服务。\r\n\r\n拷贝课程资料目录xuecheng-plus-checkcode验证码服务工程到自己的工程目录。\r\n\r\n![image-20230705224535229](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224535229.png) \r\n\r\n定义nacos配置文件\r\n\r\n```yaml\r\nserver:\r\n  servlet:\r\n    context-path: /checkcode\r\n  port: 63075\r\n```\r\n\r\n注意修改bootstrap.yml中的命名空间为自己定义的命名空间。\r\n\r\n配置redis-dev.yaml，\r\n\r\n![image-20230705224558927](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224558927.png) \r\n\r\n内容如下：\r\n\r\n```yaml\r\nspring: \r\n  redis:\r\n    host: 192.168.101.65\r\n    port: 6379\r\n    password: redis\r\n    database: 0\r\n    lettuce:\r\n      pool:\r\n        max-active: 20\r\n        max-idle: 10\r\n        min-idle: 0\r\n    timeout: 10000\r\n    #redisson:\r\n      #配置文件目录\r\n      #config: classpath:singleServerConfig.yaml\r\n```\r\n\r\n#### **3.4.2 验证码接口测试**\r\n\r\n验证码服务对外提供的接口有：\r\n\r\n1、生成验证码\r\n\r\n2、校验验证码。\r\n\r\n如下：\r\n\r\n![image-20230705224626767](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224626767.png) \r\n\r\n验证码服务如何生成并校验验证码？\r\n\r\n拿图片验证码举例：\r\n\r\n1、先生成一个指定位数的验证码，根据需要可能是数字、数字字母组合或文字。\r\n\r\n2、根据生成的验证码生成一个图片并返回给页面\r\n\r\n3、给生成的验证码分配一个key，将key和验证码一同存入缓存。这个key和图片一同返回给页面。\r\n\r\n4、用户输入验证码，连同key一同提交至认证服务。\r\n\r\n5、认证服务拿key和输入的验证码请求验证码服务去校验\r\n\r\n6、验证码服务根据key从缓存取出正确的验证码和用户输入的验证码进行比对，如果相同则校验通过，否则不通过。\r\n\r\n![image-20230705224639354](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224639354.png) \r\n\r\n根据接口分析，验证码服务接口如下：\r\n\r\n```java\r\n\r\n@Api(value = \"验证码服务接口\")\r\n@RestController\r\npublic class CheckCodeController {\r\n\r\n\r\n    @ApiOperation(value=\"生成验证信息\", notes=\"生成验证信息\")\r\n    @PostMapping(value = \"/pic\")\r\n    public CheckCodeResultDto generatePicCheckCode(CheckCodeParamsDto checkCodeParamsDto){\r\n        \r\n    }\r\n\r\n    @ApiOperation(value=\"校验\", notes=\"校验\")\r\n    @ApiImplicitParams({\r\n            @ApiImplicitParam(name = \"name\", value = \"业务名称\", required = true, dataType = \"String\", paramType=\"query\"),\r\n            @ApiImplicitParam(name = \"key\", value = \"验证key\", required = true, dataType = \"String\", paramType=\"query\"),\r\n            @ApiImplicitParam(name = \"code\", value = \"验证码\", required = true, dataType = \"String\", paramType=\"query\")\r\n    })\r\n    @PostMapping(value = \"/verify\")\r\n    public Boolean verify(String key, String code){\r\n        \r\n    }\r\n}\r\n```\r\n\r\n1、生成验证码接口\r\n\r\n```http\r\n### 申请验证码\r\nPOST {{checkcode_host}}/checkcode/pic\r\n```\r\n\r\n\r\n\r\n2、校验验证码接口\r\n\r\n根据生成验证码返回的key以及日志中输出正确的验证码去测试。\r\n\r\n```http\r\n### 校验验证码\r\nPOST {{checkcode_host}}/checkcode/verify?key=checkcode4506b95bddbe46cdb0d56810b747db1b&code=70dl\r\n```\r\n\r\n### **3.5 账号密码认证**\r\n\r\n#### **3.5.1 需求分析**\r\n\r\n到目前为止账号和密码认证所需要的技术、组件都已开发完毕，下边实现账号密码认证，输出如下图：\r\n\r\n![image-20230705224656789](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224656789.png) \r\n\r\n执行流程如下：\r\n\r\n![image-20230705224709647](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224709647.png) \r\n\r\n#### **3.5.2 账号密码认证开发**\r\n\r\n1、在认证服务定义远程调用验证码服务的接口\r\n\r\n```java\r\n\r\n/**\r\n * @description 搜索服务远程接口\r\n */\r\n @FeignClient(value = \"checkcode\",fallbackFactory = CheckCodeClientFactory.class)\r\n @RequestMapping(\"/checkcode\")\r\npublic interface CheckCodeClient {\r\n\r\n @PostMapping(value = \"/verify\")\r\n public Boolean verify(@RequestParam(\"key\") String key,@RequestParam(\"code\") String code);\r\n\r\n}\r\n```\r\n\r\nCheckCodeClientFactory:\r\n\r\n```java\r\n@Slf4j\r\n@Component\r\npublic class CheckCodeClientFactory implements FallbackFactory<CheckCodeClient> {\r\n    @Override\r\n    public CheckCodeClient create(Throwable throwable) {\r\n        return new CheckCodeClient() {\r\n\r\n            @Override\r\n            public Boolean verify(String key, String code) {\r\n                log.debug(\"调用验证码服务熔断异常:{}\", throwable.getMessage());\r\n                return null;\r\n            }\r\n        };\r\n    }\r\n}\r\n```\r\n\r\n启动类添加：\r\n\r\n`@EnableFeignClients(basePackages={\"com.xuecheng.*.feignclient\"})`\r\n\r\n配置文件引入feign-dev.yaml\r\n\r\n```yaml\r\n- data-id: feign-${spring.profiles.active}.yaml\r\n  group: xuecheng-plus-common\r\n  refresh: true\r\n```\r\n\r\n2、完善PasswordAuthServiceImpl\r\n\r\n```java\r\n\r\n\r\n/**\r\n * @description 账号密码认证\r\n */\r\n @Service(\"password_authservice\")\r\npublic class PasswordAuthServiceImpl implements AuthService {\r\n\r\n @Autowired\r\n XcUserMapper xcUserMapper;\r\n\r\n @Autowired\r\n PasswordEncoder passwordEncoder;\r\n @Autowired\r\n CheckCodeClient checkCodeClient;\r\n\r\n @Override\r\n public XcUser execute(AuthParamsDto authParamsDto) {\r\n\r\n  //校验验证码\r\n  String checkcode = authParamsDto.getCheckcode();\r\n  String checkcodekey = authParamsDto.getCheckcodekey();\r\n\r\n  if(StringUtils.isBlank(checkcodekey) || StringUtils.isBlank(checkcode)){\r\n   throw new RuntimeException(\"验证码为空\");\r\n\r\n  }\r\n  Boolean verify = checkCodeClient.verify(checkcodekey, checkcode);\r\n  if(!verify){\r\n   throw new RuntimeException(\"验证码输入错误\");\r\n  }\r\n  //账号\r\n  String username = authParamsDto.getUsername();\r\n  XcUser user = xcUserMapper.selectOne(new LambdaQueryWrapper<XcUser>().eq(XcUser::getUsername, username));\r\n  if(user==null){\r\n   //返回空表示用户不存在\r\n   throw new RuntimeException(\"账号不存在\");\r\n  }\r\n  //校验密码\r\n  //取出数据库存储的正确密码\r\n  String passwordDb  =user.getPassword();\r\n  String passwordForm = authParamsDto.getPassword();\r\n  boolean matches = passwordEncoder.matches(passwordForm, passwordDb);\r\n  if(!matches){\r\n   throw new RuntimeException(\"账号或密码错误\");\r\n  }\r\n  return user;\r\n }\r\n}\r\n```\r\n\r\n小技巧：目前账号密码方式添加了验证码校验，为了后期获取令牌方便可以重新定义一个不需要验证码校验的认证类AuthService ，AuthService 中去掉验证码的校验，方便生成令牌。\r\n\r\n \r\n\r\n#### **3.5.3 账号密码认证测试**\r\n\r\n1、使用浏览器访问 http://www.51xuecheng.cn/sign.html\r\n\r\n![image-20230705224731189](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224731189.png) \r\n\r\n2、首先测试验证码，分别输入正确的验证码和错误的验证码进行测试\r\n\r\n3、输入正确的账号密码和错误的账号密码进行测试\r\n\r\n登录成功将jwt令牌存储cookie.\r\n\r\n4、测试自动登录\r\n\r\n勾选自动登录cookie生成时间为30天，不勾选自动登录关闭浏览器窗口后自动删除cookie。\r\n\r\n \r\n\r\n \r\n\r\n## **4 微信扫码登录**\r\n\r\n### **4.1 接入规范**\r\n\r\n#### **4.1.1 接入流程**\r\n\r\n微信扫码登录基于OAuth2协议的授权码模式，\r\n\r\n接口文档：\r\n\r\nhttps://developers.weixin.qq.com/doc/oplatform/Website_App/WeChat_Login/Wechat_Login.html\r\n\r\n流程如下：\r\n\r\n![image-20230705224756059](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224756059.png) \r\n\r\n第三方应用获取access_token令牌后即可请求微信获取用户的信息，成功获取到用户的信息表示用户在第三方应用认证成功。\r\n\r\n#### **4.1.2 请求获取授权码**\r\n\r\n第三方使用网站应用授权登录前请注意已获取相应网页授权作用域（`scope=snsapi_login`），则可以通过在 PC 端打开以下链接： https://open.weixin.qq.com/connect/qrconnect?appid=APPID&redirect_uri=REDIRECT_URI&response_type=code&scope=SCOPE&state=STATE#wechat_redirect 若提示“该链接无法访问”，请检查参数是否填写错误，如`redirect_uri`的域名与审核时填写的授权域名不一致或 scope 不为`snsapi_login`。\r\n\r\n**参数说明**\r\n\r\n![image-20230705224807325](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705224807325.png) \r\n\r\n**返回说明**\r\n\r\n用户允许授权后，将会重定向到`redirect_uri`的网址上，并且带上 code 和state参数\r\n\r\n```http\r\nredirect_uri?code=CODE&state=STATE\r\n```\r\n\r\n若用户禁止授权，则不会发生重定向。\r\n\r\n登录一号店网站应用 https://test.yhd.com/wechat/login.do 打开后，一号店会生成 state 参数，跳转到 https://open.weixin.qq.com/connect/qrconnect?appid=wxbdc5610cc59c1631&redirect_uri=https%3A%2F%2Fpassport.yhd.com%2Fwechat%2Fcallback.do&response_type=code&scope=snsapi_login&state=3d6be0a4035d839573b04816624a415e#wechat_redirect 微信用户使用微信扫描二维码并且确认登录后，PC端会跳转到 https://test.yhd.com/wechat/callback.do?code=CODE&state=3d6be0a40sssssxxxxx6624a415e 为了满足网站更定制化的需求，我们还提供了第二种获取 code 的方式，支持网站将微信登录二维码内嵌到自己页面中，用户使用微信扫码授权后通过 JS 将code返回给网站。 JS微信登录主要用途：网站希望用户在网站内就能完成登录，无需跳转到微信域下登录后再返回，提升微信登录的流畅性与成功率。 网站内嵌二维码微信登录 JS 实现办法：\r\n\r\n步骤1：在页面中先引入如下 JS 文件（支持https）：\r\n\r\n```http\r\nhttp://res.wx.qq.com/connect/zh_CN/htmledition/js/wxLogin.js\r\n```\r\n\r\n步骤2：在需要使用微信登录的地方实例以下 JS 对象：\r\n\r\n```js\r\n var obj = new WxLogin({\r\n self_redirect:true,\r\n id:\"login_container\", \r\n appid: \"\", \r\n scope: \"\", \r\n redirect_uri: \"\",\r\n  state: \"\",\r\n style: \"\",\r\n href: \"\"\r\n });\r\n```\r\n\r\n![image-20230705225019477](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225019477.png)\r\n\r\n \r\n\r\n#### **4.1.3 通过 code 获取access_token**\r\n\r\n通过 code 获取`access_token`\r\n\r\n```http\r\nhttps://api.weixin.qq.com/sns/oauth2/access_token?appid=APPID&secret=SECRET&code=CODE&grant_type=authorization_code\r\n```\r\n\r\n![image-20230705225158430](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225158430.png)\r\n\r\n**返回说明**\r\n\r\n正确的返回：\r\n\r\n```json\r\n{ \r\n\"access_token\":\"ACCESS_TOKEN\", \r\n\"expires_in\":7200, \r\n\"refresh_token\":\"REFRESH_TOKEN\",\r\n\"openid\":\"OPENID\", \r\n\"scope\":\"SCOPE\",\r\n\"unionid\": \"o6_bmasdasdsad6_2sgVt7hMZOPfL\"\r\n}\r\n```\r\n\r\n**参数说明**\r\n\r\n![image-20230705225227368](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225227368.png) \r\n\r\n错误返回样例：\r\n\r\n```json\r\n{\"errcode\":40029,\"errmsg\":\"invalid code\"}\r\n```\r\n\r\n#### **4.1.4 通过access_token调用接口**\r\n\r\n获取access_token后，进行接口调用，有以下前提：\r\n\r\n```json\r\naccess_token有效且未超时；\r\n微信用户已授权给第三方应用帐号相应接口作用域（scope）。\r\n```\r\n\r\n对于接口作用域（scope），能调用的接口有以下：\r\n\r\n![image-20230705225242753](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225242753.png) \r\n\r\n \r\n\r\n 其中`snsapi_base`属于基础接口，若应用已拥有其它 scope 权限，则默认拥有`snsapi_base`的权限。使用`snsapi_base`可以让移动端网页授权绕过跳转授权登录页请求用户授权的动作，直接跳转第三方网页带上授权临时票据（code），但会使得用户已授权作用域（scope）仅为`snsapi_base`，从而导致无法获取到需要用户授权才允许获得的数据和基础功能。 接口调用方法可查阅[《微信授权关系接口调用指南》](https://developers.weixin.qq.com/doc/oplatform/Website_App/WeChat_Login/Authorized_Interface_Calling_UnionID.html)\r\n\r\n获取用户信息接口文档：https://developers.weixin.qq.com/doc/oplatform/Website_App/WeChat_Login/Authorized_Interface_Calling_UnionID.html\r\n\r\n接口地址\r\n\r\n```http\r\nhttp请求方式: GET\r\nhttps://api.weixin.qq.com/sns/userinfo?access_token=ACCESS_TOKEN&openid=OPENID\r\n```\r\n\r\n如下：\r\n\r\n![image-20230705225302910](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225302910.png) \r\n\r\n响应：\r\n\r\n![image-20230705225337018](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225337018.png) \r\n\r\n说明如下：\r\n\r\n> 参数       说明\r\n> openid     普通用户的标识，对当前开发者帐号唯一\r\n> nickname     普通用户昵称\r\n> sex       普通用户性别，1为男性，2为女性\r\n> province     普通用户个人资料填写的省份\r\n> city       普通用户个人资料填写的城市\r\n> country     国家，如中国为CN\r\n> headimgurl     用户头像，最后一个数值代表正方形头像大小（有0、46、64、96、132数值可选，0代表640*640正方形头像），用户没有头像时该项为空\r\n> privilege     用户特权信息，json数组，如微信沃卡用户为（chinaunicom）\r\n> unionid      用户统一标识。针对一个微信开放平台帐号下的应用，同一用户的 unionid 是唯一的。\r\n\r\n### **4.2 准备开发环境**\r\n\r\n#### **4.2.1 添加应用**\r\n\r\n1、注册微信开放平台\r\n\r\nhttps://open.weixin.qq.com/\r\n\r\n2、添加应用\r\n\r\n进入网站应用，添加应用\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225407356.png) \r\n\r\n3、添加应用需要指定一个外网域名作为微信回调域名\r\n\r\n审核通过后，生成app密钥。\r\n\r\n最终获取appID和AppSecret\r\n\r\n\r\n\r\n\r\n\r\n#### **4.2.2 内网穿透**\r\n\r\n我们的开发环境在局域网，微信回调指向一个公网域名。\r\n\r\n如何让微信回调请求至我们的开发计算机上呢？\r\n\r\n可以使用内网穿透技术，什么是内网穿透？\r\n\r\n内网穿透简单来说就是将内网外网通过隧道打通,让内网的数据让外网可以获取。比如常用的办公室软件等，一般在办公室或家里，通过拨号上网，这样办公软件只有在本地的局域网之内才能访问，那么问题来了，如果是手机上，或者公司外地的办公人员，如何访问到办公软件呢？这就需要内网穿透工具了。开启隧道之后，网穿透工具会分配一个专属域名/端口,办公软件就已经在公网上了,在外地的办公人员可以在任何地方愉快的访问办公软件了~~\r\n\r\n![image-20230705225437784](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225437784.png) \r\n\r\n1、在内网穿透服务器上开通隧道，配置外网域名，配置穿透内网的端口即本地电脑上的端口。\r\n\r\n![image-20230705225502880](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225502880.png) \r\n\r\n这里我们配置认证服务端口，最终实现通过外网域名访问本地认证服务。\r\n\r\n2、在本地电脑上安装内网穿透的工具，工具上配置内网穿透服务器隧道token。\r\n\r\n市面上做内网穿透的商家很多，需要时可以查阅资料了解下。\r\n\r\n \r\n\r\n#### 4.2.3 无需使用内网穿透（固定端口）\r\n\r\n认证授权服务使用谷粒的固定端口8160\r\n\r\n在`nacos`配置中心配置\r\n\r\n```properties\r\n#微信相关配置\r\n# 微信开放平台 appid\r\nwx.open.app_id=wxed9954c01bb89b47\r\n# 微信开放平台 appsecret\r\nwx.open.app_secret=a7482517235173ddb4083788de60b90e\r\n# 微信开放平台 重定向url\r\nwx.open.redirect_url=http://localhost:8160/auth/wxLogin\r\n```\r\n\r\n修改`wxsign.html`中的`appid`和`redirect_uri`\r\n\r\n```js\r\n//请用微信生成二维码\r\n  function generateWxQrcode(token) {\r\n    var wxObj = new WxLogin({\r\n        self_redirect:true,\r\n        id:\"login_container\", \r\n        appid: \"wxed9954c01bb89b47\", \r\n        scope: \"snsapi_login\", \r\n        // redirect_uri: \"http://rcar79.natappfree.cc/xuecheng/auth/wxLogin\",\r\n        // redirect_uri: \"http://tjxt-user-t.itheima.net/api/auth/wxLogin\",\r\n        redirect_uri: \"http://localhost:8160/auth/wxLogin\",\r\n        state: token,\r\n        style: \"\",\r\n        href: \"\"\r\n      });\r\n    }\r\n```\r\n\r\n> 在测试过程中，要么启动验证码服务，要么屏蔽验证码检验代码，否则登录二维码无法生成\r\n\r\n\r\n\r\n\r\n\r\n### **4.3 接入微信登录**\r\n\r\n#### **4.3.1 接入分析**\r\n\r\n根据OAuth2协议授权码流程，结合本项目自身特点，分析接入微信扫码登录的流程如下：\r\n\r\n![image-20230705225519898](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225519898.png) \r\n\r\n本项目认证服务需要做哪些事？\r\n\r\n1、需要定义接口接收微信下发的授权码。\r\n\r\n2、收到授权码调用微信接口申请令牌。\r\n\r\n3、申请到令牌调用微信获取用户信息\r\n\r\n4、获取用户信息成功将其写入本项目用户中心数据库。\r\n\r\n5、最后重定向到浏览器自动登录。\r\n\r\n#### **4.3.2 定义接口**\r\n\r\n参考接口规范中“请求获取授权码” 定义接收微信下发的授权码接口，\r\n\r\n定义WxLoginController类，如下：\r\n\r\n```java\r\n\r\n@Slf4j\r\n@Controller\r\npublic class WxLoginController {\r\n\r\n    @RequestMapping(\"/wxLogin\")\r\n    public String wxLogin(String code, String state) throws IOException {\r\n        log.debug(\"微信扫码回调,code:{},state:{}\",code,state);\r\n        //请求微信申请令牌，拿到令牌查询用户信息，将用户信息写入本项目数据库\r\n        XcUser xcUser = new XcUser();\r\n        //暂时硬编写，目的是调试环境\r\n        xcUser.setUsername(\"t1\");\r\n        if(xcUser==null){\r\n            return \"redirect:http://www.51xuecheng.cn/error.html\";\r\n        }\r\n        String username = xcUser.getUsername();\r\n        return \"redirect:http://www.51xuecheng.cn/sign.html?username=\"+username+\"&authType=wx\";\r\n    }\r\n}\r\n```\r\n\r\n定义微信认证的service\r\n\r\n```java\r\n\r\n\r\n/**\r\n * @description 微信扫码认证\r\n */\r\n@Slf4j\r\n@Service(\"wx_authservice\")\r\npublic class WxAuthServiceImpl implements AuthService {\r\n\r\n    @Autowired\r\n    XcUserMapper xcUserMapper;\r\n\r\n    @Override\r\n    public XcUserExt execute(AuthParamsDto authParamsDto) {\r\n\r\n        //账号\r\n        String username = authParamsDto.getUsername();\r\n        XcUser user = xcUserMapper.selectOne(new LambdaQueryWrapper<XcUser>().eq(XcUser::getUsername, username));\r\n        if(user==null){\r\n            //返回空表示用户不存在\r\n            throw new RuntimeException(\"账号不存在\");\r\n        }\r\n        XcUserExt xcUserExt = new XcUserExt();\r\n        BeanUtils.copyProperties(user,xcUserExt);\r\n        return xcUserExt;\r\n    }\r\n}\r\n```\r\n\r\n#### **4.3.3 接口环境测试**\r\n\r\n接口定义好下边进行测试下，主要目的是测试接口调度的环境。\r\n\r\n1、启动内网穿透工具\r\n\r\n2、在/wxLogin接口中打断点\r\n\r\n3、打开前端微信扫码页面\r\n\r\n![image-20230705225557340](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225557340.png) \r\n\r\n点击微信图标打开二维码\r\n\r\n![image-20230705225604434](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225604434.png) \r\n\r\n用户扫码，确认授权\r\n\r\n此时正常进入 `/wxLogin`  方法，最后跳转到http://www.51xuecheng.cn/sign.html?username=t1&authType=wx。\r\n\r\n \r\n\r\n#### **4.3.4 申请令牌**\r\n\r\n接下来请求微信申请令牌。\r\n\r\n1、使用restTemplate请求微信，配置RestTemplate bean\r\n\r\n在启动类配置restTemplate\r\n\r\n```java\r\n\r\n    @Bean\r\n    RestTemplate restTemplate(){\r\n        RestTemplate restTemplate = new RestTemplate(new OkHttp3ClientHttpRequestFactory());\r\n        return  restTemplate;\r\n    }\r\n```\r\n\r\n定义与微信认证的service接口：\r\n\r\n```java\r\n\r\n/**\r\n * @description 微信认证接口\r\n */\r\npublic interface WxAuthService {\r\n\r\n    public XcUser wxAuth(String code);\r\n\r\n}\r\n```\r\n\r\n继续在WxAuthServiceImpl类写WxAuthService 接口的实现，在其中定义申请令牌的私有方法并由wxAuth方法去调用：\r\n\r\n```java\r\n\r\n@Slf4j\r\n@Service(\"wx_authservice\")\r\npublic class WxAuthServiceImpl implements AuthService, WxAuthService {\r\n@Autowired\r\nXcUserMapper xcUserMapper;\r\n@Autowired\r\nRestTemplate restTemplate;\r\n\r\n@Value(\"${weixin.appid}\")\r\nString appid;\r\n@Value(\"${weixin.secret}\")\r\nString secret;\r\n\r\npublic XcUser wxAuth(String code){\r\n\r\n    //收到code调用微信接口申请access_token\r\n    Map<String, String> access_token_map = getAccess_token(code);\r\n    if(access_token_map==null){\r\n        return null;\r\n    }\r\n    //获取用户信息\r\n   \r\n    //添加用户到数据库\r\n    XcUser xcUser = null;\r\n   \r\n    return xcUser;\r\n}\r\n\r\n\r\n/**\r\n * 申请访问令牌,响应示例\r\n {\r\n \"access_token\":\"ACCESS_TOKEN\",\r\n \"expires_in\":7200,\r\n \"refresh_token\":\"REFRESH_TOKEN\",\r\n \"openid\":\"OPENID\",\r\n \"scope\":\"SCOPE\",\r\n \"unionid\": \"o6_bmasdasdsad6_2sgVt7hMZOPfL\"\r\n }\r\n*/\r\nprivate Map<String,String> getAccess_token(String code) {\r\n\r\n    String wxUrl_template = \"https://api.weixin.qq.com/sns/oauth2/access_token?appid=%s&secret=%s&code=%s&grant_type=authorization_code\";\r\n    //请求微信地址\r\n    String wxUrl = String.format(wxUrl_template, appid, secret, code);\r\n\r\n    log.info(\"调用微信接口申请access_token, url:{}\", wxUrl);\r\n\r\n    ResponseEntity<String> exchange = restTemplate.exchange(wxUrl, HttpMethod.POST, null, String.class);\r\n\r\n    String result = exchange.getBody();\r\n    log.info(\"调用微信接口申请access_token: 返回值:{}\", result);\r\n    Map<String,String> resultMap = JSON.parseObject(result, Map.class);\r\n\r\n    return resultMap;\r\n}\r\n....\r\n```\r\n\r\n下边在controller中调用wxAuth接口：\r\n\r\n```java\r\n\r\n@Slf4j\r\n@Controller\r\npublic class WxLoginController {\r\n\r\n    @Autowired\r\n    WxAuthService wxAuthService;\r\n\r\n    @RequestMapping(\"/wxLogin\")\r\n    public String wxLogin(String code, String state) throws IOException {\r\n        log.debug(\"微信扫码回调,code:{},state:{}\",code,state);\r\n        //请求微信申请令牌，拿到令牌查询用户信息，将用户信息写入本项目数据库\r\n        XcUser xcUser = wxAuthService.wxAuth(code);\r\n        if(xcUser==null){\r\n            return \"redirect:http://www.51xuecheng.cn/error.html\";\r\n        }\r\n        String username = xcUser.getUsername();\r\n        return \"redirect:http://www.51xuecheng.cn/sign.html?username=\"+username+\"&authType=wx\";\r\n    }\r\n}\r\n```\r\n\r\n测试获取用户信息\r\n\r\n1、在wxAuthService中获取用户信息处打断点\r\n\r\n2、进入http://www.51xuecheng.cn/wxsign.html\r\n\r\n3、手机扫码并授权，观察是否成功申请到令牌\r\n\r\n \r\n\r\n#### **4.3.5 获取用户信息**\r\n\r\n在WxAuthServiceImpl类中定义获取用户信息方法：\r\n\r\n```java\r\n\r\n/**获取用户信息，示例如下：\r\n {\r\n \"openid\":\"OPENID\",\r\n \"nickname\":\"NICKNAME\",\r\n \"sex\":1,\r\n \"province\":\"PROVINCE\",\r\n \"city\":\"CITY\",\r\n \"country\":\"COUNTRY\",\r\n \"headimgurl\": \"https://thirdwx.qlogo.cn/mmopen/g3MonUZtNHkdmzicIlibx6iaFqAc56vxLSUfpb6n5WKSYVY0ChQKkiaJSgQ1dZuTOgvLLrhJbERQQ4eMsv84eavHiaiceqxibJxCfHe/0\",\r\n \"privilege\":[\r\n \"PRIVILEGE1\",\r\n \"PRIVILEGE2\"\r\n ],\r\n \"unionid\": \" o6_bmasdasdsad6_2sgVt7hMZOPfL\"\r\n }\r\n*/\r\nprivate Map<String,String> getUserinfo(String access_token,String openid) {\r\n\r\n    String wxUrl_template = \"https://api.weixin.qq.com/sns/userinfo?access_token=%s&openid=%s\";\r\n    //请求微信地址\r\n    String wxUrl = String.format(wxUrl_template, access_token,openid);\r\n\r\n    log.info(\"调用微信接口申请access_token, url:{}\", wxUrl);\r\n\r\n    ResponseEntity<String> exchange = restTemplate.exchange(wxUrl, HttpMethod.POST, null, String.class);\r\n\r\n    //防止乱码进行转码\r\n    String result = new     String(exchange.getBody().getBytes(StandardCharsets.ISO_8859_1),StandardCharsets.UTF_8);\r\n    log.info(\"调用微信接口申请access_token: 返回值:{}\", result);\r\n    Map<String,String> resultMap = JSON.parseObject(result, Map.class);\r\n\r\n    return resultMap;\r\n}\r\n```\r\n\r\n调用获取用户信息。\r\n\r\n```java\r\n\r\npublic XcUser wxAuth(String code){\r\n\r\n    //收到code调用微信接口申请access_token\r\n    Map<String, String> access_token_map = getAccess_token(code);\r\n    if(access_token_map==null){\r\n        return null;\r\n    }\r\n    System.out.println(access_token_map);\r\n    String openid = access_token_map.get(\"openid\");\r\n    String access_token = access_token_map.get(\"access_token\");\r\n    //拿access_token查询用户信息\r\n    Map<String, String> userinfo = getUserinfo(access_token, openid);\r\n    if(userinfo==null){\r\n        return null;\r\n    }\r\n    //添加用户到数据库\r\n    XcUser xcUser = null;\r\n    \r\n    return xcUser;\r\n}\r\n```\r\n\r\n测试获取用户信息\r\n\r\n1、在获取用户信息处打断点\r\n\r\n2、进入http://www.51xuecheng.cn/wxsign.html\r\n\r\n3、手机扫码授权\r\n\r\n \r\n\r\n#### **4.3.6 保存用户信息**\r\n\r\n向数据库保存用户信息，如果用户不存在将其保存在数据库。\r\n\r\n```java\r\n\r\n@Autowired\r\nXcUserRoleMapper xcUserRoleMapper;\r\n\r\n@Transactional\r\npublic XcUser addWxUser(Map userInfo_map){\r\n    String unionid = userInfo_map.get(\"unionid\").toString();\r\n    //根据unionid查询数据库\r\n    XcUser xcUser = xcUserMapper.selectOne(new LambdaQueryWrapper<XcUser>().eq(XcUser::getWxUnionid, unionid));\r\n    if(xcUser!=null){\r\n        return xcUser;\r\n    }\r\n    String userId = UUID.randomUUID().toString();\r\n    xcUser = new XcUser();\r\n    xcUser.setId(userId);\r\n    xcUser.setWxUnionid(unionid);\r\n    //记录从微信得到的昵称\r\n    xcUser.setNickname(userInfo_map.get(\"nickname\").toString());\r\n    xcUser.setUserpic(userInfo_map.get(\"headimgurl\").toString());\r\n    xcUser.setName(userInfo_map.get(\"nickname\").toString());\r\n    xcUser.setUsername(unionid);\r\n    xcUser.setPassword(unionid);\r\n    xcUser.setUtype(\"101001\");//学生类型\r\n    xcUser.setStatus(\"1\");//用户状态\r\n    xcUser.setCreateTime(LocalDateTime.now());\r\n    xcUserMapper.insert(xcUser);\r\n    XcUserRole xcUserRole = new XcUserRole();\r\n    xcUserRole.setId(UUID.randomUUID().toString());\r\n    xcUserRole.setUserId(userId);\r\n    xcUserRole.setRoleId(\"17\");//学生角色\r\n    xcUserRoleMapper.insert(xcUserRole);\r\n    return xcUser;\r\n}\r\n```\r\n\r\n调用保存用户信息\r\n\r\n```java\r\n\r\n@Autowired\r\nWxAuthServiceImpl currentProxy;\r\n\r\npublic XcUser wxAuth(String code){\r\n\r\n    //收到code调用微信接口申请access_token\r\n    Map<String, String> access_token_map = getAccess_token(code);\r\n    if(access_token_map==null){\r\n        return null;\r\n    }\r\n    System.out.println(access_token_map);\r\n    String openid = access_token_map.get(\"openid\");\r\n    String access_token = access_token_map.get(\"access_token\");\r\n    //拿access_token查询用户信息\r\n    Map<String, String> userinfo = getUserinfo(access_token, openid);\r\n    if(userinfo==null){\r\n        return null;\r\n    }\r\n    //将用户信息保存到数据库\r\n    XcUser xcUser = currentProxy.addWxUser(userinfo);\r\n    return xcUser;\r\n}\r\n```\r\n\r\n测试保存用户信息\r\n\r\n1、在保存用户信息处打断点\r\n\r\n2、进入http://www.51xuecheng.cn/wxsign.html\r\n\r\n3、手机扫码授权\r\n\r\n4、自动跳转到登录页面，提交认证成功。\r\n\r\n \r\n\r\n## **5 用户授权**\r\n\r\n### **5.1 RBAC**\r\n\r\n如何实现授权？业界通常基于RBAC实现授权。\r\n\r\nRBAC分为两种方式：\r\n\r\n基于角色的访问控制（Role-Based Access Control）\r\n\r\n基于资源的访问控制（Resource-Based Access Control）\r\n\r\n角色的访问控制（Role-Based Access Control）是按角色进行授权，比如：主体的角色为总经理可以查询企业运营报表，查询员工工资信息等，访问控制流程如下：\r\n\r\n![image-20230705225635823](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225635823.png) \r\n\r\n根据上图中的判断逻辑，授权代码可表示如下：\r\n\r\n```java\r\nif(主体.hasRole(\"总经理角色id\")){\r\n查询工资\r\n}\r\n```\r\n\r\n如果上图中查询工资所需要的角色变化为总经理和部门经理，此时就需要修改判断逻辑为“判断用户的角色是否是总经理或部门经理”，修改代码如下：\r\n\r\n```java\r\nif(主体.hasRole(\"总经理角色id\") ||  主体.hasRole(\"部门经理角色id\")){\r\n    查询工资\r\n}\r\n```\r\n\r\n根据上边的例子发现，当需要修改角色的权限时就需要修改授权的相关代码，系统可扩展性差。\r\n\r\n \r\n\r\n基于资源的访问控制（Resource-Based Access\r\n\r\nControl）是按资源（或权限）进行授权，比如：用户必须具有查询工资权限才可以查询员工工资信息等，访问控制流程如下：\r\n\r\n![image-20230705225645727](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225645727.png) \r\n\r\n根据上图中的判断，授权代码可以表示为：\r\n\r\n```java\r\nif(主体.hasPermission(\"查询工资权限标识\")){\r\n    查询工资\r\n}\r\n```\r\n\r\n优点：系统设计时定义好查询工资的权限标识，即使查询工资所需要的角色变化为总经理和部门经理也不需要修改授权代码，系统可扩展性强。\r\n\r\n \r\n\r\n### **5.2 资源服务授权流程**\r\n\r\n本项目在资源服务内部进行授权，基于资源的授权模式，因为接口在资源服务，通过在接口处添加授权注解实现授权。\r\n\r\n1、首先配置nginx代理\r\n\r\n```apl\r\n\r\n   http {\r\n    server_names_hash_bucket_size 64;\r\n    ...\r\n   \r\n   #前端开发服务\r\n  upstream uidevserver{\r\n    server 127.0.0.1:8601 weight=10;\r\n  } \r\n   server {\r\n        listen       80;\r\n        server_name  teacher.51xuecheng.cn;\r\n        #charset koi8-r;\r\n        ssi on;\r\n        ssi_silent_errors on;\r\n        #access_log  logs/host.access.log  main;\r\n        #location / {\r\n         #   alias   D:/itcast2022/xc_edu3.0/code_1/dist/;\r\n         #   index  index.html index.htm;\r\n        #}\r\n        location / {\r\n            proxy_pass   http://uidevserver;\r\n        }\r\n\r\n        location /api/ {\r\n                proxy_pass http://gatewayserver/;\r\n        } \r\n        \r\n        \r\n   }\r\n```\r\n\r\n加载nginx 配置。\r\n\r\n \r\n\r\n2、在资源服务集成Spring Security\r\n\r\n在需要授权的接口处使用`@PreAuthorize(\"hasAuthority('权限标识符')\")`进行控制\r\n\r\n下边代码指定`/course/list`接口需要拥有`xc_teachmanager_course_list` 权限。\r\n\r\n![image-20230705225657359](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225657359.png) \r\n\r\n设置了`@PreAuthorize`表示执行此方法需要授权，如果当前用户请求接口没有权限则抛出异常\r\n\r\n`org.springframework.security.access.AccessDeniedException`: 不允许访问\r\n\r\n3、在统一异常处理处解析此异常信息\r\n\r\n```java\r\n@ResponseBody\r\n@ExceptionHandler(Exception.class)\r\n@ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR)\r\npublic RestErrorResponse exception(Exception e) {\r\n\r\n   log.error(\"【系统异常】{}\",e.getMessage(),e);\r\n   e.printStackTrace();\r\n   if(e.getMessage().equals(\"不允许访问\")){\r\n      return new RestErrorResponse(\"没有操作此功能的权限\");\r\n   }\r\n   return new RestErrorResponse(CommonError.UNKOWN_ERROR.getErrMessage());\r\n\r\n\r\n}\r\n```\r\n\r\n4、重启资源服务进行测试\r\n\r\n使用教学机构用户登录系统\r\n\r\n这里使用t1用户登录，账号:t1、密码：111111\r\n\r\n登录成功，点击“教学机构”\r\n\r\n![image-20230705225706766](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225706766.png) \r\n\r\n当用户没有权限时页面提示：没有操作此功能的权限。\r\n\r\n![image-20230705225713175](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225713175.png) \r\n\r\n### **5.3 授权相关的数据模型**\r\n\r\n如何给用户分配权限呢？\r\n\r\n首先要学习数据模型，本项目授权相关的数据表如下：\r\n\r\n![image-20230705225720492](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225720492.png) \r\n\r\n说明如下：\r\n\r\n`xc_user`：用户表，存储了系统用户信息，用户类型包括：学生、老师、管理员等\r\n\r\n`xc_role`：角色表，存储了系统的角色信息，学生、老师、教学管理员、系统管理员等。\r\n\r\n`xc_user_role`：用户角色表，一个用户可拥有多个角色，一个角色可被多个用户所拥有\r\n\r\n`xc_menu`：模块表，记录了菜单及菜单下的权限\r\n\r\n`xc_permission`：角色权限表，一个角色可拥有多个权限，一个权限可被多个角色所拥有\r\n\r\n \r\n\r\n本项目教学阶段不再实现权限定义及用户权限分配的功能，权限分配的界面原型如下图所示：\r\n\r\n![image-20230705225732787](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225732787.png) \r\n\r\n \r\n\r\n本项目要求掌握基于权限数据模型（5张数据表），要求在数据库中操作完成给用户分配权限、查询用户权限等需求。\r\n\r\n1、查询用户所拥有的权限\r\n\r\n步骤：\r\n\r\n查询用户的id\r\n\r\n查询用户所拥有的角色\r\n\r\n查询用户所拥有的权限\r\n\r\n例子：\r\n\r\n```sql\r\nSELECT * FROM xc_menu WHERE id IN(\r\n  SELECT menu_id FROM xc_permission WHERE role_id IN(\r\n    SELECT role_id FROM xc_user_role WHERE user_id = '49'\r\n  )\r\n)\r\n```\r\n\r\n2、给用户分配权限\r\n\r\n1）添加权限\r\n\r\n查询用户的id\r\n\r\n查询权限的id\r\n\r\n查询用户的角色，如果没有角色需要先给用户指定角色\r\n\r\n向角色权限表添加记录\r\n\r\n2）删除用户权限\r\n\r\n本项目是基于角色分配权限，如果要删除用户的权限可以给用户换角色，那么新角色下的权限就是用户的权限；如果不换用户的角色可以删除角色下的权限即删除角色权限关系表相应记录，这样操作是将角色下的权限删除，属于该角色的用户都将删除此权限。\r\n\r\n \r\n\r\n### **5.4 查询用户权限**\r\n\r\n使用Spring Security进行授权，首先在生成jwt前会查询用户的权限，如下图：\r\n\r\n![image-20230705225743413](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225743413.png) \r\n\r\n接下来需要修改UserServiceImpl和PasswordAuthServiceImpl从数据库查询用户的权限。\r\n\r\n1、定义mapper接口\r\n\r\n```java\r\npublic interface XcMenuMapper extends BaseMapper<XcMenu> {\r\n    @Select(\"SELECT    * FROM xc_menu WHERE id IN (SELECT menu_id FROM xc_permission WHERE role_id IN ( SELECT role_id FROM xc_user_role WHERE user_id = #{userId} ))\")\r\n    List<XcMenu> selectPermissionByUserId(@Param(\"userId\") String userId);\r\n}\r\n```\r\n\r\n2、修改PasswordAuthServiceImpl\r\n\r\n修改UserServiceImpl类的getUserPrincipal方法，查询权限信息\r\n\r\n```java\r\n\r\n//查询用户身份\r\npublic UserDetails getUserPrincipal(XcUserExt user){\r\n    String password = user.getPassword();\r\n    //查询用户权限\r\n    List<XcMenu> xcMenus = menuMapper.selectPermissionByUserId(user.getId());\r\n    List<String> permissions = new ArrayList<>();\r\n    if(xcMenus.size()<=0){\r\n        //用户权限,如果不加则报Cannot pass a null GrantedAuthority collection\r\n        permissions.add(\"p1\");\r\n    }else{\r\n        xcMenus.forEach(menu->{\r\n            permissions.add(menu.getCode());\r\n        });\r\n    }\r\n    //将用户权限放在XcUserExt中\r\n    user.setPermissions(permissions);\r\n\r\n    //为了安全在令牌中不放密码\r\n    user.setPassword(null);\r\n    //将user对象转json\r\n    String userString = JSON.toJSONString(user);\r\n    String[] authorities = permissions.toArray(new String[0]);\r\n    UserDetails userDetails = User.withUsername(userString).password(password).authorities(authorities).build();\r\n    return userDetails;\r\n\r\n}\r\n```\r\n\r\n### **5.5 授权测试**\r\n\r\n以上实现了认证时从数据库查询用户的权限，下边进行用户授权测试。\r\n\r\n \r\n\r\n重启认证服务，使用内容管理课程列表查询为例，代码如下：\r\n\r\n![image-20230705225751417](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225751417.png) \r\n\r\n用户拥有`xc_teachmanager_course_list`权限方可访问课程查询接口。\r\n\r\n以用户stu1为例，当它没有此权限时页面报“没有此操作的权限”错误\r\n\r\n![image-20230705225757328](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225757328.png) \r\n\r\n将`xc_teachmanager_course_list`权限分配给用户。\r\n\r\n1）首先找到当前用户的角色\r\n\r\n2）找到`xc_teachmanager_course_list`权限的主键\r\n\r\n3）在角色权限关系表中添加记录\r\n\r\n分配完权限需要重新登录\r\n\r\n由于用户分配了`xc_teachmanager_course_list`权限，用户具有访问课程查询接口的权限。\r\n\r\n \r\n\r\n### **5.6 细粒度授权**\r\n\r\n#### **5.6.1 什么是细粒度授权**\r\n\r\n什么是细粒度授权？\r\n\r\n细粒度授权也叫数据范围授权，即不同的用户所拥有的操作权限相同，但是能够操作的数据范围是不一样的。一个例子：用户A和用户B都是教学机构，他们都拥有“我的课程”权限，但是两个用户所查询到的数据是不一样的。\r\n\r\n本项目有哪些细粒度授权？\r\n\r\n比如：\r\n\r\n我的课程，教学机构只允许查询本教学机构下的课程信息。\r\n\r\n我的选课，学生只允许查询自己所选课。\r\n\r\n如何实现细粒度授权？\r\n\r\n细粒度授权涉及到不同的业务逻辑，通常在service层实现，根据不同的用户进行校验，根据不同的参数查询不同的数据或操作不同的数据。\r\n\r\n#### **5.6.2 教学机构细粒度授权**\r\n\r\n教学机构在维护课程时只允许维护本机构的课程，教学机构细粒度授权过程如下：\r\n\r\n- 1）获取当前登录的用户身份\r\n- 2）得到用户所属教育机构的Id\r\n- 3）查询该教学机构下的课程信息\r\n\r\n最终实现了用户只允许查询自己机构的课程信息。\r\n\r\n根据公司Id查询课程，流程如下：\r\n\r\n- 1）教学机构用户登录系统，从用户身份中取出所属机构的id\r\n- 在用户表中设计了`company_id`字段存储该用户所属的机构id.\r\n- 2）接口层取出当前登录用户的身份，取出机构id\r\n- 3）将机构id传入service方法。\r\n- 4）service方法将机构id传入Dao方法，最终查询出本机构的课程信息。\r\n\r\n代码实现如下：\r\n\r\n```java\r\n\r\n@ApiOperation(\"课程查询接口\")\r\n@PreAuthorize(\"hasAuthority('xc_teachmanager_course_list')\")//拥有课程列表查询的权限方可访问\r\n@PostMapping(\"/course/list\")\r\npublic PageResult<CourseBase> list(PageParams pageParams, @RequestBody QueryCourseParamsDto queryCourseParams){\r\n    //取出用户身份\r\n    XcUser user = SecurityUtil.getUser();\r\n    //机构id\r\n    String companyId = user.getCompanyId();\r\n    return courseBaseInfoService.queryCourseBaseList(Long.parseLong(companyId),pageParams,queryCourseParams);\r\n}\r\n```\r\n\r\n\r\n\r\nService方法如下：\r\n\r\n```java\r\n@Override\r\npublic PageResult<CourseBase> queryCourseBaseList(Long companyId,PageParams pageParams, QueryCourseParamsDto queryCourseParamsDto) {\r\n\r\n //构建查询条件对象\r\n LambdaQueryWrapper<CourseBase> queryWrapper = new LambdaQueryWrapper<>();\r\n //机构id\r\n queryWrapper.eq(CourseBase::getCompanyId,companyId);\r\n ....\r\n```\r\n\r\n#### **5.6.3 教学机构细粒度授权测试**\r\n\r\n使用一个教学机构的用户登录项目，并且此用户具有查询课程的权限。\r\n\r\n手机修改数据库指定用户归属到一个机构中，涉及以下数据表：\r\n\r\n`xc_company`为机构表\r\n\r\n`xc_company_user`为机构用户关系表\r\n\r\n`xc_user`表中有`company_id`字段。\r\n\r\n我们准备了t1 用户作为此次测试的用户，使用此用户登录系统：\r\n\r\n提前在查询课程列表接口处打上断点。\r\n\r\n经过测试可以正常取出用户所属的机构id\r\n\r\n![image-20230705225810633](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225810633.png) \r\n\r\n跟踪持久层日志发现已将机构id传入dao方法，拼装sql语句，查询本机构的课程信息\r\n\r\n![image-20230705225815714](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225815714.png) \r\n\r\n \r\n\r\n## **6 实战**\r\n\r\n### **6.1 找回密码(实战)**\r\n\r\n需求：忘记密码需要找回，可以通过手机号找回密码，通过邮箱找回密码以及人工通道。\r\n\r\n界面访问地址：http://www.51xuecheng.cn/findpassword.html\r\n\r\n![image-20230705225823457](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225823457.png) \r\n\r\n接口：\r\n\r\n手机验证码：`/api/checkcode/phone?param1=手机号`\r\n\r\n邮箱验证码：/api/checkcode/phone?param1=电子邮箱地址\r\n\r\n找回密码：`/api/auth/findpassword`\r\n\r\n请求：\r\n\r\n```json\r\n{\r\n     cellphone:'',\r\n     email:'',\r\n     checkcodekey:'',\r\n     checkcode:'',\r\n     confirmpwd:'',\r\n     password:''\r\n }\r\n```\r\n\r\n响应：\r\n\r\n200: 找回成功\r\n\r\n其它：找回失败，失败原因使用统一异常处理返回的信息格式\r\n\r\n执行流程\r\n1、校验验证码，不一致则抛出异常\r\n\r\n2、判断两次密码是否一致，不一致则抛出异常\r\n\r\n3、根据手机号和邮箱查询用户\r\n\r\n4、如果找到用户更新为新密码\r\n\r\n \r\n\r\n \r\n\r\n### **6.2 注册(实战)**\r\n\r\n需求：为学生提供注册入口，通过此入口注册的用户为学生用户。\r\n\r\n界面访问地址：http://www.51xuecheng.cn/register.html\r\n\r\n![image-20230705225845103](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705225845103.png) \r\n\r\n接口：\r\n\r\n手机验证码：`/api/checkcode/phone?param1=手机号`\r\n\r\n注册：`/api/auth/register`\r\n\r\n请求：\r\n\r\n```json\r\n\r\n{\r\n   cellphone:'',\r\n   username:'',\r\n   email:'',\r\n   nickname:'',\r\n   password:'',\r\n   confirmpwd:'',\r\n   checkcodekey:'',\r\n   checkcode:''\r\n}\r\n```\r\n\r\n响应：\r\n\r\n200: 注册成功\r\n\r\n其它：注册失败，失败原因使用统一异常处理返回的信息格式\r\n\r\n执行流程：\r\n\r\n1、校验验证码，如果不一致则抛出异常\r\n\r\n2、校验两次密码是否一致，如果不一致则抛出异常\r\n\r\n3、校验用户是否存在，如果存在则抛出异常\r\n\r\n4、向用户表、用户角色关系表添加数据。角色为学生角色。\r\n\r\n \r\n\r\n "},{"title":"Spring Cloud组件","tags":["Spring Cloud","Spring Cloud Alibaba","gateway"],"categories":["Java","微服务"],"author":"imklaus","excerpt":"\r\n\r\n## 1、SpringCloud Alibaba 简介\r\n\r\n### 1）、简介\r\n\r\n- Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。\r\n\r\n- 依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。\r\n- https://github.com/alibaba/spring-cloud-alibaba\r\n","link":"/posts/SpringCloud-Component","content":"\r\n\r\n## 1、SpringCloud Alibaba 简介\r\n\r\n### 1）、简介\r\n\r\n- Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。\r\n\r\n- 依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。\r\n- https://github.com/alibaba/spring-cloud-alibaba\r\n<!-- more -->\r\n\r\n### 2）、为什么使用\r\n\r\n![image-20230426190744205](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426190744205.png)\r\n\r\n- **SpringCloud 的几大痛点**\r\n  - SpringCloud 部分组件停止维护和更新，给开发带来不便；\r\n  - SpringCloud 部分环境搭建复杂，没有完善的可视化界面，我们需要大量的二次开发和定制\r\n  - SpringCloud 配置复杂，难以上手，部分配置差别难以区分和合理应用\r\n- SpringCloud Alibaba 的优势：\r\n  - 阿里使用过的组件经历了考验，性能强悍，设计合理，现在开源出来大家用成套的产品搭配完善的可视化界面给开发运维带来极大的便利搭建简单，学习曲线低。\r\n- 结合 SpringCloud Alibaba 我们最终的技术搭配方案：\r\n  - SpringCloud Alibaba - Nacos：注册中心（服务发现/注册）\r\n  - SpringCloud Alibaba - Nacos：配置中心（动态配置管理）\r\n  - SpringCloud - Ribbon：负载均衡\r\n  - SpringCloud - Feign：声明式 HTTP 客户端（调用远程服务）\r\n  - SpringCloud Alibaba - Sentinel：服务容错（限流、降级、熔断）\r\n  - SpringCloud - Gateway：API 网关（webflux 编程模式）\r\n  - SpringCloud - Sleuth：调用链监控\r\n  - SpringCloud Alibaba - Seata：原 Fescar，即分布式事务解决方案\r\n\r\n\r\n\r\n### 3）、版本选择\r\n\r\n由于 Spring Boot 1 和 Spring Boot 2 在 Actuator 模块的接口和注解有很大的变更，且spring-cloud-commons 从 1.x.x 版本升级到 2.0.0 版本也有较大的变更，因此我们采取跟SpringBoot 版本号一致的版本:\r\n\r\n- 1.5.x 版本适用于 Spring Boot 1.5.x\r\n- 2.0.x 版本适用于 Spring Boot 2.0.x\r\n- 2.1.x 版本适用于 Spring Boot 2.1.x\r\n\r\n### 4）、项目中的依赖\r\n\r\n```xml\r\n<dependencyManagement>\r\n        <dependencies>\r\n            <dependency>\r\n                <groupId>com.alibaba.cloud</groupId>\r\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\r\n                <version>2.1.0.RELEASE</version>\r\n                <type>pom</type>\r\n                <scope>import</scope>\r\n            </dependency>\r\n        </dependencies>\r\n    </dependencyManagement>\r\n```\r\n\r\n\r\n\r\n## 2、SpringCloud Alibaba-Nacos[作为注册中心]\r\n\r\n- Nacos 是阿里巴巴开源的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。他是使用 java 编写。需要依赖 java 环境\r\n\r\n- Nacos 文档地址： https://nacos.io/zh-cn/docs/quick-start.html\r\n\r\n\r\n\r\n### 1）、下载 nacos-server\r\n\r\nhttps://github.com/alibaba/nacos/releases\r\n\r\n\r\n\r\n### 2）、启动 nacos-server\r\n\r\n- 双击 bin 中的 startup.cmd 文件\r\n\r\n- 访问 http://localhost:8848/nacos/\r\n\r\n- 使用默认的 nacos/nacos 进行登录\r\n\r\n![image-20230426191639545](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426191639545.png)\r\n\r\n\r\n\r\n### 3）、将微服务注册到 nacos 中\r\n\r\n#### 1、首先，修改 pom.xml 文件，引入 Nacos Discovery Starter。\r\n\r\n```xml\r\n<dependency>\r\n  <groupId>com.alibaba.cloud</groupId>\r\n  <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\r\n</dependency>\r\n```\r\n\r\n\r\n\r\n#### 2、在应用的 /src/main/resources/application.properties 配置文件中配置 Nacos Server 地址\r\n\r\n```properties\r\nspring.cloud.nacos.discovery.server-addr=127.0.0.1:8848\r\n```\r\n\r\n\r\n\r\n#### 3、使用@EnableDiscoveryClient 开启服务注册发现功能\r\n\r\n```java\r\n@SpringBootApplication\r\n@EnableDiscoveryClient\r\npublic class ProviderApplication {\r\n\tpublic static void main(String[] args) {\r\n\t\tSpringApplication.run(Application.class, args);\r\n\t}\r\n}\r\n```\r\n\r\n\r\n\r\n#### 4、启动应用，观察 nacos 服务列表是否已经注册上服务\r\n\r\n- 注意：每一个应用都应该有名字，这样才能注册上去。修改 application.properties 文件\r\n\r\n```properties\r\nspring.application.name=service-provider\r\nserver.port=8000\r\n```\r\n\r\n\r\n\r\n#### 5、注册更多的服务上去，测试使用 feign 远程调用\r\n\r\n- Nacos 使用三步\r\n  - 1、导包 nacos-discovery\r\n  - 2、写配置，指定 nacos 地址，指定应用的名字\r\n  - 3、开启服务注册发现功能@EnableDiscoveryClient\r\n- Feign 使用三步\r\n  - 1、导包 openfeign\r\n  - 2、开启@EnableFeignClients 功能\r\n  - 3、编写接口，进行远程调用\r\n\r\n```java\r\n@FeignClient(\"stores\")\r\npublic interface StoreClient {\r\n    \r\n\t@RequestMapping(method = RequestMethod.GET, value = \"/stores\")\r\n\tList<Store> getStores();\r\n    \r\n\t@RequestMapping(method=RequestMethod.POST,value=\"/stores/{storeId}\",consumes = \t\t\"application/json\")\r\n\tStore update(@PathVariable(\"storeId\") Long storeId, Store store);\r\n}\r\n```\r\n\r\n\r\n\r\n#### 6、更多配置\r\n\r\nhttps://github.com/alibaba/spring-cloud-alibaba/blob/master/spring-cloud-alibaba-examples/nacos-example/nacos-discovery-example/readme-zh.md#more\r\n\r\n\r\n\r\n## 3、SpringCloud Alibaba-Nacos[作为配置中心]\r\n\r\n### 1、pom.xml 引入 Nacos Config Starter。\r\n\r\n```xml\r\n<dependency>\r\n  <groupId>com.alibaba.cloud</groupId>\r\n  <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>\r\n</dependency>\r\n```\r\n\r\n\r\n\r\n### 2、在应用的 /src/main/resources/bootstrap.properties 配置文件中配置 Nacos Config 元数据\r\n\r\n- 主要配置应用名和配置中心地址\r\n\r\n```properties\r\nspring.application.name=nacos-config-example\r\nspring.cloud.nacos.config.server-addr=127.0.0.1:8848\r\n```\r\n\r\n\r\n\r\n### 3、在 nacos 中添加配置\r\n\r\n- 在 nacos 中创建一个应用名.properties 配置文件并编写配置\r\n  - Nacos Config 数据结构\r\n  - Nacos Config 主要通过 dataId 和 group 来唯一确定一条配置。\r\n  - Nacos Client 从 Nacos Server 端获取数据时，调用的是此接口 ConfigService.getConfig(String dataId, String group, long timeoutMs)。\r\n- Spring Cloud 应用获取数据\r\n  - dataID：\r\n  - 在 Nacos Config Starter 中，dataId 的拼接格式如下\r\n    - ${prefix} - ${spring.profiles.active} . ${file-extension} prefix 默认为 spring.application.name的值，也可以通过配置项 spring.cloud.nacos.config.prefix 来配置。\r\n    - spring.profiles.active 即为当前环境对应的 profile\r\n  - 注意，当 activeprofile 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成`${prefix}.${file-extension}`\r\n  - file-extension 为配置内容的数据格式，可以通过配置项spring.cloud.nacos.config.file-extension 来配置。 目前只支持 properties 类型。\r\n  - Group：\r\n    - Group 默认为 DEFAULT_GROUP，可以通过 spring.cloud.nacos.config.group 配置。\r\n\r\n\r\n\r\n### 4、在应用中使用@Value 和@RefreshScope\r\n\r\n完成上述两步后，应用会从 Nacos Config 中获取相应的配置，并添加在 Spring Environment的\r\nPropertySources中 。 这里我们使用@Value 注解来将对应的配置注入到SampleController 的 userName 和 age 字段，并添加 @RefreshScope 打开动态刷新功能\r\n\r\n```java\r\n@RefreshScope\r\nclass SampleController {\r\n\t@Value(\"${user.name}\")\r\n\tString userName;\r\n\t@Value(\"${user.age}\")\r\n\tint age;\r\n}\r\n```\r\n\r\n\r\n\r\n### 5、进阶\r\n\r\n#### 1、核心概念\r\n\r\n- 命名空间：\r\n  - 用于进行租户粒度的配置隔离。不同的命名空间下，可以存在相同的 Group 或 Data ID 的配置。Namespace 的常用场景之一是不同环境的配置的区分隔离，例如开发测试环境和生产环境的资源（如配置、服务）隔离等。\r\n- 配置集：\r\n  - 一组相关或者不相关的配置项的集合称为配置集。在系统中，一个配置文件通常就是一个配置集，包含了系统各个方面的配置。例如，一个配置集可能包含了数据源、线程池、日志级别等配置项。\r\n- 配置集 ID：\r\n  - Nacos 中的某个配置集的 ID。配置集 ID 是组织划分配置的维度之一。Data ID 通常用于组织划分系统的配置集。一个系统或者应用可以包含多个配置集，每个配置集都可以被一个有意义的名称标识。Data ID 通常采用类 Java 包（如 com.taobao.tc.refund.log.level）的命名规则保证全局唯一性。此命名规则非强制。\r\n- 配置分组：\r\n  - Nacos 中的一组配置集，是组织配置的维度之一。通过一个有意义的字符串（如 Buy 或Trade ）对配置集进行分组，从而区分 Data ID 相同的配置集。当您在 Nacos 上创建一个配置时，如果未填写配置分组的名称，则配置分组的名称默认采用 DEFAULT_GROUP 。配置分组的常见场景：不同的应用或组件使用了相同的配置类型，如 database_url 配置和MQ_topic 配置。\r\n\r\n\r\n\r\n#### 2、原理\r\n\r\n- 自动注入：\r\n  - NacosConfigStarter 实现了org.springframework.cloud.bootstrap.config.PropertySourceLocator接口，并将优先级设置成了最高。\r\n  - 在 Spring Cloud 应用启动阶段，会主动从 Nacos Server 端获取对应的数据，并将获取到的数据转换成 PropertySource 且注入到 Environment 的 PropertySources 属性中，所以使用@Value 注解也能直接获取 Nacos Server 端配置的内容。\r\n- 动态刷新：\r\n  - Nacos Config Starter 默认为所有获取数据成功的 Nacos 的配置项添加了监听功能，在监听到服务端配置发生变化时会实时触发org.springframework.cloud.context.refresh.ContextRefresher 的 refresh 方法 。\r\n  - 如果需要对 Bean 进行动态刷新，请参照 Spring 和 Spring Cloud 规范。推荐给类添加@RefreshScope 或 @ConfigurationProperties 注解\r\n\r\n\r\n\r\n#### 3、加载多配置文件\r\n\r\n```properties\r\nspring.cloud.nacos.config.server-addr=127.0.0.1:8848\r\nspring.cloud.nacos.config.namespace=31098de9-fa28-41c9-b0bd-c754ce319ed4\r\nspring.cloud.nacos.config.ext-config[0].data-id=gulimall-datasource.yml\r\nspring.cloud.nacos.config.ext-config[0].refresh=false\r\nspring.cloud.nacos.config.ext-config[0].group=dev\r\n```\r\n\r\n\r\n\r\n#### 4、namespace 与 group 最佳实践\r\n\r\n- 每个微服务创建自己的 namespace 进行隔离，group 来区分 dev，beta，prod 等环境\r\n\r\n## 4、SpringCloud Alibaba-Sentinel\r\n\r\n### 1、简介\r\n\r\n#### 1）、熔断降级限流\r\n\r\n- 什么是熔断\r\n\r\n​       A 服务调用 B 服务的某个功能，由于网络不稳定问题，或者 B 服务卡机，导致功能时间超长。如果这样子的次数太多。我们就可以直接将 B 断路了（A 不再请求 B 接口），凡是调用 B 的直接返回降级数据，不必等待 B 的超长执行。 这样 B 的故障问题，就不会级联影响到 A。\r\n\r\n- 什么是降级\r\n\r\n​        整个网站处于流量高峰期，服务器压力剧增，根据当前业务情况及流量，对一些服务和页面进行有策略的降级[停止服务，所有的调用直接返回降级数据]。以此缓解服务器资源的的压力，以保证核心业务的正常运行，同时也保持了客户和大部分客户的得到正确的相应。\r\n\r\n- 异同：\r\n\r\n  - 相同点：\r\n\r\n    - 1、为了保证集群大部分服务的可用性和可靠性，防止崩溃，牺牲小我\r\n\r\n    - 2、用户最终都是体验到某个功能不可用\r\n\r\n  - 不同点：\r\n\r\n  - 1、熔断是被调用方故障，触发的系统主动规则\r\n\r\n  - 2、降级是基于全局考虑，停止一些正常服务，释放资源\r\n\r\n- 什么是限流\r\n  - 对打入服务的请求流量进行控制，使服务能够承担不超过自己能力的流量压力\r\n\r\n\r\n\r\n#### 2）、Sentinel 简介\r\n\r\n- 官方文档：https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D\r\n- 项目地址：https://github.com/alibaba/Sentinel\r\n\r\n​        随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\r\n\r\n- Sentinel 具有以下特征:\r\n  - **丰富的应用场景**：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。\r\n  - **完备的实时监控**：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。\r\n  - **广泛的开源生态**：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。\r\n  - **完善的 SPI 扩展点**：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。\r\n\r\n![image-20230426200648761](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426200648761.png)\r\n\r\n- Sentinel 分为两个部分:\r\n  - 核心库（Java 客户端）不依赖任何框架/库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持。\r\n  - 控制台（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的Tomcat 等应用容器。\r\n\r\n- Sentinel 基本概念\r\n- 资源\r\n  - 资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。在接下来的文档中，我们都会用资源来描述代码块。\r\n\r\n> 只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。\r\n\r\n- 规则\r\n  - 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。\r\n\r\n\r\n\r\n### 2、Hystrix 与 Sentinel 比较\r\n\r\n![image-20230426223918898](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426223918898.png)\r\n\r\n\r\n\r\n### 3、整合 Feign+Sentinel 测试熔断降级\r\n\r\nhttps://github.com/alibaba/Sentinel/wiki/%E4%B8%BB%E9%A1%B5\r\n\r\n- 什么是熔断降级\r\n  - 除了流量控制以外，降低调用链路中的不稳定资源也是 Sentinel 的使命之一。由于调用关系的复杂性，如果调用链路中的某个资源出现了不稳定，最终会导致请求发生堆积。\r\n\r\n![image-20230426201450220](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426201450220.png)\r\n\r\n- Sentinel 和 Hystrix 的原则是一致的: 当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间长或异常比例升高的时候，则对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联故障。\r\n\r\n- 熔断降级设计理念\r\n  - 在限制的手段上，Sentinel 和 Hystrix 采取了完全不一样的方法。\r\n  - Hystrix 通过 线程池隔离 的方式，来对依赖（在 Sentinel 的概念中对应 资源）进行了隔离。这样做的好处是资源和资源之间做到了最彻底的隔离。缺点是除了增加了线程切换的成本（过多的线程池导致线程数目过多），还需要预先给各个资源做线程池大小的分配。\r\n\r\n- Sentinel 对这个问题采取了两种手段:\r\n\r\n  - 通过并发线程数进行限制\r\n    - 和资源池隔离的方法不同，Sentinel 通过限制资源并发线程的数量，来减少不稳定资源对其它资源的影响。这样不但没有线程切换的损耗，也不需要您预先分配线程池的大小。当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程数在特定资源上堆积到一定的数量之后，对该资源的新请求就会被拒绝。堆积的线程完成任务后才开始继续接收请求。\r\n\r\n  - 通过响应时间对资源进行降级\r\n    - 除了对并发线程数进行控制以外，Sentinel 还可以通过响应时间来快速降级不稳定的资源。当依赖的资源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新恢复。\r\n\r\n- 整合测试：\r\n\r\nhttps://github.com/alibaba/spring-cloud-alibaba/blob/master/spring-cloud-alibaba-examples/sentinel-example/sentinel-feign-example/readme-zh.md\r\n\r\n\r\n\r\n#### 1）、引入依赖\r\n\r\n```xml\r\n<dependency>\r\n\t<groupId>org.springframework.cloud</groupId>\r\n\t<artifactId>spring-cloud-starter-openfeign</artifactId>\r\n</dependency>\r\n<dependency>\r\n\t<groupId>com.alibaba.cloud</groupId>\r\n\t<artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\r\n</dependency>\r\n```\r\n\r\n\r\n\r\n#### 2）、使用 Nacos 注册中心\r\n\r\n```xml\r\n<dependency>\r\n\t<groupId>com.alibaba.cloud</groupId>\r\n\t<artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\r\n</dependency>\r\n```\r\n\r\n\r\n\r\n#### 3）、定义 fallback 实现\r\n\r\n- 在服务消费者中，实现 feign 远程接口，接口的实现方法即为调用错误的容错方法\r\n\r\n```java\r\npublic class OrderFeignServiceFallBack implements OrderFeignService {\r\n\t@Override\r\n\tpublic Resp<OrderVo> getOrderInfo(String orderSn) {\r\n\t\treturn null;\r\n\t}\r\n}\r\n```\r\n\r\n\r\n\r\n#### 4）、定义 fallbackfactory 并放在容器中\r\n\r\n```java\r\n@Component\r\npublic class OrderFeignFallbackFactory implements FallbackFactory<OrderFeignServiceFallBack> {\r\n\t@Override\r\n\tpublic OrderFeignServiceFallBack create(Throwable throwable) {\r\n\t\treturn new OrderFeignServiceFallBack(throwable);\r\n\t}\r\n}\r\n```\r\n\r\n\r\n\r\n#### 5）、改造 fallback 类接受异常并实现容错方法\r\n\r\n```java\r\npublic class OrderFeignServiceFallBack implements OrderFeignService {\r\n\tprivate Throwable throwable;\r\n\tpublic OrderFeignServiceFallBack(Throwable throwable){\r\n\t\tthis.throwable = throwable;\r\n\t}\r\n\r\n\t@Override\r\n\tpublic Resp<OrderVo> getOrderInfo(String orderSn) {\r\n\t\treturn Resp.fail(new OrderVo());\r\n\t}\r\n}\r\n```\r\n\r\n\r\n\r\n#### 6、远程接口配置 feign 客户端容错\r\n\r\n```java\r\n@FeignClient(value = \"gulimall-oms\",fallbackFactory = OrderFeignFallbackFactory.class)\r\npublic interface OrderFeignService {\r\n\t@GetMapping(\"/oms/order/bysn/{orderSn}\")\r\n\tpublic Resp<OrderVo> getOrderInfo(@PathVariable(\"orderSn\") StringorderSn);\r\n}\r\n```\r\n\r\n\r\n\r\n#### 7）、开启 sentinel 代理 feign 功能；在 application.properties 中配置\r\n\r\n```properties\r\nfeign.sentinel.enabled=true\r\n```\r\n\r\n- 测试熔断效果。当远程服务出现问题，会自动调用回调方法返回默认数据，并且更快的容错方式\r\n\r\n##### i）、使用@SentinelResource，并定义 fallback\r\n\r\n```java\r\n@SentinelResource(value = \"order\",fallback = \"e\")\r\n```\r\n\r\n- Fallback 和原方法签名一致，但是最多多一个 Throwable 类型的变量接受异常。\r\n\r\nhttps://github.com/alibaba/Sentinel/wiki/%E6%B3%A8%E8%A7%A3%E6%94%AF%E6%8C%81\r\n\r\n- 需要给容器中配置注解切面\r\n\r\n```java\r\n@Bean\r\npublic SentinelResourceAspect sentinelResourceAspect() {\r\n\treturn new SentinelResourceAspect();\r\n}\r\n```\r\n\r\n- 在控制台添加降级策略\r\n\r\n![image-20230426203412661](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426203412661.png)\r\n\r\n\r\n\r\n##### ii）、测试降级效果\r\n\r\n- 当远程服务停止，前几个服务会尝试调用远程服务，满足降级策略条件以后则不会再尝试调用远程服务\r\n\r\n\r\n\r\n### 4、整合 Sentinel 测试限流（流量控制）\r\n\r\nhttps://github.com/alibaba/spring-cloud-alibaba/blob/master/spring-cloud-alibaba-examples/sentinel-example/sentinel-core-example/readme-zh.md\r\n\r\n- 什么是流量控制\r\n\r\n​\t\t流量控制在网络传输中是一个常用的概念，它用于调整网络包的发送数据。然而，从系统稳定性角度考虑，在处理请求的速度上，也有非常多的讲究。任意时间到来的请求往往是随机不可控的，而系统的处理能力是有限的。我们需要根据系统的处理能力对流量进行控制。\r\n\r\n- Sentinel 作为一个调配器，可以根据需要把随机的请求调整成合适的形状，如下图所示：\r\n\r\n![image-20230426203735032](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426203735032.png)\r\n\r\n- 流量控制设计理念\r\n\r\n  - 流量控制有以下几个角度:\r\n\r\n    - 资源的调用关系，例如资源的调用链路，资源和资源之间的关系；\r\n\r\n    - 运行指标，例如 QPS、线程池、系统负载等；\r\n\r\n    - 控制的效果，例如直接限流、冷启动、排队等。\r\n\r\n- Sentinel 的设计理念是让您自由选择控制的角度，并进行灵活组合，从而达到想要的效果。\r\n\r\n#### 1）、引入 Sentinel starter\r\n\r\n```xml\r\n<dependency>\r\n\t<groupId>com.alibaba.cloud</groupId>\r\n\t<artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\r\n</dependency>\r\n```\r\n\r\n\r\n\r\n#### 2）、接入限流埋点\r\n\r\n- HTTP 埋点\r\n  - Sentinel starter 默认为所有的 HTTP 服务提供了限流埋点，如果只想对 HTTP 服务进行限流，那么只需要引入依赖，无需修改代码。\r\n\r\n- 自定义埋点\r\n  - 如果需要对某个特定的方法进行限流或降级，可以通过 @SentinelResource 注解来完成限流的埋点，示例代码如下：\r\n\r\n```java\r\n@SentinelResource(\"resource\")\r\npublic String hello() {\r\nreturn \"Hello\";\r\n}\r\n```\r\n\r\n> 当然也可以通过原始的 SphU.entry(xxx) 方法进行埋点，可以参见Sentinel 文 档（ https://github.com/alibaba/Sentinel/wiki/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8#%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90 ）。\r\n\r\n\r\n\r\n#### 3）、配置限流规则\r\n\r\n- Sentinel 提供了两种配置限流规则的方式：代码配置 和 控制台配置。\r\n- 通过代码来实现限流规则的配置。一个简单的限流规则配置示例代码如下，更多限流规则配置详情请参考 Sentinel 文档。\r\n  - （ https://github.com/alibaba/Sentinel/wiki/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8#%E5%AE%9A%E4%B9%89%E8%A7%84%E5%88%99 ）\r\n\r\n\r\n```java\r\nList<FlowRule> rules = new ArrayList<FlowRule>();\r\nFlowRule rule = new FlowRule();\r\nrule.setResource(str);\r\n// set limit qps to 10\r\nrule.setCount(10);\r\nrule.setGrade(RuleConstant.FLOW_GRADE_QPS);\r\nrule.setLimitApp(\"default\");\r\nrules.add(rule);\r\nFlowRuleManager.loadRules(rules);\r\n```\r\n\r\n- 通过控制台进行限流规则配置\r\n  - 1、下载控制台：http://edas-public.oss-cn-hangzhou.aliyuncs.com/install_package/demo/sentinel-dashboard.jar\r\n  - 2、启动控制台，执行 Java 命令 java -jar sentinel-dashboard.jar 完成 Sentinel 控制台的启动。 控制台默认的监听端口为 8080。\r\n\r\n\r\n\r\n#### 4）、启动应用并配置\r\n\r\n- 增加配置，在应用的 /src/main/resources/application.properties 中添加基本配置信息\r\n\r\n```properties\r\nspring.application.name=sentinel-example\r\nserver.port=18083\r\nspring.cloud.sentinel.transport.dashboard=localhost:8080\r\n```\r\n\r\n\r\n\r\n#### 5）、控制台配置限流规则并验证\r\n\r\n- 访问 http://localhost:8080 页面。\r\n\r\n![image-20230426204723727](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426204723727.png)\r\n\r\n- 如果您在控制台没有找到应用，请调用一下进行了 Sentinel 埋点的 URL 或方法，因为 Sentinel 使用了 lazy load 策略。\r\n- 任意发送请求，可以在簇点链路里面看到刚才的请求，可以对请求进行流控；\r\n\r\n![image-20230426204910942](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426204910942.png)\r\n\r\n- 测试流控效果\r\n\r\n![image-20230426204933235](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426204933235.png)\r\n\r\n\r\n\r\n#### 6）、自定义流控响应\r\n\r\n```java\r\npublic enum BizCodeEnum {\r\n\t...\r\n    TOO_MANY_REQUESTS(10003, \"请求流量过大\"),\r\n    ...\r\n}\r\n```\r\n\r\n```java\r\n/**\r\n * Sentinel配置自定义异常返回结果\r\n * @author Klaus\r\n * @date 2023/3/12\r\n */\r\n@Configuration\r\npublic class OrderSentinelConfig {\r\n\r\n    public OrderSentinelConfig(){\r\n        WebCallbackManager.setUrlBlockHandler(new UrlBlockHandler() {\r\n            @Override\r\n            public void blocked(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, BlockException e) throws IOException {\r\n                R error = R.error(BizCodeEnum.TOO_MANY_REQUESTS.getCode(), BizCodeEnum.TOO_MANY_REQUESTS.getMsg());\r\n                httpServletResponse.setCharacterEncoding(\"UTF-8\");\r\n                httpServletResponse.setContentType(\"application/json\");\r\n                httpServletResponse.getWriter().write(JSON.toJSONString(error));\r\n            }\r\n        });\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n#### 7）、持久化流控规则\r\n\r\n- 默认的流控规则是保存在项目的内存中，项目停止再启动，流控规则就是失效。我们可以持久化保存规则；\r\n\r\nhttps://github.com/alibaba/Sentinel/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%99%E6%89%A9%E5%B1%95#datasource-%E6%89%A9%E5%B1%95\r\n\r\n- 生产环境使用模式：\r\n- 我们推荐**通过控制台设置规则后将规则推送到统一的规则中心，客户端实现 ReadableDataSource 接口端监听规则中心实时获取变更**\r\n\r\n![image-20230426205909812](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426205909812.png)\r\n\r\n- 解决方案：\r\n  - DataSource 扩展常见的实现方式有:\r\n    - 拉模式：客户端主动向某个规则管理中心定期轮询拉取规则，这个规则中心可以是RDBMS、文件，甚至是 VCS 等。这样做的方式是简单，缺点是无法及时获取变更；\r\n    - 推模式：规则中心统一推送，客户端通过注册监听器的方式时刻监听变化，比如使用Nacos、Zookeeper 等配置中心。这种方式有更好的实时性和一致性保证。\r\n\r\n- 推模式：使用 Nacos 配置规则\r\n- 1、引入依赖\r\n\r\n```xml\r\n<dependency>\r\n\t<groupId>com.alibaba.csp</groupId>\r\n\t<artifactId>sentinel-datasource-nacos</artifactId>\r\n\t<version>1.6.3</version>\r\n</dependency>\r\n```\r\n\r\n- 2、编写配置类\r\n\r\nhttps://github.com/alibaba/Sentinel/wiki/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%99%E6%89%A9%E5%B1%95#%E6%8E%A8%E6%A8%A1%E5%BC%8F%E4%BD%BF%E7%94%A8-nacos-%E9%85%8D%E7%BD%AE%E8%A7%84%E5%88%99\r\n\r\n```java\r\n@Configuration\r\npublic class SentinelConfig {\r\n\tpublic SentinelConfig(){\r\n        //1、加载流控策略\r\n        ReadableDataSource<String, List<FlowRule>> flowRuleDataSource = new\r\n        NacosDataSource<>(\"127.0.0.1:8848\", \"demo\", \"sentinel\",\r\n        source -> JSON.parseObject(source, new TypeReference<List<FlowRule>>() {}));\r\n        FlowRuleManager.register2Property(flowRuleDataSource.getProperty());\r\n\r\n        //2、加载降级策略\r\n        ReadableDataSource<String, List<DegradeRule>> degradeRuleDataSource =\r\n        new NacosDataSource<>(\"127.0.0.1:8848\", \"demo\", \"sentinel\",\r\n        source -> JSON.parseObject(source, new TypeReference<List<DegradeRule>>() {}));\r\n        DegradeRuleManager.register2Property(degradeRuleDataSource.getProperty());\r\n        //3、加载系统规则\r\n        ReadableDataSource<String, List<SystemRule>> systemRuleDataSource =\r\n        new NacosDataSource<>(\"127.0.0.1:8848\", \"demo\", \"sentinel\",\r\n        source -> JSON.parseObject(source, new TypeReference<List<SystemRule>>() {}));\r\n        SystemRuleManager.register2Property(systemRuleDataSource.getProperty());\r\n        //4、加载权限策略\r\n        ReadableDataSource<String, List<AuthorityRule>> authorityRuleDataSource = new \t\t             NacosDataSource<>(\"127.0.0.1:8848\", \"demo\", \"sentinel\",\r\n        source -> JSON.parseObject(source, new TypeReference<List<AuthorityRule>>() {}));\r\n        AuthorityRuleManager.register2Property(authorityRuleDataSource.getProperty());\r\n\t}\r\n}\r\n```\r\n\r\n> 参照 https://github.com/alibaba/Sentinel/wiki/Dynamic-Rule-Configuration 查看更多控制规则\r\n\r\n- 3、在 nacos 中创建 dataId，并使用 json 格式\r\n\r\n![image-20230426210614070](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426210614070.png)\r\n\r\n- 4、添加一条流控规则测试\r\n\r\n```json\r\n[\r\n    {\r\n        \"resource\": \"/ums/member/list\",\r\n        \"limitApp\": \"default\",\r\n        \"grade\": 1,\r\n        \"count\": 5,\r\n        \"strategy\": 0,\r\n        \"controlBehavior\": 0,\r\n        \"clusterMode\": false\r\n    }\r\n]\r\n```\r\n\r\n- 配置含义说明：\r\n\r\n  https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6\r\n\r\n  - resource：资源名，即限流规则的作用对象\r\n\r\n  - count: 限流阈值\r\n\r\n  - grade: 限流阈值类型（QPS 或并发线程数）\r\n\r\n  - limitApp: 流控针对的调用来源，若为 default 则不区分调用来源\r\n\r\n  - strategy: 调用关系限流策略\r\n\r\n  - controlBehavior: 流量控制效果（直接拒绝、Warm Up、匀速排队）\r\n\r\n- 5、系统规则，降级规则等均可添加\r\n\r\n```json\r\n[\r\n    {\r\n        \"resource\": \"/ums/member/list\",\r\n        \"limitApp\": \"default\",\r\n        \"grade\": 1,\r\n        \"count\": 5,\r\n        \"strategy\": 0,\r\n        \"controlBehavior\": 0,\r\n        \"clusterMode\": false\r\n    },\r\n    {\r\n        \"highestSystemLoad\": -1,\r\n        \"highestCpuUsage\": 0.99,\r\n        \"qps\": 2,\r\n        \"avgRt\": 10,\r\n        \"maxThread\": 10\r\n    }\r\n]\r\n```\r\n\r\n\r\n\r\n- 6、最终效果\r\n  - Sentinel 控制台改变流控规则，不能推送到 nacos 中，Nacos 中改变流控规则可以实时观察到变化\r\n\r\n![image-20230426211149631](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426211149631.png)\r\n\r\n- 第 2 步 API 的方式，可以直接变为配置方式；在 application.properties 中配置\r\n\r\n```properties\r\nspring.cloud.sentinel.datasource.ds.nacos.server-addr=127.0.0.1:8848\r\nspring.cloud.sentinel.datasource.ds.nacos.data-id=sentinel\r\nspring.cloud.sentinel.datasource.ds.nacos.group-id=demo\r\nspring.cloud.sentinel.datasource.ds.nacos.rule-type=flow\r\nspring.cloud.sentinel.datasource.ds1.nacos.server-addr=127.0.0.1:8848\r\nspring.cloud.sentinel.datasource.ds1.nacos.data-id=sentinel\r\nspring.cloud.sentinel.datasource.ds1.nacos.group-id=demo\r\nspring.cloud.sentinel.datasource.ds1.nacos.rule-type=system\r\n```\r\n\r\n> ds,ds1 是随便写的。\r\n\r\n\r\n\r\n## 5、SpringCloud Alibaba-Seata\r\n\r\n### 1、简介\r\n\r\n- Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。\r\n\r\nhttps://seata.io/zh-cn/\r\n\r\n\r\n\r\n### 2、核心概念\r\n\r\n- TC - 事务协调者\r\n  - 维护全局和分支事务的状态，驱动全局事务提交或回滚。\r\n\r\n- TM - 事务管理器\r\n  - 定义全局事务的范围：开始全局事务、提交或回滚全局事务。\r\n\r\n- RM - 资源管理器\r\n  - 管理分支事务处理的资源，与 TC 交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。\r\n- 工作原理：\r\n\r\n![image-20230322152804762](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230322152804762.png)\r\n\r\n\r\n\r\n### 3、使用步骤（测试 AT 模式）\r\n\r\n#### 1、为每个服务创建 undo_log 表\r\n\r\n```sql\r\nDROP TABLE IF EXISTS `undo_log`;\r\nCREATE TABLE `undo_log` (\r\n`id` bigint(20) NOT NULL AUTO_INCREMENT,\r\n`branch_id` bigint(20) NOT NULL,\r\n`xid` varchar(100) NOT NULL,\r\n`context` varchar(128) NOT NULL,\r\n`rollback_info` longblob NOT NULL,\r\n`log_status` int(11) NOT NULL,\r\n`log_created` datetime NOT NULL,\r\n`log_modified` datetime NOT NULL,\r\n`ext` varchar(100) DEFAULT NULL,\r\nPRIMARY KEY (`id`),\r\nUNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)\r\n) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;\r\n```\r\n\r\n\r\n\r\n#### 2、需要分布式事务的服务导入 seata-starter\r\n\r\n```xml\r\n<dependency>\r\n\t<groupId>com.alibaba.cloud</groupId>\r\n    <artifactId>spring-cloud-alibaba-seata</artifactId>\r\n    <version>2.0.0.RELEASE</version>\r\n</dependency>\r\n```\r\n\r\n\r\n\r\n#### 3、使用 seata 数据源代理原数据源\r\n\r\n```java\r\n  @Configuration\r\n  public class DataSourceConfig {\r\n  \t  @Bean\r\n      @ConfigurationProperties(prefix = \"spring.datasource\")\r\n      public DruidDataSource druidDataSource() {\r\n      return new DruidDataSource();\r\n  }\r\n      /**\r\n      * 需要将 DataSourceProxy 设置为主数据源，否则事务无法回滚\r\n      *\r\n      * @param druidDataSource The DruidDataSource\r\n      * @return The default datasource\r\n      */\r\n      @Primary\r\n      @Bean(\"dataSource\")\r\n      public DataSource dataSource(DruidDataSource druidDataSource) {\r\n     \t return new DataSourceProxy(druidDataSource);\t\r\n      }\r\n  }\r\n```\r\n\r\n  \r\n\r\n#### 4、给微服务加入 file.conf 和 registry.conf\r\n\r\n```java\r\nregistry.conf\r\nregistry {\r\n\r\n    # file 、nacos 、eureka、redis、zk\r\n    type = \"file\"\r\n    nacos {\r\n    serverAddr = \"localhost\"\r\n    namespace = \"public\"\r\n    cluster = \"default\"\r\n    }\r\n    eureka {\r\n    serviceUrl = \"http://localhost:1001/eureka\"\r\n    application = \"default\"\r\n    weight = \"1\"\r\n    }\r\n    redis {\r\n    serverAddr = \"localhost:6381\"\r\n    db = \"0\"\r\n    }\r\n    zk {\r\n    cluster = \"default\"\r\n    serverAddr = \"127.0.0.1:2181\"\r\n    session.timeout = 6000\r\n    connect.timeout = 2000\r\n    }\r\n    file {\r\n    name = \"file.conf\"\r\n    }\r\n}\r\nconfig {\r\n    # file、nacos 、apollo、zk\r\n    type = \"file\"\r\n    nacos {\r\n    serverAddr = \"localhost\"\r\n    namespace = \"public\"\r\n    cluster = \"default\"\r\n    }\r\n    apollo {\r\n    app.id = \"fescar-server\"\r\n    apollo.meta = \"http://192.168.1.204:8801\"\r\n    }\r\n    zk {\r\n    serverAddr = \"127.0.0.1:2181\"\r\n    session.timeout = 6000\r\n    connect.timeout = 2000\r\n    }\r\n    file {\r\n    name = \"file.conf\"\r\n    }\r\n}\r\n\r\nfile.conf\r\ntransport {\r\n    # tcp udt unix-domain-socket\r\n    type = \"TCP\"\r\n    #NIO NATIVE\r\n    server = \"NIO\"\r\n    #enable heartbeat\r\n    heartbeat = true\r\n    #thread factory for netty\r\n    thread-factory {\r\n    boss-thread-prefix = \"NettyBoss\"\r\n    worker-thread-prefix = \"NettyServerNIOWorker\"\r\n    server-executor-thread-prefix = \"NettyServerBizHandler\"\r\n    share-boss-worker = false\r\n    client-selector-thread-prefix = \"NettyClientSelector\"\r\n    client-selector-thread-size = 1\r\n    client-worker-thread-prefix = \"NettyClientWorkerThread\"\r\n    # netty boss thread size,will not be used for UDT\r\n    boss-thread-size = 1\r\n    #auto default pin or 8\r\n    worker-thread-size = 8\r\n}\r\nshutdown {\r\n    # when destroy server, wait seconds\r\n    wait = 3\r\n}\r\nserialization = \"seata\"\r\ncompressor = \"none\"\r\n}\r\nservice {\r\n    #vgroup->rgroup\r\n    vgroup_mapping.order-service-fescar-service-group=\"default\"\r\n    #only support single node\r\n    default.grouplist = \"127.0.0.1:8091\"\r\n    #degrade current not support\r\n    enableDegrade = false\r\n    #disable\r\n    disable = false\r\n    #unit ms,s,m,h,d represents milliseconds, seconds, minutes, hours, days, default permanent\r\n    max.commit.retry.timeout = \"-1\"\r\n    max.rollback.retry.timeout = \"-1\"\r\n    disableGlobalTransaction = false\r\n}\r\nclient {\r\n    async.commit.buffer.limit = 10000\r\n    lock {\r\n    retry.internal = 10\r\n    retry.times = 30\r\n    }\r\n    report.retry.count = 5\r\n    tm.commit.retry.count = 1\r\n    tm.rollback.retry.count = 1\r\n}\r\ntransaction {\r\n    undo.data.validation = true\r\n    undo.log.serialization = \"jackson\"\r\n    undo.log.save.days = 7\r\n    #schedule delete expired undo_log in milliseconds\r\n    undo.log.delete.period = 86400000\r\n    undo.log.table = \"undo_log\"\r\n}\r\nsupport {\r\n    ## spring\r\n    spring {\r\n        # auto proxy the DataSource bean\r\n        datasource.autoproxy = false\r\n    }\r\n}\r\n```\r\n\r\n\r\n\r\n#### 5、启动 seata 服务器\r\n\r\n- 从 https://github.com/seata/seata/releases ,下载服务器软件包，将其解压缩。\r\n\r\n\r\n\r\n#### 6、使用事务注解\r\n\r\n- @GlobalTransactional：标注在总事务中，其他分支事务，继续使用@Transactional 即可\r\n\r\n\r\n\r\n#### 7、测试回滚效果\r\n\r\n- 测试本地事务出现问题后，远程事务是否可以回滚\r\n\r\n\r\n\r\n#### 8、官方更多示例\r\n\r\n- https://github.com/seata/seata-samples/tree/master/springcloud-nacos-seata 整合 nacos\r\n\r\n- https://github.com/seata/seata-samples/tree/master/springcloud-jpa-seata 整合 jpa\r\n- https://github.com/seata/seata-samples/tree/master/springboot-dubbo-seata 整合 dubbo\r\n- https://github.com/seata/seata-samples/tree/master/springboot-shardingsphere-seata\r\n\r\n\r\n\r\n\r\n\r\n## 6、SpringCloud Alibaba-OSS\r\n\r\n### 1、简介\r\n\r\n对象存储服务（Object Storage Service，OSS）是一种海量、安全、低成本、高可靠的云存储服务，适合存放任意类型的文件。容量和处理能力弹性扩展，多种存储类型供选择，全面优化存储成本。\r\n\r\n\r\n\r\n### 2、使用步骤\r\n\r\n#### 1、开通阿里云对象存储服务\r\n\r\n![image-20230426213046758](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426213046758.png)\r\n\r\nhttps://www.aliyun.com/product/oss\r\n\r\n\r\n\r\n#### 2、引入 SpringCloud Alibaba-OSS\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>com.alibaba.cloud</groupId>\r\n    <artifactId>spring-cloud-alicloud-oss</artifactId>\r\n</dependency>\r\n```\r\n\r\n\r\n\r\n#### 3、配置阿里云 oss 相关的账号信息\r\n\r\n```yaml\r\nspring:\r\n    cloud:\r\n        alicloud:\r\n            oss:\r\n            \tendpoint: oss-cn-shanghai.aliyuncs.com\r\n            access-key: xxxxxx\r\n            secret-key: xxxxxx\r\n```\r\n\r\n> 注意：必须申请 RAM 账号信息，并且分配 OSS 操作权限\r\n\r\n\r\n\r\n#### 4、测试使用 OssClient 上传\r\n\r\n```java\r\n@Autowired\r\nOSSClient ossClient;\r\n@Test\r\npublic void contextLoads2() throws FileNotFoundException {\r\n    InputStream inputStream = new\r\n    FileInputStream(\"C:\\\\Users\\\\lfy\\\\Pictures\\\\bug.jpg\");\r\n    ossClient.putObject(\"gulimall\", \"aaa/bug222.jpg\", inputStream);\r\n    System.out.println(\"ok\");\r\n}\r\n```\r\n\r\n\r\n\r\n# 二、SpringCloud\r\n\r\n## 1、Feign 声明式远程调用\r\n\r\n### 1、简介\r\n\r\n- Feign 是一个声明式的 HTTP 客户端，它的目的就是让远程调用更加简单。Feign 提供了 HTTP请求的模板，通过编写简单的接口和插入注解，就可以定义好 HTTP 请求的参数、格式、地址等信息。\r\n- Feign 整合了 Ribbon（负载均衡）和 Hystrix(服务熔断)，可以让我们不再需要显式地使用这两个组件。\r\n- SpringCloudFeign 在 NetflixFeign 的基础上扩展了对 SpringMVC 注解的支持，在其实现下，我们只需创建一个接口并用注解的方式来配置它，即可完成对服务提供方的接口绑定。简化了SpringCloudRibbon 自行封装服务调用客户端的开发量。\r\n\r\n\r\n\r\n### 2、使用\r\n\r\n- 1、引入依赖\r\n\r\n```xml\r\n<dependency>\r\n  <groupId>org.springframework.cloud</groupId>\r\n  <artifactId>spring-cloud-starter-openfeign</artifactId>\r\n</dependency>\r\n```\r\n\r\n- 2、开启 feign 功能\r\n\r\n```java\r\n@EnableFeignClients(basePackages = \"com.atguigu.gulimall.pms.feign\")\r\n```\r\n\r\n- 3、声明远程接口\r\n\r\n```java\r\n@FeignClient(\"gulimall-ware\")\r\npublic interface WareFeignService {\r\n\t@PostMapping(\"/ware/waresku/skus\")\r\n\tpublic Resp<List<SkuStockVo>> skuWareInfos(@RequestBody List<Long> skuIds);\r\n}\r\n```\r\n\r\n\r\n\r\n### 3、原理\r\n\r\n![image-20230426214256506](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426214256506.png)\r\n\r\n\r\n\r\n## 2、Gateway\r\n\r\n### 1、简介\r\n\r\n- 网关作为流量的入口，常用功能包括路由转发、权限校验、限流控制等。而 springcloud gateway 作为 SpringCloud 官方推出的第二代网关框架，取代了 Zuul 网关。\r\n\r\n![image-20230426214409516](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426214409516.png)\r\n\r\n- 网关提供 API 全托管服务，丰富的 API 管理功能，辅助企业管理大规模的 API，以降低管理成本和安全风险，包括协议适配、协议转发、安全策略、防刷、流量、监控日志等功能。\r\n- Spring Cloud Gateway 旨在提供一种简单而有效的方式来对 API 进行路由，并为他们提供切面，例如：安全性，监控/指标 和弹性等。\r\n- 官方文档地址：\r\n\r\nhttps://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.1.3.RELEASE/single/spring-cloud-gateway.html\r\n\r\n- Spring Cloud Gateway 特点:\r\n\r\n  - 基于 Spring5，支持响应式编程和 SpringBoot2.0\r\n\r\n  - 支持使用任何请求属性进行路由匹配\r\n\r\n  - 特定于路由的断言和过滤器\r\n\r\n  - 集成 Hystrix 进行断路保护\r\n\r\n  - 集成服务发现功能\r\n\r\n  - 易于编写 Predicates 和 Filters\r\n\r\n  - 支持请求速率限制\r\n\r\n  - 支持路径重写\r\n\r\n- 思考：\r\n- 为什么使用 API 网关？\r\n- API 网关出现的原因是微服务架构的出现，不同的微服务一般会有不同的网络地址，而外部客户端可能需要调用多个服务的接口才能完成一个业务需求，如果让客户端直接与各个微服务通信，会有以下的问题：\r\n  - 客户端会多次请求不同的微服务，增加了客户端的复杂性。\r\n  - 存在跨域请求，在一定场景下处理相对复杂。\r\n  - 认证复杂，每个服务都需要独立认证。\r\n  - 难以重构，随着项目的迭代，可能需要重新划分微服务。例如，可能将多个服务合并成一个或者将一个服务拆分成多个。如果客户端直接与微服务通信，那么重构将会很难实施。\r\n  - 某些微服务可能使用了防火墙 / 浏览器不友好的协议，直接访问会有一定的困难。\r\n- 以上这些问题可以借助 API 网关解决。API 网关是介于客户端和服务器端之间的中间层，所有的外部请求都会先经过 API 网关这一层。也就是说，API 的实现方面更多的考虑业务逻辑，而安全、性能、监控可以交由 API 网关来做，这样既提高业务灵活性又不缺安全性：使用 API 网关后的优点如下：\r\n  - 易于监控。可以在网关收集监控数据并将其推送到外部系统进行分析。\r\n  - 易于认证。可以在网关上进行认证，然后再将请求转发到后端的微服务，而无须在每个微服务中进行认证。\r\n  - 减少了客户端与各个微服务之间的交互次数。\r\n\r\n\r\n\r\n### 2、核心概念\r\n\r\n- 路由。路由是网关最基础的部分，路由信息有一个 ID、一个目的 URL、一组断言和一组Filter 组成。如果断言路由为真，则说明请求的 URL 和配置匹配\r\n- 断言。Java8 中的断言函数。Spring Cloud Gateway 中的断言函数输入类型是 Spring5.0 框架中的 ServerWebExchange。Spring Cloud Gateway 中的断言函数允许开发者去定义匹配来自于 http request 中的任何信息，比如请求头和参数等。\r\n- 过滤器。一个标准的 Spring webFilter。Spring cloud gateway 中的 filter 分为两种类型的Filter，分别是 Gateway Filter 和 Global Filter。过滤器 Filter 将会对请求和响应进行修改处理\r\n\r\n**工作原理：**\r\n\r\n![image-20230426215740384](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426215740384.png)\r\n\r\n> 客户端发送请求给网关，弯管 HandlerMapping 判断是否请求满足某个路由，满足就发给网关的 WebHandler。这个 WebHandler 将请求交给一个过滤器链，请求到达目标服务之前，会执行所有过滤器的 pre 方法。请求到达目标服务处理之后再依次执行所有过滤器的 post 方法\r\n>\r\n> 一句话：**满足某些断言（predicates）就路由到指定的地址（uri），使用指定的过滤器（filter）**\r\n\r\n\r\n\r\n### 3、使用\r\n\r\n#### 1、HelloWorld\r\n\r\n- 1、创建网关项目，引入网关\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-gateway</artifactId>\r\n</dependency>\r\n```\r\n\r\n- 2、编写网关配置文件\r\n\r\n```yaml\r\nspring:\r\n    cloud:\r\n        gateway:\r\n            routes:\r\n                id: add_request_parameter_route\r\n                uri: https://example.org\r\n                predicates:\r\n                Query=baz\r\n                filters:\r\n                AddRequestParameter=foo, bar\r\n```\r\n\r\n- 3、注意\r\n  - 各种 Predicates 同时存在于同一个路由时，请求必须同时满足所有的条件才被这个路由匹配。\r\n  - 一个请求满足多个路由的谓词条件时，请求只会被首个成功匹配的路由转发\r\n- 4、测试\r\n  - 可以使用 postman 进行测试网关的路由功能\r\n\r\n\r\n\r\n#### 2、断言（Predicates）\r\n\r\n![image-20230426220240928](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426220240928.png)\r\n\r\n\r\n\r\n#### 3、过滤器（filters）\r\n\r\n- 1、GatewayFilter\r\n\r\n![image-20230426220419538](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426220419538.png)\r\n\r\n\r\n\r\n- 2、GlobalFilter\r\n\r\n![image-20230426220449447](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426220449447.png)\r\n\r\n\r\n\r\n## 3、Sleuth+Zipkin 服务链路追踪\r\n\r\n### 1、为什么用\r\n\r\n- 微服务架构是一个分布式架构，它按业务划分服务单元，一个分布式系统往往有很多个服务单元。由于服务单元数量众多，业务的复杂性，如果出现了错误和异常，很难去定位。主要体现在，一个请求可能需要调用很多个服务，而内部服务的调用复杂性，决定了问题难以定位。所以微服务架构中，必须实现分布式链路追踪，去跟进一个请求到底有哪些服务参与，参与的顺序又是怎样的，从而达到每个请求的步骤清晰可见，出了问题，很快定位。\r\n\r\n- 链路追踪组件有 Google 的 Dapper，Twitter 的 Zipkin，以及阿里的 Eagleeye （鹰眼）等，它们都是非常优秀的链路追踪开源组件。\r\n\r\n\r\n\r\n### 2、基本术语\r\n\r\n- Span（跨度）：基本工作单元，发送一个远程调度任务 就会产生一个 Span，Span 是一个 64 位 ID 唯一标识的，Trace 是用另一个 64 位 ID 唯一标识的，Span 还有其他数据信息，比如摘要、时间戳事件、Span 的 ID、以及进度 ID。\r\n- Trace（跟踪）：一系列 Span 组成的一个树状结构。请求一个微服务系统的 API 接口，这个 API 接口，需要调用多个微服务，调用每个微服务都会产生一个新的 Span，所有由这个请求产生的 Span 组成了这个 Trace。\r\n- Annotation（标注）：用来及时记录一个事件的，一些核心注解用来定义一个请求的开\r\n- 始和结束 。这些注解包括以下：\r\n  - cs - Client Sent -客户端发送一个请求，这个注解描述了这个 Span 的开始\r\n  - sr - Server Received -服务端获得请求并准备开始处理它，如果将其 sr 减去 cs 时间戳便可得到网络传输的时间。\r\n  - ss - Server Sent （服务端发送响应）–该注解表明请求处理的完成(当请求返回客户端)，如果 ss 的时间戳减去 sr 时间戳，就可以得到服务器请求的时间。\r\n  - cr - Client Received （客户端接收响应）-此时 Span 的结束，如果 cr 的时间戳减去cs 时间戳便可以得到整个请求所消耗的时间。\r\n\r\n- 官方文档：\r\n\r\nhttps://cloud.spring.io/spring-cloud-static/spring-cloud-sleuth/2.1.3.RELEASE/single/spring-cloud-sleuth.html\r\n\r\n- 如果服务调用顺序如下\r\n\r\n![image-20230426221503561](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426221503561.png)\r\n\r\n- 那么用以上概念完整的表示出来如下：\r\n\r\n![image-20230426221545654](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426221545654.png)\r\n\r\n- Span 之间的父子关系如下：\r\n\r\n![image-20230426221605154](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426221605154.png)\r\n\r\n\r\n\r\n\r\n\r\n### 3、整合 Sleuth\r\n\r\n- 1、服务提供者与消费者导入依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-sleuth</artifactId>\r\n</dependency>\r\n```\r\n\r\n- 2、打开 debug 日志\r\n\r\n```yaml\r\nlogging:\r\n    level:\r\n        org.springframework.cloud.openfeign: debug\r\n        org.springframework.cloud.sleuth: debug\r\n```\r\n\r\n- 3、发起一次远程调用，观察控制台\r\n  - DEBUG [user-service,541450f08573fff5,541450f08573fff5,false]\r\n  - user-service：服务名\r\n  - 541450f08573fff5：是 TranceId，一条链路中，只有一个 TranceId\r\n  - 541450f08573fff5：是 spanId，链路中的基本工作单元 id\r\n  - false：表示是否将数据输出到其他服务，true 则会把信息输出到其他可视化的服务上观察\r\n\r\n\r\n\r\n### 4、整合 zipkin 可视化观察\r\n\r\n- 通过 Sleuth 产生的调用链监控信息，可以得知微服务之间的调用链路，但监控信息只输出到控制台不方便查看。我们需要一个图形化的工具-zipkin。Zipkin 是 Twitter 开源的分布式跟踪系统，主要用来收集系统的时序数据，从而追踪系统的调用问题。zipkin 官网地址如下：\r\n\r\nhttps://zipkin.io/\r\n\r\n![image-20230426222010516](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426222010516.png)\r\n\r\n- 1、docker 安装 zipkin 服务器\r\n\r\n`docker run -d -p 9411:9411 openzipkin/zipkin`\r\n\r\n- 2、导入\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-zipkin</artifactId>\r\n</dependency>\r\n```\r\n\r\n> zipkin 依赖也同时包含了 sleuth，可以省略 sleuth 的引用\r\n\r\n- 3、添加 zipkin 相关配置\r\n\r\n```yaml\r\nspring:\r\n    application:\r\n  \t  name: user-service\r\n    zipkin:\r\n        base-url: http://192.168.56.10:9411/ # zipkin 服务器的地址\r\n        # 关闭服务发现，否则 Spring Cloud 会把 zipkin 的 url 当做服务名称\r\n        discoveryClientEnabled: false\r\n        sender:\r\n        \ttype: web # 设置使用 http 的方式传输数据\r\n    sleuth:\r\n    \tsampler:\r\n   \t \t\tprobability: 1 # 设置抽样采集率为 100%，默认为 0.1，即 10%\r\n```\r\n\r\n> 发送远程请求，测试 zipkin。\r\n\r\n- 服务调用链追踪信息统计\r\n\r\n![image-20230426222654484](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426222654484.png)\r\n\r\n- 服务依赖信息统计\r\n\r\n![image-20230426222740970](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426222740970.png)\r\n\r\n\r\n\r\n### 5、Zipkin 数据持久化\r\n\r\n- Zipkin 默认是将监控数据存储在内存的，如果 Zipkin 挂掉或重启的话，那么监控数据就会丢失。所以如果想要搭建生产可用的 Zipkin，就需要实现监控数据的持久化。而想要实现数据持久化，自然就是得将数据存储至数据库。好在 Zipkin 支持将数据存储至：\r\n  - 内存（默认）\r\n  - MySQL\r\n  - Elasticsearch\r\n  - Cassandra\r\n- Zipkin 数据持久化相关的官方文档地址如下：\r\n\r\nhttps://github.com/openzipkin/zipkin#storage-component\r\n\r\n\r\n\r\n- Zipkin 支持的这几种存储方式中，内存显然是不适用于生产的，这一点开始也说了。而使用MySQL 的话，当数据量大时，查询较为缓慢，也不建议使用。Twitter 官方使用的是 Cassandra作为 Zipkin 的存储数据库，但国内大规模用 Cassandra 的公司较少，而且 Cassandra 相关文档也不多。\r\n\r\n- 综上，故采用 Elasticsearch 是个比较好的选择，关于使用 Elasticsearch 作为 Zipkin 的存储数据库的官方文档如下：\r\n\r\n  - elasticsearch-storage：\r\n\r\n    https://github.com/openzipkin/zipkin/tree/master/zipkin-server#elasticsearch-storage\r\n\r\n  - zipkin-storage/elasticsearch\r\n\r\n    https://github.com/openzipkin/zipkin/tree/master/zipkin-storage/elasticsearch\r\n\r\n- 通过 docker 的方式\r\n\r\n- `docker run --env STORAGE_TYPE=elasticsearch --env ES_HOSTS=192.168.56.10:9200 openzipkin/zipkin-dependencies`\r\n\r\n![image-20230426224650512](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426224650512.png)\r\n\r\n- 使用 es 时 Zipkin Dependencies 支持的环境变量\r\n\r\n![image-20230426223556598](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230426223556598.png)"},{"title":"系统接口","tags":["Spring Boot","Spring Cloud","gateway","Swagger2","Knife4j"],"categories":["Java","未分类"],"author":"imklaus","excerpt":"\r\n\r\n## 基本介绍\r\n\r\n[参考系统接口实现](http://doc.ruoyi.vip/ruoyi/document/htsc.html#系统接口)\r\n\r\n在现在的开发过程中还有很大一部分公司都是以口口相传的方式来进行前后端的联调，而接口文档很大一部分都只停留在了说说而已的地步，或者写了代码再写文档。 还有一点就是文档的修改，定义好的接口并不是一成不变的，可能在开发过程中文档修改不止一次的变化，这个时候就会很难受了。 只要不是强制性要求，没人会愿意写这东西，而且在写的过程中，一个字母的错误就会导致联调时候的很大麻烦，但是通过`Swagger`，我们可以省略了这一步，而且文档出错率近乎于零， 只要你在写代码的时候，稍加几个注解，文档自动生成。\r\n","link":"/posts/System_interface","content":"\r\n\r\n## 基本介绍\r\n\r\n[参考系统接口实现](http://doc.ruoyi.vip/ruoyi/document/htsc.html#系统接口)\r\n\r\n在现在的开发过程中还有很大一部分公司都是以口口相传的方式来进行前后端的联调，而接口文档很大一部分都只停留在了说说而已的地步，或者写了代码再写文档。 还有一点就是文档的修改，定义好的接口并不是一成不变的，可能在开发过程中文档修改不止一次的变化，这个时候就会很难受了。 只要不是强制性要求，没人会愿意写这东西，而且在写的过程中，一个字母的错误就会导致联调时候的很大麻烦，但是通过`Swagger`，我们可以省略了这一步，而且文档出错率近乎于零， 只要你在写代码的时候，稍加几个注解，文档自动生成。\r\n<!-- more -->\r\n\r\n1、在控制层`Controller`中添加注解来描述接口信息如:\r\n\r\n```java\r\n@Api(\"参数配置\")\r\n@Controller\r\n@RequestMapping(\"/system/config\")\r\npublic class ConfigController\r\n```\r\n\r\n2、在方法中配置接口的标题信息\r\n\r\n```sql\r\n@ApiOperation(\"查询参数列表\")\r\n@ResponseBody\r\npublic TableDataInfo list(Config config)\r\n{\r\n\tstartPage();\r\n\tList<Config> list = configService.selectConfigList(config);\r\n\treturn getDataTable(list);\r\n}\r\n```\r\n\r\n3、在`系统工具-系统接口`测试相关接口\r\n\r\n```\r\n注意：SwaggerConfig可以指定根据注解或者包名扫描具体的API\r\n```\r\n\r\n#### API详细说明\r\n\r\n| 作用范围           | API                | 使用位置                         |\r\n| ------------------ | ------------------ | -------------------------------- |\r\n| 协议集描述         | @Api               | 用于controller类上               |\r\n| 对象属性           | @ApiModelProperty  | 用在出入参数对象的字段上         |\r\n| 协议描述           | @ApiOperation      | 用在controller的方法上           |\r\n| Response集         | @ApiResponses      | 用在controller的方法上           |\r\n| Response           | @ApiResponse       | 用在 @ApiResponses里边           |\r\n| 非对象参数集       | @ApiImplicitParams | 用在controller的方法上           |\r\n| 非对象参数描述     | @ApiImplicitParam  | 用在@ApiImplicitParams的方法里边 |\r\n| 描述返回对象的意义 | @ApiModel          | 用在返回对象类上                 |\r\n\r\n`api`标记，用在类上，说明该类的作用。可以标记一个`Controller`类做为`Swagger`文档资源，使用方式：\r\n\r\n```java\r\n@Api(value = \"/user\", description = \"用户管理\")\r\n```\r\n\r\n与`Controller`注解并列使用。 属性配置：\r\n\r\n| 属性名称       | 备注                                             |\r\n| -------------- | ------------------------------------------------ |\r\n| value          | url的路径值                                      |\r\n| tags           | 如果设置这个值、value的值会被覆盖                |\r\n| description    | 对api资源的描述                                  |\r\n| basePath       | 基本路径可以不配置                               |\r\n| position       | 如果配置多个Api 想改变显示的顺序位置             |\r\n| produces       | For example, \"application/json, application/xml\" |\r\n| consumes       | For example, \"application/json, application/xml\" |\r\n| protocols      | Possible values: http, https, ws, wss.           |\r\n| authorizations | 高级特性认证时配置                               |\r\n| hidden         | 配置为true 将在文档中隐藏                        |\r\n\r\n`ApiOperation`标记，用在方法上，说明方法的作用，每一个`url`资源的定义,使用方式：\r\n\r\n```java\r\n@ApiOperation(\"获取用户信息\")\r\n```\r\n\r\n与`Controller`中的方法并列使用，属性配置：\r\n\r\n| 属性名称          | 备注                                                         |\r\n| ----------------- | ------------------------------------------------------------ |\r\n| value             | url的路径值                                                  |\r\n| tags              | 如果设置这个值、value的值会被覆盖                            |\r\n| description       | 对api资源的描述                                              |\r\n| basePath          | 基本路径可以不配置                                           |\r\n| position          | 如果配置多个Api 想改变显示的顺序位置                         |\r\n| produces          | For example, \"application/json, application/xml\"             |\r\n| consumes          | For example, \"application/json, application/xml\"             |\r\n| protocols         | Possible values: http, https, ws, wss.                       |\r\n| authorizations    | 高级特性认证时配置                                           |\r\n| hidden            | 配置为true将在文档中隐藏                                     |\r\n| response          | 返回的对象                                                   |\r\n| responseContainer | 这些对象是有效的 \"List\", \"Set\" or \"Map\".，其他无效           |\r\n| httpMethod        | \"GET\", \"HEAD\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\" and \"PATCH\" |\r\n| code              | http的状态码 默认 200                                        |\r\n| extensions        | 扩展属性                                                     |\r\n\r\n`ApiParam`标记，请求属性，使用方式：\r\n\r\n```java\r\npublic TableDataInfo list(@ApiParam(value = \"查询用户列表\", required = true)User user)\r\n```\r\n\r\n与Controller中的方法并列使用，属性配置：\r\n\r\n| 属性名称        | 备注         |\r\n| --------------- | ------------ |\r\n| name            | 属性名称     |\r\n| value           | 属性值       |\r\n| defaultValue    | 默认属性值   |\r\n| allowableValues | 可以不配置   |\r\n| required        | 是否属性必填 |\r\n| access          | 不过多描述   |\r\n| allowMultiple   | 默认为false  |\r\n| hidden          | 隐藏该属性   |\r\n| example         | 举例子       |\r\n\r\n`piResponse`标记，响应配置，使用方式：\r\n\r\n```java\r\n@ApiResponse(code = 400, message = \"查询用户失败\")\r\n```\r\n\r\n与`Controller`中的方法并列使用，属性配置：\r\n\r\n| 属性名称          | 备注                             |\r\n| ----------------- | -------------------------------- |\r\n| code              | http的状态码                     |\r\n| message           | 描述                             |\r\n| response          | 默认响应类 Void                  |\r\n| reference         | 参考ApiOperation中配置           |\r\n| responseHeaders   | 参考 ResponseHeader 属性配置说明 |\r\n| responseContainer | 参考ApiOperation中配置           |\r\n\r\n`ApiResponses`标记，响应集配置，使用方式:\r\n\r\n```java\r\n@ApiResponses({ @ApiResponse(code = 400, message = \"无效的用户\") })\r\n```\r\n\r\n与`Controller`中的方法并列使用，属性配置：\r\n\r\n| 属性名称 | 备注                |\r\n| -------- | ------------------- |\r\n| value    | 多个ApiResponse配置 |\r\n\r\n`ResponseHeader`标记，响应头设置，使用方法\r\n\r\n```java\r\n@ResponseHeader(name=\"head\",description=\"响应头设计\")\r\n```\r\n\r\n与`Controller`中的方法并列使用，属性配置：\r\n\r\n| 属性名称          | 备注                   |\r\n| ----------------- | ---------------------- |\r\n| name              | 响应头名称             |\r\n| description       | 描述                   |\r\n| response          | 默认响应类 void        |\r\n| responseContainer | 参考ApiOperation中配置 |\r\n\r\n\r\n\r\n## 如何使用\r\n\r\n1、添加依赖\r\n\r\n```xml\r\n<!-- SpringBoot Web -->\r\n<dependency>\r\n\t<groupId>org.springframework.boot</groupId>\r\n\t<artifactId>spring-boot-starter-web</artifactId>\r\n</dependency>\r\n\r\n<!-- Swagger -->\r\n<dependency>\r\n\t<groupId>io.springfox</groupId>\r\n\t<artifactId>springfox-swagger2</artifactId>\r\n\t<version>${swagger.fox.version}</version>\r\n</dependency>\r\n\r\n<!-- Swagger UI -->\r\n<dependency>\r\n\t<groupId>io.springfox</groupId>\r\n\t<artifactId>springfox-swagger-ui</artifactId>\r\n\t<version>${swagger.fox.version}</version>\r\n</dependency>\r\n```\r\n\r\n2、在`application.yml`添加服务配置\r\n\r\n```yml\r\nserver:\r\n  port: 6666\r\n\r\nspring:\r\n  application:\r\n    name: ruoyi-xxxx\r\n```\r\n\r\n3、在`Application`启动类加入注解`@SpringBootApplication`。\r\n\r\n```java\r\n@EnableSwagger2\r\n@SpringBootApplication\r\npublic class RuoYiSwaggerApplication\r\n{\r\n    public static void main(String[] args)\r\n    {\r\n        SpringApplication.run(RuoYiSwaggerApplication.class, args);\r\n        System.out.println(\"(♥◠‿◠)ﾉﾞ  Swagger启动成功   ლ(´ڡ`ლ)ﾞ  \\n\" +\r\n                \" .-------.       ____     __        \\n\" +\r\n                \" |  _ _   \\\\      \\\\   \\\\   /  /    \\n\" +\r\n                \" | ( ' )  |       \\\\  _. /  '       \\n\" +\r\n                \" |(_ o _) /        _( )_ .'         \\n\" +\r\n                \" | (_,_).' __  ___(_ o _)'          \\n\" +\r\n                \" |  |\\\\ \\\\  |  ||   |(_,_)'         \\n\" +\r\n                \" |  | \\\\ `'   /|   `-'  /           \\n\" +\r\n                \" |  |  \\\\    /  \\\\      /           \\n\" +\r\n                \" ''-'   `'-'    `-..-'              \");\r\n    }\r\n}\r\n```\r\n\r\n4、添加`TestUserController.java`，模拟接口返回用户信息。\r\n\r\n```java\r\nimport org.springframework.web.bind.annotation.GetMapping;\r\nimport org.springframework.web.bind.annotation.RestController;\r\n\r\n@RestController\r\npublic class TestUserController\r\n{\r\n    @GetMapping(\"/user/info\")\r\n    public Object info()\r\n    {\r\n        return \"{\\\"username\\\":\\\"admin\\\",\\\"password\\\":\\\"admin123\\\"}\";\r\n    }\r\n}\r\n```\r\n\r\n5、访问`http://localhost:6666/swagger-ui/index.html`，测试验证接口返回正确数据表示测试通过。\r\n\r\n## 接口模块\r\n\r\n项目中存在`common-swagger`模块，可以直接依赖后使用。\r\n\r\n- `common-swagger`模块：`gulimall-swagger-spring-boot-starter`\r\n\r\n  - 引入依赖\r\n\r\n  ```xml\r\n  <!-- SpringBoot Web -->\r\n  <dependency>\r\n      <groupId>org.springframework.boot</groupId>\r\n      <artifactId>spring-boot-starter-web</artifactId>\r\n  </dependency>\r\n  \r\n  <!-- Swagger -->\r\n  <dependency>\r\n      <groupId>io.springfox</groupId>\r\n      <artifactId>springfox-swagger2</artifactId>\r\n      <version>${swagger.fox.version}</version>\r\n  </dependency>\r\n  ```\r\n\r\n  - 自定义Swagger注解\r\n\r\n  ```java\r\n  @Target({ ElementType.TYPE })\r\n  @Retention(RetentionPolicy.RUNTIME)\r\n  @Documented\r\n  @Inherited\r\n  @Import({ SwaggerAutoConfiguration.class })\r\n  public @interface EnableCustomSwagger2\r\n  {\r\n  \r\n  }\r\n  ```\r\n\r\n  - Swagger相关属性\r\n\r\n  ```java\r\n  /**\r\n   * Swagger 配置\r\n   */\r\n  @Data\r\n  @ConfigurationProperties(\"swagger\")\r\n  public class SwaggerProperties\r\n  {\r\n      /**\r\n       * 是否开启swagger\r\n       */\r\n      private Boolean enabled;\r\n  \r\n      /**\r\n       * swagger会解析的包路径\r\n       **/\r\n      private String basePackage = \"\";\r\n  \r\n      /**\r\n       * swagger会解析的url规则\r\n       **/\r\n      private List<String> basePath = new ArrayList<>();\r\n  \r\n      /**\r\n       * 在basePath基础上需要排除的url规则\r\n       **/\r\n      private List<String> excludePath = new ArrayList<>();\r\n  \r\n      /**\r\n       * 标题\r\n       **/\r\n      private String title = \"\";\r\n  \r\n      /**\r\n       * 描述\r\n       **/\r\n      private String description = \"\";\r\n  \r\n      /**\r\n       * 版本\r\n       **/\r\n      private String version = \"\";\r\n  \r\n      /**\r\n       * 许可证\r\n       **/\r\n      private String license = \"\";\r\n  \r\n      /**\r\n       * 许可证URL\r\n       **/\r\n      private String licenseUrl = \"\";\r\n  \r\n      /**\r\n       * 服务条款URL\r\n       **/\r\n      private String termsOfServiceUrl = \"\";\r\n  \r\n      /**\r\n       * host信息\r\n       **/\r\n      private String host = \"\";\r\n  \r\n      /**\r\n       * 联系人信息\r\n       */\r\n      private Contact contact = new Contact();\r\n  \r\n      /**\r\n       * 全局统一鉴权配置\r\n       **/\r\n      private Authorization authorization = new Authorization();\r\n  \r\n     \r\n  \t@Data\r\n      public static class Contact\r\n      {\r\n          /**\r\n           * 联系人\r\n           **/\r\n          private String name = \"\";\r\n          /**\r\n           * 联系人url\r\n           **/\r\n          private String url = \"\";\r\n          /**\r\n           * 联系人email\r\n           **/\r\n          private String email = \"\";\r\n      }\r\n          \r\n  \t@Data\r\n      public static class Authorization\r\n      {\r\n          /**\r\n           * 鉴权策略ID，需要和SecurityReferences ID保持一致\r\n           */\r\n          private String name = \"\";\r\n  \r\n          /**\r\n           * 需要开启鉴权URL的正则\r\n           */\r\n          private String authRegex = \"^.*$\";\r\n  \r\n          /**\r\n           * 鉴权作用域列表\r\n           */\r\n          private List<AuthorizationScope> authorizationScopeList = new ArrayList<>();\r\n  \r\n          private List<String> tokenUrlList = new ArrayList<>();\r\n  \r\n          \r\n      }\r\n  \r\n      @Data\r\n      public static class AuthorizationScope\r\n      {\r\n          /**\r\n           * 作用域名称\r\n           */\r\n          private String scope = \"\";\r\n  \r\n          /**\r\n           * 作用域描述\r\n           */\r\n          private String description = \"\";\r\n  \r\n  \r\n      }\r\n  }\r\n  ```\r\n\r\n  - swagger配置类\r\n\r\n  ```java\r\n  @Primary\r\n  @Configuration\r\n  @EnableSwagger2\r\n  @EnableConfigurationProperties(SwaggerProperties.class)\r\n  @ConditionalOnProperty(name = \"swagger.enabled\", matchIfMissing = true)\r\n  @Import({SwaggerWebConfiguration.class})\r\n  public class SwaggerAutoConfiguration\r\n  {\r\n      /**\r\n       * 默认的排除路径，排除Spring Boot默认的错误处理路径和端点\r\n       */\r\n      private static final List<String> DEFAULT_EXCLUDE_PATH = Arrays.asList(\"/error\", \"/actuator/**\");\r\n  \r\n      private static final String BASE_PATH = \"/**\";\r\n  \r\n      @Bean\r\n      public Docket api(SwaggerProperties swaggerProperties)\r\n      {\r\n          // base-path处理\r\n          if (swaggerProperties.getBasePath().isEmpty())\r\n          {\r\n              swaggerProperties.getBasePath().add(BASE_PATH);\r\n          }\r\n          // noinspection unchecked\r\n          List<Predicate<String>> basePath = new ArrayList<Predicate<String>>();\r\n          swaggerProperties.getBasePath().forEach(path -> basePath.add(PathSelectors.ant(path)));\r\n  \r\n          // exclude-path处理\r\n          if (swaggerProperties.getExcludePath().isEmpty())\r\n          {\r\n              swaggerProperties.getExcludePath().addAll(DEFAULT_EXCLUDE_PATH);\r\n          }\r\n  \r\n          List<Predicate<String>> excludePath = new ArrayList<>();\r\n          swaggerProperties.getExcludePath().forEach(path -> excludePath.add(PathSelectors.ant(path)));\r\n  \r\n          ApiSelectorBuilder builder = new Docket(DocumentationType.SWAGGER_2).host(swaggerProperties.getHost())\r\n                  .apiInfo(apiInfo(swaggerProperties)).select()\r\n                  .apis(RequestHandlerSelectors.basePackage(swaggerProperties.getBasePackage()));\r\n  \r\n          swaggerProperties.getBasePath().forEach(p -> builder.paths(PathSelectors.ant(p)));\r\n          swaggerProperties.getExcludePath().forEach(p -> builder.paths(PathSelectors.ant(p).negate()));\r\n  \r\n          return builder.build().securitySchemes(securitySchemes()).securityContexts(securityContexts()).pathMapping(\"/\");\r\n      }\r\n  \r\n      /**\r\n       * 安全模式，这里指定token通过Authorization头请求头传递\r\n       */\r\n      private List<SecurityScheme> securitySchemes()\r\n      {\r\n          List<SecurityScheme> apiKeyList = new ArrayList<SecurityScheme>();\r\n          apiKeyList.add(new ApiKey(\"Authorization\", \"Authorization\", \"header\"));\r\n          return apiKeyList;\r\n      }\r\n  \r\n      /**\r\n       * 安全上下文\r\n       */\r\n      private List<SecurityContext> securityContexts()\r\n      {\r\n          List<SecurityContext> securityContexts = new ArrayList<>();\r\n          securityContexts.add(\r\n                  SecurityContext.builder()\r\n                          .securityReferences(defaultAuth())\r\n                          .operationSelector(o -> o.requestMappingPattern().matches(\"/.*\"))\r\n                          .build());\r\n          return securityContexts;\r\n      }\r\n  \r\n      /**\r\n       * 默认的全局鉴权策略\r\n       *\r\n       * @return\r\n       */\r\n      private List<SecurityReference> defaultAuth()\r\n      {\r\n          AuthorizationScope authorizationScope = new AuthorizationScope(\"global\", \"accessEverything\");\r\n          AuthorizationScope[] authorizationScopes = new AuthorizationScope[1];\r\n          authorizationScopes[0] = authorizationScope;\r\n          List<SecurityReference> securityReferences = new ArrayList<>();\r\n          securityReferences.add(new SecurityReference(\"Authorization\", authorizationScopes));\r\n          return securityReferences;\r\n      }\r\n  \r\n      private ApiInfo apiInfo(SwaggerProperties swaggerProperties)\r\n      {\r\n          return new ApiInfoBuilder()\r\n                  .title(swaggerProperties.getTitle())\r\n                  .description(swaggerProperties.getDescription())\r\n                  .license(swaggerProperties.getLicense())\r\n                  .licenseUrl(swaggerProperties.getLicenseUrl())\r\n                  .termsOfServiceUrl(swaggerProperties.getTermsOfServiceUrl())\r\n                  .contact(new Contact(swaggerProperties.getContact().getName(), swaggerProperties.getContact().getUrl(), swaggerProperties.getContact().getEmail()))\r\n                  .version(swaggerProperties.getVersion())\r\n                  .build();\r\n      }\r\n  }\r\n  ```\r\n\r\n  - swagger 资源映射路径\r\n\r\n  ```java\r\n  public class SwaggerWebConfiguration implements WebMvcConfigurer\r\n  {\r\n      @Override\r\n      public void addResourceHandlers(ResourceHandlerRegistry registry)\r\n      {\r\n          /** swagger-ui 地址 */\r\n          registry.addResourceHandler(\"/swagger-ui/**\")\r\n                  .addResourceLocations(\"classpath:/META-INF/resources/webjars/springfox-swagger-ui/\");\r\n      }\r\n  }\r\n  ```\r\n\r\n  - 在src/main/resources/META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports文件中加入Spring容器管理\r\n\r\n  ```tex\r\n  # com.klaus.gulimall.springboot.starter.swagger.config.SwaggerAutoConfiguration\r\n  # com.klaus.gulimall.springboot.starter.swagger.config.SwaggerWebConfiguration\r\n  ```\r\n\r\n  \r\n\r\n1、业务模块添加依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>com.klaus.gulimall</groupId>\r\n    <artifactId>gulimall-swagger-spring-boot-starter</artifactId>\r\n    <version>0.0.1-SNAPSHOT</version>\r\n</dependency>\r\n```\r\n\r\n2、在`xxxx-dev.yml`添加swagger配置\r\n\r\n```yml\r\n# swagger配置\r\nswagger:\r\n  title: 系统模块接口文档\r\n  license: Powered By imklaus\r\n  licenseUrl: https://imlklaus.github.io/\r\n```\r\n\r\n3、在`Application`启动类加入系统接口注解`@EnableCustomSwagger2`\r\n\r\n```java\r\n@EnableCustomConfig\r\n@EnableCustomSwagger2\r\n@EnableRyFeignClients\r\n@SpringCloudApplication\r\npublic class RuoYiSystemApplication\r\n{\r\n    public static void main(String[] args)\r\n    {\r\n        SpringApplication.run(RuoYiSystemApplication.class, args);\r\n        System.out.println(\"(♥◠‿◠)ﾉﾞ  系统模块启动成功   ლ(´ڡ`ლ)ﾞ  \\n\" +\r\n                \" .-------.       ____     __        \\n\" +\r\n                \" |  _ _   \\\\      \\\\   \\\\   /  /    \\n\" +\r\n                \" | ( ' )  |       \\\\  _. /  '       \\n\" +\r\n                \" |(_ o _) /        _( )_ .'         \\n\" +\r\n                \" | (_,_).' __  ___(_ o _)'          \\n\" +\r\n                \" |  |\\\\ \\\\  |  ||   |(_,_)'         \\n\" +\r\n                \" |  | \\\\ `'   /|   `-'  /           \\n\" +\r\n                \" |  |  \\\\    /  \\\\      /           \\n\" +\r\n                \" ''-'   `'-'    `-..-'              \");\r\n    }\r\n}\r\n```\r\n\r\n4、测试验证\r\n\r\n访问`http://{ip}:{port}/swagger-ui/index.html`地址，出现如下图表示成功。\r\n\r\n![swagger](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/up-24a0d329ed368fa86c6da597ed158898e4f.png)\r\n\r\n## 接口聚合\r\n\r\n访问`swagger-ui.html`的时候会发现右上角的`Select a spec`这个下拉选项\r\n\r\n![swagger](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/up-9d740e616ac8523c9d8285ce553689ca20b.png)\r\n\r\n当启动一个`springboot`项目的时候会发现这个下拉选项毫无用处，不过它的强大是在于这个下拉可以用来切换不同项目的`swagger`接口地址，这就实现了使用一个网关的`url`访问所有的项目接口。\r\n\r\n1、网关模块添加依赖\r\n\r\n```xml\r\n<!-- SpringCloud Gateway -->\r\n<dependency>\r\n\t<groupId>org.springframework.cloud</groupId>\r\n\t<artifactId>spring-cloud-starter-gateway</artifactId>\r\n</dependency>\r\n\r\n<!-- SpringCloud Alibaba Nacos -->\r\n<dependency>\r\n\t<groupId>com.alibaba.cloud</groupId>\r\n\t<artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\r\n</dependency>\r\n\t\t\r\n<!-- Swagger UI -->\r\n<dependency>\r\n\t<groupId>io.springfox</groupId>\r\n\t<artifactId>springfox-swagger-ui</artifactId>\r\n\t<version>${swagger.fox.version}</version>\r\n</dependency>\r\n\r\n<!-- Swagger -->\r\n<dependency>\r\n\t<groupId>io.springfox</groupId>\r\n\t<artifactId>springfox-swagger2</artifactId>\r\n\t<version>${swagger.fox.version}</version>\r\n</dependency>\r\n```\r\n\r\n2、网关服务创建一个类`SwaggerProvider.java`实现`SwaggerResourcesProvider`\r\n\r\n```java\r\nimport java.util.ArrayList;\r\nimport java.util.List;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.cloud.gateway.config.GatewayProperties;\r\nimport org.springframework.cloud.gateway.route.RouteLocator;\r\nimport org.springframework.cloud.gateway.support.NameUtils;\r\nimport org.springframework.stereotype.Component;\r\nimport springfox.documentation.swagger.web.SwaggerResource;\r\nimport springfox.documentation.swagger.web.SwaggerResourcesProvider;\r\n\r\n/**\r\n * 聚合系统接口\r\n */\r\n@Component\r\npublic class SwaggerProvider implements SwaggerResourcesProvider\r\n{\r\n    /**\r\n     * Swagger2默认的url后缀\r\n     */\r\n    public static final String SWAGGER2URL = \"/v2/api-docs\";\r\n    /**\r\n     * 网关路由\r\n     */\r\n    @Autowired\r\n    private RouteLocator routeLocator;\r\n\r\n    @Autowired\r\n    private GatewayProperties gatewayProperties;\r\n\r\n    /**\r\n     * 聚合其他服务接口\r\n     * \r\n     * @return\r\n     */\r\n    @Override\r\n    public List<SwaggerResource> get()\r\n    {\r\n        List<SwaggerResource> resourceList = new ArrayList<>();\r\n        List<String> routes = new ArrayList<>();\r\n        // 获取网关中配置的route\r\n        routeLocator.getRoutes().subscribe(route -> routes.add(route.getId()));\r\n        gatewayProperties.getRoutes().stream()\r\n                .filter(routeDefinition -> routes\r\n                        .contains(routeDefinition.getId()))\r\n                .forEach(routeDefinition -> routeDefinition.getPredicates().stream()\r\n                        .filter(predicateDefinition -> \"Path\".equalsIgnoreCase(predicateDefinition.getName()))\r\n                        .filter(predicateDefinition -> !\"ruoyi-auth\".equalsIgnoreCase(routeDefinition.getId()))\r\n                        .forEach(predicateDefinition -> resourceList\r\n                                .add(swaggerResource(routeDefinition.getId(), predicateDefinition.getArgs()\r\n                                        .get(NameUtils.GENERATED_NAME_PREFIX + \"0\").replace(\"/**\", SWAGGER2URL)))));\r\n        return resourceList;\r\n    }\r\n\r\n    private SwaggerResource swaggerResource(String name, String location)\r\n    {\r\n        SwaggerResource swaggerResource = new SwaggerResource();\r\n        swaggerResource.setName(name);\r\n        swaggerResource.setLocation(location);\r\n        swaggerResource.setSwaggerVersion(\"2.0\");\r\n        return swaggerResource;\r\n    }\r\n}\r\n```\r\n\r\n3、创建一个聚合接口类`SwaggerHandler.java`\r\n\r\n```java\r\nimport java.util.Optional;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.http.HttpStatus;\r\nimport org.springframework.http.ResponseEntity;\r\nimport org.springframework.web.bind.annotation.GetMapping;\r\nimport org.springframework.web.bind.annotation.RequestMapping;\r\nimport org.springframework.web.bind.annotation.RestController;\r\nimport reactor.core.publisher.Mono;\r\nimport springfox.documentation.swagger.web.SecurityConfiguration;\r\nimport springfox.documentation.swagger.web.SecurityConfigurationBuilder;\r\nimport springfox.documentation.swagger.web.SwaggerResourcesProvider;\r\nimport springfox.documentation.swagger.web.UiConfiguration;\r\nimport springfox.documentation.swagger.web.UiConfigurationBuilder;\r\n\r\n@RestController\r\n@RequestMapping(\"/swagger-resources\")\r\npublic class SwaggerHandler\r\n{\r\n    @Autowired(required = false)\r\n    private SecurityConfiguration securityConfiguration;\r\n\r\n    @Autowired(required = false)\r\n    private UiConfiguration uiConfiguration;\r\n\r\n    private final SwaggerResourcesProvider swaggerResources;\r\n\r\n    @Autowired\r\n    public SwaggerHandler(SwaggerResourcesProvider swaggerResources)\r\n    {\r\n        this.swaggerResources = swaggerResources;\r\n    }\r\n\r\n    @GetMapping(\"/configuration/security\")\r\n    public Mono<ResponseEntity<SecurityConfiguration>> securityConfiguration()\r\n    {\r\n        return Mono.just(new ResponseEntity<>(\r\n                Optional.ofNullable(securityConfiguration).orElse(SecurityConfigurationBuilder.builder().build()),\r\n                HttpStatus.OK));\r\n    }\r\n\r\n    @GetMapping(\"/configuration/ui\")\r\n    public Mono<ResponseEntity<UiConfiguration>> uiConfiguration()\r\n    {\r\n        return Mono.just(new ResponseEntity<>(\r\n                Optional.ofNullable(uiConfiguration).orElse(UiConfigurationBuilder.builder().build()), HttpStatus.OK));\r\n    }\r\n\r\n    @SuppressWarnings(\"rawtypes\")\r\n    @GetMapping(\"\")\r\n    public Mono<ResponseEntity> swaggerResources()\r\n    {\r\n        return Mono.just((new ResponseEntity<>(swaggerResources.get(), HttpStatus.OK)));\r\n    }\r\n}\r\n```\r\n\r\n4、配置注册中心及路由信息\r\n\r\n```yml\r\nspring:\r\n  profiles:\r\n    # 环境配置\r\n    active: dev\r\n  cloud:\r\n  \tnacos:\r\n      discovery:\r\n        # 服务注册地址\r\n        server-addr: 127.0.0.1:8848\r\n    gateway:\r\n      discovery:\r\n        locator:\r\n          enabled: false\r\n          # 服务名默认必须大写，否则会抛404错误，如果服务名要用小写，可在属性配置文件中添加spring.cloud.gateway.discovery.locator.lowerCaseServiceId=true配置解决\r\n          lower-case-service-id: true\r\n      #default-filters:  #全局用于配置所有路由共享过滤器\r\n      #  - StripPrefix=1 #去掉- Path=/auth 前缀\r\n      #  - PreserveHostHeader #发送原主机头\r\n      routes:\r\n#          uri: https://www.baidu.com\r\n#          predicates:\r\n#            - Query=url,baidu\r\n#        - id: qq_route\r\n#          uri: https://www.qq.com\r\n#          predicates:\r\n#            - Query=url,qq  # localhost:88?url=qq\r\n        #TODO 页面 http://localhost:88/product/api/product/**\r\n\r\n        #-> http://localhost:10000/product/**\r\n        - id: product_route\r\n          uri: lb://gulimall-product # 路由给商品系统http://localhost:10000/product/**\r\n          predicates:\r\n            - Path=/api/product/**\r\n          filters:\r\n            # http://localhost:10000/api/product/**\r\n            #->http://localhost:10000/product/**\r\n            - StripPrefix=2\r\n            - RewritePath=/api/(?<segment>.*),/$\\{segment}\r\n        #页面 http://localhost:88/api/api/member/*\r\n\r\n       #->http://localhost:8000/member/**\r\n        - id: coupon_route\r\n          uri: lb://gulimall-coupon # 路由给用户系统http://localhost:8000/member/**\r\n          predicates:\r\n            - Path=/api/coupon/**\r\n          filters:\r\n            # 与商品格式一致\r\n            # http://localhost:8000/api/member/**\r\n            #->http://localhost:8000/member/**\r\n            - StripPrefix=2\r\n            - RewritePath=/api/(?<segment>.*),/$\\{segment}\r\n        # 页面路由网关都以http://localhost:88/api/开头，网关可以路由到指定服务\r\n\r\n\r\n        # 页面 http://localhost:88/api/thirdparty/oss/policy/*\r\n        #-> http://localhost:30000/oss/policy/*\r\n        - id: third_party_route\r\n          uri: lb://gulimall-third-party # 路由给第三方服务http://localhost:30000/oss/policy\r\n          predicates: # 什么情况下路由给它  以下前缀路由给第三方服务\r\n            - Path=/api/thirdparty/**\r\n          # 路径重写 截掉/api/thirdparty/，留下/api/thirdparty/后的路径与网关路径拼接\r\n          filters:\r\n            # http://localhost:30000/api/thirdparty/oss/policy\r\n            #-> http://localhost:30000/oss/policy\r\n            - StripPrefix=2\r\n            - RewritePath=/api/thirdparty/(?<segment>.*),/$\\{segment}\r\n        #页面 http://localhost:88/api/api/member/*\r\n\r\n        #->http://localhost:8000/member/**\r\n        - id: member_route\r\n          uri: lb://gulimall-member # 路由给用户系统http://localhost:8000/member/**\r\n          predicates:\r\n            - Path=/api/member/**\r\n          filters:\r\n            # 与商品格式一致\r\n            # http://localhost:8000/api/member/**\r\n            #->http://localhost:8000/member/**\r\n            - StripPrefix=2\r\n            - RewritePath=/api/(?<segment>.*),/$\\{segment}\r\n        #页面 http://localhost:88/api/api/ware/*\r\n\r\n        #->http://localhost:11000/ware/**\r\n        - id: ware_route\r\n          uri: lb://gulimall-ware # 路由给仓库系统http://localhost:11000/ware/**\r\n          predicates:\r\n            - Path=/api/ware/**\r\n          filters:\r\n            # 与商品格式一致\r\n            # http://localhost:11000/api/ware/**\r\n            #->http://localhost:11000/ware/**\r\n            - StripPrefix=2\r\n            - RewritePath=/api/(?<segment>.*),/$\\{segment}\r\n```\r\n\r\n5、测试验证\r\n\r\n打开浏览器，输入：([http://localhost:88/swagger-ui/index.html (opens new window)](http://localhost:88/swagger-ui/index.html))\r\n\r\n![swagger](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/up-7455b9e8a7850faebf31f2a869412e2132d.png)\r\n\r\n选择切换不同服务的`swagger`接口\r\n\r\n## 全局授权\r\n\r\n在测试系统接口中可能存在一些接口用到用户信息或权限验证，此时需要添加全局的`token`参数。如图\r\n\r\n![swagger](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/up-a474910efef3e0739b42f3d5cc329f8ef66.png)\r\n\r\n`token`是在登录成功后返回的，可以在浏览器通过F12查看`Network`中的请求地址，对应参数`Authorization`。复制截图内容到`swagger`全局`Authorization`属性`value`参数中，点击`Authorize`，以后每次访问接口会携带此`token`信息。\r\n\r\n![swagger](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/up-4f771cfc906fa9dcc173f20fae80c7f5191.png)\r\n\r\n## 整合knife4j\r\n\r\n在`Spring Cloud`的微服务架构下，每个微服务并不需要引入前端的`ui`资源，因此在每个微服务的`Spring Boot`项目下，引入`ruoyi-common-swagger`提供的`starter`即可。\r\n\r\n1、在`ruoyi-gateway`网关模块下，把`knife4j`依赖资源引入\r\n\r\n```xml\r\n<!-- knife4j -->\r\n<dependency>\r\n\t<groupId>com.github.xiaoymin</groupId>\r\n\t<!--  <artifactId>knife4j-spring-ui</artifactId> -->\r\n    <artifactId>knife4j-micro-spring-boot-starter</artifactId>\r\n\t<version>3.0.3</version>\r\n</dependency>\r\n<dependency>\r\n\t<groupId>com.github.xiaoymin</groupId>\r\n\t<artifactId>knife4j-spring-boot-starter</artifactId>\r\n\t<version>3.0.3</version>\r\n</dependency>\r\n```\r\n\r\n\r\n\r\n2、在`common-swagger`系统接口模块下，把`knife4j`依赖资源引入\r\n\r\n```xml\r\n<!-- knife4j -->\r\n<dependency>\r\n\t<groupId>com.github.xiaoymin</groupId>\r\n\t<artifactId>knife4j-spring-boot-starter</artifactId>\r\n\t<version>3.0.3</version>\r\n</dependency>\r\n```\r\n\r\n3、在其他`mall-xxxx-xxxx`服务下，把`common-swagger`依赖资源引入\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>com.klaus.gulimall</groupId>\r\n    <artifactId>gulimall-swagger-spring-boot-starter</artifactId>\r\n    <version>0.0.1-SNAPSHOT</version>\r\n</dependency>\r\n```\r\n\r\n4、在`SwaggerProvider.java`的类注解追加`@Primary`\r\n\r\n```java\r\n@Slf4j\r\n@Component\r\n@Primary\r\n@AllArgsConstructor\r\n```\r\n\r\n5、测试验证\r\n\r\n访问`http://{ip}:{port}/doc.html`地址，出现如下图表示成功。\r\n\r\n![knife4j](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/up-860f80bd38f5998dfc319b2514cf1bae169.png)\r\n\r\n> 重复swagger依赖剔除\r\n>\r\n> 在`ruoyi-common-swagger`引用`knife4j-spring-boot-starter`依赖，其中的`springfox-swagger2`依赖可以删除。\r\n> 在`ruoyi-gateway`引用`knife4j-spring-ui`、`knife4j-spring-boot-starter`依赖，其中的`springfox-swagger-ui`、`springfox-swagger2`依赖可以删除。\r\n>\r\n> `swagger3.0`和`knife4j`都需要SpringBoot2.3以上，否则报错"},{"title":"分布式任务调度-xxlJob","tags":["Spring Cloud","Spring Boot","minio","xxlJob","freemarker","elasticsearch"],"categories":["Java","微系统与第三方框架"],"author":"imklaus","excerpt":"\r\n\r\n参考视频：[黑马学成在线项目](https://www.bilibili.com/video/BV1j8411N7Bm/)\r\n\r\n","link":"/posts/xxlJob","content":"\r\n\r\n参考视频：[黑马学成在线项目](https://www.bilibili.com/video/BV1j8411N7Bm/)\r\n\r\n<!-- more -->\r\n\r\n\r\n\r\n## **一 分布式任务处理**\r\n\r\n### **1.1 什么是分布式任务调度**\r\n\r\n对一个视频的转码可以理解为一个任务的执行，如果视频的数量比较多，如何去高效处理一批任务呢？\r\n\r\n1、多线程\r\n\r\n多线程是充分利用单机的资源。\r\n\r\n2、分布式加多线程\r\n\r\n充分利用多台计算机，每台计算机使用多线程处理。\r\n\r\n方案2可扩展性更强。\r\n\r\n方案2是一种分布式任务调度的处理方案。\r\n\r\n什么是分布式任务调度？\r\n\r\n我们可以先思考一下下面业务场景的解决方案：\r\n\r\n- 每隔24小时执行数据备份任务。\r\n\r\n- 12306网站会根据车次不同，设置几个时间点分批次放票。\r\n- 某财务系统需要在每天上午10点前结算前一天的账单数据，统计汇总。\r\n\r\n- 商品成功发货后，需要向客户发送短信提醒。\r\n\r\n\r\n类似的场景还有很多，我们该如何实现？\r\n\r\n**多线程方式实现：**\r\n\r\n学过多线程的同学，可能会想到，我们可以开启一个线程，每sleep一段时间，就去检查是否已到预期执行时间。\r\n\r\n以下代码简单实现了任务调度的功能：\r\n\r\n```java\r\npublic static void main(String[] args) {    \r\n    //任务执行间隔时间\r\n    final long timeInterval = 1000;\r\n    Runnable runnable = new Runnable() {\r\n        public void run() {\r\n            while (true) {\r\n                //TODO：something\r\n                try {\r\n                    Thread.sleep(timeInterval);\r\n                } catch (InterruptedException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        }\r\n    };\r\n    Thread thread = new Thread(runnable);\r\n    thread.start();\r\n}\r\n```\r\n\r\n上面的代码实现了按一定的间隔时间执行任务调度的功能。\r\n\r\nJdk也为我们提供了相关支持，如Timer、ScheduledExecutor，下边我们了解下。\r\n\r\n**Timer方式实现**：\r\n\r\n```java\r\npublic static void main(String[] args){  \r\n    Timer timer = new Timer();  \r\n    timer.schedule(new TimerTask(){\r\n        @Override  \r\n        public void run() {  \r\n           //TODO：something\r\n        }  \r\n    }, 1000, 2000);  //1秒后开始调度，每2秒执行一次\r\n}\r\n```\r\n\r\n- Timer 的优点在于简单易用，每个Timer对应一个线程，因此可以同时启动多个Timer并行执行多个任务，同一个Timer中的任务是串行执行。\r\n\r\n**ScheduledExecutor方式实现**：\r\n\r\n```java\r\npublic static void main(String [] agrs){\r\n    ScheduledExecutorService service = Executors.newScheduledThreadPool(10);\r\n    service.scheduleAtFixedRate(\r\n            new Runnable() {\r\n                @Override\r\n                public void run() {\r\n                    //TODO：something\r\n                    System.out.println(\"todo something\");\r\n                }\r\n            }, 1,\r\n            2, TimeUnit.SECONDS);\r\n}\r\n```\r\n\r\n- Java 5 推出了基于线程池设计的 ScheduledExecutor，其设计思想是，每一个被调度的任务都会由线程池中一个线程去执行，因此任务是并发执行的，相互之间不会受到干扰。\r\n\r\n- Timer 和 ScheduledExecutor 都仅能提供基于开始时间与重复间隔的任务调度，不能胜任更加复杂的调度需求。比如，设置每月第一天凌晨1点执行任务、复杂调度任务的管理、任务间传递数据等等。\r\n\r\n \r\n\r\n**第三方Quartz方式实现，项目地址：https://github.com/quartz-scheduler/quartz**  \r\n\r\n- Quartz 是一个功能强大的任务调度框架，它可以满足更多更复杂的调度需求，Quartz 设计的核心类包括 Scheduler, Job 以及 Trigger。其中，Job 负责定义需要执行的任务，Trigger 负责设置调度策略，Scheduler 将二者组装在一起，并触发任务开始执行。Quartz支持简单的按时间间隔调度、还支持按日历调度方式，通过设置CronTrigger表达式（包括：秒、分、时、日、月、周、年）进行任务调度。\r\n\r\n下边是一个例子代码：\r\n\r\n```java\r\npublic static void main(String [] agrs) throws SchedulerException {\r\n    //创建一个Scheduler\r\n    SchedulerFactory schedulerFactory = new StdSchedulerFactory();\r\n    Scheduler scheduler = schedulerFactory.getScheduler();\r\n    //创建JobDetail\r\n    JobBuilder jobDetailBuilder = JobBuilder.newJob(MyJob.class);\r\n    jobDetailBuilder.withIdentity(\"jobName\",\"jobGroupName\");\r\n    JobDetail jobDetail = jobDetailBuilder.build();\r\n    //创建触发的CronTrigger 支持按日历调度\r\n        CronTrigger trigger = TriggerBuilder.newTrigger()\r\n                .withIdentity(\"triggerName\", \"triggerGroupName\")\r\n                .startNow()\r\n                .withSchedule(CronScheduleBuilder.cronSchedule(\"0/2 * * * * ?\"))\r\n                .build();\r\n    scheduler.scheduleJob(jobDetail,trigger);\r\n    scheduler.start();\r\n}\r\n\r\npublic class MyJob implements Job {\r\n    @Override\r\n    public void execute(JobExecutionContext jobExecutionContext){\r\n        System.out.println(\"todo something\");\r\n    }\r\n}\r\n```\r\n\r\n通过以上内容我们学习了什么是任务调度，任务调度所解决的问题，以及任务调度的多种实现方式。\r\n\r\n**任务调度顾名思义，就是对任务的调度，它是指系统为了完成特定业务，基于给定时间点，给定时间间隔或者给定执行次数自动执行任务。**\r\n\r\n**什么是分布式任务调度？**\r\n\r\n- 通常任务调度的程序是集成在应用中的，比如：优惠卷服务中包括了定时发放优惠卷的的调度程序，结算服务中包括了定期生成报表的任务调度程序，由于采用分布式架构，一个服务往往会部署多个冗余实例来运行我们的业务，在这种分布式系统环境下运行任务调度，我们称之为**分布式任务调度**，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps95.jpg) \r\n\r\n**分布式调度要实现的目标：**\r\n\r\n- 不管是任务调度程序集成在应用程序中，还是单独构建的任务调度系统，如果采用分布式调度任务的方式就相当于将任务调度程序分布式构建，这样就可以具有分布式系统的特点，并且提高任务的调度处理能力：\r\n\r\n1、并行任务调度\r\n\r\n- 并行任务调度实现靠多线程，如果有大量任务需要调度，此时光靠多线程就会有瓶颈了，因为一台计算机CPU的处理能力是有限的。\r\n\r\n- 如果将任务调度程序分布式部署，每个结点还可以部署为集群，这样就可以让多台计算机共同去完成任务调度，我们可以将任务分割为若干个分片，由不同的实例并行执行，来提高任务调度的处理效率。\r\n\r\n2、高可用\r\n\r\n- 若某一个实例宕机，不影响其他实例来执行任务。\r\n\r\n3、弹性扩容\r\n\r\n- 当集群中增加实例就可以提高并执行任务的处理效率。\r\n\r\n4、任务管理与监测\r\n\r\n- 对系统中存在的所有定时任务进行统一的管理及监测。让开发人员及运维人员能够时刻了解任务执行情况，从而做出快速的应急处理响应。\r\n\r\n5、避免任务重复执行\r\n\r\n- 当任务调度以集群方式部署，同一个任务调度可能会执行多次，比如在上面提到的电商系统中到点发优惠券的例子，就会发放多次优惠券，对公司造成很多损失，所以我们需要控制相同的任务在多个运行实例上只执行一次。\r\n\r\n \r\n\r\n### **1.2 XXL-JOB介绍**\r\n\r\nXXL-JOB是一个轻量级分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。\r\n\r\n官网：https://www.xuxueli.com/xxl-job/\r\n\r\n文档：https://www.xuxueli.com/xxl-job/#%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E5%B9%B3%E5%8F%B0XXL-JOB%E3%80%8B\r\n\r\nXXL-JOB主要有调度中心、执行器、任务：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps96.jpg) \r\n\r\n**调度中心：**\r\n\r\n- 负责管理调度信息，按照调度配置发出调度请求，自身不承担业务代码；\r\n\r\n- 主要职责为执行器管理、任务管理、监控运维、日志管理等\r\n\r\n**任务执行器：**\r\n\r\n- 负责接收调度请求并执行任务逻辑；\r\n\r\n- 只要职责是注册服务、任务执行服务（接收到任务后会放入线程池中的任务队列）、执行结果上报、日志服务等\r\n\r\n**任务：**负责执行具体的业务处理。\r\n\r\n \r\n\r\n调度中心与执行器之间的工作流程如下：\r\n\r\n![image-20230704234905831](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704234905831.png)\r\n\r\n \r\n\r\n**执行流程：**\r\n\r\n- 1.任务执行器根据配置的调度中心的地址，自动注册到调度中心\r\n- 2.达到任务触发条件，调度中心下发任务\r\n- 3.执行器基于线程池执行任务，并把执行结果放入内存队列中、把执行日志写入日志文件中\r\n- 4.执行器消费内存队列中的执行结果，主动上报给调度中心\r\n- 5.当用户在调度中心查看任务日志，调度中心请求任务执行器，任务执行器读取任务日志文件并返回日志详情\r\n\r\n \r\n\r\n## **二 任务调度实战—视频处理**\r\n\r\n### **2.1 视频转码需求**\r\n\r\n \r\n\r\n#### **2.1.1 什么是视频编码**\r\n\r\n视频上传成功后需要对视频进行转码处理。\r\n\r\n什么是视频编码？查阅百度百科如下：\r\n\r\n![image-20230704234151230](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704234151230.png)\r\n\r\n详情参考 ：[https://baike.baidu.com/item/%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81/839038](https://baike.baidu.com/item/视频编码/839038)\r\n\r\n首先我们要分清文件格式和编码格式：\r\n\r\n文件格式：是指`.mp4、.avi、.rmvb`等 这些不同扩展名的视频文件的文件格式  ，视频文件的内容主要包括视频和音频，其文件格式是按照一 定的编码格式去编码，并且按照该文件所规定的封装格式将视频、音频、字幕等信息封装在一起，播放器会根据它们的封装格式去提取出编码，然后由播放器解码，最终播放音视频。\r\n\r\n音视频编码格式：通过音视频的压缩技术，将视频格式转换成另一种视频格式，通过视频编码实现流媒体的传输。比如：一个`.avi`的视频文件原来的编码是a，通过编码后编码格式变为b，音频原来为c，通过编码后变为d。\r\n\r\n \r\n\r\n音视频编码格式各类繁多，主要有几下几类：\r\n\r\nMPEG系列\r\n\r\n> （由ISO[国际标准组织机构]下属的MPEG[运动图象专家组]开发 ）视频编码方面主要是Mpeg1（vcd用的就是它）、Mpeg2（DVD使用）、Mpeg4（的DVDRIP使用的都是它的变种，如：divx，xvid等）、Mpeg4 AVC（正热门）；音频编码方面主要是MPEG Audio Layer 1/2、MPEG Audio Layer 3（大名鼎鼎的mp3）、MPEG-2 AAC 、MPEG-4 AAC等等。注意：DVD音频没有采用Mpeg的。\r\n>\r\n\r\nH.26X系列\r\n\r\n> （由ITU[国际电传视讯联盟]主导，侧重网络传输，注意：只是视频编码）\r\n>\r\n> 包括`H.261、H.262、H.263、H.263+、H.263++、H.264`（就是`MPEG4 AVC-`合作的结晶）\r\n>\r\n> 目前最常用的编码标准是视频`H.264`，音频`AAC`。\r\n>\r\n\r\n提问：\r\n\r\n- `H.264`是编码格式还是文件格式？\r\n- `mp4`是编码格式还是文件格式？\r\n\r\n \r\n\r\n#### **2.1.2 FFmpeg 的基本使用**\r\n\r\n我们将视频录制完成后，使用视频编码软件对视频进行编码，本项目 使用FFmpeg对视频进行编码 。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps92.jpg) \r\n\r\n> FFmpeg被许多开源项目采用，QQ影音、暴风影音、VLC等。\r\n>\r\n> 下载：FFmpeg https://www.ffmpeg.org/download.html#build-windows\r\n>\r\n> 请从常用工具软件目录找到ffmpeg.exe，并将ffmpeg.exe加入环境变量path中。\r\n>\r\n> 测试是否正常：cmd运行 `ffmpeg -version`\r\n>\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps93.jpg) \r\n\r\n> 安装成功，作下简单测试\r\n>\r\n> 将一个.avi文件转成mp4、mp3、gif等。\r\n>\r\n> 比如我们将nacos.avi文件转成mp4，运行如下命令：\r\n>\r\n> `D:\\soft\\ffmpeg\\ffmpeg.exe -i 1.avi 1.mp4`\r\n>\r\n> 可以将ffmpeg.exe配置到环境变量path中，进入视频目录直接运行：`ffmpeg.exe -i 1.avi 1.mp4`\r\n>\r\n> 转成mp3：`ffmpeg -i nacos.avi nacos.mp3`\r\n>\r\n> 转成gif：`ffmpeg -i nacos.avi nacos.gif`\r\n>\r\n> 官方文档（英文）：http://ffmpeg.org/ffmpeg.html\r\n>\r\n\r\n#### **2.1.3 视频处理工具类**\r\n\r\n将课程资料的工具类中的util拷贝至base工程。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps94.jpg) \r\n\r\n其中Mp4VideoUtil类是用于将视频转为mp4格式，是我们项目要使用的工具类。\r\n\r\n下边看下这个类的代码，并进行测试。\r\n\r\n我们要通过ffmpeg对视频转码，Java程序调用ffmpeg，使用`java.lang.ProcessBuilder`去完成，具体在Mp4VideoUtil类的63行，下边进行简单的测试，下边的代码运行本机安装的QQ软件。\r\n\r\n```java\r\nProcessBuilder builder = new ProcessBuilder();\r\nbuilder.command(\"C:\\\\Program Files (x86)\\\\Tencent\\\\QQ\\\\Bin\\\\QQScLauncher.exe\");\r\n//将标准输入流和错误输入流合并，通过标准输入流程读取信息\r\nbuilder.redirectErrorStream(true);\r\nProcess p = builder.start();\r\n```\r\n\r\n对Mp4VideoUtil类需要学习使用方法，下边代码将一个avi视频转为mp4视频，如下：\r\n\r\n```java\r\npublic static void main(String[] args) throws IOException {\r\n    //ffmpeg的路径\r\n    String ffmpeg_path = \"D:\\\\soft\\\\ffmpeg\\\\ffmpeg.exe\";//ffmpeg的安装位置\r\n    //源avi视频的路径\r\n    String video_path = \"D:\\\\develop\\\\bigfile_test\\\\nacos01.avi\";\r\n    //转换后mp4文件的名称\r\n    String mp4_name = \"nacos01.mp4\";\r\n    //转换后mp4文件的路径\r\n    String mp4_path = \"D:\\\\develop\\\\bigfile_test\\\\nacos01.mp4\";\r\n    //创建工具类对象\r\n    Mp4VideoUtil videoUtil = new Mp4VideoUtil(ffmpeg_path,video_path,mp4_name,mp4_path);\r\n    //开始视频转换，成功将返回success\r\n    String s = videoUtil.generateMp4();\r\n    System.out.println(s);\r\n}\r\n```\r\n\r\n执行main方法，最终在控制台输出 success 表示执行成功。\r\n\r\n\r\n\r\n### **2.2 搭建XXL-JOB**\r\n\r\n#### **2.2.1 调度中心**\r\n\r\n1）创建挂载目录\r\n\r\n```bash\r\nmkdir -p -m 777 /mydata/xxl-job/{logs,conf}\r\n```\r\n\r\n`conf` 目录下创建 `application.properties` 文件。\r\n\r\n```properties\r\n### web\r\nserver.port=8088\r\nserver.servlet.context-path=/xxl-job-admin\r\n\r\n### actuator\r\nmanagement.server.servlet.context-path=/actuator\r\nmanagement.health.mail.enabled=false\r\n\r\n### resources\r\nspring.mvc.servlet.load-on-startup=0\r\nspring.mvc.static-path-pattern=/static/**\r\nspring.resources.static-locations=classpath:/static/\r\n\r\n### freemarker\r\nspring.freemarker.templateLoaderPath=classpath:/templates/\r\nspring.freemarker.suffix=.ftl\r\nspring.freemarker.charset=UTF-8\r\nspring.freemarker.request-context-attribute=request\r\nspring.freemarker.settings.number_format=0.##########\r\n\r\n### mybatis\r\nmybatis.mapper-locations=classpath:/mybatis-mapper/*Mapper.xml\r\n#mybatis.type-aliases-package=com.xxl.job.admin.core.model\r\n\r\n###更改配置文件连接mysql信息\r\n### xxl-job, datasource\r\nspring.datasource.url=jdbc:mysql://dockermysql:3306/xxl_job?characterEncoding=UTF-8&serverTimezone=UTC&useSSL=false&autoReconnect=true ###ip\r\nspring.datasource.username=root\r\nspring.datasource.password=1234\r\nspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver\r\n\r\n### datasource-pool\r\nspring.datasource.type=com.zaxxer.hikari.HikariDataSource\r\nspring.datasource.hikari.minimum-idle=10\r\nspring.datasource.hikari.maximum-pool-size=30\r\nspring.datasource.hikari.auto-commit=true\r\nspring.datasource.hikari.idle-timeout=30000\r\nspring.datasource.hikari.pool-name=HikariCP\r\nspring.datasource.hikari.max-lifetime=900000\r\nspring.datasource.hikari.connection-timeout=10000\r\nspring.datasource.hikari.connection-test-query=SELECT 1\r\nspring.datasource.hikari.validation-timeout=1000\r\n\r\n### xxl-job, email\r\nspring.mail.host=smtp.qq.com\r\nspring.mail.port=25\r\nspring.mail.username=xxx@qq.com\r\nspring.mail.from=xxx@qq.com\r\nspring.mail.password=xxx\r\nspring.mail.properties.mail.smtp.auth=true\r\nspring.mail.properties.mail.smtp.starttls.enable=true\r\nspring.mail.properties.mail.smtp.starttls.required=true\r\nspring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory\r\n\r\n### xxl-job, access token\r\nxxl.job.accessToken=default_token\r\n\r\n### xxl-job, i18n (default is zh_CN, and you can choose \"zh_CN\", \"zh_TC\" and \"en\")\r\nxxl.job.i18n=zh_CN\r\n\r\n## xxl-job, triggerpool max size\r\nxxl.job.triggerpool.fast.max=200\r\nxxl.job.triggerpool.slow.max=100\r\n\r\n### xxl-job, log retention days\r\nxxl.job.logretentiondays=30\r\n\r\n```\r\n\r\n2）下载XXL-JOB\r\n\r\nGitHub：https://github.com/xuxueli/xxl-job\r\n\r\n码云：https://gitee.com/xuxueli0323/xxl-job\r\n\r\n项目使用2.3.1版本： https://github.com/xuxueli/xxl-job/releases/tag/2.3.1\r\n\r\n也可从课程资料目录获取，解压xxl-job-2.3.1.zip\r\n\r\n使用IDEA打开解压后的目录\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps98.jpg) \r\n\r\nxxl-job-admin：调度中心\r\n\r\nxxl-job-core：公共依赖\r\n\r\nxxl-job-executor-samples：执行器Sample示例（选择合适的版本执行器，可直接使用）\r\n\r\n  ：xxl-job-executor-sample-springboot：Springboot版本，通过Springboot管理执行器，推荐这种方式；\r\n\r\n  ：xxl-job-executor-sample-frameless：无框架版本；\r\n\r\ndoc :文档资料，包含数据库脚本\r\n\r\n在下发的虚拟机的MySQL中已经创建了xxl_job_2.3.1数据库\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps99.jpg) \r\n\r\n如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps100.jpg) \r\n\r\n执行`sh /data/soft/restart.sh`自动启动xxl-job调度中心\r\n\r\n3）创建容器\r\n\r\n```shell\r\ndocker run -d \\\r\n-p 8088:8080 \\\r\n--name=xxl-job-admin \\\r\n--link mysql:dockermysql \\\r\n--restart=always \\\r\n-v ~/docker/software/xxl-job/conf/application.properties:/application.properties \\\r\n-e PARAMS='--spring.config.location=/application.properties' \\\r\nxuxueli/xxl-job-admin:2.3.1\r\n```\r\n\r\n`--link`：请确保 Docker 中运行着名为 mysql 的容器。连接上 MySQL 容器后，实现网络互通。\r\n\r\n4）访问后台\r\n\r\n访问：http://192.168.2.203:8088/xxl-job-admin/\r\n\r\n账号和密码：admin/123456\r\n\r\n如果无法使用虚拟机运行xxl-job可以在本机idea运行xxl-job调度中心。\r\n\r\n#### **2.2.2 执行器**\r\n\r\n下边配置执行器，执行器负责与调度中心通信接收调度中心发起的任务调度请求。\r\n\r\n1、下边进入调度中心添加执行器\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps101.jpg) \r\n\r\n \r\n\r\n点击新增，填写执行器信息，appname是前边在nacos中配置xxl信息时指定的执行器的应用名。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps102.jpg) \r\n\r\n添加成功：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps103.jpg) \r\n\r\n \r\n\r\n2、首先在媒资管理模块的service工程添加依赖，在项目的父工程已约定了版本2.3.1\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>com.xuxueli</groupId>\r\n    <artifactId>xxl-job-core</artifactId>\r\n</dependency>\r\n```\r\n\r\n3、在nacos下的media-service-dev.yaml下配置xxl-job\r\n\r\n```yaml\r\nxxl:\r\n  job:\r\n    admin: \r\n      addresses: http://192.168.2.203:8088/xxl-job-admin\r\n    executor:\r\n      appname: media-process-service\r\n      address: \r\n      ip: \r\n      port: 9999\r\n      logpath: /data/applogs/xxl-job/jobhandler\r\n      logretentiondays: 30\r\n    accessToken: default_token\r\n```\r\n\r\n注意配置中的appname这是执行器的应用名，port是执行器启动的端口，如果本地启动多个执行器注意端口不能重复。\r\n\r\n4、配置xxl-job的执行器\r\n\r\n将xxl-job示例工程下配置类拷贝到媒资管理的service工程下\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps104.jpg) \r\n\r\n```java\r\n/**\r\n * @author Klaus\r\n * @date 2023/06/24 1:52\r\n * @description TODO\r\n */\r\n@Configuration\r\npublic class XxlJobConfig {\r\n    private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class);\r\n\r\n    @Value(\"${xxl.job.admin.addresses}\")\r\n    private String adminAddresses;\r\n\r\n    @Value(\"${xxl.job.accessToken}\")\r\n    private String accessToken;\r\n\r\n    @Value(\"${xxl.job.executor.appname}\")\r\n    private String appname;\r\n\r\n    @Value(\"${xxl.job.executor.address}\")\r\n    private String address;\r\n\r\n    @Value(\"${xxl.job.executor.ip}\")\r\n    private String ip;\r\n\r\n    @Value(\"${xxl.job.executor.port}\")\r\n    private int port;\r\n\r\n    @Value(\"${xxl.job.executor.logpath}\")\r\n    private String logPath;\r\n\r\n    @Value(\"${xxl.job.executor.logretentiondays}\")\r\n    private int logRetentionDays;\r\n\r\n\r\n    @Bean\r\n    public XxlJobSpringExecutor xxlJobExecutor() {\r\n        logger.info(\">>>>>>>>>>> xxl-job config init.\");\r\n        XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();\r\n        xxlJobSpringExecutor.setAdminAddresses(adminAddresses);\r\n        xxlJobSpringExecutor.setAppname(appname);\r\n        xxlJobSpringExecutor.setAddress(address);\r\n        xxlJobSpringExecutor.setIp(ip);\r\n        xxlJobSpringExecutor.setPort(port);\r\n        xxlJobSpringExecutor.setAccessToken(accessToken);\r\n        xxlJobSpringExecutor.setLogPath(logPath);\r\n        xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays);\r\n\r\n        return xxlJobSpringExecutor;\r\n    }\r\n\r\n    /**\r\n     * 针对多网卡、容器内部署等情况，可借助 \"spring-cloud-commons\" 提供的 \"InetUtils\" 组件灵活定制注册IP；\r\n     *\r\n     *      1、引入依赖：\r\n     *          <dependency>\r\n     *             <groupId>org.springframework.cloud</groupId>\r\n     *             <artifactId>spring-cloud-commons</artifactId>\r\n     *             <version>${version}</version>\r\n     *         </dependency>\r\n     *\r\n     *      2、配置文件，或者容器启动变量\r\n     *          spring.cloud.inetutils.preferred-networks: 'xxx.xxx.xxx.'\r\n     *\r\n     *      3、获取IP\r\n     *          String ip_ = inetUtils.findFirstNonLoopbackHostInfo().getIpAddress();\r\n     */\r\n\r\n\r\n}\r\n```\r\n\r\n \r\n\r\n \r\n\r\n到此完成媒资管理模块service工程配置xxl-job执行器，在xxl-job调度中心添加执行器，下边准备测试执行器与调度中心是否正常通信，因为接口工程依赖了service工程，所以启动媒资管理模块的接口工程。\r\n\r\n启动后观察日志，出现下边的日志表示执行器在调度中心注册成功\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps106.jpg) \r\n\r\n同时观察调度中心中的执行器界面\r\n\r\n![image-20230704235939281](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230704235939281.png)\r\n\r\n在线机器地址处已显示1个执行器。\r\n\r\n \r\n\r\n#### **2.2.3 执行任务**\r\n\r\n下边编写任务，参考示例工程中任务类的编写方法\r\n\r\n在媒资服务service包下新建jobhandler存放任务类，下边参考示例工程编写一个任务类\r\n\r\n```java\r\n/**\r\n * @description 测试执行器\r\n */\r\n @Component\r\n @Slf4j\r\npublic class SampleJob {\r\n\r\n /**\r\n  * 1、简单任务示例（Bean模式）\r\n  */\r\n @XxlJob(\"testJob\")\r\n public void testJob() throws Exception {\r\n  log.info(\"开始执行.....\");\r\n\r\n }\r\n\r\n}\r\n```\r\n\r\n下边在调度中心添加任务，进入任务管理\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps109.jpg) \r\n\r\n点击新增，填写任务信息\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps110.jpg) \r\n\r\n注意红色标记处：\r\n\r\n调度类型：\r\n\r\n固定速度指按固定的间隔定时调度。\r\n\r\nCron，通过Cron表达式实现更丰富的定时调度策略。\r\n\r\nCron表达式是一个字符串，通过它可以定义调度策略，格式如下：\r\n\r\n`{秒数} {分钟} {小时} {日期} {月份} {星期} {年份(可为空)}`\r\n\r\nxxl-job提供图形界面去配置：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps111.jpg) \r\n\r\n> 一些例子如下：\r\n>\r\n> `30 10 1 * * ?`  每天1点10分30秒触发\r\n>\r\n> `0/30 * * * * ?` 每30秒触发一次\r\n>\r\n> `\\* 0/10 * * * ?` 每10分钟触发一次\r\n>\r\n> 运行模式有BEAN和GLUE，bean模式较常用就是在项目工程中编写执行器的任务代码，GLUE是将任务代码编写在调度中心。\r\n>\r\n> JobHandler即任务方法名，填写任务方法上边@XxlJob注解中的名称。\r\n>\r\n> 路由策略：当执行器集群部署时，调度中心向哪个执行器下发任务，这里选择第一个表示只向第一个执行器下发任务，路由策略的其它选项稍后在分片广播章节详细解释。\r\n>\r\n> 高级配置的其它配置项稍后在分片广播章节详细解释。\r\n\r\n \r\n\r\n添加成功，启动任务\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps112.jpg) \r\n\r\n通过调度日志查看任务执行情况\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps113.jpg) \r\n\r\n \r\n\r\n下边启动媒资管理的service工程，启动执行器。\r\n\r\n观察执行器方法的执行。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps114.jpg) \r\n\r\n如果要停止任务需要在调度中心操作\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps115.jpg) \r\n\r\n任务跑一段时间注意清理日志\r\n\r\n![image-20230705001455431](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705001455431.png)\r\n\r\n **2.3 分片广播**\r\n\r\n掌握了xxl-job的基本使用，下边思考如何进行分布式任务处理呢？如下图，我们会启动多个执行器组成一个集群，去执行任务。\r\n\r\n![image-20230705001607572](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/image-20230705001607572.png)\r\n\r\n \r\n\r\n执行器在集群部署下调度中心有哪些路由策略呢？\r\n\r\n查看xxl-job官方文档，阅读高级配置相关的内容：\r\n\r\n> 高级配置：\r\n> \\- 路由策略：当执行器集群部署时，提供丰富的路由策略，包括；\r\n> FIRST（第一个）：固定选择第一个机器；\r\n> LAST（最后一个）：固定选择最后一个机器；\r\n> ROUND（轮询）：；\r\n> RANDOM（随机）：随机选择在线的机器；\r\n> CONSISTENT_HASH（一致性HASH）：每个任务按照Hash算法固定选择某一台机器，且所有任务均匀散列在不同机器上。\r\n> LEAST_FREQUENTLY_USED（最不经常使用）：使用频率最低的机器优先被选举；\r\n> LEAST_RECENTLY_USED（最近最久未使用）：最久未使用的机器优先被选举；\r\n> FAILOVER（故障转移）：按照顺序依次进行心跳检测，第一个心跳检测成功的机器选定为目标执行器并发起调度；\r\n> BUSYOVER（忙碌转移）：按照顺序依次进行空闲检测，第一个空闲检测成功的机器选定为目标执行器并发起调度；\r\n> SHARDING_BROADCAST(分片广播)：广播触发对应集群中所有机器执行一次任务，同时系统自动传递分片参数；可根据分片参数开发分片任务；\r\n>\r\n> \\- 子任务：每个任务都拥有一个唯一的任务ID(任务ID可以从任务列表获取)，当本任务执行结束并且执行成功时，将会触发子任务ID所对应的任务的一次主动调度，通过子任务可以实现一个任务执行完成去执行另一个任务。\r\n> \\- 调度过期策略：\r\n> \\- 忽略：调度过期后，忽略过期的任务，从当前时间开始重新计算下次触发时间；\r\n> \\- 立即执行一次：调度过期后，立即执行一次，并从当前时间开始重新计算下次触发时间；\r\n> \\- 阻塞处理策略：调度过于密集执行器来不及处理时的处理策略；\r\n> 单机串行（默认）：调度请求进入单机执行器后，调度请求进入FIFO队列并以串行方式运行；\r\n> 丢弃后续调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，本次请求将会被丢弃并标记为失败；\r\n> 覆盖之前调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，将会终止运行中的调度任务并清空队列，然后运行本地调度任务；\r\n> \\- 任务超时时间：支持自定义任务超时时间，任务运行超时将会主动中断任务；\r\n> \\- 失败重试次数；支持自定义任务失败重试次数，当任务失败时将会按照预设的失败重试次数主动进行重试；\r\n\r\n下边要重点说的是分片广播策略，分片是指是调度中心以执行器为维度进行分片，将集群中的执行器标上序号：0，1，2，3...，广播是指每次调度会向集群中的所有执行器发送任务调度，请求中携带分片参数。\r\n\r\n如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps118.jpg) \r\n\r\n \r\n\r\n每个执行器收到调度请求同时接收分片参数。\r\n\r\nxxl-job支持动态扩容执行器集群从而动态增加分片数量，当有任务量增加可以部署更多的执行器到集群中，调度中心会动态修改分片的数量。\r\n\r\n**作业分片适用哪些场景呢？**\r\n\r\n• 分片任务场景：10个执行器的集群来处理10w条数据，每台机器只需要处理1w条数据，耗时降低10倍；\r\n\r\n• 广播任务场景：广播执行器同时运行shell脚本、广播集群节点进行缓存更新等。\r\n\r\n所以，广播分片方式不仅可以充分发挥每个执行器的能力，并且根据分片参数可以控制任务是否执行，最终灵活控制了执行器集群分布式处理任务。\r\n\r\n \r\n\r\n**使用说明：**\r\n\r\n\"分片广播\" 和普通任务开发流程一致，不同之处在于可以获取分片参数进行分片业务处理。\r\n\r\nJava语言任务获取分片参数方式：\r\n\r\nBEAN、GLUE模式(Java)，可参考Sample示例执行器中的示例任务\"ShardingJobHandler\"：\r\n\r\n```java\r\n/**\r\n * 2、分片广播任务\r\n */\r\n@XxlJob(\"shardingJobHandler\")\r\npublic void shardingJobHandler() throws Exception {\r\n    // 分片序号，从0开始\r\n    int shardIndex = XxlJobHelper.getShardIndex();\r\n    // 分片总数\r\n    int shardTotal = XxlJobHelper.getShardTotal();\r\n    ....\r\n```\r\n\r\n \r\n\r\n下边测试作业分片：\r\n\r\n1、定义作业分片的任务方法\r\n\r\n```java\r\n/**\r\n  * 2、分片广播任务\r\n  */\r\n @XxlJob(\"shardingJobHandler\")\r\n public void shardingJobHandler() throws Exception {\r\n\r\n  // 分片参数\r\n  int shardIndex = XxlJobHelper.getShardIndex();\r\n  int shardTotal = XxlJobHelper.getShardTotal();\r\n\r\nlog.info(\"分片参数：当前分片序号 = {}, 总分片数 = {}\", shardIndex, shardTotal);\r\nlog.info(\"开始执行第\"+shardIndex+\"批任务\");\r\n\r\n }\r\n```\r\n\r\n2、在调度中心添加任务\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps119.jpg) \r\n\r\n \r\n\r\n添加成功：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps120.jpg) \r\n\r\n启动任务，观察日志\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps121.jpg) \r\n\r\n下边启动两个执行器实例，观察每个实例的执行情况\r\n\r\n首先在nacos中配置media-service的本地优先配置：\r\n\r\n```yaml\r\n#配置本地优先 \r\nspring:  \r\n  cloud:  \r\n   config:   \r\n \t override-none: true\r\n```\r\n\r\n将media-service启动两个实例\r\n\r\n两个实例的在启动时注意端口不能冲突：\r\n\r\n实例1 在VM options处添加：`-Dserver.port=63051 -Dxxl.job.executor.port=9998`\r\n\r\n实例2 在VM options处添加：`-Dserver.port=63050 -Dxxl.job.executor.port=9999`\r\n\r\n例如：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps122.jpg) \r\n\r\n启动两个实例\r\n\r\n观察任务调度中心，稍等片刻执行器有两个\r\n\r\n \r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps123.jpg) \r\n\r\n观察两个执行实例的日志：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps124.jpg) \r\n\r\n另一实例的日志如下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps125.jpg) \r\n\r\n从日志可以看每个实例的分片序号不同。\r\n\r\n如果其中一个执行器挂掉，只剩下一个执行器在工作，稍等片刻调用中心发现少了一个执行器将动态调整总分片数为1。\r\n\r\n到此作业分片任务调试完成，此时我们可以思考：\r\n\r\n当一次分片广播到来，各执行器如何根据分片参数去分布式执行任务，保证执行器之间执行的任务不重复呢？\r\n\r\n \r\n\r\n \r\n\r\n### **2.4 技术方案**\r\n\r\n#### **2.4.1 作业分片方案**\r\n\r\n掌握了xxl-job的分片广播调度方式，下边思考如何分布式去执行学成在线平台中的视频处理任务。\r\n\r\n任务添加成功后，对于要处理的任务会添加到待处理任务表中，现在启动多个执行器实例去查询这些待处理任务，此时如何保证多个执行器不会查询到重复的任务呢？\r\n\r\nXXL-JOB并不直接提供数据处理的功能，它只会给执行器分配好分片序号，在向执行器任务调度的同时下发分片总数以及分片序号等参数，执行器收到这些参数根据自己的业务需求去利用这些参数。\r\n\r\n下图表示了多个执行器获取视频处理任务的结构：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps126.jpg) \r\n\r\n每个执行器收到广播任务有两个参数：分片总数、分片序号。每个执行从数据表取任务时可以让任务id 模上 分片总数，如果等于分片序号则执行此任务。\r\n\r\n上边两个执行器实例那么分片总数为2，序号为0、1，从任务1开始，如下：\r\n\r\n`1  %  2 = 1`   执行器2执行\r\n\r\n`2  %  2 =  0`   执行器1执行\r\n\r\n`3  %  2 =  1`   执行器2执行\r\n\r\n以此类推.\r\n\r\n#### **2.4.2 保证任务不重复执行**\r\n\r\n通过作业分片方案保证了执行器之间查询到不重复的任务，如果一个执行器在处理一个视频还没有完成，此时调度中心又一次请求调度，为了不重复处理同一个视频该怎么办？\r\n\r\n首先配置调度过期策略：\r\n\r\n查看文档如下：\r\n\r\n  \\- 调度过期策略：调度中心错过调度时间的补偿处理策略，包括：忽略、立即补偿触发一次等；\r\n    \\- 忽略：调度过期后，忽略过期的任务，从当前时间开始重新计算下次触发时间；\r\n    \\- 立即执行一次：调度过期后，立即执行一次，并从当前时间开始重新计算下次触发时间；\r\n  \\- 阻塞处理策略：调度过于密集执行器来不及处理时的处理策略；\r\n\r\n这里我们选择忽略，如果立即执行一次就可能重复执行相同的任务。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps127.jpg) \r\n\r\n其次，再看阻塞处理策略，阻塞处理策略就是当前执行器正在执行任务还没有结束时调度中心进行任务调度，此时该如何处理。\r\n\r\n查看文档如下：\r\n    单机串行（默认）：调度请求进入单机执行器后，调度请求进入FIFO队列并以串行方式运行；\r\n    丢弃后续调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，本次请求将会被丢弃并标记为失败；\r\n    覆盖之前调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，将会终止运行中的调度任务并清空队列，然后运行本地调度任务；\r\n\r\n这里如果选择覆盖之前调度则可能重复执行任务，这里选择 丢弃后续调度或单机串行方式来避免任务重复执行。\r\n\r\n只做这些配置可以保证任务不会重复执行吗？\r\n\r\n做不到，还需要保证任务处理的幂等性，什么是任务的幂等性？任务的幂等性是指：对于数据的操作不论多少次，操作的结果始终是一致的。在本项目中要实现的是不论多少次任务调度同一个视频只执行一次成功的转码。\r\n\r\n什么是幂等性？\r\n\r\n它描述了一次和多次请求某一个资源对于资源本身应该具有同样的结果。\r\n\r\n幂等性是为了解决重复提交问题，比如：恶意刷单，重复支付等。\r\n\r\n解决幂等性常用的方案：\r\n\r\n1）数据库约束，比如：唯一索引，主键。\r\n\r\n2）乐观锁，常用于数据库，更新数据时根据乐观锁状态去更新。\r\n\r\n3）唯一序列号，操作传递一个唯一序列号，操作时判断与该序列号相等则执行。\r\n\r\n基于以上分析，在执行器接收调度请求去执行视频处理任务时要实现视频处理的幂等性，要有办法去判断该视频是否处理完成，如果正在处理中或处理完则不再处理。这里我们在数据库视频处理表中添加处理状态字段，视频处理完成更新状态为完成，执行视频处理前判断状态是否完成，如果完成则不再处理。\r\n\r\n \r\n\r\n#### **2.4.3 视频处理方案**\r\n\r\n确定了分片方案，下边梳理整个视频上传及处理的业务流程。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps128.jpg) \r\n\r\n上传视频成功向视频处理待处理表添加记录。\r\n\r\n视频处理的详细流程如下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps129.jpg) \r\n\r\n1、任务调度中心广播作业分片。\r\n\r\n2、执行器收到广播作业分片，从数据库读取待处理任务，读取未处理及处理失败的任务。\r\n\r\n3、执行器更新任务为处理中，根据任务内容从MinIO下载要处理的文件。\r\n\r\n4、执行器启动多线程去处理任务。\r\n\r\n5、任务处理完成，上传处理后的视频到MinIO。\r\n\r\n6、将更新任务处理结果，如果视频处理完成除了更新任务处理结果以外还要将文件的访问地址更新至任务处理表及文件表中，最后将任务完成记录写入历史表。\r\n\r\n \r\n\r\n \r\n\r\n### **2.5 查询待处理任务**\r\n\r\n#### **2.5.1 需求分析**\r\n\r\n查询待处理任务只处理未提交及处理失败的任务，任务处理失败后进行重试，最多重试3次。\r\n\r\n任务处理成功将待处理记录移动到历史任务表。\r\n\r\n下图是待处理任务表：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps130.jpg) \r\n\r\n历史任务表与待处理任务表的结构相同。\r\n\r\n \r\n\r\n \r\n\r\n#### **2.5.2添加待处理任务**\r\n\r\n上传视频成功向视频处理待处理表添加记录，暂时只添加对avi视频的处理记录。\r\n\r\n根据MIME Type去判断是否是avi视频，下边列出部分MIME Type\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps131.jpg) \r\n\r\navi视频的MIME Type是`video/x-msvideo`\r\n\r\n修改文件信息入库方法，如下：\r\n\r\n```java\r\n@Transactional\r\npublic MediaFiles addMediaFilesToDb(Long companyId, String fileMd5, UploadFileParamsDto uploadFileParamsDto, String bucket, String objectName) {\r\n    //从数据库查询文件\r\n    MediaFiles mediaFiles = mediaFilesMapper.selectById(fileMd5);\r\n    if (mediaFiles == null) {\r\n        mediaFiles = new MediaFiles();\r\n        //拷贝基本信息\r\n        BeanUtils.copyProperties(uploadFileParamsDto, mediaFiles);\r\n        mediaFiles.setId(fileMd5);\r\n        mediaFiles.setFileId(fileMd5);\r\n        mediaFiles.setCompanyId(companyId);\r\n        //媒体类型\r\n        mediaFiles.setUrl(\"/\" + bucket + \"/\" + objectName);\r\n        mediaFiles.setBucket(bucket);\r\n        mediaFiles.setFilePath(objectName);\r\n        mediaFiles.setCreateDate(LocalDateTime.now());\r\n        mediaFiles.setAuditStatus(\"002003\");\r\n        mediaFiles.setStatus(\"1\");\r\n        //保存文件信息到文件表\r\n        int insert = mediaFilesMapper.insert(mediaFiles);\r\n        if (insert < 0) {\r\n            log.error(\"保存文件信息到数据库失败,{}\", mediaFiles.toString());\r\n            XueChengPlusException.cast(\"保存文件信息失败\");\r\n        }\r\n        //添加到待处理任务表\r\n        addWaitingTask(mediaFiles);\r\n        log.debug(\"保存文件信息到数据库成功,{}\", mediaFiles.toString());\r\n\r\n    }\r\n    return mediaFiles;\r\n\r\n}\r\n\r\n/**\r\n * 添加待处理任务\r\n * @param mediaFiles 媒资文件信息\r\n */\r\nprivate void addWaitingTask(MediaFiles mediaFiles){\r\n    //文件名称\r\n    String filename = mediaFiles.getFilename();\r\n    //文件扩展名\r\n    String extension = filename.substring(filename.lastIndexOf(\".\"));\r\n    //文件mimeType\r\n    String mimeType = getMimeType(extension);\r\n    //如果是avi视频添加到视频待处理表\r\n    if(mimeType.equals(\"video/x-msvideo\")){\r\n        MediaProcess mediaProcess = new MediaProcess();\r\n        BeanUtils.copyProperties(mediaFiles,mediaProcess);\r\n        mediaProcess.setStatus(\"1\");//未处理\r\n        mediaProcess.setFailCount(0);//失败次数默认为0\r\n        mediaProcessMapper.insert(mediaProcess);\r\n    }\r\n}\r\n```\r\n\r\n \r\n\r\n进行前后端测试，上传4个avi视频，观察待处理任务表是否存在记录，记录是否完成。\r\n\r\n \r\n\r\n \r\n\r\n#### **2.5.3 查询待处理任务**\r\n\r\n如何保证查询到的待处理视频记录不重复？\r\n\r\n编写根据分片参数获取待处理任务的DAO方法，定义DAO接口如下：\r\n\r\n```java\r\npublic interface MediaProcessMapper extends BaseMapper<MediaProcess> {\r\n    /**\r\n     * @description 根据分片参数获取待处理任务\r\n     * @param shardTotal  分片总数\r\n     * @param shardindex  分片序号\r\n     * @param count 任务数\r\n     * @return java.util.List<com.xuecheng.media.model.po.MediaProcess> \r\n    */\r\n    @Select(\"select * from media_process t where t.id % #{shardTotal} = #{shardIndex} and (t.status = '1' or t.status = '3') and t.fail_count < 3 limit #{count}\")\r\n    List<MediaProcess> selectListByShardIndex(@Param(\"shardTotal\") int shardTotal,@Param(\"shardIndex\") int shardIndex,@Param(\"count\") int count);\r\n}\r\n```\r\n\r\n定义Service接口，查询待处理\r\n\r\n```java\r\n/**\r\n * @description 媒资文件处理业务方法\r\n */\r\npublic interface MediaFileProcessService {\r\n\r\n    /**\r\n     * @description 获取待处理任务\r\n     * @param shardIndex 分片序号\r\n     * @param shardTotal 分片总数\r\n     * @param count 获取记录数\r\n     * @return java.util.List<com.xuecheng.media.model.po.MediaProcess>\r\n    */\r\n    public List<MediaProcess> getMediaProcessList(int shardIndex,int shardTotal,int count);\r\n\r\n\r\n}\r\n```\r\n\r\nservice接口实现\r\n\r\n```java\r\n@Slf4j\r\n@Service\r\npublic class MediaFileProcessServiceImpl implements MediaFileProcessService {\r\n\r\n @Autowired\r\n MediaFilesMapper mediaFilesMapper;\r\n\r\n @Autowired\r\n MediaProcessMapper mediaProcessMapper;\r\n\r\n @Override\r\n public List<MediaProcess> getMediaProcessList(int shardIndex, int shardTotal, int count) {\r\n  List<MediaProcess> mediaProcesses = mediaProcessMapper.selectListByShardIndex(shardTotal, shardIndex, count);\r\n   return mediaProcesses;\r\n }\r\n}\r\n```\r\n\r\n\r\n\r\n### **2.6 开始执行任务**\r\n\r\n#### **2.6.1 分布式锁**\r\n\r\n前边分析了保证任务不重复执行的方案，理论上每个执行器分到的任务是不重复的，但是当在执行器弹性扩容时无法绝对避免任务不重复执行，比如：原来有四个执行器正在执行任务，由于网络问题原有的0、1号执行器无法与调度中心通信，调度中心就会对执行器重新编号，原来的3、4执行器可能就会执行和0、1号执行器相同的任务。\r\n\r\n为了避免多线程去争抢同一个任务可以使用`synchronized`同步锁去解决，如下代码：\r\n\r\n```java\r\nsynchronized(锁对象){   \r\n    执行任务... \r\n}\r\n```\r\n\r\nsynchronized只能保证同一个虚拟机中多个线程去争抢锁。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps132.jpg) \r\n\r\n如果是多个执行器分布式部署，并不能保证同一个视频只有一个执行器去处理。\r\n\r\n现在要实现分布式环境下所有虚拟机中的线程去同步执行就需要让多个虚拟机去共用一个锁，虚拟机可以分布式部署，锁也可以分布式部署，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps133.jpg) \r\n\r\n \r\n\r\n虚拟机都去抢占同一个锁，锁是一个单独的程序提供加锁、解锁服务。\r\n\r\n**该锁已不属于某个虚拟机，而是分布式部署，由多个虚拟机所共享，这种锁叫分布式锁。**\r\n\r\n实现分布式锁的方案有很多，常用的如下：\r\n\r\n1、基于数据库实现分布锁\r\n\r\n利用数据库主键唯一性的特点，或利用数据库唯一索引、行级锁的特点，比如：多个线程同时向数据库插入主键相同的同一条记录，谁插入成功谁就获取锁，多个线程同时去更新相同的记录，谁更新成功谁就抢到锁。\r\n\r\n2、基于`redis`实现锁\r\n\r\n`redis`提供了分布式锁的实现方案，比如：`SETNX、set nx、redisson`等。\r\n\r\n拿`SETNX`举例说明，`SETNX`命令的工作过程是去set一个不存在的key，多个线程去设置同一个key只会有一个线程设置成功，设置成功的的线程拿到锁。\r\n\r\n3、使用`zookeeper`实现\r\n\r\n`zookeeper`是一个分布式协调服务，主要解决分布式程序之间的同步的问题。`zookeeper`的结构类似的文件目录，多线程向`zookeeper`创建一个子目录(节点)只会有一个创建成功，利用此特点可以实现分布式锁，谁创建该结点成功谁就获得锁。\r\n\r\n本次我们选用数据库实现分布锁，后边的模块会选用其它方案到时再详细介绍。\r\n\r\n#### **2.6.2 开启任务**\r\n\r\n下边基于数据库方式实现分布锁，开始执行任务将任务执行状态更新为4表示任务执行中。\r\n\r\n下边的sql语句可以实现更新操作：\r\n\r\n```sql\r\nupdate media_process m set m.status='4' where  m.id=?\r\n```\r\n\r\n如果是多个线程去执行该sql都将会执行成功，但需求是只能有一个线程抢到锁，所以此sql无法满足需求。\r\n\r\n使用乐观锁方式实现更新操作：\r\n\r\n```sql\r\n update media_process m set m.status='4' where (m.status='1' or m.status='3') and m.fail_count<3 and m.id=?\r\n```\r\n\r\n多个线程同时执行上边的sql只会有一个线程执行成功。\r\n\r\n什么是乐观锁、悲观锁？\r\n\r\n`synchronized`是一种悲观锁，在执行被synchronized包裹的代码时需要首先获取锁，没有拿到锁则无法执行，是总悲观的认为别的线程会去抢，所以要悲观锁。\r\n\r\n乐观锁的思想是它不认为会有线程去争抢，尽管去执行，如果没有执行成功就再去重试。\r\n\r\n数据库的乐观锁实现方式是在表中增加一个`version`字段，更新时判断是否等于某个版本，等于则更新否则更新失败，如下方式。\r\n\r\n```sql\r\nupdate t1 set t1.data1 = '',t1.version='2' where t1.version='1'\r\n```\r\n\r\n实现如下：\r\n\r\n1、定义mapper\r\n\r\n```java\r\npublic interface MediaProcessMapper extends BaseMapper<MediaProcess> {\r\n\r\n    /**\r\n     * 开启一个任务\r\n     * @param id 任务id\r\n     * @return 更新记录数\r\n     */\r\n    @Update(\"update media_process m set m.status='4' where (m.status='1' or m.status='3') and m.fail_count<3 and m.id=#{id}\")\r\n    int startTask(@Param(\"id\") long id);\r\n\r\n}\r\n```\r\n\r\n2、在MediaFileProcessService中定义接口\r\n\r\n```java\r\n/**\r\n *  开启一个任务\r\n * @param id 任务id\r\n * @return true开启任务成功，false开启任务失败\r\n */\r\npublic boolean startTask(long id);\r\n\r\n//实现如下\r\npublic boolean startTask(long id) {\r\n    int result = mediaProcessMapper.startTask(id);\r\n    return result<=0?false:true;\r\n}\r\n```\r\n\r\n \r\n\r\n### **2.7 更新任务状态**\r\n\r\n任务处理完成需要更新任务处理结果，任务执行成功更新视频的URL、及任务处理结果，将待处理任务记录删除，同时向历史任务表添加记录。\r\n\r\n在MediaFileProcessService接口添加方法\r\n\r\n```java\r\n/**\r\n * @description 保存任务结果\r\n * @param taskId  任务id\r\n * @param status 任务状态\r\n * @param fileId  文件id\r\n * @param url url\r\n * @param errorMsg 错误信息\r\n * @return void\r\n */\r\nvoid saveProcessFinishStatus(Long taskId,String status,String fileId,String url,String errorMsg);\r\n```\r\n\r\nservice接口方法实现如下：\r\n\r\n```java\r\n@Slf4j\r\n@Service\r\npublic class MediaFileProcessServiceImpl implements MediaFileProcessService {\r\n\r\n @Autowired\r\n MediaFilesMapper mediaFilesMapper;\r\n\r\n @Autowired\r\n MediaProcessMapper mediaProcessMapper;\r\n\r\n @Autowired\r\n MediaProcessHistoryMapper mediaProcessHistoryMapper;\r\n\r\n\r\n\r\n@Transactional\r\n@Override\r\npublic void saveProcessFinishStatus(Long taskId, String status, String fileId, String url, String errorMsg) {\r\n    //查出任务，如果不存在则直接返回\r\n    MediaProcess mediaProcess = mediaProcessMapper.selectById(taskId);\r\n    if(mediaProcess == null){\r\n        return ;\r\n    }\r\n    //处理失败，更新任务处理结果\r\n    LambdaQueryWrapper<MediaProcess> queryWrapperById = new LambdaQueryWrapper<MediaProcess>().eq(MediaProcess::getId, taskId);\r\n    //处理失败\r\n    if(status.equals(\"3\")){\r\n        MediaProcess mediaProcess_u = new MediaProcess();\r\n        mediaProcess_u.setStatus(\"3\");\r\n        mediaProcess_u.setErrormsg(errorMsg);\r\n        mediaProcess_u.setFailCount(mediaProcess.getFailCount()+1);\r\n        mediaProcessMapper.update(mediaProcess_u,queryWrapperById);\r\n        log.debug(\"更新任务处理状态为失败，任务信息:{}\",mediaProcess_u);\r\n        return ;\r\n    }\r\n    //任务处理成功\r\n    MediaFiles mediaFiles = mediaFilesMapper.selectById(fileId);\r\n    if(mediaFiles!=null){\r\n        //更新媒资文件中的访问url\r\n        mediaFiles.setUrl(url);\r\n        mediaFilesMapper.updateById(mediaFiles);\r\n    }\r\n    //处理成功，更新url和状态\r\n    mediaProcess.setUrl(url);\r\n    mediaProcess.setStatus(\"2\");\r\n    mediaProcess.setFinishDate(LocalDateTime.now());\r\n    mediaProcessMapper.updateById(mediaProcess);\r\n\r\n    //添加到历史记录\r\n    MediaProcessHistory mediaProcessHistory = new MediaProcessHistory();\r\n    BeanUtils.copyProperties(mediaProcess, mediaProcessHistory);\r\n    mediaProcessHistoryMapper.insert(mediaProcessHistory);\r\n    //删除mediaProcess\r\n    mediaProcessMapper.deleteById(mediaProcess.getId());\r\n\r\n}\r\n\r\n @Override\r\n public List<MediaProcess> getMediaProcessList(int shardIndex, int shardTotal, int count) {\r\n  List<MediaProcess> mediaProcesses = mediaProcessMapper.selectListByShardIndex(shardTotal, shardIndex, count);\r\n   return mediaProcesses;\r\n }\r\n\r\n}\r\n```\r\n\r\n \r\n\r\n### **2.8 视频处理**\r\n\r\n视频采用并发处理，每个视频使用一个线程去处理，每次处理的视频数量不要超过cpu核心数。\r\n\r\n所有视频处理完成结束本次执行，为防止代码异常出现无限期等待则添加超时设置，到达超时时间还没有处理完成仍结束任务。\r\n\r\n定义任务类VideoTask 如下：\r\n\r\n```java\r\n@Slf4j\r\n@Component\r\npublic class VideoTask {\r\n\r\n    @Autowired\r\n    MediaFileService mediaFileService;\r\n    @Autowired\r\n    MediaFileProcessService mediaFileProcessService;\r\n\r\n\r\n    @Value(\"${videoprocess.ffmpegpath}\")\r\n    String ffmpegpath;\r\n\r\n    @XxlJob(\"videoJobHandler\")\r\n    public void videoJobHandler() throws Exception {\r\n\r\n        // 分片参数\r\n    int shardIndex = XxlJobHelper.getShardIndex();\r\n    int shardTotal = XxlJobHelper.getShardTotal();\r\n    List<MediaProcess> mediaProcessList = null;\r\n    int size = 0;\r\n    try {\r\n        //取出cpu核心数作为一次处理数据的条数\r\n        int processors = Runtime.getRuntime().availableProcessors();\r\n        //一次处理视频数量不要超过cpu核心数\r\n        mediaProcessList = mediaFileProcessService.getMediaProcessList(shardIndex, shardTotal, processors);\r\n        size = mediaProcessList.size();\r\n        log.debug(\"取出待处理视频任务{}条\", size);\r\n        if (size <= 0) {\r\n            return;\r\n        }\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n        return;\r\n    }\r\n    //启动size个线程的线程池\r\n    ExecutorService threadPool = Executors.newFixedThreadPool(size);\r\n    //计数器\r\n    CountDownLatch countDownLatch = new CountDownLatch(size);\r\n    //将处理任务加入线程池\r\n    mediaProcessList.forEach(mediaProcess -> {\r\n        threadPool.execute(() -> {\r\n            try {\r\n                //任务id\r\n                Long taskId = mediaProcess.getId();\r\n                //抢占任务\r\n                boolean b = mediaFileProcessService.startTask(taskId);\r\n                if (!b) {\r\n                    return;\r\n                }\r\n                log.debug(\"开始执行任务:{}\", mediaProcess);\r\n                //下边是处理逻辑\r\n                //桶\r\n                String bucket = mediaProcess.getBucket();\r\n                //存储路径\r\n                String filePath = mediaProcess.getFilePath();\r\n                //原始视频的md5值\r\n                String fileId = mediaProcess.getFileId();\r\n                //原始文件名称\r\n                String filename = mediaProcess.getFilename();\r\n                //将要处理的文件下载到服务器上\r\n                File originalFile = mediaFileService.downloadFileFromMinIO(mediaProcess.getBucket(), mediaProcess.getFilePath());\r\n                if (originalFile == null) {\r\n                    log.debug(\"下载待处理文件失败,originalFile:{}\", mediaProcess.getBucket().concat(mediaProcess.getFilePath()));\r\n                    mediaFileProcessService.saveProcessFinishStatus(mediaProcess.getId(), \"3\", fileId, null, \"下载待处理文件失败\");\r\n                    return;\r\n                }\r\n                //处理下载的视频文件\r\n                File mp4File = null;\r\n                try {\r\n                    mp4File = File.createTempFile(\"mp4\", \".mp4\");\r\n                } catch (IOException e) {\r\n                    log.error(\"创建mp4临时文件失败\");\r\n                    mediaFileProcessService.saveProcessFinishStatus(mediaProcess.getId(), \"3\", fileId, null, \"创建mp4临时文件失败\");\r\n                    return;\r\n                }\r\n                //视频处理结果\r\n                String result = \"\";\r\n                try {\r\n                    //开始处理视频\r\n                    Mp4VideoUtil videoUtil = new Mp4VideoUtil(ffmpegpath, originalFile.getAbsolutePath(), mp4File.getName(), mp4File.getAbsolutePath());\r\n                    //开始视频转换，成功将返回success\r\n                    result = videoUtil.generateMp4();\r\n                } catch (Exception e) {\r\n                    e.printStackTrace();\r\n                    log.error(\"处理视频文件:{},出错:{}\", mediaProcess.getFilePath(), e.getMessage());\r\n                }\r\n                if (!result.equals(\"success\")) {\r\n                    //记录错误信息\r\n                    log.error(\"处理视频失败,视频地址:{},错误信息:{}\", bucket + filePath, result);\r\n                    mediaFileProcessService.saveProcessFinishStatus(mediaProcess.getId(), \"3\", fileId, null, result);\r\n                    return;\r\n                }\r\n    \r\n                //将mp4上传至minio\r\n                //mp4在minio的存储路径\r\n                String objectName = getFilePath(fileId, \".mp4\");\r\n                //访问url\r\n                String url = \"/\" + bucket + \"/\" + objectName;\r\n                try {\r\n                    mediaFileService.addMediaFilesToMinIO(mp4File.getAbsolutePath(), \"video/mp4\", bucket, objectName);\r\n                    //将url存储至数据，并更新状态为成功，并将待处理视频记录删除存入历史\r\n                    mediaFileProcessService.saveProcessFinishStatus(mediaProcess.getId(), \"2\", fileId, url, null);\r\n                } catch (Exception e) {\r\n                    log.error(\"上传视频失败或入库失败,视频地址:{},错误信息:{}\", bucket + objectName, e.getMessage());\r\n                    //最终还是失败了\r\n                    mediaFileProcessService.saveProcessFinishStatus(mediaProcess.getId(), \"3\", fileId, null, \"处理后视频上传或入库失败\");\r\n                }\r\n            }finally {\r\n                countDownLatch.countDown();\r\n            }\r\n        });\r\n    });\r\n    //等待,给一个充裕的超时时间,防止无限等待，到达超时时间还没有处理完成则结束任务\r\n    countDownLatch.await(30, TimeUnit.MINUTES);\r\n    }\r\n\r\n    private String getFilePath(String fileMd5,String fileExt){\r\n        return   fileMd5.substring(0,1) + \"/\" + fileMd5.substring(1,2) + \"/\" + fileMd5 + \"/\" +fileMd5 +fileExt;\r\n    }\r\n\r\n}\r\n```\r\n\r\n \r\n\r\n### **2.9 测试**\r\n\r\n#### **2.9.1 基本测试**\r\n\r\n进入xxl-job调度中心添加执行器和视频处理任务\r\n\r\n在xxl-job配置任务调度策略：\r\n\r\n1）配置阻塞处理策略为：丢弃后续调度。\r\n\r\n2）配置视频处理调度时间间隔不用根据视频处理时间去确定，可以配置的小一些，如：5分钟，即使到达调度时间如果视频没有处理完会丢弃调度请求。\r\n\r\n配置完成开始测试视频处理：\r\n\r\n1、首先上传至少4个视频，非mp4格式。\r\n\r\n2、在xxl-job启动视频处理任务\r\n\r\n3、观察媒资管理服务后台日志\r\n\r\n#### **2.9.2 失败测试**\r\n\r\n1、先停止调度中心的视频处理任务。\r\n\r\n2、上传视频，手动修改待处理任务表中file_path字段为一个不存在的文件地址\r\n\r\n3、启动任务\r\n\r\n观察任务处理失败后是否会重试，并记录失败次数。\r\n\r\n#### **2.9.3 抢占任务测试**\r\n\r\n1、修改调度中心中视频处理任务的阻塞处理策略为“覆盖之间的调度”\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps134.jpg) \r\n\r\n2、在抢占任务代码处打断点并选择支持多线程方式\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps135.jpg) \r\n\r\n3、在抢占任务代码处的下边两行代码分别打上断点，避免观察时代码继续执行。\r\n\r\n4、启动任务\r\n\r\n此时多个线程执行都停留在断点处\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps136.jpg) \r\n\r\n依次放行，观察同一个任务只会被一个线程抢占成功。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps137.jpg) \r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps138.jpg) \r\n\r\n \r\n\r\n### **2.10 其它问题**\r\n\r\n#### **2.10.1 任务补偿机制**\r\n\r\n如果有线程抢占了某个视频的处理任务，如果线程处理过程中挂掉了，该视频的状态将会一直是处理中，其它线程将无法处理，这个问题需要用补偿机制。\r\n\r\n单独启动一个任务找到待处理任务表中超过执行期限但仍在处理中的任务，将任务的状态改为执行失败。\r\n\r\n任务执行期限是处理一个视频的最大时间，比如定为30分钟，通过任务的启动时间去判断任务是否超过执行期限。\r\n\r\n大家思考这个sql该如何实现？\r\n\r\n大家尝试自己实现此任务补偿机制。\r\n\r\n#### **2.10.2 达到最大失败次数**\r\n\r\n当任务达到最大失败次数时一般就说明程序处理此视频存在问题，这种情况就需要人工处理，在页面上会提示失败的信息，人工可手动执行该视频进行处理，或通过其它转码工具进行视频转码，转码后直接上传mp4视频。\r\n\r\n \r\n\r\n#### **2.10.3  分块文件清理问题**\r\n\r\n上传一个文件进行分块上传，上传一半不传了，之前上传到minio的分块文件要清理吗？怎么做的？\r\n\r\n1、在数据库中有一张文件表记录minio中存储的文件信息。\r\n\r\n2、文件开始上传时会写入文件表，状态为上传中，上传完成会更新状态为上传完成。\r\n\r\n3、当一个文件传了一半不再上传了说明该文件没有上传完成，会有定时任务去查询文件表中的记录，如果文件未上传完成则删除minio中没有上传成功的文件目录。\r\n\r\n\r\n\r\n## **三 任务调度实战—课程发布**\r\n\r\n### **3.1 需求分析**\r\n\r\n#### **3.1.1 数据模型**\r\n\r\n教学机构人员在课程审核通过后即可发布课程，课程发布后会公开展示在网站上供学生查看、选课和学习。\r\n\r\n在网站上展示课程信息需要解决课程信息显示的性能问题，如果速度慢(排除网速)会影响用户的体验性。\r\n\r\n如何去快速搜索课程？\r\n\r\n打开课程详情页面仍然去查询数据库可行吗？\r\n\r\n为了提高网站的速度需要将课程信息进行缓存，并且要将课程信息加入索引库方便搜索，下图显示了课程发布后课程信息的流转情况：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps1.jpg) \r\n\r\n1、向内容管理数据库的课程发布表存储课程发布信息，更新课程基本信息表中发布状态为已发布。\r\n\r\n2、向Redis存储课程缓存信息。\r\n\r\n3、向Elasticsearch存储课程索引信息。\r\n\r\n4、请求分布文件系统存储课程静态化页面(即html页面)，实现快速浏览课程详情页面。\r\n\r\n \r\n\r\n课程发布表的数据来源于课程预发布表，它们的结构基本一样，只是课程发布表中的状态是课程发布状态，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps2.jpg) \r\n\r\nredis中的课程缓存信息是将课程发布表中的数据转为json进行存储。\r\n\r\nelasticsearch中的课程索引信息是根据搜索需要将课程名称、课程介绍等信息进行索引存储。\r\n\r\nMinIO中存储了课程的静态化页面文件（html网页），查看课程详情是通过文件系统去浏览课程详情页面。\r\n\r\n\r\n\r\n### **3.2 课程发布的场景方案**\r\n\r\n\r\n\r\n目前我们已经有了任务调度的技术积累，这里选用任务调度的方案去实现分布式事务控制，课程发布满足：课程发布操作后，先更新数据库中的课程发布状态，更新后向redis、elasticsearch、MinIO写课程信息，只要在一定时间内最终向redis、elasticsearch、MinIO写数据成功即可。\r\n\r\n下图是具体的技术方案：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps3.jpg) \r\n\r\n \r\n\r\n1、在内容管理服务的数据库中添加一个消息表，消息表和课程发布表在同一个数据库。\r\n\r\n2、点击课程发布通过本地事务向课程发布表写入课程发布信息，同时向消息表写课程发布的消息。通过数据库进行控制，只要课程发布表插入成功消息表也插入成功，消息表的数据就记录了某门课程发布的任务。\r\n\r\n3、启动任务调度系统定时调度内容管理服务去定时扫描消息表的记录。\r\n\r\n4、当扫描到课程发布的消息时即开始完成向redis、elasticsearch、MinIO同步数据的操作。\r\n\r\n5、同步数据的任务完成后删除消息表记录。\r\n\r\n时序图如下：\r\n\r\n下图是课程发布操作的流程：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps4.jpg) \r\n\r\n1、执行发布操作，内容管理服务存储课程发布表的同时向消息表添加一条“课程发布任务”。这里使用本地事务保证课程发布信息保存成功，同时消息表也保存成功。\r\n\r\n2、任务调度服务定时调度内容管理服务扫描消息表，由于课程发布操作后向消息表插入一条课程发布任务，此时扫描到一条任务。\r\n\r\n3、拿到任务开始执行任务，分别向redis、elasticsearch及文件系统存储数据。\r\n\r\n4、任务完成后删除消息表记录。\r\n\r\n\r\n\r\n### **3.3 课程发布接口**\r\n\r\n**3.3.1 接口定义**\r\n\r\n根据课程发布的分布式事务控制方案，课程发布操作首先通过本地事务向课程发布表写入课程发布信息并向消息表插入一条消息，这里定义的课程发布接口要实现该功能。\r\n\r\n在内容管理接口工程中定义课程发布接口。\r\n\r\n```java\r\n\r\n /**\r\n * @description 课程预览，发布\r\n */\r\n@Api(value = \"课程预览发布接口\",tags = \"课程预览发布接口\")\r\n@Controller\r\npublic class CoursePublishController {\r\n...\r\n @ApiOperation(\"课程发布\")\r\n @ResponseBody\r\n @PostMapping (\"/coursepublish/{courseId}\")\r\npublic void coursepublish(@PathVariable(\"courseId\") Long courseId){\r\n\r\n}\r\n...\r\n```\r\n\r\n#### **3.3.2 接口开发**\r\n\r\n##### **3.3.2.1 DAO开发**\r\n\r\n课程发布操作对数据库操作如下：\r\n\r\n1、向课程发布表course_publish插入一条记录,记录来源于课程预发布表，如果存在则更新，发布状态为：已发布。\r\n\r\n2、更新course_base表的课程发布状态为：已发布\r\n\r\n3、删除课程预发布表的对应记录。\r\n\r\n4、向mq_message消息表插入一条消息，消息类型为：course_publish\r\n\r\n约束：\r\n\r\n1、课程审核通过方可发布。\r\n\r\n2、本机构只允许发布本机构的课程。\r\n\r\n \r\n\r\n以上功能使用自动生成的mapper接口即可完成。\r\n\r\n \r\n\r\n1、在内容管理数据库创建mq_message消息表及消息历史消息表（历史表存储已经完成的消息）。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps5.jpg) \r\n\r\n消息表结构如下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps6.jpg) \r\n\r\n \r\n\r\n2、生成mq_message消息表、course_publish课程发布表的po和mapper接口\r\n\r\n稍后会开发一个通用的消息处理组件，这里先不生成代码。\r\n\r\n \r\n\r\n##### **3.3.2.2 Service开发**\r\n\r\n定义Service接口：\r\n\r\n```java\r\n\r\n/**\r\n * @description 课程发布接口\r\n * @param companyId 机构id\r\n * @param courseId 课程id\r\n * @return void\r\n*/\r\npublic void publish(Long companyId,Long courseId);\r\n```\r\n\r\n编写课程发布的Service方法：\r\n\r\n```java\r\n\r\n @Transactional\r\n @Override\r\n public void publish(Long companyId, Long courseId) {\r\n\r\n  //约束校验\r\n  //查询课程预发布表\r\n  CoursePublishPre coursePublishPre = coursePublishPreMapper.selectById(courseId);\r\n  if(coursePublishPre == null){\r\n     XueChengPlusException.cast(\"请先提交课程审核，审核通过才可以发布\");\r\n  }\r\n  //本机构只允许提交本机构的课程\r\n  if(!coursePublishPre.getCompanyId().equals(companyId)){\r\n   XueChengPlusException.cast(\"不允许提交其它机构的课程。\");\r\n  }\r\n\r\n\r\n  //课程审核状态\r\n  String auditStatus = coursePublishPre.getStatus();\r\n  //审核通过方可发布\r\n  if(!\"202004\".equals(auditStatus)){\r\n   XueChengPlusException.cast(\"操作失败，课程审核通过方可发布。\");\r\n  }\r\n\r\n  //保存课程发布信息\r\n  saveCoursePublish(courseId);\r\n\r\n  //保存消息表\r\n  saveCoursePublishMessage(courseId);\r\n\r\n //删除课程预发布表对应记录\r\n  coursePublishPreMapper.deleteById(courseId);\r\n\r\n }\r\n\r\n/**\r\n * @description 保存课程发布信息\r\n * @param courseId  课程id\r\n * @return void\r\n*/\r\n private void saveCoursePublish(Long courseId){\r\n   //整合课程发布信息\r\n  //查询课程预发布表\r\n  CoursePublishPre coursePublishPre = coursePublishPreMapper.selectById(courseId);\r\n  if(coursePublishPre == null){\r\n   XueChengPlusException.cast(\"课程预发布数据为空\");\r\n  }\r\n\r\n  CoursePublish coursePublish = new CoursePublish();\r\n\r\n  //拷贝到课程发布对象\r\n  BeanUtils.copyProperties(coursePublishPre,coursePublish);\r\n  coursePublish.setStatus(\"203002\");\r\n  CoursePublish coursePublishUpdate = coursePublishMapper.selectById(courseId);\r\n  if(coursePublishUpdate == null){\r\n   coursePublishMapper.insert(coursePublish);\r\n  }else{\r\n   coursePublishMapper.updateById(coursePublish);\r\n  }\r\n  //更新课程基本表的发布状态\r\n  CourseBase courseBase = courseBaseMapper.selectById(courseId);\r\n  courseBase.setStatus(\"203002\");\r\n  courseBaseMapper.updateById(courseBase);\r\n\r\n }\r\n\r\n /**\r\n  * @description 保存消息表记录，稍后实现\r\n  * @param courseId  课程id\r\n  * @return void\r\n  */\r\nprivate void saveCoursePublishMessage(Long courseId){\r\n\r\n\r\n}\r\n```\r\n\r\n##### **3.3.2.3 接口完善**\r\n\r\n完善接口层代码\r\n\r\n```java\r\n\r\n @ApiOperation(\"课程发布\")\r\n @ResponseBody\r\n @PostMapping (\"/coursepublish/{courseId}\")\r\npublic void coursepublish(@PathVariable(\"courseId\") Long courseId){\r\n     Long companyId = 1232141425L;\r\n     coursePublishService.publish(companyId,courseId);\r\n\r\n }\r\n```\r\n\r\n#### **3.3.3 接口测试**\r\n\r\n先使用httpclient方法测试：\r\n\r\n```http\r\n### 课程发布\r\nPOST {{content_host}}/content/coursepublish/2\r\n```\r\n\r\n先测试约束条件：\r\n\r\n1、在未提交审核时进行课程发布测试。\r\n\r\n2、在课程未审核通过时进行发布。\r\n\r\n正常流程测试：\r\n\r\n1、提交审核课程\r\n\r\n2、手动修改课程预发布表与课程基本信息的审核状态为审核通过。\r\n\r\n3、执行课程发布\r\n\r\n4、观察课程发布表记录是否正常，课程预发布表记录已经删除，课程基本信息表与课程发布表的发布状态为”发布“。\r\n\r\n使用前后端联调方式测试。\r\n\r\n### **3.4 消息处理SDK**\r\n\r\n#### **3.4.1 消息模块技术方案**\r\n\r\n课程发布操作执行后需要扫描消息表的记录，有关消息表处理的有哪些？\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps7.jpg) \r\n\r\n上图中红色框内的都是与消息处理相关的操作：\r\n\r\n1、新增消息表\r\n\r\n2、扫描消息表。\r\n\r\n3、更新消息表。\r\n\r\n4、删除消息表。\r\n\r\n使用消息表这种方式实现最终事务一致性的地方除了课程发布还有其它业务场景。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps8.jpg) \r\n\r\n如果在每个地方都实现一套针对消息表定时扫描、处理的逻辑基本上都是重复的，软件的可复用性太低，成本太高。\r\n\r\n如何解决这个问题？\r\n\r\n针对这个问题可以想到将消息处理相关的逻辑做成一个通用的东西。\r\n\r\n是做成通用的服务，还是做成通用的代码组件呢？\r\n\r\n通用的服务是完成一个通用的独立功能，并提供独立的网络接口，比如：项目中的文件系统服务，提供文件的分布式存储服务。\r\n\r\n代码组件也是完成一个通用的独立功能，通常会提供API的方式供外部系统使用，比如：fastjson、Apache commons工具包等。\r\n\r\n如果将消息处理做成一个通用的服务，该服务需要连接多个数据库，因为它要扫描微服务数据库下的消息表，并且要提供与微服务通信的网络接口，单就针对当前需求而言开发成本有点高。\r\n\r\n如果将消息处理做一个SDK工具包相比通用服务不仅可以解决将消息处理通用化的需求，还可以降低成本。\r\n\r\n所以，本项目确定将对消息表相关的处理做成一个SDK组件供各微服务使用,如下图所示：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps9.jpg) \r\n\r\n下边对消息SDK的设计内容进行说明：\r\n\r\nsdk需要提供执行任务的逻辑吗？\r\n\r\n拿课程发布任务举例，执行课程发布任务是要向redis、索引库等同步数据，其它任务的执行逻辑是不同的，所以执行任务在sdk中不用实现任务逻辑，只需要提供一个抽象方法由具体的执行任务方去实现。\r\n\r\n如何保证任务的幂等性？\r\n\r\n在视频处理章节介绍的视频处理的幂等性方案，这里可以采用类似方案，任务执行完成后会从消息表删除，如果消息的状态是完成或不存在消息表中则不用执行。\r\n\r\n如何保证任务不重复执行？\r\n\r\n采用和视频处理章节一致方案，除了保证任务的幂等性外，任务调度采用分片广播，根据分片参数去获取任务，另外阻塞调度策略为丢弃任务。\r\n\r\n注意：这里是信息同步类任务，即使任务重复执行也没有关系，不再使用抢占任务的方式保证任务不重复执行。\r\n\r\n还有一个问题，根据消息表记录是否存在或消息表中的任务状态去保证任务的幂等性，如果一个任务有好几个小任务，比如：课程发布任务需要执行三个同步操作：存储课程到redis、存储课程到索引库，存储课程页面到文件系统。如果其中一个小任务已经完成也不应该去重复执行。这里该如何设计？\r\n\r\n \r\n\r\n将小任务作为任务的不同的阶段，在消息表中设计阶段状态。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps10.jpg) \r\n\r\n每完成一个阶段在相应的阶段状态字段打上完成标记，即使这个大任务没有完成再重新执行时，如果小阶段任务完成了也不会重复执行某个小阶段的任务。\r\n\r\n综上所述，除了消息表的基本的增、删、改、查的接口外，消息SDK还具有如下接口功能：\r\n\r\n```java\r\n\r\npackage com.xuecheng.messagesdk.service;\r\n\r\nimport com.baomidou.mybatisplus.extension.service.IService;\r\nimport com.xuecheng.messagesdk.model.po.MqMessage;\r\n\r\nimport java.util.List;\r\n\r\n/**\r\n * <p>\r\n *  服务类\r\n * </p>\r\n */\r\npublic interface MqMessageService extends IService<MqMessage> {\r\n\r\n    /**\r\n     * @description 扫描消息表记录，采用与扫描视频处理表相同的思路\r\n     * @param shardIndex 分片序号\r\n     * @param shardTotal 分片总数\r\n     * @param count 扫描记录数\r\n     * @return java.util.List 消息记录\r\n     */\r\n    public List<MqMessage> getMessageList(int shardIndex, int shardTotal,  String messageType,int count);\r\n\r\n    /**\r\n     * @description 完成任务\r\n     * @param id 消息id\r\n     * @return int 更新成功：1\r\n     */\r\n    public int completed(long id);\r\n\r\n    /**\r\n     * @description 完成阶段任务\r\n     * @param id 消息id\r\n     * @return int 更新成功：1\r\n     */\r\n    public int completedStageOne(long id);\r\n    public int completedStageTwo(long id);\r\n    public int completedStageThree(long id);\r\n    public int completedStageFour(long id);\r\n\r\n    /**\r\n     * @description 查询阶段状态\r\n     * @param id\r\n     * @return int\r\n    */\r\n    public int getStageOne(long id);\r\n    public int getStageTwo(long id);\r\n    public int getStageThree(long id);\r\n    public int getStageFour(long id);\r\n\r\n}\r\n```\r\n\r\n消息SDK提供消息处理抽象类，此抽象类供使用方去继承使用，如下：\r\n\r\n```java\r\nJava\r\npackage com.xuecheng.messagesdk.service;\r\n\r\nimport com.xuecheng.messagesdk.model.po.MqMessage;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\n\r\nimport java.util.List;\r\nimport java.util.concurrent.*;\r\n\r\n/**\r\n * @description 消息处理抽象类\r\n */\r\n@Slf4j\r\n@Data\r\npublic abstract class MessageProcessAbstract {\r\n\r\n    @Autowired\r\n    MqMessageService mqMessageService;\r\n\r\n\r\n    /**\r\n     * @param mqMessage 执行任务内容\r\n     * @return boolean true:处理成功，false处理失败\r\n     * @description 任务处理\r\n     */\r\n    public abstract boolean execute(MqMessage mqMessage);\r\n\r\n\r\n    /**\r\n     * @description 扫描消息表多线程执行任务\r\n     * @param shardIndex 分片序号\r\n     * @param shardTotal 分片总数\r\n     * @param messageType  消息类型\r\n     * @param count  一次取出任务总数\r\n     * @param timeout 预估任务执行时间,到此时间如果任务还没有结束则强制结束 单位秒\r\n     * @return void\r\n    */\r\n    public void process(int shardIndex, int shardTotal,  String messageType,int count,long timeout) {\r\n\r\n        try {\r\n            //扫描消息表获取任务清单\r\n            List<MqMessage> messageList = mqMessageService.getMessageList(shardIndex, shardTotal,messageType, count);\r\n            //任务个数\r\n            int size = messageList.size();\r\n            log.debug(\"取出待处理消息\"+size+\"条\");\r\n            if(size<=0){\r\n                return ;\r\n            }\r\n\r\n            //创建线程池\r\n            ExecutorService threadPool = Executors.newFixedThreadPool(size);\r\n            //计数器\r\n            CountDownLatch countDownLatch = new CountDownLatch(size);\r\n            messageList.forEach(message -> {\r\n                threadPool.execute(() -> {\r\n                    log.debug(\"开始任务:{}\",message);\r\n                    //处理任务\r\n                    try {\r\n                        boolean result = execute(message);\r\n                        if(result){\r\n                            log.debug(\"任务执行成功:{})\",message);\r\n                            //更新任务状态,删除消息表记录,添加到历史表\r\n                            int completed = mqMessageService.completed(message.getId());\r\n                            if (completed>0){\r\n                                log.debug(\"任务执行成功:{}\",message);\r\n                            }else{\r\n                                log.debug(\"任务执行失败:{}\",message);\r\n                            }\r\n                        }\r\n                    } catch (Exception e) {\r\n                        e.printStackTrace();\r\n                        log.debug(\"任务出现异常:{},任务:{}\",e.getMessage(),message);\r\n                    }\r\n                    //计数\r\n                    countDownLatch.countDown();\r\n                    log.debug(\"结束任务:{}\",message);\r\n\r\n                });\r\n            });\r\n\r\n            //等待,给一个充裕的超时时间,防止无限等待，到达超时时间还没有处理完成则结束任务\r\n            countDownLatch.await(timeout,TimeUnit.SECONDS);\r\n            System.out.println(\"结束....\");\r\n        } catch (InterruptedException e) {\r\n           e.printStackTrace();\r\n\r\n        }\r\n\r\n    }\r\n\r\n}\r\n```\r\n\r\n#### **3.4.2 消息模块SDK测试**\r\n\r\n1、在内容管理数据库创建消息表和消息历史表\r\n\r\n2、拷贝课程资料中的xuecheng-plus-message-sdk到工程目录，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps11.jpg) \r\n\r\n3、修改test下的bootstrap.yml中的数据库连接\r\n\r\n下边测试消息SDK的接口：\r\n\r\n1、继承MessageProcessAbstract 抽象类编写任务执行方法\r\n\r\n```java\r\n\r\npackage com.xuecheng.messagesdk;\r\n\r\nimport com.xuecheng.messagesdk.model.po.MqMessage;\r\nimport com.xuecheng.messagesdk.service.MessageProcessAbstract;\r\nimport com.xuecheng.messagesdk.service.MqMessageService;\r\nimport lombok.extern.slf4j.Slf4j;\r\nimport org.springframework.beans.factory.annotation.Autowired;\r\nimport org.springframework.stereotype.Component;\r\nimport org.springframework.stereotype.Service;\r\n\r\n/**\r\n * @description 消息处理测试类，继承MessageProcessAbstract\r\n */\r\n@Slf4j\r\n@Component\r\npublic class MessageProcessClass extends MessageProcessAbstract {\r\n\r\n\r\n    @Autowired\r\n    MqMessageService mqMessageService;\r\n\r\n    //执行任务\r\n    @Override\r\n    public boolean execute(MqMessage mqMessage) {\r\n        Long id = mqMessage.getId();\r\n        log.debug(\"开始执行任务:{}\",id);\r\n        try {\r\n            Thread.sleep(5000);\r\n        } catch (InterruptedException e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n\r\n        //取出阶段状态\r\n        int stageOne = mqMessageService.getStageOne(id);\r\n        if(stageOne<1){\r\n            log.debug(\"开始执行第一阶段任务\");\r\n            System.out.println();\r\n            int i = mqMessageService.completedStageOne(id);\r\n            if(i>0){\r\n                log.debug(\"完成第一阶段任务\");\r\n            }\r\n\r\n        }else{\r\n            log.debug(\"无需执行第一阶段任务\");\r\n        }\r\n\r\n        return true;\r\n    }\r\n}\r\n```\r\n\r\n2、编写测试类\r\n\r\n```java\r\n\r\n@SpringBootTest\r\npublic class MessageProcessClassTest {\r\n\r\n    @Autowired\r\n    MessageProcessClass messageProcessClass;\r\n\r\n    @Test\r\n    public void test() {\r\n\r\n        System.out.println(\"开始执行-----》\" + LocalDateTime.now());\r\n        messageProcessClass.process(0, 1, \"test\", 5, 30);\r\n        System.out.println(\"结束执行-----》\" + LocalDateTime.now());\r\n        Thread.sleep(9000000);\r\n    }\r\n}\r\n```\r\n\r\n3、准备测试数据，在消息表添加消息类型为\"test\"的消息\r\n\r\n4、执行MessageProcessClassTest 类中的test()方法，观察控制台任务执行的日志信息。\r\n\r\n \r\n\r\n#### **3.4.3 集成消息SDK**\r\n\r\n##### **3.4.3.1 添加消息**\r\n\r\n1、在内容管理数据库创建消息表和消息历史表\r\n\r\n2、拷贝课程资料中的xuecheng-plus-message-sdk到工程目录，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps12.jpg) \r\n\r\n3、在内容管理service工程中添加sdk依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>com.xuecheng</groupId>\r\n    <artifactId>xuecheng-plus-message-sdk</artifactId>\r\n    <version>0.0.1-SNAPSHOT</version>\r\n</dependency>\r\n```\r\n\r\n4、课程发布操作使用本地事务保存课程发布信息、添加消息表。\r\n\r\n回到当初编写课程发布时的代码，如下：\r\n\r\n```java\r\n\r\n@Transactional\r\n@Override\r\npublic void publish(Long companyId, Long courseId) {\r\n\r\n //约束校验\r\n //查询课程预发布表\r\n CoursePublishPre coursePublishPre = coursePublishPreMapper.selectById(courseId);\r\n if(coursePublishPre == null){\r\n    XueChengPlusException.cast(\"请先提交课程审核，审核通过才可以发布\");\r\n }\r\n //本机构只允许提交本机构的课程\r\n if(!coursePublishPre.getCompanyId().equals(companyId)){\r\n  XueChengPlusException.cast(\"不允许提交其它机构的课程。\");\r\n }\r\n\r\n //课程审核状态\r\n String auditStatus = coursePublishPre.getStatus();\r\n //审核通过方可发布\r\n if(!\"202004\".equals(auditStatus)){\r\n  XueChengPlusException.cast(\"操作失败，课程审核通过方可发布。\");\r\n }\r\n //保存课程发布信息\r\n saveCoursePublish(courseId);\r\n\r\n //保存消息表\r\n saveCoursePublishMessage(courseId);\r\n\r\n//删除课程预发布表对应记录\r\n coursePublishPreMapper.deleteById(courseId);\r\n\r\n}\r\n```\r\n\r\n我们要填充的saveCoursePublishMessage(courseId)方法，如下：\r\n\r\n```java\r\n\r\n /**\r\n  * @description 保存消息表记录\r\n  * @param courseId  课程id\r\n  * @return void\r\n  */\r\nprivate void saveCoursePublishMessage(Long courseId){\r\n MqMessage mqMessage = mqMessageService.addMessage(\"course_publish\", String.valueOf(courseId), null, null);\r\n if(mqMessage==null){\r\n  XueChengPlusException.cast(CommonError.UNKOWN_ERROR);\r\n }\r\n}\r\n```\r\n\r\n下边进行测试：\r\n\r\n发布一门课程，观察消息表是否正常添加消息。\r\n\r\n需要手动修改课程审核状态为审核通过执行发布操作，发布后可以修改发布状态为下架重新发布测试。\r\n\r\n##### **3.4.3.2 课程发布任务处理**\r\n\r\n在内容管理服务添加消息处理sdk的依赖即可使用它，实现sdk中的MessageProcessAbstract类，重写execte方法。\r\n\r\n实现sdk中的MessageProcessAbstract类：\r\n\r\n```java\r\n\r\n@Slf4j\r\n@Component\r\npublic class CoursePublishTask extends MessageProcessAbstract {\r\n\r\n    //课程发布任务处理\r\n    @Override\r\n    public boolean execute(MqMessage mqMessage) {\r\n        //获取消息相关的业务信息\r\n        String businessKey1 = mqMessage.getBusinessKey1();\r\n        long courseId = Integer.parseInt(businessKey1);\r\n        //课程静态化\r\n        generateCourseHtml(mqMessage,courseId);\r\n        //课程索引\r\n        saveCourseIndex(mqMessage,courseId);\r\n        //课程缓存\r\n        saveCourseCache(mqMessage,courseId);\r\n        return true;\r\n    }\r\n\r\n\r\n    //生成课程静态化页面并上传至文件系统\r\n    public void generateCourseHtml(MqMessage mqMessage,long courseId){\r\n\r\n        log.debug(\"开始进行课程静态化,课程id:{}\",courseId);\r\n        //消息id\r\n        Long id = mqMessage.getId();\r\n        //消息处理的service\r\n        MqMessageService mqMessageService = this.getMqMessageService();\r\n        //消息幂等性处理\r\n        int stageOne = mqMessageService.getStageOne(id);\r\n        if(stageOne >0){\r\n            log.debug(\"课程静态化已处理直接返回，课程id:{}\",courseId);\r\n            return ;\r\n        }\r\n        try {\r\n            TimeUnit.SECONDS.sleep(10);\r\n        } catch (InterruptedException e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n        //保存第一阶段状态\r\n        mqMessageService.completedStageOne(id);\r\n\r\n    }\r\n\r\n    //将课程信息缓存至redis\r\n    public void saveCourseCache(MqMessage mqMessage,long courseId){\r\n        log.debug(\"将课程信息缓存至redis,课程id:{}\",courseId);\r\n        try {\r\n            TimeUnit.SECONDS.sleep(2);\r\n        } catch (InterruptedException e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n\r\n\r\n    }\r\n    //保存课程索引信息\r\n    public void saveCourseIndex(MqMessage mqMessage,long courseId){\r\n        log.debug(\"保存课程索引信息,课程id:{}\",courseId);\r\n        try {\r\n            TimeUnit.SECONDS.sleep(2);\r\n        } catch (InterruptedException e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n\r\n    }\r\n\r\n}\r\n```\r\n\r\n##### **3.4.3.3 开启任务调度**\r\n\r\n1、首先在内容管理service工程中添加xxl-job依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>com.xuxueli</groupId>\r\n    <artifactId>xxl-job-core</artifactId>\r\n</dependency>\r\n```\r\n\r\n2、配置执行器\r\n\r\n在nacos中在content-service-dev.yaml中配置\r\n\r\n```yaml\r\n\r\nxxl:\r\n  job:\r\n    admin: \r\n      addresses: http://192.168.2.203:8088/xxl-job-admin\r\n    executor:\r\n      appname: coursepublish-job\r\n      address: \r\n      ip: \r\n      port: 8999\r\n      logpath: /data/applogs/xxl-job/jobhandler\r\n      logretentiondays: 30\r\n    accessToken: default_token\r\n```\r\n\r\n3、从媒资管理服务层工程中拷贝一个XxlJobConfig配置类到内容管理service工程中。\r\n\r\n \r\n\r\n在xxl-job-admin控制台中添加执行器\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps13.jpg) \r\n\r\n \r\n\r\n3、编写任务调度入口\r\n\r\n```java\r\n\r\n@Slf4j\r\n@Component\r\npublic class CoursePublishTask extends MessageProcessAbstract {\r\n\r\n    //任务调度入口\r\n    @XxlJob(\"CoursePublishJobHandler\")\r\n    public void coursePublishJobHandler() throws Exception {\r\n        // 分片参数\r\n        int shardIndex = XxlJobHelper.getShardIndex();\r\n        int shardTotal = XxlJobHelper.getShardTotal();\r\n        log.debug(\"shardIndex=\"+shardIndex+\",shardTotal=\"+shardTotal);\r\n        //参数:分片序号、分片总数、消息类型、一次最多取到的任务数量、一次任务调度执行的超时时间\r\n        process(shardIndex,shardTotal,\"course_publish\",30,60);\r\n    }\r\n    ....\r\n```\r\n\r\n4、在xxl-job添加任务\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps14.jpg) \r\n\r\n任务配置如下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps15.jpg) \r\n\r\n到此SDK开发、集成完成，下一步添加课程发布后页面静态化、课程缓存、课程索引等任务。\r\n\r\n##### **3.4.3.4 测试**\r\n\r\n在消息表添加课程发布的消息，消息类型为course_publish,business_key1为发布课程的ID\r\n\r\n1、测试是否可以正常调度执行。\r\n\r\n2、测试任务幂等性\r\n\r\n在 saveCourseCache(mqMessage,courseId);处打断点，待执行到这里观察数据库第一阶段完成的标记预期标记为1。\r\n\r\n结束进程，再重新启动，观察第一阶段的任务预期不再执行。\r\n\r\n3、任务执行完成删除消息表记录，插入历史表，state状态字段为1\r\n\r\n \r\n\r\n### **3.5 页面静态化**\r\n\r\n#### **3.5.1 什么是页面静态化**\r\n\r\n根据课程发布的操作流程，执行课程发布后要将课程详情信息页面静态化，生成html页面上传至文件系统。\r\n\r\n什么是页面静态化？\r\n\r\n课程预览功能通过模板引擎技术在页面模板中填充数据，生成html页面，这个过程是当客户端请求服务器时服务器才开始渲染生成html页面，最后响应给浏览器，服务端渲染的并发能力是有限的。\r\n\r\n页面静态化则强调将生成html页面的过程提前，提前使用模板引擎技术生成html页面，当客户端请求时直接请求html页面，由于是静态页面可以使用nginx、apache等高性能的web服务器，并发性能高。\r\n\r\n什么时候能用页面静态化技术？\r\n\r\n当数据变化不频繁，一旦生成静态页面很长一段时间内很少变化，此时可以使用页面静态化。因为如果数据变化频繁，一旦改变就需要重新生成静态页面，导致维护静态页面的工作量很大。\r\n\r\n根据课程发布的业务需求，虽然课程发布后仍可以修改课程信息，但需要经过课程审核，且修改频度不大，所以适合使用页面静态化。\r\n\r\n \r\n\r\n#### **3.5.2 静态化测试**\r\n\r\n下边使用freemarker技术对页面静态化生成html页面。\r\n\r\n在内容管理service工程中添加freemarker依赖\r\n\r\n```xml\r\n<dependency>\r\n    <groupId>org.springframework.boot</groupId>\r\n    <artifactId>spring-boot-starter-freemarker</artifactId>\r\n</dependency>\r\n```\r\n\r\n编写测试方法\r\n\r\n```java\r\n\r\n@SpringBootTest\r\npublic class FreemarkerTest {\r\n\r\n    @Autowired\r\n    CoursePublishService coursePublishService;\r\n\r\n\r\n    //测试页面静态化\r\n    @Test\r\n    public void testGenerateHtmlByTemplate() throws IOException, TemplateException {\r\n        //配置freemarker\r\n        Configuration configuration = new Configuration(Configuration.getVersion());\r\n\r\n        //加载模板\r\n        //选指定模板路径,classpath下templates下\r\n        //得到classpath路径\r\n        String classpath = this.getClass().getResource(\"/\").getPath();\r\n        configuration.setDirectoryForTemplateLoading(new File(classpath + \"/templates/\"));\r\n        //设置字符编码\r\n        configuration.setDefaultEncoding(\"utf-8\");\r\n\r\n        //指定模板文件名称\r\n        Template template = configuration.getTemplate(\"course_template.ftl\");\r\n\r\n        //准备数据\r\n        CoursePreviewDto coursePreviewInfo = coursePublishService.getCoursePreviewInfo(2L);\r\n\r\n        Map<String, Object> map = new HashMap<>();\r\n        map.put(\"model\", coursePreviewInfo);\r\n\r\n        //静态化\r\n        //参数1：模板，参数2：数据模型\r\n        String content = FreeMarkerTemplateUtils.processTemplateIntoString(template, map);\r\n        System.out.println(content);\r\n        //将静态化内容输出到文件中\r\n        InputStream inputStream = IOUtils.toInputStream(content);\r\n        //输出流\r\n        FileOutputStream outputStream = new FileOutputStream(\"D:\\\\develop\\\\test.html\");\r\n        IOUtils.copy(inputStream, outputStream);\r\n\r\n    }\r\n\r\n}\r\n```\r\n\r\n将content-api工程下的模板拷贝到content-service工程下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps16.jpg) \r\n\r\n \r\n\r\n执行测试方法，观察D:\\\\develop\\\\test.html 是否成功生成。\r\n\r\n \r\n\r\n#### **3.5.3 上传文件测试**\r\n\r\n##### **3.5.3.1 配置远程调用环境**\r\n\r\n静态化生成文件后需要上传至分布式文件系统，根据微服务的职责划分，媒资管理服务负责维护文件系统中的文件，所以内容管理服务对页面静态化生成html文件需要调用媒资管理服务的上传文件接口。如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps17.jpg) \r\n\r\n微服务之间难免会存在远程调用，在Spring Cloud中可以使用Feign进行远程调用，\r\n\r\nFeign是一个声明式的http客户端，官方地址：https://github.com/OpenFeign/feign\r\n\r\n其作用就是帮助我们优雅的实现http请求的发送，解决上面提到的问题。\r\n\r\n下边先准备Feign的开发环境:\r\n\r\n1、在内容管理content-service工程添加依赖：\r\n\r\n```xml\r\n\r\n<dependency>\r\n    <groupId>com.alibaba.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\r\n</dependency>\r\n<!-- Spring Cloud 微服务远程调用 -->\r\n<dependency>\r\n    <groupId>org.springframework.cloud</groupId>\r\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\r\n</dependency>\r\n<dependency>\r\n    <groupId>io.github.openfeign</groupId>\r\n    <artifactId>feign-httpclient</artifactId>\r\n</dependency>\r\n<!--feign支持Multipart格式传参-->\r\n<dependency>\r\n    <groupId>io.github.openfeign.form</groupId>\r\n    <artifactId>feign-form</artifactId>\r\n    <version>3.8.0</version>\r\n</dependency>\r\n<dependency>\r\n    <groupId>io.github.openfeign.form</groupId>\r\n    <artifactId>feign-form-spring</artifactId>\r\n    <version>3.8.0</version>\r\n</dependency>\r\n```\r\n\r\n2、在nacos配置feign-dev.yaml公用配置文件\r\n\r\n```yaml\r\n\r\nfeign:\r\n  hystrix:\r\n    enabled: true\r\n  circuitbreaker:\r\n    enabled: true\r\nhystrix:\r\n  command:\r\n    default:\r\n      execution:\r\n        isolation:\r\n          thread:\r\n            timeoutInMilliseconds: 30000  #熔断超时时间\r\nribbon:\r\n  ConnectTimeout: 60000 #连接超时时间\r\n  ReadTimeout: 60000 #读超时时间\r\n  MaxAutoRetries: 0 #重试次数\r\n  MaxAutoRetriesNextServer: 1 #切换实例的重试次数\r\n\r\n```\r\n\r\n3、在内容管理service工程和内容管理api工程都引入此配置文件\r\n\r\n```yaml\r\n\r\nshared-configs:\r\n  - data-id: feign-${spring.profiles.active}.yaml\r\n    group: xuecheng-plus-common\r\n    refresh: true\r\n```\r\n\r\n4、在内容管理service工程配置feign支持Multipart，拷贝课程资料下的MultipartSupportConfig 到content-service工程下的config包下。\r\n\r\n \r\n\r\n##### **3.5.3.2 扩充上传文件接口**\r\n\r\n现在需要将课程的静态文件上传到minio，单独存储到course目录下，文件的objectname为\"课程id.html\"，原有的上传文件接口需要增加一个参数 objectname。\r\n\r\n下边扩充媒资服务的上传文件接口\r\n\r\n```java\r\n\r\n@ApiOperation(\"上传文件\")\r\n@RequestMapping(value = \"/upload/coursefile\",consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\r\npublic UploadFileResultDto upload(@RequestPart(\"filedata\") MultipartFile filedata,\r\n                                  @RequestParam(value= \"objectName\",required=false) String objectName) throws IOException{\r\n                                  //....\r\n }\r\n```\r\n\r\nservice接口也增加一个参数：\r\n\r\n```java\r\n\r\n/**\r\n * 上传文件\r\n * @param companyId 机构id\r\n * @param uploadFileParamsDto 上传文件信息\r\n * @param localFilePath 文件磁盘路径\r\n * @param objectName 对象名\r\n * @return 文件信息\r\n */\r\npublic UploadFileResultDto uploadFile(Long companyId, UploadFileParamsDto uploadFileParamsDto, String localFilePath,String objectName);\r\n```\r\n\r\n修改原有uploadFile方法，判断如果objectName为空则采取年月日样式的路径方式。\r\n\r\n```java\r\n\r\n//存储到minio中的对象名(带目录)\r\nif(StringUtils.isEmpty(objectName)){\r\n    objectName =  defaultFolderPath + fileMd5 + extension;\r\n}\r\n//        String objectName = defaultFolderPath + fileMd5 + extension;\r\n```\r\n\r\n##### **3.5.3.3 远程调用测试**\r\n\r\n在content-service下编写feign接口\r\n\r\n```java\r\n\r\n\r\n/**\r\n * @description 媒资管理服务远程接口\r\n */\r\n @FeignClient(value = \"media-api\",configuration = MultipartSupportConfig.class)\r\npublic interface MediaServiceClient {\r\n\r\n @RequestMapping(value = \"/media/upload/coursefile\",consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\r\n String uploadFile(@RequestPart(\"filedata\") MultipartFile upload,@RequestParam(value = \"objectName\",required=false) String objectName);\r\n}\r\n```\r\n\r\n在启动类添加@EnableFeignClients注解\r\n\r\n`@EnableFeignClients(basePackages={\"com.xuecheng.content.feignclient\"})`\r\n\r\n编写测试方法\r\n\r\n```java\r\n\r\n\r\n/**\r\n * @description 测试使用feign远程上传文件\r\n */\r\n@SpringBootTest\r\npublic class FeignUploadTest {\r\n\r\n    @Autowired\r\n    MediaServiceClient mediaServiceClient;\r\n\r\n    //远程调用，上传文件\r\n    @Test\r\n    public void test() {\r\n    \r\n        MultipartFile multipartFile = MultipartSupportConfig.getMultipartFile(new File(\"D:\\\\develop\\\\test.html\"));\r\n        mediaServiceClient.uploadFile(multipartFile,\"course\",\"test.html\");\r\n    }\r\n\r\n}\r\n```\r\n\r\n下边进行测试，启动媒资服务，执行测试方法，上传文件成功，进入minIO查看文件\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps18.jpg) \r\n\r\n访问：http://192.168.101.65:9000/mediafiles/course/74b386417bb9f3764009dc94068a5e44.html\r\n\r\n查看是否可以正常访问。\r\n\r\n\r\n\r\n#### **3.5.4 课程静态化开发**\r\n\r\n课程页面静态化和静态页面远程上传测试通过，下一步开发课程静态化功能，最终使用消息处理SDK去调度执行。\r\n\r\n \r\n\r\n##### **3.5.4.1 静态化实现**\r\n\r\n课程静态化包括两部分工作：生成课程静态化页面，上传静态页面到文件系统。\r\n\r\n在课程发布的service编写这两部分内容，最后通过消息去调度执行。\r\n\r\n1、接口定义\r\n\r\n```java\r\n\r\n/**\r\n * @description 课程静态化\r\n * @param courseId  课程id\r\n * @return File 静态化文件\r\n*/\r\npublic File generateCourseHtml(Long courseId);\r\n/**\r\n * @description 上传课程静态化页面\r\n * @param file  静态化文件\r\n * @return void\r\n*/\r\npublic void  uploadCourseHtml(Long courseId,File file);\r\n```\r\n\r\n2、接口实现\r\n\r\n将之前编写的静态化测试代码以及上传静态文件测试代码拷贝过来使用\r\n\r\n```java\r\n\r\n\t@Override\r\n    public File generateCourseHtml(Long courseId) {\r\n\r\n        //静态化文件\r\n        File htmlFile  = null;\r\n\r\n        try {\r\n            //配置freemarker\r\n            Configuration configuration = new Configuration(Configuration.getVersion());\r\n\r\n            //加载模板\r\n            //选指定模板路径,classpath下templates下\r\n            //得到classpath路径\r\n            String classpath = this.getClass().getResource(\"/\").getPath();\r\n            configuration.setDirectoryForTemplateLoading(new File(classpath + \"/templates/\"));\r\n            //设置字符编码\r\n            configuration.setDefaultEncoding(\"utf-8\");\r\n\r\n            //指定模板文件名称\r\n            Template template = configuration.getTemplate(\"course_template.ftl\");\r\n\r\n            //准备数据\r\n            CoursePreviewDto coursePreviewInfo = this.getCoursePreviewInfo(courseId);\r\n\r\n            Map<String, Object> map = new HashMap<>();\r\n            map.put(\"model\", coursePreviewInfo);\r\n\r\n            //静态化\r\n            //参数1：模板，参数2：数据模型\r\n            String content = FreeMarkerTemplateUtils.processTemplateIntoString(template, map);\r\n//            System.out.println(content);\r\n            //将静态化内容输出到文件中\r\n            InputStream inputStream = IOUtils.toInputStream(content);\r\n            //创建静态化文件\r\n            htmlFile = File.createTempFile(\"course\",\".html\");\r\n            log.debug(\"课程静态化，生成静态文件:{}\",htmlFile.getAbsolutePath());\r\n            //输出流\r\n            FileOutputStream outputStream = new FileOutputStream(htmlFile);\r\n            IOUtils.copy(inputStream, outputStream);\r\n        } catch (Exception e) {\r\n            log.error(\"课程静态化异常:{}\",e.toString());\r\n            XueChengPlusException.cast(\"课程静态化异常\");\r\n        }\r\n\r\n        return htmlFile;\r\n    }\r\n\r\n    @Override\r\n    public void uploadCourseHtml(Long courseId, File file) {\r\n        MultipartFile multipartFile = MultipartSupportConfig.getMultipartFile(file);\r\n        String course = mediaServiceClient.uploadFile(multipartFile, \"course/\"+courseId+\".html\");\r\n        if(course==null){\r\n            XueChengPlusException.cast(\"上传静态文件异常\");\r\n        }\r\n    }\r\n```\r\n\r\n完善课程发布任务CoursePublishTask类的代码：\r\n\r\n```java\r\nJava\r\n//生成课程静态化页面并上传至文件系统\r\npublic void generateCourseHtml(MqMessage mqMessage,long courseId){\r\n    log.debug(\"开始进行课程静态化,课程id:{}\",courseId);\r\n    //消息id\r\n    Long id = mqMessage.getId();\r\n    //消息处理的service\r\n    MqMessageService mqMessageService = this.getMqMessageService();\r\n    //消息幂等性处理\r\n    int stageOne = mqMessageService.getStageOne(id);\r\n    if(stageOne == 1){\r\n        log.debug(\"课程静态化已处理直接返回，课程id:{}\",courseId);\r\n        return ;\r\n    }\r\n\r\n    //生成静态化页面\r\n    File file = coursePublishService.generateCourseHtml(courseId);\r\n    //上传静态化页面\r\n    if(file!=null){\r\n        coursePublishService.uploadCourseHtml(courseId,file);\r\n    }\r\n    //保存第一阶段状态\r\n    mqMessageService.completedStageOne(id);\r\n\r\n}\r\n```\r\n\r\n##### **3.5.4.2 测试**\r\n\r\n1、启动网关、媒资管理服务工程。\r\n\r\n2、在内容管理api工程的启动类上配置FeignClient\r\n\r\n `@EnableFeignClients(basePackages={\"com.xuecheng.content.feignclient\"})`\r\n\r\n在bootstrap.yml引用feign-dev.yaml\r\n\r\n```yaml\r\n\r\n- data-id: feign-${spring.profiles.active}.yaml\r\n  group: xuecheng-plus-common\r\n  refresh: true  #profiles默认为dev\r\n```\r\n\r\n启动内容管理接口工程。\r\n\r\n在CoursePublishTask类的execute方法中打上断点。\r\n\r\n \r\n\r\n3、发布一门课程，保存消息表存在未处理的处理。\r\n\r\n \r\n\r\n4、启动xxl-job调度中心、启动课程发布任务，等待定时调度。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps19.jpg) \r\n\r\n \r\n\r\n \r\n\r\n5、观察任务调度日志，观察任务是否可以正常处理。\r\n\r\n6、处理完成进入文件系统，查询mediafiles桶内是否存在以课程id命名的html文件\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps20.jpg) \r\n\r\n如果不存在说明课程静态化存在问题，再仔细查看执行日志，排查问题。\r\n\r\n如果存在则说明课程静态化并上传到minio成功。\r\n\r\n##### **3.5.4.3 浏览详细页面**\r\n\r\n课程静态化成功后可以用浏览器访问html文件是否可以正常浏览，下图表示可以正常浏览。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps21.jpg) \r\n\r\n页面还没有样式，需要在nginx配置虚拟目录，在www.51xuecheng.cn下配置：\r\n\r\n```http\r\nlocation /course/ {  \r\n        proxy_pass http://fileserver/mediafiles/course/;\r\n} \r\n```\r\n\r\n加载nginx配置文件\r\n\r\n访问：http://www.51xuecheng.cn/course/2.html\r\n\r\n2.html为以课程id命名的html文件。\r\n\r\n### **3.6 课程搜索**\r\n\r\n#### **3.6.1 需求分析**\r\n\r\n##### **3.6.1.1 模块介绍**\r\n\r\n搜索功能是一个系统的重要功能，是信息查询的方式。课程搜索是课程展示的渠道，用户通过课程搜索找到课程信息，进一步去查看课程的详细信息，进行选课、支付、学习。\r\n\r\n本项目的课程搜索支持全文检索技术，什么是全文检索？\r\n\r\n[全文检索](https://baike.baidu.com/item/全文检索/8028630?fromModule=lemma_inlink)是指计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。这个过程类似于通过字典中的检索字表查字的过程。\r\n\r\n全文检索可以简单理解为通过索引搜索文章。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps22.jpg) \r\n\r\n全文检索的速度非常快，早期应用在搜索引擎技术中，比如：百度、google等，现在通常一些大型网站的搜索功能都是采用全文检索技术。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps23.jpg) \r\n\r\n课程搜索也要将课程信息建立索引，在课程发布时建立课程索引，索引建立好用户可通过搜索网页去查询课程信息。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps24.jpg) \r\n\r\n所以，课程搜索模块包括两部分：课程索引、课程搜索。\r\n\r\n课程索引是将课程信息建立索引。\r\n\r\n课程搜索是通过前端网页，通过关键字等条件去搜索课程。\r\n\r\n \r\n\r\n##### **3.6.1.2 业务流程**\r\n\r\n根据模块介绍的内容，课程搜索模块包括课程索引、课程搜索两部分。\r\n\r\n1、课程索引\r\n\r\n在课程发布操作执行后通过消息处理方式创建课程索引，如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps25.jpg) \r\n\r\n本项目使用elasticsearch作为索引及搜索服务。\r\n\r\n \r\n\r\n2、课程搜索\r\n\r\n课程索引创建完成，用户才可以通过前端搜索课程信息。\r\n\r\n课程搜索可以从首页进入搜索页面。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps26.jpg) \r\n\r\n下图是搜索界面，可以通过课程分类、课程难度等级等条件进行搜索。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps27.jpg) \r\n\r\n#### **3.6.2 准备环境**\r\n\r\n##### **3.6.2.1 搭建elasticsearch**\r\n\r\n在课前下发的虚拟中已经在docker容器中安装了elasticsearch和kibana。\r\n\r\nkibana 是 ELK（Elasticsearch , Logstash, Kibana ）之一，kibana 一款开源的数据分析和可视化平台，通过可视化界面访问elasticsearch的索引库，并可以生成一个数据报表。\r\n\r\n开发中主要使用kibana通过api对elasticsearch进行索引和搜索操作，通过浏览器访问 http://192.168.101.65:5601/app/dev_tools#/console进入kibana的开发工具界面。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps28.jpg)\r\n\r\n \r\n\r\n可通过命令：GET /_cat/indices?v  查看所有的索引，通过此命令判断kibana是否正常连接elasticsearch。\r\n\r\n索引相当于MySQL中的表，Elasticsearch与MySQL之间概念的对应关系见下表：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps29.jpg) \r\n\r\n要使用elasticsearch需要建立索引，Mapping相当于表结构，Mapping创建后其字段不能删除，如果要删除需要删除整个索引，下边介绍创建索引、查询索引、删除索引的方法：\r\n\r\n1、创建索引，并指定Mapping。\r\n\r\n`PUT /course-publish`\r\n\r\n```json\r\n\r\n{\r\n  \"settings\": {\r\n    \"number_of_shards\": 1,\r\n    \"number_of_replicas\": 0\r\n  },\r\n  \"mappings\": {\r\n    \"properties\": {\r\n      \"id\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"companyId\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"companyName\": {\r\n        \"analyzer\": \"ik_max_word\",\r\n        \"search_analyzer\": \"ik_smart\",\r\n        \"type\": \"text\"\r\n      },\r\n      \"name\": {\r\n        \"analyzer\": \"ik_max_word\",\r\n        \"search_analyzer\": \"ik_smart\",\r\n        \"type\": \"text\"\r\n      },\r\n      \"users\": {\r\n        \"index\": false,\r\n        \"type\": \"text\"\r\n      },\r\n      \"tags\": {\r\n        \"analyzer\": \"ik_max_word\",\r\n        \"search_analyzer\": \"ik_smart\",\r\n        \"type\": \"text\"\r\n      },\r\n      \"mt\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"mtName\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"st\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"stName\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"grade\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"teachmode\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"pic\": {\r\n        \"index\": false,\r\n        \"type\": \"text\"\r\n      },\r\n      \"description\": {\r\n        \"analyzer\": \"ik_max_word\",\r\n        \"search_analyzer\": \"ik_smart\",\r\n        \"type\": \"text\"\r\n      },\r\n      \"createDate\": {\r\n        \"format\": \"yyyy-MM-dd HH:mm:ss\",\r\n        \"type\": \"date\"\r\n      },\r\n      \"status\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"remark\": {\r\n        \"index\": false,\r\n        \"type\": \"text\"\r\n      },\r\n      \"charge\": {\r\n        \"type\": \"keyword\"\r\n      },\r\n      \"price\": {\r\n        \"type\": \"scaled_float\",\r\n        \"scaling_factor\": 100\r\n      },\r\n      \"originalPrice\": {\r\n        \"type\": \"scaled_float\",\r\n        \"scaling_factor\": 100\r\n      },\r\n      \"validDays\": {\r\n        \"type\": \"integer\"\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n```\r\n\r\n2、查询索引\r\n\r\n通过 `GET /_cat/indices?v` 查询所有的索引，查找course-publish是否创建成功。\r\n\r\n通过`GET /course-publish/_mapping` 查询course-publish的索引结构。\r\n\r\n```json\r\n\r\n{\r\n  \"course-publish\" : {\r\n    \"mappings\" : {\r\n      \"properties\" : {\r\n        \"charge\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"companyId\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"companyName\" : {\r\n          \"type\" : \"text\",\r\n          \"analyzer\" : \"ik_max_word\",\r\n          \"search_analyzer\" : \"ik_smart\"\r\n        },\r\n        \"createDate\" : {\r\n          \"type\" : \"date\",\r\n          \"format\" : \"yyyy-MM-dd HH:mm:ss\"\r\n        },\r\n        \"description\" : {\r\n          \"type\" : \"text\",\r\n          \"analyzer\" : \"ik_max_word\",\r\n          \"search_analyzer\" : \"ik_smart\"\r\n        },\r\n        \"grade\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"id\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"mt\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"mtName\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"name\" : {\r\n          \"type\" : \"text\",\r\n          \"analyzer\" : \"ik_max_word\",\r\n          \"search_analyzer\" : \"ik_smart\"\r\n        },\r\n        \"originalPrice\" : {\r\n          \"type\" : \"scaled_float\",\r\n          \"scaling_factor\" : 100.0\r\n        },\r\n        \"pic\" : {\r\n          \"type\" : \"text\",\r\n          \"index\" : false\r\n        },\r\n        \"price\" : {\r\n          \"type\" : \"scaled_float\",\r\n          \"scaling_factor\" : 100.0\r\n        },\r\n        \"remark\" : {\r\n          \"type\" : \"text\",\r\n          \"index\" : false\r\n        },\r\n        \"st\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"stName\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"status\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"tags\" : {\r\n          \"type\" : \"text\",\r\n          \"analyzer\" : \"ik_max_word\",\r\n          \"search_analyzer\" : \"ik_smart\"\r\n        },\r\n        \"teachmode\" : {\r\n          \"type\" : \"keyword\"\r\n        },\r\n        \"users\" : {\r\n          \"type\" : \"text\",\r\n          \"index\" : false\r\n        },\r\n        \"validDays\" : {\r\n          \"type\" : \"integer\"\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n```\r\n\r\n3、删除索引\r\n\r\n如果发现创建的course-publish不正确可以删除重新创建。\r\n\r\n删除索引后当中的文档数据也同时删除，一定要谨慎操作！\r\n\r\n删除索引命令：DELETE /course-publish\r\n\r\n##### **3.6.2.2 部署搜索工程**\r\n\r\n拷贝课程资料中的xuecheng-plus-search搜索工程到自己的工程目录。\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps30.jpg) \r\n\r\n修改bootstrap.xml中nacos的namespace为自己的命名空间。\r\n\r\n启动网关、搜索服务。\r\n\r\n部署完成通过httpclient进行测试\r\n\r\n```http\r\nJava\r\n### 添加课程索引\r\nPOST {{search_host}}/search/index/course\r\nContent-Type: application/json\r\n\r\n{\r\n  \"charge\" : \"201000\",\r\n  \"companyId\" : 100000,\r\n  \"companyName\" : \"北京黑马程序\",\r\n  \"createDate\" : \"2022-09-25 09:36:11\",\r\n  \"description\" : \"《Spring编程思想》是2007年6月1日机械工业出版社出版的图书，作者是埃克尔，译者是陈昊鹏。主要内容本书赢得了全球程序员的广泛赞誉，即使是最晦涩的概念，在Bruce Eckel的文字亲和力和小而直接的编程示例面前也会化解于无形。从Java的基础语法到最高级特性（深入的面向对象概念、多线程、自动项目构建、单元测试和调试等），本书都能逐步指导你轻松掌握。从本书获得的各项大奖以及来自世界各地的读者评论中，不难看出这是一本经典之作\",\r\n  \"grade\" : \"204001\",\r\n  \"id\" : 102,\r\n  \"mt\" : \"1-3\",\r\n  \"mtName\" : \"编程开发\",\r\n  \"name\" : \"Spring编程思想\",\r\n  \"originalPrice\" : 200.0,\r\n  \"pic\" : \"/mediafiles/2022/09/20/1d0f0e6ed8a0c4a89bfd304b84599d9c.png\",\r\n  \"price\" : 100.0,\r\n  \"remark\" : \"没有备注\",\r\n  \"st\" : \"1-3-2\",\r\n  \"stName\" : \"Java语言\",\r\n  \"status\" : \"203002\",\r\n  \"tags\" : \"没有标签\",\r\n  \"teachmode\" : \"200002\",\r\n  \"validDays\" : 222\r\n}\r\n```\r\n\r\n```http\r\n### 搜索课程\r\nGET {{search_host}}/search/course/list?pageNo=1&keywords=spring\r\nContent-Type: application/json\r\n```\r\n\r\n进入前端搜索界面http://www.51xuecheng.cn/course/search.html\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps31.jpg) \r\n\r\n \r\n\r\n#### **3.6.3 课程信息索引同步**\r\n\r\n##### **3.6.3.1 技术方案**\r\n\r\n通过向索引中添加课程信息最终实现了课程的搜索，我们发现课程信息是先保存在关系数据库中，而后再写入索引，这个过程是将关系数据中的数据同步到elasticsearch索引中的过程，可以简单成为索引同步。\r\n\r\n通常项目中使用elasticsearch需要完成索引同步，索引同步的方法很多：\r\n\r\n1、针对实时性非常高的场景需要满足数据的及时同步，可以同步调用，或使用Canal去实现。\r\n\r\n1）同步调用即在向MySQL写数据后远程调用搜索服务的接口写入索引，此方法简单但是耦合代码太高。\r\n\r\n2）可以使用一个中间的软件canal解决耦合性的问题，但存在学习与维护成本。\r\n\r\ncanal主要用途是基于 MySQL 数据库增量日志解析，并能提供增量数据订阅和消费，实现将MySQL的数据同步到消息队列、Elasticsearch、其它数据库等，应用场景十分丰富。 \r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps32.jpg) \r\n\r\n它的地址：\r\n\r\ngithub地址：https://github.com/alibaba/canal \r\n\r\n版本下载地址：https://github.com/alibaba/canal/releases \r\n\r\n文档地址：https://github.com/alibaba/canal/wiki/Docker-QuickStart \r\n\r\n \r\n\r\nCanal基于mysql的binlog技术实现数据同步，什么是binlog，它是一个文件，二进制格式，记录了对数据库更新的SQL语句，向数据库写数据的同时向binlog文件里记录对应的sql语句。当数据库服务器发生了故障就可以使用binlog文件对数据库进行恢复。\r\n\r\n所以，使用canal是需要开启mysql的binlog写入功能，Canal工作原理如下：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps33.jpg) \r\n\r\n1、canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump \r\n\r\n协议 \r\n\r\n2、MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal ) \r\n\r\n3、canal 解析 binary log 对象(原始为 byte 流)\r\n\r\n详细使用Canal进行索引同步的步骤参考：Canal实现索引同步.pdf\r\n\r\n \r\n\r\n2、当索引同步的实时性要求不高时可用的技术比较多，比如：MQ、Logstash、任务调度等。\r\n\r\nMQ：向mysql写数据的时候向mq写入消息，搜索服务监听MQ，收到消息后写入索引。使用MQ的优势是代码解耦，但是需要处理消息可靠性的问题有一定的技术成本，做到消息可靠性需要做到生产者投递成功、消息持久化以及消费者消费成功三个方面，另外还要做好消息幂等性问题。\r\n\r\nLogstash： 开源实时日志分析平台 ELK包括Elasticsearch、Kibana、Logstash，Logstash负责收集、解析和转换日志信息，可以实现MySQL与Elasticsearch之间的数据同步。也可以实现解耦合并且是官方推荐，但需要增加学习与维护成本。\r\n\r\n任务调度：向mysql写数据的时候记录修改记录，开启一个定时任务根据修改记录将数据同步到Elasticsearch。\r\n\r\n \r\n\r\n根据本项目的需求，课程发布后信息同步的实时性要求不高，从提交审核到发布成功一般两个工作日完成。综合比较以上技术方案本项目的索引同步技术使用任务调度的方法。\r\n\r\n如下图：\r\n\r\n![img](https://gcore.jsdelivr.net/gh/imLKlauS/blog-picture@main/blogs/wps34.jpg) \r\n\r\n1、课程发布向消息表插入记录。\r\n\r\n2、由任务调度程序通过消息处理SDK对消息记录进行处理。\r\n\r\n3、向elasticsearch索引中保存课程信息。\r\n\r\n如何向向elasticsearch索引中保存课程信息？\r\n\r\n执行流程如下：\r\n\r\n由内容管理服务远程调用搜索服务添加课程信息索引，搜索服务再请求elasticsearch向课程索引中添加文档。\r\n\r\n \r\n\r\n##### **3.6.3.2 课程索引任务开发**\r\n\r\n1、拷贝CourseIndex 模型类到内容管理model 工程的dto包下。\r\n\r\n2、在内容管理服务中添加FeignClient\r\n\r\n```java\r\n\r\n\r\n/**\r\n * @description 搜索服务远程接口\r\n */\r\n@FeignClient(value = \"search\",fallbackFactory = SearchServiceClientFallbackFactory.class)\r\npublic interface SearchServiceClient {\r\n\r\n @PostMapping(\"/search/index/course\")\r\n public Boolean add(@RequestBody CourseIndex courseIndex);\r\n}\r\n```\r\n\r\n定义SearchServiceClientFallbackFactory ：\r\n\r\n```java\r\n\r\n@Slf4j\r\n@Component\r\npublic class SearchServiceClientFallbackFactory implements FallbackFactory<SearchServiceClient> {\r\n    @Override\r\n    public SearchServiceClient create(Throwable throwable) {\r\n\r\n        return new SearchServiceClient() {\r\n\r\n            @Override\r\n            public Boolean add(CourseIndex courseIndex) {\r\n                throwable.printStackTrace();\r\n                log.debug(\"调用搜索发生熔断走降级方法,熔断异常:\", throwable.getMessage());\r\n\r\n                return false;\r\n            }\r\n        };\r\n    }\r\n}\r\n```\r\n\r\n3、编写课程索引任务执行方法\r\n\r\n完善CoursePublishTask类中的saveCourseIndex方法\r\n\r\n```java\r\n\r\n//保存课程索引信息\r\npublic void saveCourseIndex(MqMessage mqMessage,long courseId){\r\n    log.debug(\"保存课程索引信息,课程id:{}\",courseId);\r\n\r\n    //消息id\r\n    Long id = mqMessage.getId();\r\n    //消息处理的service\r\n    MqMessageService mqMessageService = this.getMqMessageService();\r\n    //消息幂等性处理\r\n    int stageTwo = mqMessageService.getStageTwo(id);\r\n    if(stageTwo > 0){\r\n        log.debug(\"课程索引已处理直接返回，课程id:{}\",courseId);\r\n        return ;\r\n    }\r\n\r\n    Boolean result = saveCourseIndex(courseId);\r\n    if(result){\r\n        //保存第一阶段状态\r\n        mqMessageService.completedStageTwo(id);\r\n    }\r\n}\r\n\r\nprivate Boolean saveCourseIndex(Long courseId) {\r\n\r\n    //取出课程发布信息\r\n    CoursePublish coursePublish = coursePublishMapper.selectById(courseId);\r\n    //拷贝至课程索引对象\r\n    CourseIndex courseIndex = new CourseIndex();\r\n    BeanUtils.copyProperties(coursePublish,courseIndex);\r\n    //远程调用搜索服务api添加课程信息到索引\r\n    Boolean add = searchServiceClient.add(courseIndex);\r\n    if(!add){\r\n        XueChengPlusException.cast(\"添加索引失败\");\r\n    }\r\n    return add;\r\n\r\n}\r\n```\r\n\r\n##### **3.6.3.3 测试**\r\n\r\n测试流程如下：\r\n\r\n1、启动elasticsearch、kibana。\r\n\r\n2、启动网关、内容管理、搜索服务、nginx。\r\n\r\n3、启动xxl-job调度中心。\r\n\r\n4、在任务调度中心开始课程发布任务。\r\n\r\n5、发布一门课程，页面提示操作成功，查看发布课程任务是否写到任务表。\r\n\r\n6、经过任务调度将课程信息写入索引。\r\n\r\n7、通过门户进入搜索页面，查看课程信息是否展示。"}]
